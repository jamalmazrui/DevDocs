The Python Library Reference



Release 3.13.2



Guido van Rossum and the Python development team



February 15, 2025



Python Software Foundation

Email: docs@python.org





CONTENTS




1 Introduction 3

1.1 Notes on availability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.1.1 WebAssembly platforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

1.1.2 Mobile platforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

2 Built-in Functions 7

3 Built-in Constants 35

3.1 Constants added by the site module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

4 Built-in Types 37

4.1 Truth Value Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

4.2 Boolean Operations — and, or, not . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

4.3 Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

4.4 Numeric Types — int, float, complex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

4.4.1 Bitwise Operations on Integer Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

4.4.2 Additional Methods on Integer Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

4.4.3 Additional Methods on Float . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

4.4.4 Hashing of numeric types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

4.5 Boolean Type -bool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

4.6 Iterator Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45

4.6.1 Generator Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

4.7 Sequence Types — list, tuple, range . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

4.7.1 Common Sequence Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

4.7.2 Immutable Sequence Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

4.7.3 Mutable Sequence Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

4.7.4 Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

4.7.5 Tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

4.7.6 Ranges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

4.8 Text Sequence Type — str . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51

4.8.1 String Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52

4.8.2 printf-style String Formatting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

4.9 Binary Sequence Types — bytes, bytearray, memoryview . . . . . . . . . . . . . . . . . . . 63

4.9.1 Bytes Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63

4.9.2 Bytearray Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64

4.9.3 Bytes and Bytearray Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65

4.9.4 printf-style Bytes Formatting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

4.9.5 Memory Views . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78

4.10 Set Types — set, frozenset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85

4.11 Mapping Types — dict . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87

4.11.1 Dictionary view objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91

4.12 Context Manager Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92

4.13 Type Annotation Types — Generic Alias, Union . . . . . . . . . . . . . . . . . . . . . . . . . . . 93

4.13.1 Generic Alias Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93

4.13.2 Union Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97



4.14 Other Built-in Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

4.14.1 Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

4.14.2 Classes and Class Instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

4.14.3 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

4.14.4 Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99

4.14.5 Code Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

4.14.6 Type Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

4.14.7 The Null Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

4.14.8 The Ellipsis Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

4.14.9 The NotImplemented Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100

4.14.10 Internal Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101

4.15 Special Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101

4.16 Integer string conversion length limitation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101

4.16.1 Affected APIs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102

4.16.2 Configuring the limit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102

4.16.3 Recommended configuration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103

5 Built-in Exceptions 105

5.1 Exception context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105

5.2 Inheriting from built-in exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106

5.3 Base classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106

5.4 Concrete exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107

5.4.1 OS exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112

5.5 Warnings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113

5.6 Exception groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114

5.7 Exception hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116

6 Text Processing Services 119

6.1 string — Common string operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119

6.1.1 String constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119

6.1.2 Custom String Formatting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120

6.1.3 Format String Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121

6.1.4 Template strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128

6.1.5 Helper functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130

6.2 re — Regular expression operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130

6.2.1 Regular Expression Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131

6.2.2 Module Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137

6.2.3 Regular Expression Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143

6.2.4 Match Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145

6.2.5 Regular Expression Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148

6.3 difflib — Helpers for computing deltas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153

6.3.1 SequenceMatcher Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157

6.3.2 SequenceMatcher Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160

6.3.3 Differ Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161

6.3.4 Differ Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161

6.3.5 A command-line interface to difflib . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162

6.3.6 ndiff example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163

6.4 textwrap — Text wrapping and filling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165

6.5 unicodedata — Unicode Database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169

6.6 stringprep — Internet String Preparation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171

6.7 readline — GNU readline interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172

6.7.1 Init file . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173

6.7.2 Line buffer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173

6.7.3 History file . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173

6.7.4 History list . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174

6.7.5 Startup hooks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174

6.7.6 Completion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175

6.7.7 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175



6.8 rlcompleter — Completion function for GNU readline . . . . . . . . . . . . . . . . . . . . . . 177

7 Binary Data Services 179

7.1 struct — Interpret bytes as packed binary data . . . . . . . . . . . . . . . . . . . . . . . . . . 179

7.1.1 Functions and Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179

7.1.2 Format Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180

7.1.3 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184

7.1.4 Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185

7.2 codecs — Codec registry and base classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186

7.2.1 Codec Base Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189

7.2.2 Encodings and Unicode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195

7.2.3 Standard Encodings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197

7.2.4 Python Specific Encodings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199

7.2.5 encodings.idna — Internationalized Domain Names in Applications . . . . . . . . . . 201

7.2.6 encodings.mbcs — Windows ANSI codepage . . . . . . . . . . . . . . . . . . . . . . 202

7.2.7 encodings.utf_8_sig — UTF-8 codec with BOM signature . . . . . . . . . . . . . . 202

8 Data Types 203

8.1 datetime — Basic date and time types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203

8.1.1 Aware and Naive Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203

8.1.2 Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204

8.1.3 Available Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204

8.1.4 timedelta Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205

8.1.5 date Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208

8.1.6 datetime Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213

8.1.7 time Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225

8.1.8 tzinfo Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228

8.1.9 timezone Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235

8.1.10 strftime() and strptime() Behavior . . . . . . . . . . . . . . . . . . . . . . . . . 236

8.2 zoneinfo — IANA time zone support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240

8.2.1 Using ZoneInfo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240

8.2.2 Data sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241

8.2.3 The ZoneInfo class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242

8.2.4 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244

8.2.5 Globals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244

8.2.6 Exceptions and warnings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245

8.3 calendar — General calendar-related functions . . . . . . . . . . . . . . . . . . . . . . . . . . 245

8.3.1 Command-Line Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251

8.4 collections — Container datatypes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253

8.4.1 ChainMap objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253

8.4.2 Counter objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255

8.4.3 deque objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259

8.4.4 defaultdict objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262

8.4.5 namedtuple() Factory Function for Tuples with Named Fields . . . . . . . . . . . . . 264

8.4.6 OrderedDict objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267

8.4.7 UserDict objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269

8.4.8 UserList objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270

8.4.9 UserString objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270

8.5 collections.abc — Abstract Base Classes for Containers . . . . . . . . . . . . . . . . . . . . 270

8.5.1 Collections Abstract Base Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272

8.5.2 Collections Abstract Base Classes – Detailed Descriptions . . . . . . . . . . . . . . . . . 273

8.5.3 Examples and Recipes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275

8.6 heapq — Heap queue algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276

8.6.1 Basic Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277

8.6.2 Priority Queue Implementation Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277

8.6.3 Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278

8.7 bisect — Array bisection algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279

8.7.1 Performance Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281



8.7.2 Searching Sorted Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281

8.7.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282

8.8 array — Efficient arrays of numeric values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283

8.9 weakref — Weak references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286

8.9.1 Weak Reference Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290

8.9.2 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291

8.9.3 Finalizer Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291

8.9.4 Comparing finalizers with __del__() methods . . . . . . . . . . . . . . . . . . . . . . 292

8.10 types — Dynamic type creation and names for built-in types . . . . . . . . . . . . . . . . . . . . 293

8.10.1 Dynamic Type Creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294

8.10.2 Standard Interpreter Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295

8.10.3 Additional Utility Classes and Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 299

8.10.4 Coroutine Utility Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299

8.11 copy — Shallow and deep copy operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300

8.12 pprint — Data pretty printer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301

8.12.1 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301

8.12.2 PrettyPrinter Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302

8.12.3 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304

8.13 reprlib — Alternate repr() implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . 307

8.13.1 Repr Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308

8.13.2 Subclassing Repr Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309

8.14 enum — Support for enumerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310

8.14.1 Module Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311

8.14.2 Data Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312

8.14.3 Utilities and Decorators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323

8.14.4 Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325

8.15 graphlib — Functionality to operate with graph-like structures . . . . . . . . . . . . . . . . . . 325

8.15.1 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327

9 Numeric and Mathematical Modules 329

9.1 numbers — Numeric abstract base classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329

9.1.1 The numeric tower . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329

9.1.2 Notes for type implementers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330

9.2 math — Mathematical functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332

9.2.1 Number-theoretic functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333

9.2.2 Floating point arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334

9.2.3 Floating point manipulation functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335

9.2.4 Power, exponential and logarithmic functions . . . . . . . . . . . . . . . . . . . . . . . . 337

9.2.5 Summation and product functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338

9.2.6 Angular conversion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339

9.2.7 Trigonometric functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339

9.2.8 Hyperbolic functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339

9.2.9 Special functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 340

9.2.10 Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 340

9.3 cmath — Mathematical functions for complex numbers . . . . . . . . . . . . . . . . . . . . . . . 341

9.3.1 Conversions to and from polar coordinates . . . . . . . . . . . . . . . . . . . . . . . . . 342

9.3.2 Power and logarithmic functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342

9.3.3 Trigonometric functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343

9.3.4 Hyperbolic functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343

9.3.5 Classification functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343

9.3.6 Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344

9.4 decimal — Decimal fixed-point and floating-point arithmetic . . . . . . . . . . . . . . . . . . . 345

9.4.1 Quick-start Tutorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346

9.4.2 Decimal objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349

9.4.3 Context objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357

9.4.4 Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363

9.4.5 Rounding modes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363

9.4.6 Signals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364



9.4.7 Floating-Point Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365

9.4.8 Working with threads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367

9.4.9 Recipes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367

9.4.10 Decimal FAQ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370

9.5 fractions — Rational numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373

9.6 random — Generate pseudo-random numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377

9.6.1 Bookkeeping functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377

9.6.2 Functions for bytes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378

9.6.3 Functions for integers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378

9.6.4 Functions for sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378

9.6.5 Discrete distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 380

9.6.6 Real-valued distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 380

9.6.7 Alternative Generator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381

9.6.8 Notes on Reproducibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382

9.6.9 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382

9.6.10 Recipes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384

9.6.11 Command-line usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385

9.6.12 Command-line example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386

9.7 statistics — Mathematical statistics functions . . . . . . . . . . . . . . . . . . . . . . . . . . 386

9.7.1 Averages and measures of central location . . . . . . . . . . . . . . . . . . . . . . . . . 387

9.7.2 Measures of spread . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387

9.7.3 Statistics for relations between two inputs . . . . . . . . . . . . . . . . . . . . . . . . . . 388

9.7.4 Function details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 388

9.7.5 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397

9.7.6 NormalDist objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397

9.7.7 Examples and Recipes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399

10 Functional Programming Modules 403

10.1 itertools — Functions creating iterators for efficient looping . . . . . . . . . . . . . . . . . . . 403

10.1.1 Itertool Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405

10.1.2 Itertools Recipes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 415

10.2 functools — Higher-order functions and operations on callable objects . . . . . . . . . . . . . . 420

10.2.1 partial Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430

10.3 operator — Standard operators as functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431

10.3.1 Mapping Operators to Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435

10.3.2 In-place Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436

11 File and Directory Access 439

11.1 pathlib — Object-oriented filesystem paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439

11.1.1 Basic use . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440

11.1.2 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441

11.1.3 Pure paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441

11.1.4 Concrete paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 450

11.1.5 Pattern language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 461

11.1.6 Comparison to the glob module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 462

11.1.7 Comparison to the os and os.path modules . . . . . . . . . . . . . . . . . . . . . . . . 462

11.2 os.path — Common pathname manipulations . . . . . . . . . . . . . . . . . . . . . . . . . . . 464

11.3 stat — Interpreting stat() results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470

11.4 filecmp — File and Directory Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . 476

11.4.1 The dircmp class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 477

11.5 tempfile — Generate temporary files and directories . . . . . . . . . . . . . . . . . . . . . . . 478

11.5.1 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 482

11.5.2 Deprecated functions and variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 483

11.6 glob — Unix style pathname pattern expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . 484

11.6.1 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 485

11.7 fnmatch — Unix filename pattern matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . 486

11.8 linecache — Random access to text lines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 487

11.9 shutil — High-level file operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 488



11.9.1 Directory and files operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 488

11.9.2 Archiving operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 494

11.9.3 Querying the size of the output terminal . . . . . . . . . . . . . . . . . . . . . . . . . . 498

12 Data Persistence 499

12.1 pickle — Python object serialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499

12.1.1 Relationship to other Python modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499

12.1.2 Data stream format . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 500

12.1.3 Module Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 501

12.1.4 What can be pickled and unpickled? . . . . . . . . . . . . . . . . . . . . . . . . . . . . 504

12.1.5 Pickling Class Instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 505

12.1.6 Custom Reduction for Types, Functions, and Other Objects . . . . . . . . . . . . . . . . 511

12.1.7 Out-of-band Buffers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 511

12.1.8 Restricting Globals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 513

12.1.9 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 514

12.1.10 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 514

12.2 copyreg — Register pickle support functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 515

12.2.1 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 515

12.3 shelve — Python object persistence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 516

12.3.1 Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 517

12.3.2 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 518

12.4 marshal — Internal Python object serialization . . . . . . . . . . . . . . . . . . . . . . . . . . . 518

12.5 dbm — Interfaces to Unix “databases” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 520

12.5.1 dbm.sqlite3 — SQLite backend for dbm . . . . . . . . . . . . . . . . . . . . . . . . 522

12.5.2 dbm.gnu — GNU database manager . . . . . . . . . . . . . . . . . . . . . . . . . . . . 522

12.5.3 dbm.ndbm — New Database Manager . . . . . . . . . . . . . . . . . . . . . . . . . . . 524

12.5.4 dbm.dumb — Portable DBM implementation . . . . . . . . . . . . . . . . . . . . . . . 525

12.6 sqlite3 — DB-API 2.0 interface for SQLite databases . . . . . . . . . . . . . . . . . . . . . . 526

12.6.1 Tutorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 526

12.6.2 Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 528

12.6.3 How-to guides . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 549

12.6.4 Explanation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 556

13 Data Compression and Archiving 559

13.1 zlib — Compression compatible with gzip . . . . . . . . . . . . . . . . . . . . . . . . . . . . 559

13.2 gzip — Support for gzip files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 562

13.2.1 Examples of usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 565

13.2.2 Command Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 565

13.3 bz2 — Support for bzip2 compression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 566

13.3.1 (De)compression of files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 566

13.3.2 Incremental (de)compression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 568

13.3.3 One-shot (de)compression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 569

13.3.4 Examples of usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 569

13.4 lzma — Compression using the LZMA algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 570

13.4.1 Reading and writing compressed files . . . . . . . . . . . . . . . . . . . . . . . . . . . . 571

13.4.2 Compressing and decompressing data in memory . . . . . . . . . . . . . . . . . . . . . . 572

13.4.3 Miscellaneous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 574

13.4.4 Specifying custom filter chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 574

13.4.5 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 575

13.5 zipfile — Work with ZIP archives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 576

13.5.1 ZipFile Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 577

13.5.2 Path Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 582

13.5.3 PyZipFile Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 583

13.5.4 ZipInfo Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 584

13.5.5 Command-Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 586

13.5.6 Decompression pitfalls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 586

13.6 tarfile — Read and write tar archive files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 587

13.6.1 TarFile Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 591



13.6.2 TarInfo Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 594

13.6.3 Extraction filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 597

13.6.4 Command-Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 600

13.6.5 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 601

13.6.6 Supported tar formats . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602

13.6.7 Unicode issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602

14 File Formats 605

14.1 csv — CSV File Reading and Writing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605

14.1.1 Module Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605

14.1.2 Dialects and Formatting Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609

14.1.3 Reader Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 610

14.1.4 Writer Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 610

14.1.5 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 611

14.2 configparser — Configuration file parser . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 612

14.2.1 Quick Start . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 613

14.2.2 Supported Datatypes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 614

14.2.3 Fallback Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 615

14.2.4 Supported INI File Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 615

14.2.5 Unnamed Sections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 617

14.2.6 Interpolation of values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 617

14.2.7 Mapping Protocol Access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 618

14.2.8 Customizing Parser Behaviour . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 619

14.2.9 Legacy API Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 623

14.2.10 ConfigParser Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 625

14.2.11 RawConfigParser Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 629

14.2.12 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 630

14.3 tomllib — Parse TOML files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 630

14.3.1 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 631

14.3.2 Conversion Table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 632

14.4 netrc — netrc file processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 632

14.4.1 netrc Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 633

14.5 plistlib — Generate and parse Apple .plist files . . . . . . . . . . . . . . . . . . . . . . . . 633

14.5.1 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 635

15 Cryptographic Services 637

15.1 hashlib — Secure hashes and message digests . . . . . . . . . . . . . . . . . . . . . . . . . . . 637

15.1.1 Hash algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 637

15.1.2 Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 638

15.1.3 Constructors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 638

15.1.4 Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 639

15.1.5 Hash Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 639

15.1.6 SHAKE variable length digests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 640

15.1.7 File hashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 640

15.1.8 Key derivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 641

15.1.9 BLAKE2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 641

15.2 hmac — Keyed-Hashing for Message Authentication . . . . . . . . . . . . . . . . . . . . . . . . 648

15.3 secrets — Generate secure random numbers for managing secrets . . . . . . . . . . . . . . . . 650

15.3.1 Random numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 650

15.3.2 Generating tokens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 650

15.3.3 Other functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 651

15.3.4 Recipes and best practices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 651

16 Generic Operating System Services 653

16.1 os — Miscellaneous operating system interfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . 653

16.1.1 File Names, Command Line Arguments, and Environment Variables . . . . . . . . . . . 654

16.1.2 Python UTF-8 Mode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 654

16.1.3 Process Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 655

16.1.4 File Object Creation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 662



16.1.5 File Descriptor Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 662

16.1.6 Files and Directories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 675

16.1.7 Process Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 701

16.1.8 Interface to the scheduler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 714

16.1.9 Miscellaneous System Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 716

16.1.10 Random numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 717

16.2 io — Core tools for working with streams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 719

16.2.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 719

16.2.2 Text Encoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 720

16.2.3 High-level Module Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 720

16.2.4 Class hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 721

16.2.5 Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 731

16.3 time — Time access and conversions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 732

16.3.1 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 733

16.3.2 Clock ID Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 742

16.3.3 Timezone Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 744

16.4 logging — Logging facility for Python . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 744

16.4.1 Logger Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 746

16.4.2 Logging Levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 750

16.4.3 Handler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 751

16.4.4 Formatter Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 753

16.4.5 Filter Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 754

16.4.6 LogRecord Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 755

16.4.7 LogRecord attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 756

16.4.8 LoggerAdapter Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 758

16.4.9 Thread Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 758

16.4.10 Module-Level Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 758

16.4.11 Module-Level Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 762

16.4.12 Integration with the warnings module . . . . . . . . . . . . . . . . . . . . . . . . . . . . 763

16.5 logging.config — Logging configuration . . . . . . . . . . . . . . . . . . . . . . . . . . . . 763

16.5.1 Configuration functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 764

16.5.2 Security considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 766

16.5.3 Configuration dictionary schema . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 766

16.5.4 Configuration file format . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 773

16.6 logging.handlers — Logging handlers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 775

16.6.1 StreamHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 776

16.6.2 FileHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 776

16.6.3 NullHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 777

16.6.4 WatchedFileHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 777

16.6.5 BaseRotatingHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 778

16.6.6 RotatingFileHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 779

16.6.7 TimedRotatingFileHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 779

16.6.8 SocketHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 781

16.6.9 DatagramHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 782

16.6.10 SysLogHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 782

16.6.11 NTEventLogHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 784

16.6.12 SMTPHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 785

16.6.13 MemoryHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 785

16.6.14 HTTPHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 786

16.6.15 QueueHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 787

16.6.16 QueueListener . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 788

16.7 platform — Access to underlying platform’s identifying data . . . . . . . . . . . . . . . . . . . 789

16.7.1 Cross Platform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 789

16.7.2 Java Platform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 791

16.7.3 Windows Platform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 791

16.7.4 macOS Platform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 792

16.7.5 iOS Platform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 792

16.7.6 Unix Platforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 792



16.7.7 Linux Platforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 792

16.7.8 Android Platform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 793

16.8 errno — Standard errno system symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 793

16.9 ctypes — A foreign function library for Python . . . . . . . . . . . . . . . . . . . . . . . . . . 801

16.9.1 ctypes tutorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 801

16.9.2 ctypes reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 819

17 Command Line Interface Libraries 835

17.1 argparse — Parser for command-line options, arguments and subcommands . . . . . . . . . . . 835

17.1.1 ArgumentParser objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 836

17.1.2 The add_argument() method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 843

17.1.3 The parse_args() method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 853

17.1.4 Other utilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 856

17.1.5 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 865

17.2 optparse — Parser for command line options . . . . . . . . . . . . . . . . . . . . . . . . . . . 879

17.2.1 Choosing an argument parsing library . . . . . . . . . . . . . . . . . . . . . . . . . . . . 879

17.2.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 880

17.2.3 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 881

17.2.4 Tutorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 883

17.2.5 Reference Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 890

17.2.6 Option Callbacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 899

17.2.7 Extending optparse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 903

17.2.8 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 906

17.3 getpass — Portable password input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 906

17.4 fileinput — Iterate over lines from multiple input streams . . . . . . . . . . . . . . . . . . . . 907

17.5 curses — Terminal handling for character-cell displays . . . . . . . . . . . . . . . . . . . . . . 909

17.5.1 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 910

17.5.2 Window Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 916

17.5.3 Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 923

17.6 curses.textpad — Text input widget for curses programs . . . . . . . . . . . . . . . . . . . . 934

17.6.1 Textbox objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 934

17.7 curses.ascii — Utilities for ASCII characters . . . . . . . . . . . . . . . . . . . . . . . . . . 935

17.8 curses.panel — A panel stack extension for curses . . . . . . . . . . . . . . . . . . . . . . . . 939

17.8.1 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 939

17.8.2 Panel Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 939

18 Concurrent Execution 941

18.1 threading — Thread-based parallelism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 941

18.1.1 Thread-Local Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 944

18.1.2 Thread Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 944

18.1.3 Lock Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 947

18.1.4 RLock Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 948

18.1.5 Condition Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 949

18.1.6 Semaphore Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 951

18.1.7 Event Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 952

18.1.8 Timer Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 953

18.1.9 Barrier Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 953

18.1.10 Using locks, conditions, and semaphores in the with statement . . . . . . . . . . . . . . 954

18.2 multiprocessing — Process-based parallelism . . . . . . . . . . . . . . . . . . . . . . . . . . 955

18.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 955

18.2.2 Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 962

18.2.3 Programming guidelines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 990

18.2.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 993

18.3 multiprocessing.shared_memory — Shared memory for direct access across processes . . . 999

18.4 The concurrent package . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1005

18.5 concurrent.futures — Launching parallel tasks . . . . . . . . . . . . . . . . . . . . . . . . 1005

18.5.1 Executor Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1005

18.5.2 ThreadPoolExecutor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1006



18.5.3 ProcessPoolExecutor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1008

18.5.4 Future Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1010

18.5.5 Module Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1011

18.5.6 Exception classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1012

18.6 subprocess — Subprocess management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1012

18.6.1 Using the subprocess Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1012

18.6.2 Security Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1021

18.6.3 Popen Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1021

18.6.4 Windows Popen Helpers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1023

18.6.5 Older high-level API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1026

18.6.6 Replacing Older Functions with the subprocess Module . . . . . . . . . . . . . . . . . 1027

18.6.7 Legacy Shell Invocation Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1030

18.6.8 Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1031

18.7 sched — Event scheduler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1032

18.7.1 Scheduler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1033

18.8 queue — A synchronized queue class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1034

18.8.1 Queue Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1035

18.8.2 SimpleQueue Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1036

18.9 contextvars — Context Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1037

18.9.1 Context Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1037

18.9.2 Manual Context Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1038

18.9.3 asyncio support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1040

18.10 _thread — Low-level threading API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1041

19 Networking and Interprocess Communication 1045

19.1 asyncio — Asynchronous I/O . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1045

19.1.1 Runners . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1046

19.1.2 Coroutines and Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1048

19.1.3 Streams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1067

19.1.4 Synchronization Primitives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1075

19.1.5 Subprocesses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1080

19.1.6 Queues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1085

19.1.7 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1088

19.1.8 Event Loop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1089

19.1.9 Futures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1112

19.1.10 Transports and Protocols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1115

19.1.11 Policies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1129

19.1.12 Platform Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1132

19.1.13 Extending . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1134

19.1.14 High-level API Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1135

19.1.15 Low-level API Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1137

19.1.16 Developing with asyncio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1141

19.2 socket — Low-level networking interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1144

19.2.1 Socket families . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1145

19.2.2 Module contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1148

19.2.3 Socket Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1161

19.2.4 Notes on socket timeouts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1168

19.2.5 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1168

19.3 ssl — TLS/SSL wrapper for socket objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1172

19.3.1 Functions, Constants, and Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1173

19.3.2 SSL Sockets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1184

19.3.3 SSL Contexts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1188

19.3.4 Certificates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1197

19.3.5 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1199

19.3.6 Notes on non-blocking sockets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1202

19.3.7 Memory BIO Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1203

19.3.8 SSL session . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1205

19.3.9 Security considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1205



19.3.10 TLS 1.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1206

19.4 select — Waiting for I/O completion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1207

19.4.1 /dev/poll Polling Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1209

19.4.2 Edge and Level Trigger Polling (epoll) Objects . . . . . . . . . . . . . . . . . . . . . . . 1210

19.4.3 Polling Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1211

19.4.4 Kqueue Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1212

19.4.5 Kevent Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1212

19.5 selectors — High-level I/O multiplexing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1214

19.5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1214

19.5.2 Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1214

19.5.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1217

19.6 signal — Set handlers for asynchronous events . . . . . . . . . . . . . . . . . . . . . . . . . . 1217

19.6.1 General rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1217

19.6.2 Module contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1218

19.6.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1225

19.6.4 Note on SIGPIPE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1225

19.6.5 Note on Signal Handlers and Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . 1226

19.7 mmap — Memory-mapped file support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1227

19.7.1 MADV_* Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1231

19.7.2 MAP_* Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1231

20 Internet Data Handling 1233

20.1 email — An email and MIME handling package . . . . . . . . . . . . . . . . . . . . . . . . . . 1233

20.1.1 email.message: Representing an email message . . . . . . . . . . . . . . . . . . . . . 1234

20.1.2 email.parser: Parsing email messages . . . . . . . . . . . . . . . . . . . . . . . . . . 1242

20.1.3 email.generator: Generating MIME documents . . . . . . . . . . . . . . . . . . . . 1245

20.1.4 email.policy: Policy Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1248

20.1.5 email.errors: Exception and Defect classes . . . . . . . . . . . . . . . . . . . . . . . 1254

20.1.6 email.headerregistry: Custom Header Objects . . . . . . . . . . . . . . . . . . . . 1256

20.1.7 email.contentmanager: Managing MIME Content . . . . . . . . . . . . . . . . . . . 1261

20.1.8 email: Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1263

20.1.9 email.message.Message: Representing an email message using the compat32 API . 1270

20.1.10 email.mime: Creating email and MIME objects from scratch . . . . . . . . . . . . . . . 1278

20.1.11 email.header: Internationalized headers . . . . . . . . . . . . . . . . . . . . . . . . . 1281

20.1.12 email.charset: Representing character sets . . . . . . . . . . . . . . . . . . . . . . . 1283

20.1.13 email.encoders: Encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1285

20.1.14 email.utils: Miscellaneous utilities . . . . . . . . . . . . . . . . . . . . . . . . . . . 1286

20.1.15 email.iterators: Iterators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1288

20.2 json — JSON encoder and decoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1289

20.2.1 Basic Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1292

20.2.2 Encoders and Decoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1294

20.2.3 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1296

20.2.4 Standard Compliance and Interoperability . . . . . . . . . . . . . . . . . . . . . . . . . 1297

20.2.5 Command Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1298

20.3 mailbox — Manipulate mailboxes in various formats . . . . . . . . . . . . . . . . . . . . . . . . 1299

20.3.1 Mailbox objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1300

20.3.2 Message objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1309

20.3.3 Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1317

20.3.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1317

20.4 mimetypes — Map filenames to MIME types . . . . . . . . . . . . . . . . . . . . . . . . . . . 1318

20.4.1 MimeTypes Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1320

20.5 base64 — Base16, Base32, Base64, Base85 Data Encodings . . . . . . . . . . . . . . . . . . . . 1321

20.5.1 Security Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1325

20.6 binascii — Convert between binary and ASCII . . . . . . . . . . . . . . . . . . . . . . . . . . 1325

20.7 quopri — Encode and decode MIME quoted-printable data . . . . . . . . . . . . . . . . . . . . 1327

21 Structured Markup Processing Tools 1329

21.1 html — HyperText Markup Language support . . . . . . . . . . . . . . . . . . . . . . . . . . . 1329

21.2 html.parser — Simple HTML and XHTML parser . . . . . . . . . . . . . . . . . . . . . . . . 1329

21.2.1 Example HTML Parser Application . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1330

21.2.2 HTMLParser Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1330

21.2.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1332

21.3 html.entities — Definitions of HTML general entities . . . . . . . . . . . . . . . . . . . . . 1334

21.4 XML Processing Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1334

21.4.1 XML vulnerabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1335

21.4.2 The defusedxml Package . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1336

21.5 xml.etree.ElementTree — The ElementTree XML API . . . . . . . . . . . . . . . . . . . . 1336

21.5.1 Tutorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1336

21.5.2 XPath support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1341

21.5.3 Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1343

21.5.4 XInclude support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1346

21.5.5 Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1347

21.6 xml.dom — The Document Object Model API . . . . . . . . . . . . . . . . . . . . . . . . . . . 1355

21.6.1 Module Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1356

21.6.2 Objects in the DOM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1357

21.6.3 Conformance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1364

21.7 xml.dom.minidom — Minimal DOM implementation . . . . . . . . . . . . . . . . . . . . . . . 1365

21.7.1 DOM Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1367

21.7.2 DOM Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1368

21.7.3 minidom and the DOM standard . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1369

21.8 xml.dom.pulldom — Support for building partial DOM trees . . . . . . . . . . . . . . . . . . . 1369

21.8.1 DOMEventStream Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1371

21.9 xml.sax — Support for SAX2 parsers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1371

21.9.1 SAXException Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1373

21.10 xml.sax.handler — Base classes for SAX handlers . . . . . . . . . . . . . . . . . . . . . . . 1373

21.10.1 ContentHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1375

21.10.2 DTDHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1377

21.10.3 EntityResolver Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1377

21.10.4 ErrorHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1377

21.10.5 LexicalHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1378

21.11 xml.sax.saxutils — SAX Utilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1378

21.12 xml.sax.xmlreader — Interface for XML parsers . . . . . . . . . . . . . . . . . . . . . . . . 1379

21.12.1 XMLReader Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1380

21.12.2 IncrementalParser Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1381

21.12.3 Locator Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1382

21.12.4 InputSource Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1382

21.12.5 The Attributes Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1383

21.12.6 The AttributesNS Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1383

21.13 xml.parsers.expat — Fast XML parsing using Expat . . . . . . . . . . . . . . . . . . . . . . 1383

21.13.1 XMLParser Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1384

21.13.2 ExpatError Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1389

21.13.3 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1389

21.13.4 Content Model Descriptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1390

21.13.5 Expat error constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1390

22 Internet Protocols and Support 1395

22.1 webbrowser — Convenient web-browser controller . . . . . . . . . . . . . . . . . . . . . . . . 1395

22.1.1 Browser Controller Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1397

22.2 wsgiref — WSGI Utilities and Reference Implementation . . . . . . . . . . . . . . . . . . . . . 1398

22.2.1 wsgiref.util – WSGI environment utilities . . . . . . . . . . . . . . . . . . . . . . . 1398

22.2.2 wsgiref.headers – WSGI response header tools . . . . . . . . . . . . . . . . . . . . 1400

22.2.3 wsgiref.simple_server – a simple WSGI HTTP server . . . . . . . . . . . . . . . . 1401

22.2.4 wsgiref.validate — WSGI conformance checker . . . . . . . . . . . . . . . . . . . 1402

22.2.5 wsgiref.handlers – server/gateway base classes . . . . . . . . . . . . . . . . . . . . 1403

22.2.6 wsgiref.types – WSGI types for static type checking . . . . . . . . . . . . . . . . . . 1406

22.2.7 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1406



22.3 urllib — URL handling modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1408

22.4 urllib.request — Extensible library for opening URLs . . . . . . . . . . . . . . . . . . . . . 1408

22.4.1 Request Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1413

22.4.2 OpenerDirector Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1415

22.4.3 BaseHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1416

22.4.4 HTTPRedirectHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1417

22.4.5 HTTPCookieProcessor Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1418

22.4.6 ProxyHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1418

22.4.7 HTTPPasswordMgr Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1418

22.4.8 HTTPPasswordMgrWithPriorAuth Objects . . . . . . . . . . . . . . . . . . . . . . . . . 1418

22.4.9 AbstractBasicAuthHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1419

22.4.10 HTTPBasicAuthHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1419

22.4.11 ProxyBasicAuthHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1419

22.4.12 AbstractDigestAuthHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1419

22.4.13 HTTPDigestAuthHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1419

22.4.14 ProxyDigestAuthHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1419

22.4.15 HTTPHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1419

22.4.16 HTTPSHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1419

22.4.17 FileHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1419

22.4.18 DataHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1420

22.4.19 FTPHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1420

22.4.20 CacheFTPHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1420

22.4.21 UnknownHandler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1420

22.4.22 HTTPErrorProcessor Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1420

22.4.23 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1420

22.4.24 Legacy interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1423

22.4.25 urllib.request Restrictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1425

22.5 urllib.response — Response classes used by urllib . . . . . . . . . . . . . . . . . . . . . . . 1426

22.6 urllib.parse — Parse URLs into components . . . . . . . . . . . . . . . . . . . . . . . . . . 1426

22.6.1 URL Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1427

22.6.2 URL parsing security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1431

22.6.3 Parsing ASCII Encoded Bytes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1432

22.6.4 Structured Parse Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1432

22.6.5 URL Quoting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1433

22.7 urllib.error — Exception classes raised by urllib.request . . . . . . . . . . . . . . . . . . . . 1435

22.8 urllib.robotparser — Parser for robots.txt . . . . . . . . . . . . . . . . . . . . . . . . . . . 1436

22.9 http — HTTP modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1437

22.9.1 HTTP status codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1438

22.9.2 HTTP status category . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1439

22.9.3 HTTP methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1440

22.10 http.client — HTTP protocol client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1440

22.10.1 HTTPConnection Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1443

22.10.2 HTTPResponse Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1445

22.10.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1446

22.10.4 HTTPMessage Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1448

22.11 ftplib — FTP protocol client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1448

22.11.1 Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1448

22.12 poplib — POP3 protocol client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1454

22.12.1 POP3 Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1456

22.12.2 POP3 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1457

22.13 imaplib — IMAP4 protocol client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1457

22.13.1 IMAP4 Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1459

22.13.2 IMAP4 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1464

22.14 smtplib — SMTP protocol client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1464

22.14.1 SMTP Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1466

22.14.2 SMTP Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1470

22.15 uuid — UUID objects according to RFC 4122 . . . . . . . . . . . . . . . . . . . . . . . . . . . 1471

22.15.1 Command-Line Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1474



22.15.2 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1474

22.15.3 Command-Line Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1475

22.16 socketserver — A framework for network servers . . . . . . . . . . . . . . . . . . . . . . . . 1475

22.16.1 Server Creation Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1476

22.16.2 Server Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1477

22.16.3 Request Handler Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1479

22.16.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1480

22.17 http.server — HTTP servers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1483

22.17.1 Security Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1490

22.18 http.cookies — HTTP state management . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1490

22.18.1 Cookie Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1491

22.18.2 Morsel Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1491

22.18.3 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1492

22.19 http.cookiejar — Cookie handling for HTTP clients . . . . . . . . . . . . . . . . . . . . . . 1493

22.19.1 CookieJar and FileCookieJar Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1495

22.19.2 FileCookieJar subclasses and co-operation with web browsers . . . . . . . . . . . . . . . 1497

22.19.3 CookiePolicy Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1497

22.19.4 DefaultCookiePolicy Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1498

22.19.5 Cookie Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1500

22.19.6 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1501

22.20 xmlrpc — XMLRPC server and client modules . . . . . . . . . . . . . . . . . . . . . . . . . . . 1502

22.21 xmlrpc.client — XML-RPC client access . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1502

22.21.1 ServerProxy Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1504

22.21.2 DateTime Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1505

22.21.3 Binary Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1505

22.21.4 Fault Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1506

22.21.5 ProtocolError Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1507

22.21.6 MultiCall Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1507

22.21.7 Convenience Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1508

22.21.8 Example of Client Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1509

22.21.9 Example of Client and Server Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1509

22.22 xmlrpc.server — Basic XML-RPC servers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1510

22.22.1 SimpleXMLRPCServer Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1510

22.22.2 CGIXMLRPCRequestHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1514

22.22.3 Documenting XMLRPC server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1514

22.22.4 DocXMLRPCServer Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1515

22.22.5 DocCGIXMLRPCRequestHandler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1515

22.23 ipaddress — IPv4/IPv6 manipulation library . . . . . . . . . . . . . . . . . . . . . . . . . . . 1515

22.23.1 Convenience factory functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1516

22.23.2 IP Addresses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1516

22.23.3 IP Network definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1521

22.23.4 Interface objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1526

22.23.5 Other Module Level Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1528

22.23.6 Custom Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1529

23 Multimedia Services 1531

23.1 wave — Read and write WAV files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1531

23.1.1 Wave_read Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1531

23.1.2 Wave_write Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1532

23.2 colorsys — Conversions between color systems . . . . . . . . . . . . . . . . . . . . . . . . . . 1534

24 Internationalization 1535

24.1 gettext — Multilingual internationalization services . . . . . . . . . . . . . . . . . . . . . . . . 1535

24.1.1 GNU gettext API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1535

24.1.2 Class-based API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1536

24.1.3 Internationalizing your programs and modules . . . . . . . . . . . . . . . . . . . . . . . 1540

24.1.4 Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1542

24.2 locale — Internationalization services . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1543



24.2.1 Background, details, hints, tips and caveats . . . . . . . . . . . . . . . . . . . . . . . . . 1550

24.2.2 For extension writers and programs that embed Python . . . . . . . . . . . . . . . . . . . 1550

24.2.3 Access to message catalogs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1550

25 Program Frameworks 1551

25.1 turtle — Turtle graphics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1551

25.1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1551

25.1.2 Get started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1551

25.1.3 Tutorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1552

25.1.4 How to… . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1553

25.1.5 Turtle graphics reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1555

25.1.6 Methods of RawTurtle/Turtle and corresponding functions . . . . . . . . . . . . . . . . . 1557

25.1.7 Methods of TurtleScreen/Screen and corresponding functions . . . . . . . . . . . . . . . 1574

25.1.8 Public classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1581

25.1.9 Explanation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1582

25.1.10 Help and configuration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1583

25.1.11 turtledemo — Demo scripts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1585

25.1.12 Changes since Python 2.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1586

25.1.13 Changes since Python 3.0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1586

25.2 cmd — Support for line-oriented command interpreters . . . . . . . . . . . . . . . . . . . . . . . 1587

25.2.1 Cmd Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1587

25.2.2 Cmd Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1589

25.3 shlex — Simple lexical analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1592

25.3.1 shlex Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1593

25.3.2 Parsing Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1595

25.3.3 Improved Compatibility with Shells . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1596

26 Graphical User Interfaces with Tk 1599

26.1 tkinter — Python interface to Tcl/Tk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1599

26.1.1 Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1600

26.1.2 Tkinter Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1600

26.1.3 Tkinter Life Preserver . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1602

26.1.4 Threading model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1605

26.1.5 Handy Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1606

26.1.6 File Handlers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1611

26.2 tkinter.colorchooser — Color choosing dialog . . . . . . . . . . . . . . . . . . . . . . . . 1612

26.3 tkinter.font — Tkinter font wrapper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1612

26.4 Tkinter Dialogs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1613

26.4.1 tkinter.simpledialog — Standard Tkinter input dialogs . . . . . . . . . . . . . . . 1613

26.4.2 tkinter.filedialog — File selection dialogs . . . . . . . . . . . . . . . . . . . . . 1614

26.4.3 tkinter.commondialog — Dialog window templates . . . . . . . . . . . . . . . . . . 1616

26.5 tkinter.messagebox — Tkinter message prompts . . . . . . . . . . . . . . . . . . . . . . . . 1616

26.6 tkinter.scrolledtext — Scrolled Text Widget . . . . . . . . . . . . . . . . . . . . . . . . 1618

26.7 tkinter.dnd — Drag and drop support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1619

26.8 tkinter.ttk — Tk themed widgets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1620

26.8.1 Using Ttk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1620

26.8.2 Ttk Widgets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1620

26.8.3 Widget . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1621

26.8.4 Combobox . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1623

26.8.5 Spinbox . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1624

26.8.6 Notebook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1625

26.8.7 Progressbar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1627

26.8.8 Separator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1627

26.8.9 Sizegrip . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1628

26.8.10 Treeview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1628

26.8.11 Ttk Styling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1633

26.9 IDLE — Python editor and shell . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1638

26.9.1 Menus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1638



26.9.2 Editing and Navigation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1642

26.9.3 Startup and Code Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1645

26.9.4 Help and Preferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1648

26.9.5 idlelib — implementation of IDLE application . . . . . . . . . . . . . . . . . . . . . . . 1649

27 Development Tools 1651

27.1 typing — Support for type hints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1651

27.1.1 Specification for the Python Type System . . . . . . . . . . . . . . . . . . . . . . . . . . 1652

27.1.2 Type aliases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1652

27.1.3 NewType . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1652

27.1.4 Annotating callable objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1654

27.1.5 Generics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1655

27.1.6 Annotating tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1656

27.1.7 The type of class objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1657

27.1.8 Annotating generators and coroutines . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1657

27.1.9 User-defined generic types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1658

27.1.10 The Any type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1661

27.1.11 Nominal vs structural subtyping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1662

27.1.12 Module contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1663

27.1.13 Deprecation Timeline of Major Features . . . . . . . . . . . . . . . . . . . . . . . . . . 1703

27.2 pydoc — Documentation generator and online help system . . . . . . . . . . . . . . . . . . . . . 1703

27.3 Python Development Mode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1704

27.3.1 Effects of the Python Development Mode . . . . . . . . . . . . . . . . . . . . . . . . . . 1705

27.3.2 ResourceWarning Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1706

27.3.3 Bad file descriptor error example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1707

27.4 doctest — Test interactive Python examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1707

27.4.1 Simple Usage: Checking Examples in Docstrings . . . . . . . . . . . . . . . . . . . . . . 1709

27.4.2 Simple Usage: Checking Examples in a Text File . . . . . . . . . . . . . . . . . . . . . . 1710

27.4.3 How It Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1711

27.4.4 Basic API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1718

27.4.5 Unittest API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1720

27.4.6 Advanced API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1722

27.4.7 Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1726

27.4.8 Soapbox . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1729

27.5 unittest — Unit testing framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1730

27.5.1 Basic example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1731

27.5.2 Command-Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1732

27.5.3 Test Discovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1733

27.5.4 Organizing test code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1735

27.5.5 Re-using old test code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1736

27.5.6 Skipping tests and expected failures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1737

27.5.7 Distinguishing test iterations using subtests . . . . . . . . . . . . . . . . . . . . . . . . . 1739

27.5.8 Classes and functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1740

27.5.9 Class and Module Fixtures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1758

27.5.10 Signal Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1760

27.6 unittest.mock — mock object library . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1761

27.6.1 Quick Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1761

27.6.2 The Mock Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1763

27.6.3 The patchers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1780

27.6.4 MagicMock and magic method support . . . . . . . . . . . . . . . . . . . . . . . . . . . 1789

27.6.5 Helpers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1793

27.6.6 Order of precedence of side_effect, return_value and wraps . . . . . . . . . . . . 1800

27.7 unittest.mock — getting started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1802

27.7.1 Using Mock . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1802

27.7.2 Patch Decorators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1808

27.7.3 Further Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1810

27.8 test — Regression tests package for Python . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1822

27.8.1 Writing Unit Tests for the test package . . . . . . . . . . . . . . . . . . . . . . . . . . 1822



27.8.2 Running tests using the command-line interface . . . . . . . . . . . . . . . . . . . . . . 1824

27.9 test.support — Utilities for the Python test suite . . . . . . . . . . . . . . . . . . . . . . . . 1824

27.10 test.support.socket_helper — Utilities for socket tests . . . . . . . . . . . . . . . . . . . 1833

27.11 test.support.script_helper — Utilities for the Python execution tests . . . . . . . . . . . 1834

27.12 test.support.bytecode_helper — Support tools for testing correct bytecode generation . . 1835

27.13 test.support.threading_helper — Utilities for threading tests . . . . . . . . . . . . . . . 1836

27.14 test.support.os_helper — Utilities for os tests . . . . . . . . . . . . . . . . . . . . . . . . 1837

27.15 test.support.import_helper — Utilities for import tests . . . . . . . . . . . . . . . . . . . 1838

27.16 test.support.warnings_helper — Utilities for warnings tests . . . . . . . . . . . . . . . . 1840

28 Debugging and Profiling 1843

28.1 Audit events table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1843

28.2 bdb — Debugger framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1847

28.3 faulthandler — Dump the Python traceback . . . . . . . . . . . . . . . . . . . . . . . . . . . 1852

28.3.1 Dumping the traceback . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1852

28.3.2 Fault handler state . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1853

28.3.3 Dumping the tracebacks after a timeout . . . . . . . . . . . . . . . . . . . . . . . . . . . 1853

28.3.4 Dumping the traceback on a user signal . . . . . . . . . . . . . . . . . . . . . . . . . . . 1853

28.3.5 Issue with file descriptors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1853

28.3.6 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1854

28.4 pdb — The Python Debugger . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1854

28.4.1 Debugger Commands . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1857

28.5 The Python Profilers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1863

28.5.1 Introduction to the profilers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1863

28.5.2 Instant User’s Manual . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1863

28.5.3 profile and cProfile Module Reference . . . . . . . . . . . . . . . . . . . . . . . . 1865

28.5.4 The Stats Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1867

28.5.5 What Is Deterministic Profiling? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1869

28.5.6 Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1869

28.5.7 Calibration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1870

28.5.8 Using a custom timer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1870

28.6 timeit — Measure execution time of small code snippets . . . . . . . . . . . . . . . . . . . . . 1871

28.6.1 Basic Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1871

28.6.2 Python Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1871

28.6.3 Command-Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1873

28.6.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1874

28.7 trace — Trace or track Python statement execution . . . . . . . . . . . . . . . . . . . . . . . . 1876

28.7.1 Command-Line Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1876

28.7.2 Programmatic Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1877

28.8 tracemalloc — Trace memory allocations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1878

28.8.1 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1879

28.8.2 API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1883

29 Software Packaging and Distribution 1889

29.1 ensurepip — Bootstrapping the pip installer . . . . . . . . . . . . . . . . . . . . . . . . . . . 1889

29.1.1 Command line interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1889

29.1.2 Module API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1890

29.2 venv — Creation of virtual environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1891

29.2.1 Creating virtual environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1891

29.2.2 How venvs work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1893

29.2.3 API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1894

29.2.4 An example of extending EnvBuilder . . . . . . . . . . . . . . . . . . . . . . . . . . . 1897

29.3 zipapp — Manage executable Python zip archives . . . . . . . . . . . . . . . . . . . . . . . . . 1900

29.3.1 Basic Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1901

29.3.2 Command-Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1901

29.3.3 Python API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1901

29.3.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1902

29.3.5 Specifying the Interpreter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1903



29.3.6 Creating Standalone Applications with zipapp . . . . . . . . . . . . . . . . . . . . . . . 1903

29.3.7 The Python Zip Application Archive Format . . . . . . . . . . . . . . . . . . . . . . . . 1904

30 Python Runtime Services 1905

30.1 sys — System-specific parameters and functions . . . . . . . . . . . . . . . . . . . . . . . . . . 1905

30.2 sys.monitoring — Execution event monitoring . . . . . . . . . . . . . . . . . . . . . . . . . 1931

30.2.1 Tool identifiers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1931

30.2.2 Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1932

30.2.3 Turning events on and off . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1934

30.2.4 Registering callback functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1934

30.3 sysconfig — Provide access to Python’s configuration information . . . . . . . . . . . . . . . . 1935

30.3.1 Configuration variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1935

30.3.2 Installation paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1936

30.3.3 User scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1937

30.3.4 Home scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1937

30.3.5 Prefix scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1938

30.3.6 Installation path functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1939

30.3.7 Other functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1940

30.3.8 Using sysconfig as a script . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1941

30.4 builtins — Built-in objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1941

30.5 __main__ — Top-level code environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1942

30.5.1 __name__ == '__main__' . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1942

30.5.2 __main__.py in Python Packages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1944

30.5.3 import __main__ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1945

30.6 warnings — Warning control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1947

30.6.1 Warning Categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1947

30.6.2 The Warnings Filter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1948

30.6.3 Temporarily Suppressing Warnings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1950

30.6.4 Testing Warnings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1951

30.6.5 Updating Code For New Versions of Dependencies . . . . . . . . . . . . . . . . . . . . 1951

30.6.6 Available Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1951

30.6.7 Available Context Managers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1953

30.7 dataclasses — Data Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1954

30.7.1 Module contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1955

30.7.2 Post-init processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1961

30.7.3 Class variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1961

30.7.4 Init-only variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1961

30.7.5 Frozen instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1962

30.7.6 Inheritance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1962

30.7.7 Re-ordering of keyword-only parameters in __init__() . . . . . . . . . . . . . . . . . 1962

30.7.8 Default factory functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1963

30.7.9 Mutable default values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1963

30.7.10 Descriptor-typed fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1964

30.8 contextlib — Utilities for with-statement contexts . . . . . . . . . . . . . . . . . . . . . . . . 1965

30.8.1 Utilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1965

30.8.2 Examples and Recipes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1974

30.8.3 Single use, reusable and reentrant context managers . . . . . . . . . . . . . . . . . . . . 1977

30.9 abc — Abstract Base Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1979

30.10 atexit — Exit handlers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1984

30.10.1 atexit Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1985

30.11 traceback — Print or retrieve a stack traceback . . . . . . . . . . . . . . . . . . . . . . . . . . 1986

30.11.1 Module-Level Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1986

30.11.2 TracebackException Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1988

30.11.3 StackSummary Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1990

30.11.4 FrameSummary Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1991

30.11.5 Examples of Using the Module-Level Functions . . . . . . . . . . . . . . . . . . . . . . 1991

30.11.6 Examples of Using TracebackException . . . . . . . . . . . . . . . . . . . . . . . . 1994

30.12 __future__ — Future statement definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1995



30.12.1 Module Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1996

30.13 gc — Garbage Collector interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1997

30.14 inspect — Inspect live objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2000

30.14.1 Types and members . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2001

30.14.2 Retrieving source code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2005

30.14.3 Introspecting callables with the Signature object . . . . . . . . . . . . . . . . . . . . . . 2006

30.14.4 Classes and functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2011

30.14.5 The interpreter stack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2013

30.14.6 Fetching attributes statically . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2015

30.14.7 Current State of Generators, Coroutines, and Asynchronous Generators . . . . . . . . . . 2016

30.14.8 Code Objects Bit Flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2017

30.14.9 Buffer flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2018

30.14.10Command Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2019

30.15 site — Site-specific configuration hook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2019

30.15.1 sitecustomize . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2020

30.15.2 usercustomize . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2021

30.15.3 Readline configuration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2021

30.15.4 Module contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2021

30.15.5 Command Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2022

31 Custom Python Interpreters 2023

31.1 code — Interpreter base classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2023

31.1.1 Interactive Interpreter Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2024

31.1.2 Interactive Console Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2024

31.2 codeop — Compile Python code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2025

32 Importing Modules 2027

32.1 zipimport — Import modules from Zip archives . . . . . . . . . . . . . . . . . . . . . . . . . . 2027

32.1.1 zipimporter Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2028

32.1.2 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2029

32.2 pkgutil — Package extension utility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2029

32.3 modulefinder — Find modules used by a script . . . . . . . . . . . . . . . . . . . . . . . . . . 2032

32.3.1 Example usage of ModuleFinder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2032

32.4 runpy — Locating and executing Python modules . . . . . . . . . . . . . . . . . . . . . . . . . 2033

32.5 importlib — The implementation of import . . . . . . . . . . . . . . . . . . . . . . . . . . . 2036

32.5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2036

32.5.2 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2037

32.5.3 importlib.abc – Abstract base classes related to import . . . . . . . . . . . . . . . . . 2038

32.5.4 importlib.machinery – Importers and path hooks . . . . . . . . . . . . . . . . . . . 2045

32.5.5 importlib.util – Utility code for importers . . . . . . . . . . . . . . . . . . . . . . . 2050

32.5.6 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2053

32.6 importlib.resources – Package resource reading, opening and access . . . . . . . . . . . . . 2055

32.6.1 Functional API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2056

32.7 importlib.resources.abc – Abstract base classes for resources . . . . . . . . . . . . . . . . 2058

32.8 importlib.metadata – Accessing package metadata . . . . . . . . . . . . . . . . . . . . . . . 2060

32.8.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2061

32.8.2 Functional API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2062

32.8.3 Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2065

32.8.4 Distribution Discovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2066

32.8.5 Extending the search algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2066

32.9 The initialization of the sys.path module search path . . . . . . . . . . . . . . . . . . . . . . . 2068

32.9.1 Virtual environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2068

32.9.2 _pth files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2069

32.9.3 Embedded Python . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2069

33 Python Language Services 2071

33.1 ast — Abstract Syntax Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2071

33.1.1 Abstract Grammar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2071

33.1.2 Node classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2074



33.1.3 ast Helpers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2103

33.1.4 Compiler Flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2107

33.1.5 Command-Line Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2108

33.2 symtable — Access to the compiler’s symbol tables . . . . . . . . . . . . . . . . . . . . . . . . 2108

33.2.1 Generating Symbol Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2108

33.2.2 Examining Symbol Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2109

33.2.3 Command-Line Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2112

33.3 token — Constants used with Python parse trees . . . . . . . . . . . . . . . . . . . . . . . . . . 2112

33.4 keyword — Testing for Python keywords . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2116

33.5 tokenize — Tokenizer for Python source . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2116

33.5.1 Tokenizing Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2117

33.5.2 Command-Line Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2118

33.5.3 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2118

33.6 tabnanny — Detection of ambiguous indentation . . . . . . . . . . . . . . . . . . . . . . . . . . 2120

33.7 pyclbr — Python module browser support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2121

33.7.1 Function Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2121

33.7.2 Class Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2122

33.8 py_compile — Compile Python source files . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2123

33.8.1 Command-Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2124

33.9 compileall — Byte-compile Python libraries . . . . . . . . . . . . . . . . . . . . . . . . . . . 2124

33.9.1 Command-line use . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2124

33.9.2 Public functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2126

33.10 dis — Disassembler for Python bytecode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2128

33.10.1 Command-line interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2129

33.10.2 Bytecode analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2129

33.10.3 Analysis functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2130

33.10.4 Python Bytecode Instructions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2133

33.10.5 Opcode collections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2149

33.11 pickletools — Tools for pickle developers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2150

33.11.1 Command line usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2150

33.11.2 Programmatic Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2151

34 MS Windows Specific Services 2153

34.1 msvcrt — Useful routines from the MS VC++ runtime . . . . . . . . . . . . . . . . . . . . . . . 2153

34.1.1 File Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2153

34.1.2 Console I/O . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2154

34.1.3 Other Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2154

34.2 winreg — Windows registry access . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2155

34.2.1 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2156

34.2.2 Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2161

34.2.3 Registry Handle Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2163

34.3 winsound — Sound-playing interface for Windows . . . . . . . . . . . . . . . . . . . . . . . . . 2164

35 Unix Specific Services 2167

35.1 posix — The most common POSIX system calls . . . . . . . . . . . . . . . . . . . . . . . . . . 2167

35.1.1 Large File Support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2167

35.1.2 Notable Module Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2167

35.2 pwd — The password database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2168

35.3 grp — The group database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2169

35.4 termios — POSIX style tty control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2169

35.4.1 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2170

35.5 tty — Terminal control functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2171

35.6 pty — Pseudo-terminal utilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2172

35.6.1 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2173

35.7 fcntl — The fcntl and ioctl system calls . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2173

35.8 resource — Resource usage information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2176

35.8.1 Resource Limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2176

35.8.2 Resource Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2179



35.9 syslog — Unix syslog library routines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2180

35.9.1 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2182

36 Modules command-line interface (CLI) 2185

37 Superseded Modules 2187

37.1 getopt — C-style parser for command line options . . . . . . . . . . . . . . . . . . . . . . . . . 2187

38 Removed Modules 2191

38.1 aifc — Read and write AIFF and AIFC files . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2191

38.2 asynchat — Asynchronous socket command/response handler . . . . . . . . . . . . . . . . . . 2191

38.3 asyncore — Asynchronous socket handler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2191

38.4 audioop — Manipulate raw audio data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2191

38.5 cgi — Common Gateway Interface support . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2192

38.6 cgitb — Traceback manager for CGI scripts . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2192

38.7 chunk — Read IFF chunked data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2192

38.8 crypt — Function to check Unix passwords . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2192

38.9 distutils — Building and installing Python modules . . . . . . . . . . . . . . . . . . . . . . . 2192

38.10 imghdr — Determine the type of an image . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2192

38.11 imp — Access the import internals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2193

38.12 mailcap — Mailcap file handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2193

38.13 msilib — Read and write Microsoft Installer files . . . . . . . . . . . . . . . . . . . . . . . . . 2193

38.14 nis — Interface to Sun’s NIS (Yellow Pages) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2193

38.15 nntplib — NNTP protocol client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2193

38.16 ossaudiodev — Access to OSS-compatible audio devices . . . . . . . . . . . . . . . . . . . . . 2193

38.17 pipes — Interface to shell pipelines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2194

38.18 smtpd — SMTP Server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2194

38.19 sndhdr — Determine type of sound file . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2194

38.20 spwd — The shadow password database . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2194

38.21 sunau — Read and write Sun AU files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2194

38.22 telnetlib — Telnet client . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2194

38.23 uu — Encode and decode uuencode files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2195

38.24 xdrlib — Encode and decode XDR data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2195

39 Security Considerations 2197

A Glossary 2199

B About this documentation 2217

B.1 Contributors to the Python documentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2217

C History and License 2219

C.1 History of the software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2219

C.2 Terms and conditions for accessing or otherwise using Python . . . . . . . . . . . . . . . . . . . . 2220

C.2.1 PYTHON SOFTWARE FOUNDATION LICENSE VERSION 2 . . . . . . . . . . . . . 2220

C.2.2 BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0 . . . . . . . . . . . . . . 2221

C.2.3 CNRI LICENSE AGREEMENT FOR PYTHON 1.6.1 . . . . . . . . . . . . . . . . . . 2221

C.2.4 CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2 . . . . . . . . . . 2222

C.2.5 ZERO-CLAUSE BSD LICENSE FOR CODE IN THE PYTHON DOCUMENTATION . 2223

C.3 Licenses and Acknowledgements for Incorporated Software . . . . . . . . . . . . . . . . . . . . . 2223

C.3.1 Mersenne Twister . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2223

C.3.2 Sockets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2224

C.3.3 Asynchronous socket services . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2225

C.3.4 Cookie management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2225

C.3.5 Execution tracing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2225

C.3.6 UUencode and UUdecode functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2226

C.3.7 XML Remote Procedure Calls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2227

C.3.8 test_epoll . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2227

C.3.9 Select kqueue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2228



C.3.10 SipHash24 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2228

C.3.11 strtod and dtoa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2229

C.3.12 OpenSSL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2229

C.3.13 expat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2232

C.3.14 libffi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2233

C.3.15 zlib . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2233

C.3.16 cfuhash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2234

C.3.17 libmpdec . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2234

C.3.18 W3C C14N test suite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2235

C.3.19 mimalloc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2236

C.3.20 asyncio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2236

C.3.21 Global Unbounded Sequences (GUS) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2236

D Copyright 2239

Bibliography 2241

Python Module Index 2243

Index 2247



The Python Library Reference, Release 3.13.2



While reference-index describes the exact syntax and semantics of the Python language, this library reference manual describes the standard library that is distributed with Python. It also describes some of the optional components that are commonly included in Python distributions.

Python’s standard library is very extensive, offering a wide range of facilities as indicated by the long table of contents listed below. The library contains built-in modules (written in C) that provide access to system functionality such as file I/O that would otherwise be inaccessible to Python programmers, as well as modules written in Python that provide standardized solutions for many problems that occur in everyday programming. Some of these modules are explicitly designed to encourage and enhance the portability of Python programs by abstracting away platform-specifics into platform-neutral APIs.

The Python installers for the Windows platform usually include the entire standard library and often also include many additional components. For Unix-like operating systems Python is normally provided as a collection of packages, so it may be necessary to use the packaging tools provided with the operating system to obtain some or all of the optional components.

In addition to the standard library, there is an active collection of hundreds of thousands of components (from in-dividual programs and modules to packages and entire application development frameworks), available from the

Python Package Index.



The Python Library Reference, Release 3.13.2





CHAPTER




ONE



INTRODUCTION



The “Python library” contains several different kinds of components.

It contains data types that would normally be considered part of the “core” of a language, such as numbers and lists. For these types, the Python language core defines the form of literals and places some constraints on their semantics, but does not fully define the semantics. (On the other hand, the language core does define syntactic properties like the spelling and priorities of operators.)

The library also contains built-in functions and exceptions — objects that can be used by all Python code without the need of an import statement. Some of these are defined by the core language, but many are not essential for the core semantics and are only described here.

The bulk of the library, however, consists of a collection of modules. There are many ways to dissect this collection. Some modules are written in C and built in to the Python interpreter; others are written in Python and imported in source form. Some modules provide interfaces that are highly specific to Python, like printing a stack trace; some provide interfaces that are specific to particular operating systems, such as access to specific hardware; others provide interfaces that are specific to a particular application domain, like the World Wide Web. Some modules are available in all versions and ports of Python; others are only available when the underlying system supports or requires them; yet others are available only when a particular configuration option was chosen at the time when Python was compiled and installed.

This manual is organized “from the inside out:” it first describes the built-in functions, data types and exceptions, and finally the modules, grouped in chapters of related modules.

This means that if you start reading this manual from the start, and skip to the next chapter when you get bored, you will get a reasonable overview of the available modules and application areas that are supported by the Python library. Of course, you don’t have to read it like a novel — you can also browse the table of contents (in front of the manual), or look for a specific function, module or term in the index (in the back). And finally, if you enjoy learning about

random subjects, you choose a random page number (see module random) and read a section or two. Regardless

of the order in which you read the sections of this manual, it helps to start with chapter Built-in Functions, as the remainder of the manual assumes familiarity with this material.

Let the show begin!



1.1 Notes on availability

• An “Availability: Unix” note means that this function is commonly found on Unix systems. It does not make

any claims about its existence on a specific operating system.

• If not separately noted, all functions that claim “Availability: Unix” are supported on macOS, iOS and Android,

all of which build on a Unix core.

• If an availability note contains both a minimum Kernel version and a minimum libc version, then both condi-

tions must hold. For example a feature with note Availability: Linux >= 3.17 with glibc >= 2.27 requires both

Linux 3.17 or newer and glibc 2.27 or newer.





The Python Library Reference, Release 3.13.2




1.1.1 WebAssembly platforms

The WebAssembly platforms wasm32-emscripten (Emscripten) and wasm32-wasi (WASI) provide a subset of POSIX APIs. WebAssembly runtimes and browsers are sandboxed and have limited access to the host and external resources. Any Python standard library module that uses processes, threading, networking, signals, or other forms of inter-process communication (IPC), is either not available or may not work as on other Unix-like systems. File I/O, file system, and Unix permission-related functions are restricted, too. Emscripten does not permit blocking I/O.

Other blocking operations like sleep() block the browser event loop.

The properties and behavior of Python on WebAssembly platforms depend on the Emscripten-SDK or WASI-SDK

version, WASM runtimes (browser, NodeJS, wasmtime), and Python build time flags. WebAssembly, Emscripten, and WASI are evolving standards; some features like networking may be supported in the future.

For Python in the browser, users should consider Pyodide or PyScript. PyScript is built on top of Pyodide, which itself is built on top of CPython and Emscripten. Pyodide provides access to browsers’ JavaScript and DOM APIs as well as limited networking capabilities with JavaScript’s XMLHttpRequest and Fetch APIs.

• Process-related APIs are not available or always fail with an error. That includes APIs that spawn new processes

(fork(), execve()), wait for processes (waitpid()), send signals (kill()), or otherwise interact with

processes. The subprocess is importable but does not work.

• The socket module is available, but is limited and behaves differently from other platforms. On Emscripten,

sockets are always non-blocking and require additional JavaScript code and helpers on the server to proxy

TCP through WebSockets; see Emscripten Networking for more information. WASI snapshot preview 1 only

permits sockets from an existing file descriptor.

• Some functions are stubs that either don’t do anything and always return hardcoded values.

• Functions related to file descriptors, file permissions, file ownership, and links are limited and don’t support

some operations. For example, WASI does not permit symlinks with absolute file names.



1.1.2 Mobile platforms

Android and iOS are, in most respects, POSIX operating systems. File I/O, socket handling, and threading all behave as they would on any POSIX operating system. However, there are several major differences:

• Mobile platforms can only use Python in “embedded” mode. There is no Python REPL, and no ability to use

separate executables such as python or pip. To add Python code to your mobile app, you must use the Python

embedding API. For more details, see using-android and using-ios.

• Subprocesses:

– On Android, creating subprocesses is possible but officially unsupported. In particular, Android does not

support any part of the System V IPC API, so multiprocessing is not available.

– An iOS app cannot use any form of subprocessing, multiprocessing, or inter-process communication. If

an iOS app attempts to create a subprocess, the process creating the subprocess will either lock up, or crash. An iOS app has no visibility of other applications that are running, nor any ability to communicate with other running applications, outside of the iOS-specific APIs that exist for this purpose.

• Mobile apps have limited access to modify system resources (such as the system clock). These resources will

often be readable, but attempts to modify those resources will usually fail.

• Console input and output:

– On Android, the native stdout and stderr are not connected to anything, so Python installs its own

streams which redirect messages to the system log. These can be seen under the tags python.stdout and python.stderr respectively.

– iOS apps have a limited concept of console output. stdout and stderr exist, and content written to

stdout and stderr will be visible in logs when running in Xcode, but this content won’t be recorded in the system log. If a user who has installed your app provides their app logs as a diagnostic aid, they will not include any detail written to stdout or stderr.

– Mobile apps have no usable stdin at all. While apps can display an on-screen keyboard, this is a software

feature, not something that is attached to stdin.

The Python Library Reference, Release 3.13.2



As a result, Python modules that involve console manipulation (such as curses and readline) are not available on mobile platforms.



The Python Library Reference, Release 3.13.2





CHAPTER




TWO



BUILT-IN FUNCTIONS



The Python interpreter has a number of functions and types built into it that are always available. They are listed here in alphabetical order.



Built-in Functions



A E L R

abs() enumerate() len() range()

aiter() eval() list() repr()

all() exec() locals() reversed()

anext() round()

any() F M

ascii() filter() map() S

float() max() set()

B format() memoryview() setattr()

bin() frozenset() min() slice()

bool() sorted()

breakpoint() G N staticmethod()

bytearray() getattr() next() str()

bytes() globals() sum()

O super()

C H object()

callable() hasattr() oct() T

chr() hash() open() tuple()

classmethod() help() ord() type()

compile() hex()

complex() P V

I pow() vars()

D id() print()

delattr() input() property() Z

dict() int() zip()

dir() isinstance()

divmod() issubclass() _

iter() __import__()



abs(x)

Return the absolute value of a number. The argument may be an integer, a floating-point number, or an object

implementing __abs__(). If the argument is a complex number, its magnitude is returned.

The Python Library Reference, Release 3.13.2



aiter(async_iterable)

Return an asynchronous iterator for an asynchronous iterable. Equivalent to calling x.__aiter__().

Note: Unlike iter(), aiter() has no 2-argument variant.

Added in version 3.10.

all(iterable)

Return True if all elements of the iterable are true (or if the iterable is empty). Equivalent to:

def all(iterable):

for element in iterable:

if not element:

return False

return True



awaitable anext(async_iterator)

awaitable anext(async_iterator, default)

When awaited, return the next item from the given asynchronous iterator, or default if given and the iterator is

exhausted.

This is the async variant of the next() builtin, and behaves similarly.

This calls the __anext__() method of async_iterator, returning an awaitable. Awaiting this returns

the next value of the iterator. If default is given, it is returned if the iterator is exhausted, otherwise

StopAsyncIteration is raised.

Added in version 3.10.

any(iterable)

Return True if any element of the iterable is true. If the iterable is empty, return False. Equivalent to:

def any(iterable):

for element in iterable:

if element:

return True

return False



ascii(object)

As repr(), return a string containing a printable representation of an object, but escape the non-ASCII char-

acters in the string returned by repr() using \x, \u, or \U escapes. This generates a string similar to that

returned by repr() in Python 2.

bin(x)

Convert an integer number to a binary string prefixed with “0b”. The result is a valid Python expression. If x

is not a Python int object, it has to define an __index__() method that returns an integer. Some examples:

>>> bin(3)

'0b11'

>>> bin(-10)

'-0b1010'



If the prefix “0b” is desired or not, you can use either of the following ways.

>>> format(14, '#b'), format(14, 'b')

('0b1110', '1110')

>>> f'{14:#b}', f'{14:b}'

('0b1110', '1110')



See also format() for more information.

The Python Library Reference, Release 3.13.2



class bool(object=False, / )

Return a Boolean value, i.e. one of True or False. The argument is converted using the standard truth testing

procedure. If the argument is false or omitted, this returns False; otherwise, it returns True. The bool

class is a subclass of int (see Numeric Types — int, float, complex). It cannot be subclassed further. Its only

instances are False and True (see Boolean Type - bool).

Changed in version 3.7: The parameter is now positional-only.

breakpoint(*args, **kws)

This function drops you into the debugger at the call site. Specifically, it calls sys.breakpointhook(),

passing args and kws straight through. By default, sys.breakpointhook() calls pdb.set_trace()

expecting no arguments. In this case, it is purely a convenience function so you don’t have to explicitly import

pdb or type as much code to enter the debugger. However, sys.breakpointhook() can be set to some

other function and breakpoint() will automatically call that, allowing you to drop into the debugger of

choice. If sys.breakpointhook() is not accessible, this function will raise RuntimeError.

By default, the behavior of breakpoint() can be changed with the PYTHONBREAKPOINT environment vari-

able. See sys.breakpointhook() for usage details.

Note that this is not guaranteed if sys.breakpointhook() has been replaced.

Raises an auditing event builtins.breakpoint with argument breakpointhook.

Added in version 3.7.

class bytearray(source=b”)

class bytearray(source, encoding)

class bytearray(source, encoding, errors)

Return a new array of bytes. The bytearray class is a mutable sequence of integers in the range 0 <= x <

256. It has most of the usual methods of mutable sequences, described in Mutable Sequence Types, as well as

most methods that the bytes type has, see Bytes and Bytearray Operations.

The optional source parameter can be used to initialize the array in a few different ways:

• If it is a string, you must also give the encoding (and optionally, errors) parameters; bytearray() then

converts the string to bytes using str.encode().

• If it is an integer, the array will have that size and will be initialized with null bytes.

• If it is an object conforming to the buffer interface, a read-only buffer of the object will be used to initialize

the bytes array.

• If it is an iterable, it must be an iterable of integers in the range 0 <= x < 256, which are used as the

initial contents of the array.

Without an argument, an array of size 0 is created.

See also Binary Sequence Types — bytes, bytearray, memoryview and Bytearray Objects.

class bytes(source=b”)

class bytes(source, encoding)

class bytes(source, encoding, errors)

Return a new “bytes” object which is an immutable sequence of integers in the range 0 <= x < 256. bytes

is an immutable version of bytearray – it has the same non-mutating methods and the same indexing and

slicing behavior.

Accordingly, constructor arguments are interpreted as for bytearray().

Bytes objects can also be created with literals, see strings.

See also Binary Sequence Types — bytes, bytearray, memoryview, Bytes Objects, and Bytes and Bytearray Op-

erations.



The Python Library Reference, Release 3.13.2



callable(object)

Return True if the object argument appears callable, False if not. If this returns True, it is still possible that

a call fails, but if it is False, calling object will never succeed. Note that classes are callable (calling a class

returns a new instance); instances are callable if their class has a __call__() method.

Added in version 3.2: This function was first removed in Python 3.0 and then brought back in Python 3.2.

chr(i)

Return the string representing a character whose Unicode code point is the integer i. For example, chr(97)

returns the string 'a', while chr(8364) returns the string '€'. This is the inverse of ord().

The valid range for the argument is from 0 through 1,114,111 (0x10FFFF in base 16). ValueError will be

raised if i is outside that range.

@classmethod

Transform a method into a class method.

A class method receives the class as an implicit first argument, just like an instance method receives the instance.

To declare a class method, use this idiom:

class C:

@classmethod

def f(cls, arg1, arg2): ...



The @classmethod form is a function decorator – see function for details.

A class method can be called either on the class (such as C.f()) or on an instance (such as C().f()). The

instance is ignored except for its class. If a class method is called for a derived class, the derived class object

is passed as the implied first argument.

Class methods are different than C++ or Java static methods. If you want those, see staticmethod() in this

section. For more information on class methods, see types.

Changed in version 3.9: Class methods can now wrap other descriptors such as property().

Changed in version 3.10: Class methods now inherit the method attributes (__module__, __name__,

__qualname__, __doc__ and __annotations__) and have a new __wrapped__ attribute.

Deprecated since version 3.11, removed in version 3.13: Class methods can no longer wrap other descriptors

such as property().

compile( source, filename, mode, flags=0, dont_inherit=False, optimize=-1)

Compile the source into a code or AST object. Code objects can be executed by exec() or eval(). source

can either be a normal string, a byte string, or an AST object. Refer to the ast module documentation for

information on how to work with AST objects.

The filename argument should give the file from which the code was read; pass some recognizable value if it

wasn’t read from a file ('' is commonly used).

The mode argument specifies what kind of code must be compiled; it can be 'exec' if source consists of a

sequence of statements, 'eval' if it consists of a single expression, or 'single' if it consists of a single

interactive statement (in the latter case, expression statements that evaluate to something other than None will

be printed).

The optional arguments flags and dont_inherit control which compiler options should be activated and which

future features should be allowed. If neither is present (or both are zero) the code is compiled with the same

flags that affect the code that is calling compile(). If the flags argument is given and dont_inherit is not (or is

zero) then the compiler options and the future statements specified by the flags argument are used in addition

to those that would be used anyway. If dont_inherit is a non-zero integer then the flags argument is it – the

flags (future features and compiler options) in the surrounding code are ignored.

Compiler options and future statements are specified by bits which can be bitwise ORed together to specify

multiple options. The bitfield required to specify a given future feature can be found as the compiler_flag

attribute on the _Feature instance in the __future__ module. Compiler flags can be found in ast module,

with PyCF_ prefix.

The Python Library Reference, Release 3.13.2



The argument optimize specifies the optimization level of the compiler; the default value of-1 selects the

optimization level of the interpreter as given by-O options. Explicit levels are 0 (no optimization; __debug__

is true), 1 (asserts are removed, __debug__ is false) or 2 (docstrings are removed too).

This function raises SyntaxError if the compiled source is invalid, and ValueError if the source contains

null bytes.

If you want to parse Python code into its AST representation, see ast.parse().



Raises an auditing event compile with arguments source and filename. This event may also be raised by

implicit compilation.



® Note

When compiling a string with multi-line code in 'single' or 'eval' mode, input must be terminated by at least one newline character. This is to facilitate detection of incomplete and complete statements in

the code module.



Á Warning

It is possible to crash the Python interpreter with a sufficiently large/complex string when compiling to an AST object due to stack depth limitations in Python’s AST compiler.



Changed in version 3.2: Allowed use of Windows and Mac newlines. Also, input in 'exec' mode does not

have to end in a newline anymore. Added the optimize parameter.

Changed in version 3.5: Previously, TypeError was raised when null bytes were encountered in source.

Added in version 3.8: ast.PyCF_ALLOW_TOP_LEVEL_AWAIT can now be passed in flags to enable support

for top-level await, async for, and async with.

class complex(number=0, / )

class complex(string, / )

class complex(real=0, imag=0)

Convert a single string or number to a complex number, or create a complex number from real and imaginary

parts.

Examples:

>>> complex('+1.23')

(1.23+0j)

>>> complex('-4.5j')

-4.5j

>>> complex('-1.23+4.5j')

(-1.23+4.5j)

>>> complex('\t( -1.23+4.5J )\n')

(-1.23+4.5j)

>>> complex('-Infinity+NaNj')

(-inf+nanj)

>>> complex(1.23)

(1.23+0j)

>>> complex(imag=-4.5)

-4.5j

>>> complex(-1.23, 4.5)

(-1.23+4.5j)



The Python Library Reference, Release 3.13.2



If the argument is a string, it must contain either a real part (in the same format as for float()) or an

imaginary part (in the same format but with a 'j' or 'J' suffix), or both real and imaginary parts (the sign of

the imaginary part is mandatory in this case). The string can optionally be surrounded by whitespaces and the

round parentheses '(' and ')', which are ignored. The string must not contain whitespace between '+', '-',

the 'j' or 'J' suffix, and the decimal number. For example, complex('1+2j') is fine, but complex('1

+ 2j') raises ValueError. More precisely, the input must conform to the complexvalue production rule

in the following grammar, after parentheses and leading and trailing whitespace characters are removed:



complexvalue ::= floatvalue |

floatvalue ("j" | "J") |

floatvalue sign absfloatvalue ("j" | "J")

If the argument is a number, the constructor serves as a numeric conversion like int and float. For a general

Python object x, complex(x) delegates to x.__complex__(). If __complex__() is not defined then it

falls back to __float__(). If __float__() is not defined then it falls back to __index__().

If two arguments are provided or keyword arguments are used, each argument may be any numeric type

(including complex). If both arguments are real numbers, return a complex number with the real component

real and the imaginary component imag. If both arguments are complex numbers, return a complex number

with the real component real.real-imag.imag and the imaginary component real.imag+imag.real.

If one of arguments is a real number, only its real component is used in the above expressions.

If all arguments are omitted, returns 0j.

The complex type is described in Numeric Types — int, float, complex.

Changed in version 3.6: Grouping digits with underscores as in code literals is allowed.

Changed in version 3.8: Falls back to __index__() if __complex__() and __float__() are not defined.

delattr( object, name)

This is a relative of setattr(). The arguments are an object and a string. The string must be the name

of one of the object’s attributes. The function deletes the named attribute, provided the object allows it. For

example, delattr(x, 'foobar') is equivalent to del x.foobar. name need not be a Python identifier

(see setattr()).

class dict(**kwarg)

class dict(mapping, **kwarg)

class dict(iterable, **kwarg)

Create a new dictionary. The dict object is the dictionary class. See dict and Mapping Types — dict for

documentation about this class.

For other containers see the built-in list, set, and tuple classes, as well as the collections module.

dir()

dir(object)

Without arguments, return the list of names in the current local scope. With an argument, attempt to return a

list of valid attributes for that object.

If the object has a method named __dir__(), this method will be called and must return the list of attributes.

This allows objects that implement a custom __getattr__() or __getattribute__() function to cus-

tomize the way dir() reports their attributes.

If the object does not provide __dir__(), the function tries its best to gather information from the object’s

__dict__ attribute, if defined, and from its type object. The resulting list is not necessarily complete and

may be inaccurate when the object has a custom __getattr__().

The default dir() mechanism behaves differently with different types of objects, as it attempts to produce the

most relevant, rather than complete, information:

• If the object is a module object, the list contains the names of the module’s attributes.

The Python Library Reference, Release 3.13.2



• If the object is a type or class object, the list contains the names of its attributes, and recursively of the

attributes of its bases.

• Otherwise, the list contains the object’s attributes’ names, the names of its class’s attributes, and recursively

of the attributes of its class’s base classes.

The resulting list is sorted alphabetically. For example:

>>> import struct

>>> dir() # show the names in the module namespace

['__builtins__', '__name__', 'struct']

>>> dir(struct) # show the names in the struct module

['Struct', '__all__', '__builtins__', '__cached__', '__doc__', '__file__',

'__initializing__', '__loader__', '__name__', '__package__', '_clearcache', 'calcsize', 'error', 'pack', 'pack_into', 'unpack', 'unpack_from']

>>> class Shape:

... def __dir__(self):

... return ['area', 'perimeter', 'location']

...

>>> s = Shape()

>>> dir(s)

['area', 'location', 'perimeter']



® Note

Because dir() is supplied primarily as a convenience for use at an interactive prompt, it tries to supply an interesting set of names more than it tries to supply a rigorously or consistently defined set of names, and its detailed behavior may change across releases. For example, metaclass attributes are not in the result list when the argument is a class.



divmod(a, b)

Take two (non-complex) numbers as arguments and return a pair of numbers consisting of their quotient and

remainder when using integer division. With mixed operand types, the rules for binary arithmetic operators

apply. For integers, the result is the same as (a // b, a % b). For floating-point numbers the result is (q,

a % b) , where q is usually math.floor(a / b) but may be 1 less than that. In any case q * b + a % b

is very close to a, if a % b is non-zero it has the same sign as b, and 0 <= abs(a % b) < abs(b).

enumerate(iterable, start=0)

Return an enumerate object. iterable must be a sequence, an iterator, or some other object which supports

iteration. The __next__() method of the iterator returned by enumerate() returns a tuple containing a

count (from start which defaults to 0) and the values obtained from iterating over iterable.

>>> seasons = ['Spring', 'Summer', 'Fall', 'Winter']

>>> list(enumerate(seasons))

[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]

>>> list(enumerate(seasons, start=1))

[(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')]



Equivalent to:

def enumerate(iterable, start=0):

n = start

for elem in iterable:

yield n, elem

n += 1



eval(source, / , globals=None, locals=None)

The Python Library Reference, Release 3.13.2



Parameters

• source (str | code object) – A Python expression.

• globals (dict | None) – The global namespace (default: None).

• locals (mapping | None) – The local namespace (default: None).

Returns

The result of the evaluated expression.

Raises

Syntax errors are reported as exceptions.



Á Warning

This function executes arbitrary code. Calling it with user-supplied input may lead to security vulnerabil-ities.



The expression argument is parsed and evaluated as a Python expression (technically speaking, a condition

list) using the globals and locals mappings as global and local namespace. If the globals dictionary is present

and does not contain a value for the key __builtins__, a reference to the dictionary of the built-in module

builtins is inserted under that key before expression is parsed. That way you can control what builtins are

available to the executed code by inserting your own __builtins__ dictionary into globals before passing

it to eval(). If the locals mapping is omitted it defaults to the globals dictionary. If both mappings are

omitted, the expression is executed with the globals and locals in the environment where eval() is called.

Note, eval() will only have access to the nested scopes (non-locals) in the enclosing environment if they are

already referenced in the scope that is calling eval() (e.g. via a nonlocal statement).

Example:

>>> x = 1

>>> eval('x+1')

2



This function can also be used to execute arbitrary code objects (such as those created by compile()). In this

case, pass a code object instead of a string. If the code object has been compiled with 'exec' as the mode

argument, eval()’s return value will be None.

Hints: dynamic execution of statements is supported by the exec() function. The globals() and locals()

functions return the current global and local dictionary, respectively, which may be useful to pass around for

use by eval() or exec().

If the given source is a string, then leading and trailing spaces and tabs are stripped.

See ast.literal_eval() for a function that can safely evaluate strings with expressions containing only

literals.



Raises an auditing event exec with the code object as the argument. Code compilation events may also be

raised.

Changed in version 3.13: The globals and locals arguments can now be passed as keywords.

Changed in version 3.13: The semantics of the default locals namespace have been adjusted as described for

the locals() builtin.

exec(source, / , globals=None, locals=None, *, closure=None)



Á Warning



The Python Library Reference, Release 3.13.2



This function executes arbitrary code. Calling it with user-supplied input may lead to security vulnerabil-ities.



This function supports dynamic execution of Python code. source must be either a string or a code object. If

it is a string, the string is parsed as a suite of Python statements which is then executed (unless a syntax error

occurs).1 If it is a code object, it is simply executed. In all cases, the code that’s executed is expected to be

valid as file input (see the section file-input in the Reference Manual). Be aware that the nonlocal, yield,

and return statements may not be used outside of function definitions even within the context of code passed

to the exec() function. The return value is None.

In all cases, if the optional parts are omitted, the code is executed in the current scope. If only globals is

provided, it must be a dictionary (and not a subclass of dictionary), which will be used for both the global and

the local variables. If globals and locals are given, they are used for the global and local variables, respectively.

If provided, locals can be any mapping object. Remember that at the module level, globals and locals are the

same dictionary.



® Note

When exec gets two separate objects as globals and locals, the code will be executed as if it were embedded in a class definition. This means functions and classes defined in the executed code will not be able to access variables assigned at the top level (as the “top level” variables are treated as class variables in a class definition).



If the globals dictionary does not contain a value for the key __builtins__, a reference to the dictionary of

the built-in module builtins is inserted under that key. That way you can control what builtins are available

to the executed code by inserting your own __builtins__ dictionary into globals before passing it to exec().

The closure argument specifies a closure–a tuple of cellvars. It’s only valid when the object is a code object

containing free (closure) variables. The length of the tuple must exactly match the length of the code object’s

co_freevars attribute.



Raises an auditing event exec with the code object as the argument. Code compilation events may also be

raised.



® Note

The built-in functions globals() and locals() return the current global and local namespace, respec-

tively, which may be useful to pass around for use as the second and third argument to exec().



® Note

The default locals act as described for function locals() below. Pass an explicit locals dictionary if you

need to see effects of the code on locals after function exec() returns.



Changed in version 3.11: Added the closure parameter.

Changed in version 3.13: The globals and locals arguments can now be passed as keywords.

Changed in version 3.13: The semantics of the default locals namespace have been adjusted as described for

the locals() builtin.

1 Note that the parser only accepts the Unix-style end of line convention. If you are reading the code from a file, make sure to use newline

conversion mode to convert Windows or Mac-style newlines.

The Python Library Reference, Release 3.13.2



filter(function, iterable)

Construct an iterator from those elements of iterable for which function is true. iterable may be either a

sequence, a container which supports iteration, or an iterator. If function is None, the identity function is

assumed, that is, all elements of iterable that are false are removed.

Note that filter(function, iterable) is equivalent to the generator expression (item for item

in iterable if function(item)) if function is not None and (item for item in iterable if

item) if function is None.

See itertools.filterfalse() for the complementary function that returns elements of iterable for which

function is false.

class float(number=0.0, / )

class float(string, / )

Return a floating-point number constructed from a number or a string.

Examples:

>>> float('+1.23')

1.23

>>> float(' -12345\n')

-12345.0

>>> float('1e-003')

0.001

>>> float('+1E6')

1000000.0

>>> float('-Infinity')

-inf



If the argument is a string, it should contain a decimal number, optionally preceded by a sign, and optionally

embedded in whitespace. The optional sign may be '+' or '-'; a '+' sign has no effect on the value produced.

The argument may also be a string representing a NaN (not-a-number), or positive or negative infinity. More

precisely, the input must conform to the floatvalue production rule in the following grammar, after leading

and trailing whitespace characters are removed:



sign ::= "+" | "-"

infinity ::= "Infinity" | "inf"

nan ::= "nan"

digit ::=

digitpart ::= digit (["_"] digit)*

number ::= [digitpart] "." digitpart | digitpart ["."]

exponent ::= ("e" | "E") [sign] digitpart

floatnumber ::= number [exponent]

absfloatvalue ::= floatnumber | infinity | nan

floatvalue ::= [sign] absfloatvalue

Case is not significant, so, for example, “inf”, “Inf”, “INFINITY”, and “iNfINity” are all acceptable spellings

for positive infinity.

Otherwise, if the argument is an integer or a floating-point number, a floating-point number with the same

value (within Python’s floating-point precision) is returned. If the argument is outside the range of a Python

float, an OverflowError will be raised.

For a general Python object x, float(x) delegates to x.__float__(). If __float__() is not defined then

it falls back to __index__().

If no argument is given, 0.0 is returned.

The float type is described in Numeric Types — int, float, complex.

Changed in version 3.6: Grouping digits with underscores as in code literals is allowed.

The Python Library Reference, Release 3.13.2



Changed in version 3.7: The parameter is now positional-only.

Changed in version 3.8: Falls back to __index__() if __float__() is not defined.

format(value, format_spec=”)

Convert a value to a “formatted” representation, as controlled by format_spec. The interpretation of for-

mat_spec will depend on the type of the value argument; however, there is a standard formatting syntax that is

used by most built-in types: Format Specification Mini-Language.

The default format_spec is an empty string which usually gives the same effect as calling str(value).

A call to format(value, format_spec) is translated to type(value).__format__(value,

format_spec) which bypasses the instance dictionary when searching for the value’s __format__()

method. A TypeError exception is raised if the method search reaches object and the format_spec is

non-empty, or if either the format_spec or the return value are not strings.

Changed in version 3.4: object().__format__(format_spec) raises TypeError if format_spec is not

an empty string.

class frozenset(iterable=set())

Return a new frozenset object, optionally with elements taken from iterable. frozenset is a built-in class.

See frozenset and Set Types — set, frozenset for documentation about this class.

For other containers see the built-in set, list, tuple, and dict classes, as well as the collections

module.

getattr( object, name)

getattr( object, name, default)

Return the value of the named attribute of object. name must be a string. If the string is the name of one

of the object’s attributes, the result is the value of that attribute. For example, getattr(x, 'foobar')

is equivalent to x.foobar. If the named attribute does not exist, default is returned if provided, otherwise

AttributeError is raised. name need not be a Python identifier (see setattr()).



® Note

Since private name mangling happens at compilation time, one must manually mangle a private attribute’s

(attributes with two leading underscores) name in order to retrieve it with getattr().



globals()

Return the dictionary implementing the current module namespace. For code within functions, this is set when

the function is defined and remains the same regardless of where the function is called.

hasattr( object, name)

The arguments are an object and a string. The result is True if the string is the name of one of the object’s

attributes, False if not. (This is implemented by calling getattr(object, name) and seeing whether it

raises an AttributeError or not.)

hash(object)

Return the hash value of the object (if it has one). Hash values are integers. They are used to quickly compare

dictionary keys during a dictionary lookup. Numeric values that compare equal have the same hash value (even

if they are of different types, as is the case for 1 and 1.0).



® Note

For objects with custom __hash__() methods, note that hash() truncates the return value based on the bit width of the host machine.



help()

The Python Library Reference, Release 3.13.2



help(request)

Invoke the built-in help system. (This function is intended for interactive use.) If no argument is given, the

interactive help system starts on the interpreter console. If the argument is a string, then the string is looked up

as the name of a module, function, class, method, keyword, or documentation topic, and a help page is printed

on the console. If the argument is any other kind of object, a help page on the object is generated.

Note that if a slash(/) appears in the parameter list of a function when invoking help(), it means that the

parameters prior to the slash are positional-only. For more info, see the FAQ entry on positional-only param-

eters.

This function is added to the built-in namespace by the site module.

Changed in version 3.4: Changes to pydoc and inspect mean that the reported signatures for callables are

now more comprehensive and consistent.

hex(x)

Convert an integer number to a lowercase hexadecimal string prefixed with “0x”. If x is not a Python int

object, it has to define an __index__() method that returns an integer. Some examples:

>>> hex(255)

'0xff'

>>> hex(-42)

'-0x2a'



If you want to convert an integer number to an uppercase or lower hexadecimal string with prefix or not, you

can use either of the following ways:

>>> '%#x' % 255, '%x' % 255, '%X' % 255

('0xff', 'ff', 'FF')

>>> format(255, '#x'), format(255, 'x'), format(255, 'X')

('0xff', 'ff', 'FF')

>>> f'{255:#x}', f'{255:x}', f'{255:X}'

('0xff', 'ff', 'FF')



See also format() for more information.

See also int() for converting a hexadecimal string to an integer using a base of 16.



® Note

To obtain a hexadecimal string representation for a float, use the float.hex() method.



id(object)

Return the “identity” of an object. This is an integer which is guaranteed to be unique and constant for this

object during its lifetime. Two objects with non-overlapping lifetimes may have the same id() value.

CPython implementation detail: This is the address of the object in memory.

Raises an auditing event builtins.id with argument id.

input()

input(prompt)

If the prompt argument is present, it is written to standard output without a trailing newline. The function then

reads a line from input, converts it to a string (stripping a trailing newline), and returns that. When EOF is

read, EOFError is raised. Example:

>>> s = input('--> ')

--> Monty Python's Flying Circus

>>> s

"Monty Python's Flying Circus"

The Python Library Reference, Release 3.13.2



If the readline module was loaded, then input() will use it to provide elaborate line editing and history

features.



Raises an auditing event builtins.input with argument prompt before reading input



Raises an auditing event builtins.input/result with the result after successfully reading input.

class int(number=0, / )

class int(string, / , base=10)

Return an integer object constructed from a number or a string, or return 0 if no arguments are given.

Examples:

>>> int(123.45)

123

>>> int('123')

123

>>> int(' -12_345\n')

-12345

>>> int('FACE', 16)

64206

>>> int('0xface', 0)

64206

>>> int('01110011', base=2)

115



If the argument defines __int__(), int(x) returns x.__int__(). If the argument defines __index__(),

it returns x.__index__(). If the argument defines __trunc__(), it returns x.__trunc__(). For floating-

point numbers, this truncates towards zero.

If the argument is not a number or if base is given, then it must be a string, bytes, or bytearray instance

representing an integer in radix base. Optionally, the string can be preceded by + or-(with no space in

between), have leading zeros, be surrounded by whitespace, and have single underscores interspersed between

digits.

A base-n integer string contains digits, each representing a value from 0 to n-1. The values 0–9 can be repre-

sented by any Unicode decimal digit. The values 10–35 can be represented by a to z (or A to Z). The default

base is 10. The allowed bases are 0 and 2–36. Base-2, -8, and -16 strings can be optionally prefixed with

0b/0B, 0o/0O, or 0x/0X, as with integer literals in code. For base 0, the string is interpreted in a similar way

to an integer literal in code, in that the actual base is 2, 8, 10, or 16 as determined by the prefix. Base 0 also

disallows leading zeros: int('010', 0) is not legal, while int('010') and int('010', 8) are.

The integer type is described in Numeric Types — int, float, complex.

Changed in version 3.4: If base is not an instance of int and the base object has a base.__index__ method,

that method is called to obtain an integer for the base. Previous versions used base.__int__ instead of

base.__index__.

Changed in version 3.6: Grouping digits with underscores as in code literals is allowed.

Changed in version 3.7: The first parameter is now positional-only.

Changed in version 3.8: Falls back to __index__() if __int__() is not defined.

Changed in version 3.11: The delegation to __trunc__() is deprecated.

Changed in version 3.11: int string inputs and string representations can be limited to help avoid denial of

service attacks. A ValueError is raised when the limit is exceeded while converting a string to an int or

when converting an int into a string would exceed the limit. See the integer string conversion length limitation

documentation.

The Python Library Reference, Release 3.13.2



isinstance(object, classinfo)

Return True if the object argument is an instance of the classinfo argument, or of a (direct, indirect, or virtual)

subclass thereof. If object is not an object of the given type, the function always returns False. If classinfo is a

tuple of type objects (or recursively, other such tuples) or a Union Type of multiple types, return True if object

is an instance of any of the types. If classinfo is not a type or tuple of types and such tuples, a TypeError

exception is raised. TypeError may not be raised for an invalid type if an earlier check succeeds.

Changed in version 3.10: classinfo can be a Union Type.

issubclass(class, classinfo)

Return True if class is a subclass (direct, indirect, or virtual) of classinfo. A class is considered a subclass of

itself. classinfo may be a tuple of class objects (or recursively, other such tuples) or a Union Type, in which

case return True if class is a subclass of any entry in classinfo. In any other case, a TypeError exception is

raised.

Changed in version 3.10: classinfo can be a Union Type.

iter(object)

iter(object, sentinel)

Return an iterator object. The first argument is interpreted very differently depending on the presence of the

second argument. Without a second argument, object must be a collection object which supports the iterable

protocol (the __iter__() method), or it must support the sequence protocol (the __getitem__() method

with integer arguments starting at 0). If it does not support either of those protocols, TypeError is raised. If

the second argument, sentinel, is given, then object must be a callable object. The iterator created in this case

will call object with no arguments for each call to its __next__() method; if the value returned is equal to

sentinel, StopIteration will be raised, otherwise the value will be returned.

See also Iterator Types.

One useful application of the second form of iter() is to build a block-reader. For example, reading fixed-

width blocks from a binary database file until the end of file is reached:

from functools import partial

with open('mydata.db', 'rb') as f:

for block in iter(partial(f.read, 64), b''):

process_block(block)



len(s)

Return the length (the number of items) of an object. The argument may be a sequence (such as a string, bytes,

tuple, list, or range) or a collection (such as a dictionary, set, or frozen set).

CPython implementation detail: len raises OverflowError on lengths larger than sys.maxsize, such

as range(2 ** 100).

class list

class list(iterable)

Rather than being a function, list is actually a mutable sequence type, as documented in Lists and Sequence

Types — list, tuple, range.

locals()

Return a mapping object representing the current local symbol table, with variable names as the keys, and their currently bound references as the values.

At module scope, as well as when using exec() or eval() with a single namespace, this function

returns the same namespace as globals().

At class scope, it returns the namespace that will be passed to the metaclass constructor.

When using exec() or eval() with separate local and global arguments, it returns the local namespace passed in to the function call.

In all of the above cases, each call to locals() in a given frame of execution will return the same mapping object. Changes made through the mapping object returned from locals() will

The Python Library Reference, Release 3.13.2



be visible as assigned, reassigned, or deleted local variables, and assigning, reassigning, or deleting local variables will immediately affect the contents of the returned mapping object.

In an optimized scope (including functions, generators, and coroutines), each call to locals() instead returns a fresh dictionary containing the current bindings of the function’s local variables and any nonlocal cell references. In this case, name binding changes made via the returned dict are not written back to the corresponding local variables or nonlocal cell references, and assigning, reassigning, or deleting local variables and nonlocal cell references does not affect the contents of previously returned dictionaries.

Calling locals() as part of a comprehension in a function, generator, or coroutine is equivalent to calling it in the containing scope, except that the comprehension’s initialised iteration variables will be included. In other scopes, it behaves as if the comprehension were running as a nested function.

Calling locals() as part of a generator expression is equivalent to calling it in a nested generator function.

Changed in version 3.12: The behaviour of locals() in a comprehension has been updated as described in

PEP 709.

Changed in version 3.13: As part of PEP 667, the semantics of mutating the mapping objects returned from

this function are now defined. The behavior in optimized scopes is now as described above. Aside from being

defined, the behaviour in other scopes remains unchanged from previous versions.

map(function, iterable, *iterables)

Return an iterator that applies function to every item of iterable, yielding the results. If additional iterables

arguments are passed, function must take that many arguments and is applied to the items from all iterables

in parallel. With multiple iterables, the iterator stops when the shortest iterable is exhausted. For cases where

the function inputs are already arranged into argument tuples, see itertools.starmap().

max(iterable, *, key=None)

max(iterable, *, default, key=None)

max(arg1, arg2, *args, key=None)

Return the largest item in an iterable or the largest of two or more arguments.

If one positional argument is provided, it should be an iterable. The largest item in the iterable is returned. If

two or more positional arguments are provided, the largest of the positional arguments is returned.

There are two optional keyword-only arguments. The key argument specifies a one-argument ordering function

like that used for list.sort(). The default argument specifies an object to return if the provided iterable is

empty. If the iterable is empty and default is not provided, a ValueError is raised.

If multiple items are maximal, the function returns the first one encountered. This is consistent with other sort-

stability preserving tools such as sorted(iterable, key=keyfunc, reverse=True)[0] and heapq.

nlargest(1, iterable, key=keyfunc) .

Changed in version 3.4: Added the default keyword-only parameter.

Changed in version 3.8: The key can be None.

class memoryview(object)

Return a “memory view” object created from the given argument. See Memory Views for more information.

min(iterable, *, key=None)

min(iterable, *, default, key=None)

min(arg1, arg2, *args, key=None)

Return the smallest item in an iterable or the smallest of two or more arguments.

If one positional argument is provided, it should be an iterable. The smallest item in the iterable is returned.

If two or more positional arguments are provided, the smallest of the positional arguments is returned.

There are two optional keyword-only arguments. The key argument specifies a one-argument ordering function

like that used for list.sort(). The default argument specifies an object to return if the provided iterable is

empty. If the iterable is empty and default is not provided, a ValueError is raised.

The Python Library Reference, Release 3.13.2



If multiple items are minimal, the function returns the first one encountered. This is consistent with other sort-

stability preserving tools such as sorted(iterable, key=keyfunc)[0] and heapq.nsmallest(1,

iterable, key=keyfunc).

Changed in version 3.4: Added the default keyword-only parameter.

Changed in version 3.8: The key can be None.

next(iterator)

next(iterator, default)

Retrieve the next item from the iterator by calling its __next__() method. If default is given, it is returned

if the iterator is exhausted, otherwise StopIteration is raised.

class object

This is the ultimate base class of all other classes. It has methods that are common to all instances of Python

classes. When the constructor is called, it returns a new featureless object. The constructor does not accept

any arguments.



® Note

object instances do not have __dict__ attributes, so you can’t assign arbitrary attributes to an instance

of object.



oct(x)

Convert an integer number to an octal string prefixed with “0o”. The result is a valid Python expression. If x

is not a Python int object, it has to define an __index__() method that returns an integer. For example:

>>> oct(8)

'0o10'

>>> oct(-56)

'-0o70'



If you want to convert an integer number to an octal string either with the prefix “0o” or not, you can use either

of the following ways.

>>> '%#o' % 10, '%o' % 10

('0o12', '12')

>>> format(10, '#o'), format(10, 'o')

('0o12', '12')

>>> f'{10:#o}', f'{10:o}'

('0o12', '12')



See also format() for more information.

open(file, mode=’r’, buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)

Open file and return a corresponding file object. If the file cannot be opened, an OSError is raised. See

tut-files for more examples of how to use this function.

file is a path-like object giving the pathname (absolute or relative to the current working directory) of the file

to be opened or an integer file descriptor of the file to be wrapped. (If a file descriptor is given, it is closed

when the returned I/O object is closed unless closefd is set to False.)

mode is an optional string that specifies the mode in which the file is opened. It defaults to 'r' which means

open for reading in text mode. Other common values are 'w' for writing (truncating the file if it already exists),

'x' for exclusive creation, and 'a' for appending (which on some Unix systems, means that all writes append

to the end of the file regardless of the current seek position). In text mode, if encoding is not specified the

encoding used is platform-dependent: locale.getencoding() is called to get the current locale encoding.

(For reading and writing raw bytes use binary mode and leave encoding unspecified.) The available modes are:

The Python Library Reference, Release 3.13.2



Character Meaning

'r' open for reading (default)

'w' open for writing, truncating the file first

'x' open for exclusive creation, failing if the file already exists

'a' open for writing, appending to the end of file if it exists

'b' binary mode

't' text mode (default)

'+' open for updating (reading and writing)



The default mode is 'r' (open for reading text, a synonym of 'rt'). Modes 'w+' and 'w+b' open and

truncate the file. Modes 'r+' and 'r+b' open the file with no truncation.

As mentioned in the Overview, Python distinguishes between binary and text I/O. Files opened in binary mode

(including 'b' in the mode argument) return contents as bytes objects without any decoding. In text mode

(the default, or when 't' is included in the mode argument), the contents of the file are returned as str, the

bytes having been first decoded using a platform-dependent encoding or using the specified encoding if given.



® Note

Python doesn’t depend on the underlying operating system’s notion of text files; all the processing is done by Python itself, and is therefore platform-independent.



buffering is an optional integer used to set the buffering policy. Pass 0 to switch buffering off (only allowed in

binary mode), 1 to select line buffering (only usable when writing in text mode), and an integer > 1 to indicate

the size in bytes of a fixed-size chunk buffer. Note that specifying a buffer size this way applies for binary

buffered I/O, but TextIOWrapper (i.e., files opened with mode='r+') would have another buffering. To

disable buffering in TextIOWrapper, consider using the write_through flag for io.TextIOWrapper.

reconfigure(). When no buffering argument is given, the default buffering policy works as follows:

• Binary files are buffered in fixed-size chunks; the size of the buffer is chosen using a heuristic trying to

determine the underlying device’s “block size” and falling back on io.DEFAULT_BUFFER_SIZE. On many systems, the buffer will typically be 4096 or 8192 bytes long.

• “Interactive” text files (files for which isatty() returns True) use line buffering. Other text files use

the policy described above for binary files.

encoding is the name of the encoding used to decode or encode the file. This should only be used in text

mode. The default encoding is platform dependent (whatever locale.getencoding() returns), but any

text encoding supported by Python can be used. See the codecs module for the list of supported encodings.

errors is an optional string that specifies how encoding and decoding errors are to be handled—this cannot

be used in binary mode. A variety of standard error handlers are available (listed under Error Handlers),

though any error handling name that has been registered with codecs.register_error() is also valid.

The standard names include:

• 'strict' to raise a ValueError exception if there is an encoding error. The default value of None

has the same effect.

• 'ignore' ignores errors. Note that ignoring encoding errors can lead to data loss.

• 'replace' causes a replacement marker (such as '?') to be inserted where there is malformed data.

• 'surrogateescape' will represent any incorrect bytes as low surrogate code units ranging from

U+DC80 to U+DCFF. These surrogate code units will then be turned back into the same bytes when the surrogateescape error handler is used when writing data. This is useful for processing files in an unknown encoding.

• 'xmlcharrefreplace' is only supported when writing to a file. Characters not supported by the

encoding are replaced with the appropriate XML character reference &#nnn;.

• 'backslashreplace' replaces malformed data by Python’s backslashed escape sequences.

The Python Library Reference, Release 3.13.2



• 'namereplace' (also only supported when writing) replaces unsupported characters with \N{...}

escape sequences.

newline determines how to parse newline characters from the stream. It can be None, '', '\n', '\r', and

'\r\n' . It works as follows:

• When reading input from the stream, if newline is None, universal newlines mode is enabled. Lines in

the input can end in '\n', '\r', or '\r\n', and these are translated into '\n' before being returned to the caller. If it is '', universal newlines mode is enabled, but line endings are returned to the caller untranslated. If it has any of the other legal values, input lines are only terminated by the given string, and the line ending is returned to the caller untranslated.

• When writing output to the stream, if newline is None, any '\n' characters written are translated to

the system default line separator, os.linesep. If newline is '' or '\n', no translation takes place. If newline is any of the other legal values, any '\n' characters written are translated to the given string.

If closefd is False and a file descriptor rather than a filename was given, the underlying file descriptor will be

kept open when the file is closed. If a filename is given closefd must be True (the default); otherwise, an error

will be raised.

A custom opener can be used by passing a callable as opener. The underlying file descriptor for the file object is

then obtained by calling opener with (file, flags). opener must return an open file descriptor (passing os.open

as opener results in functionality similar to passing None).

The newly created file is non-inheritable.

The following example uses the dir_fd parameter of the os.open() function to open a file relative to a given

directory:

>>> import os

>>> dir_fd = os.open('somedir', os.O_RDONLY)

>>> def opener(path, flags):

... return os.open(path, flags, dir_fd=dir_fd)

...

>>> with open('spamspam.txt', 'w', opener=opener) as f:

... print('This will be written to somedir/spamspam.txt', file=f)

...

>>> os.close(dir_fd) # don't leak a file descriptor



The type of file object returned by the open() function depends on the mode. When open() is used to open

a file in a text mode ('w', 'r', 'wt', 'rt', etc.), it returns a subclass of io.TextIOBase (specifically io.

TextIOWrapper ). When used to open a file in a binary mode with buffering, the returned class is a subclass

of io.BufferedIOBase. The exact class varies: in read binary mode, it returns an io.BufferedReader;

in write binary and append binary modes, it returns an io.BufferedWriter, and in read/write mode, it

returns an io.BufferedRandom. When buffering is disabled, the raw stream, a subclass of io.RawIOBase,

io.FileIO, is returned.

See also the file handling modules, such as fileinput, io (where open() is declared), os, os.path,

tempfile, and shutil.

Raises an auditing event open with arguments path, mode, flags.

The mode and flags arguments may have been modified or inferred from the original call.

Changed in version 3.3:

• The opener parameter was added.

• The 'x' mode was added.

• IOError used to be raised, it is now an alias of OSError.

• FileExistsError is now raised if the file opened in exclusive creation mode ('x') already exists.

Changed in version 3.4:

• The file is now non-inheritable.

The Python Library Reference, Release 3.13.2



Changed in version 3.5:

• If the system call is interrupted and the signal handler does not raise an exception, the function now retries

the system call instead of raising an InterruptedError exception (see PEP 475 for the rationale).

• The 'namereplace' error handler was added.

Changed in version 3.6:

• Support added to accept objects implementing os.PathLike.

• On Windows, opening a console buffer may return a subclass of io.RawIOBase other than io.FileIO.

Changed in version 3.11: The 'U' mode has been removed.

ord(c)

Given a string representing one Unicode character, return an integer representing the Unicode code point of

that character. For example, ord('a') returns the integer 97 and ord('€') (Euro sign) returns 8364. This

is the inverse of chr().

pow(base, exp, mod=None)

Return base to the power exp; if mod is present, return base to the power exp, modulo mod (computed more

efficiently than pow(base, exp) % mod). The two-argument form pow(base, exp) is equivalent to using

the power operator: base**exp.

The arguments must have numeric types. With mixed operand types, the coercion rules for binary arithmetic

operators apply. For int operands, the result has the same type as the operands (after coercion) unless the

second argument is negative; in that case, all arguments are converted to float and a float result is delivered.

For example, pow(10, 2) returns 100, but pow(10, -2) returns 0.01. For a negative base of type int

or float and a non-integral exponent, a complex result is delivered. For example, pow(-9, 0.5) returns a

value close to 3j. Whereas, for a negative base of type int or float with an integral exponent, a float result

is delivered. For example, pow(-9, 2.0) returns 81.0.

For int operands base and exp, if mod is present, mod must also be of integer type and mod must be nonzero.

If mod is present and exp is negative, base must be relatively prime to mod. In that case, pow(inv_base,

-exp, mod) is returned, where inv_base is an inverse to base modulo mod.

Here’s an example of computing an inverse for 38 modulo 97:

>>> pow(38,-1, mod=97)

23

>>> 23 * 38 % 97 == 1

True



Changed in version 3.8: For int operands, the three-argument form of pow now allows the second argument

to be negative, permitting computation of modular inverses.

Changed in version 3.8: Allow keyword arguments. Formerly, only positional arguments were supported.

print(*objects, sep=’ ’, end=’\n’, file=None, flush=False)

Print objects to the text stream file, separated by sep and followed by end. sep, end, file, and flush, if present,

must be given as keyword arguments.

All non-keyword arguments are converted to strings like str() does and written to the stream, separated by

sep and followed by end. Both sep and end must be strings; they can also be None, which means to use the

default values. If no objects are given, print() will just write end.

The file argument must be an object with a write(string) method; if it is not present or None, sys.

stdout will be used. Since printed arguments are converted to text strings, print() cannot be used with

binary mode file objects. For these, use file.write(...) instead.

Output buffering is usually determined by file. However, if flush is true, the stream is forcibly flushed.

Changed in version 3.3: Added the flush keyword argument.

The Python Library Reference, Release 3.13.2



class property(fget=None, fset=None, fdel=None, doc=None)

Return a property attribute.

fget is a function for getting an attribute value. fset is a function for setting an attribute value. fdel is a function

for deleting an attribute value. And doc creates a docstring for the attribute.

A typical use is to define a managed attribute x:

class C:

def __init__(self):

self._x = None

def getx(self):

return self._x

def setx(self, value):

self._x = value

def delx(self):

del self._x

x = property(getx, setx, delx, "I'm the 'x' property.")



If c is an instance of C, c.x will invoke the getter, c.x = value will invoke the setter, and del c.x the

deleter.

If given, doc will be the docstring of the property attribute. Otherwise, the property will copy fget’s docstring

(if it exists). This makes it possible to create read-only properties easily using property() as a decorator:

class Parrot:

def __init__(self):

self._voltage = 100000

@property

def voltage(self):

"""Get the current voltage."""

return self._voltage



The @property decorator turns the voltage() method into a “getter” for a read-only attribute with the same

name, and it sets the docstring for voltage to “Get the current voltage.”

@getter

@setter

@deleter

A property object has getter, setter, and deleter methods usable as decorators that create a copy of the property with the corresponding accessor function set to the decorated function. This is best explained with an example:

class C:

def __init__(self):

self._x = None

@property

def x(self):

"""I'm the 'x' property."""

return self._x

@x.setter

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

def x(self, value):

self._x = value

@x.deleter

def x(self):

del self._x



This code is exactly equivalent to the first example. Be sure to give the additional functions the same name as the original property (x in this case.)

The returned property object also has the attributes fget, fset, and fdel corresponding to the con-structor arguments.

Changed in version 3.5: The docstrings of property objects are now writeable.

__name__

Attribute holding the name of the property. The name of the property can be changed at runtime.

Added in version 3.13.

class range(stop)

class range(start, stop, step=1)

Rather than being a function, range is actually an immutable sequence type, as documented in Ranges and

Sequence Types — list, tuple, range.

repr(object)

Return a string containing a printable representation of an object. For many types, this function makes an

attempt to return a string that would yield an object with the same value when passed to eval(); otherwise,

the representation is a string enclosed in angle brackets that contains the name of the type of the object together

with additional information often including the name and address of the object. A class can control what

this function returns for its instances by defining a __repr__() method. If sys.displayhook() is not

accessible, this function will raise RuntimeError.

This class has a custom representation that can be evaluated:

class Person:

def __init__(self, name, age):

self.name = name

self.age = age

def __repr__(self):

return f"Person('{self.name}', {self.age})"



reversed(seq)

Return a reverse iterator. seq must be an object which has a __reversed__() method or supports the se-

quence protocol (the __len__() method and the __getitem__() method with integer arguments starting

at 0).

round(number, ndigits=None)

Return number rounded to ndigits precision after the decimal point. If ndigits is omitted or is None, it returns

the nearest integer to its input.

For the built-in types supporting round(), values are rounded to the closest multiple of 10 to the power

minus ndigits; if two multiples are equally close, rounding is done toward the even choice (so, for example,

both round(0.5) and round(-0.5) are 0, and round(1.5) is 2). Any integer value is valid for ndigits

(positive, zero, or negative). The return value is an integer if ndigits is omitted or None. Otherwise, the return

value has the same type as number.

For a general Python object number, round delegates to number.__round__.

The Python Library Reference, Release 3.13.2



® Note

The behavior of round() for floats can be surprising: for example, round(2.675, 2) gives 2.67 instead of the expected 2.68. This is not a bug: it’s a result of the fact that most decimal fractions can’t be represented exactly as a float. See tut-fp-issues for more information.



class set

class set(iterable)

Return a new set object, optionally with elements taken from iterable. set is a built-in class. See set and

Set Types — set, frozenset for documentation about this class.

For other containers see the built-in frozenset, list, tuple, and dict classes, as well as the

collections module.

setattr( object, name, value)

This is the counterpart of getattr(). The arguments are an object, a string, and an arbitrary value. The string

may name an existing attribute or a new attribute. The function assigns the value to the attribute, provided the

object allows it. For example, setattr(x, 'foobar', 123) is equivalent to x.foobar = 123.

name need not be a Python identifier as defined in identifiers unless the object chooses to enforce that, for

example in a custom __getattribute__() or via __slots__. An attribute whose name is not an identifier

will not be accessible using the dot notation, but is accessible through getattr() etc..



® Note

Since private name mangling happens at compilation time, one must manually mangle a private attribute’s

(attributes with two leading underscores) name in order to set it with setattr().



class slice(stop)

class slice(start, stop, step=None)

Return a slice object representing the set of indices specified by range(start, stop, step). The start

and step arguments default to None.

start

stop

step

Slice objects have read-only data attributes start, stop, and step which merely return the argument values (or their default). They have no other explicit functionality; however, they are used by NumPy and other third-party packages.

Slice objects are also generated when extended indexing syntax is used. For example: a[start:stop:step]

or a[start:stop, i]. See itertools.islice() for an alternate version that returns an iterator.

Changed in version 3.12: Slice objects are now hashable (provided start, stop, and step are hashable).

sorted(iterable, / , *, key=None, reverse=False)

Return a new sorted list from the items in iterable.

Has two optional arguments which must be specified as keyword arguments.

key specifies a function of one argument that is used to extract a comparison key from each element in iterable

(for example, key=str.lower). The default value is None (compare the elements directly).

reverse is a boolean value. If set to True, then the list elements are sorted as if each comparison were reversed.

Use functools.cmp_to_key() to convert an old-style cmp function to a key function.



The Python Library Reference, Release 3.13.2



The built-in sorted() function is guaranteed to be stable. A sort is stable if it guarantees not to change the

relative order of elements that compare equal — this is helpful for sorting in multiple passes (for example, sort

by department, then by salary grade).

The sort algorithm uses only < comparisons between items. While defining an __lt__() method will suffice

for sorting, PEP 8 recommends that all six rich comparisons be implemented. This will help avoid bugs when

using the same data with other ordering tools such as max() that rely on a different underlying method. Im-

plementing all six comparisons also helps avoid confusion for mixed type comparisons which can call reflected

the __gt__() method.

For sorting examples and a brief sorting tutorial, see sortinghowto.

@staticmethod

Transform a method into a static method.

A static method does not receive an implicit first argument. To declare a static method, use this idiom:

class C:

@staticmethod

def f(arg1, arg2, argN): ...



The @staticmethod form is a function decorator – see function for details.

A static method can be called either on the class (such as C.f()) or on an instance (such as C().f()).

Moreover, the static method descriptor is also callable, so it can be used in the class definition (such as f()).

Static methods in Python are similar to those found in Java or C++. Also, see classmethod() for a variant

that is useful for creating alternate class constructors.

Like all decorators, it is also possible to call staticmethod as a regular function and do something with its

result. This is needed in some cases where you need a reference to a function from a class body and you want

to avoid the automatic transformation to instance method. For these cases, use this idiom:

def regular_function():

...

class C:

method = staticmethod(regular_function)



For more information on static methods, see types.

Changed in version 3.10: Static methods now inherit the method attributes (__module__, __name__,

__qualname__, __doc__ and __annotations__), have a new __wrapped__ attribute, and are now

callable as regular functions.

class str(object=”)

class str(object=b”, encoding=’utf-8’, errors=’strict’)

Return a str version of object. See str() for details.

str is the built-in string class. For general information about strings, see Text Sequence Type — str.

sum(iterable, / , start=0)

Sums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally

numbers, and the start value is not allowed to be a string.

For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of

strings is by calling ''.join(sequence). To add floating-point values with extended precision, see math.

fsum() . To concatenate a series of iterables, consider using itertools.chain().

Changed in version 3.8: The start parameter can be specified as a keyword argument.

Changed in version 3.12: Summation of floats switched to an algorithm that gives higher accuracy and better

commutativity on most builds.

class super

The Python Library Reference, Release 3.13.2



class super(type, object_or_type=None)

Return a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing

inherited methods that have been overridden in a class.

The object_or_type determines the method resolution order to be searched. The search starts from the class

right after the type.

For example, if __mro__ of object_or_type is D -> B -> C -> A -> object and the value of type is B,

then super() searches C -> A -> object.

The __mro__ attribute of the class corresponding to object_or_type lists the method resolution search order

used by both getattr() and super(). The attribute is dynamic and can change whenever the inheritance

hierarchy is updated.

If the second argument is omitted, the super object returned is unbound. If the second argument is an object,

isinstance(obj, type) must be true. If the second argument is a type, issubclass(type2, type)

must be true (this is useful for classmethods).

When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument

super() ”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately

enclosing function (typically self). (This means that zero-argument super() will not work as expected

within nested functions, including generator expressions, which implicitly create nested functions.)

There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer

to parent classes without naming them explicitly, thus making the code more maintainable. This use closely

parallels the use of super in other programming languages.

The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This

use case is unique to Python and is not found in statically compiled languages or languages that only support

single inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes im-

plement the same method. Good design dictates that such implementations have the same calling signature in

every case (because the order of calls is determined at runtime, because that order adapts to changes in the

class hierarchy, and because that order can include sibling classes that are unknown prior to runtime).

For both use cases, a typical superclass call looks like this:

class C(B):

def method(self, arg):

super().method(arg) # This does the same thing as:

# super(C, self).method(arg)



In addition to method lookups, super() also works for attribute lookups. One possible use case for this is

calling descriptors in a parent or sibling class.

Note that super() is implemented as part of the binding process for explicit dotted attribute lookups such as

super().__getitem__(name). It does so by implementing its own __getattribute__() method for

searching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, super()

is undefined for implicit lookups using statements or operators such as super()[name].

Also note that, aside from the zero argument form, super() is not limited to use inside methods. The two

argument form specifies the arguments exactly and makes the appropriate references. The zero argument form

only works inside a class definition, as the compiler fills in the necessary details to correctly retrieve the class

being defined, as well as accessing the current instance for ordinary methods.

For practical suggestions on how to design cooperative classes using super(), see guide to using super().

class tuple

class tuple(iterable)

Rather than being a function, tuple is actually an immutable sequence type, as documented in Tuples and

Sequence Types — list, tuple, range.

class type(object)

The Python Library Reference, Release 3.13.2



class type(name, bases, dict, **kwds)

With one argument, return the type of an object. The return value is a type object and generally the same object

as returned by object.__class__.

The isinstance() built-in function is recommended for testing the type of an object, because it takes sub-

classes into account.

With three arguments, return a new type object. This is essentially a dynamic form of the class statement.

The name string is the class name and becomes the __name__ attribute. The bases tuple contains the base

classes and becomes the __bases__ attribute; if empty, object, the ultimate base of all classes, is added.

The dict dictionary contains attribute and method definitions for the class body; it may be copied or wrapped

before becoming the __dict__ attribute. The following two statements create identical type objects:

>>> class X:

... a = 1

...

>>> X = type('X', (), dict(a=1))



See also:

• Documentation on attributes and methods on classes.

• Type Objects

Keyword arguments provided to the three argument form are passed to the appropriate metaclass machinery

(usually __init_subclass__()) in the same way that keywords in a class definition (besides metaclass)

would.

See also class-customization.

Changed in version 3.6: Subclasses of type which don’t override type.__new__ may no longer use the

one-argument form to get the type of an object.

vars()

vars(object)

Return the __dict__ attribute for a module, class, instance, or any other object with a __dict__ attribute.

Objects such as modules and instances have an updateable __dict__ attribute; however, other objects may

have write restrictions on their __dict__ attributes (for example, classes use a types.MappingProxyType

to prevent direct dictionary updates).

Without an argument, vars() acts like locals().

A TypeError exception is raised if an object is specified but it doesn’t have a __dict__ attribute (for example,

if its class defines the __slots__ attribute).

Changed in version 3.13: The result of calling this function without an argument has been updated as described

for the locals() builtin.

zip(*iterables, strict=False)

Iterate over several iterables in parallel, producing tuples with an item from each one.

Example:

>>> for item in zip([1, 2, 3], ['sugar', 'spice', 'everything nice']):

... print(item)

...

(1, 'sugar')

(2, 'spice')

(3, 'everything nice')



More formally: zip() returns an iterator of tuples, where the i-th tuple contains the i-th element from each

of the argument iterables.

The Python Library Reference, Release 3.13.2



Another way to think of zip() is that it turns rows into columns, and columns into rows. This is similar to

transposing a matrix.

zip() is lazy: The elements won’t be processed until the iterable is iterated on, e.g. by a for loop or by

wrapping in a list.

One thing to consider is that the iterables passed to zip() could have different lengths; sometimes by de-

sign, and sometimes because of a bug in the code that prepared these iterables. Python offers three different

approaches to dealing with this issue:

• By default, zip() stops when the shortest iterable is exhausted. It will ignore the remaining items in the

longer iterables, cutting off the result to the length of the shortest iterable:

>>> list(zip(range(3), ['fee', 'fi', 'fo', 'fum']))

[(0, 'fee'), (1, 'fi'), (2, 'fo')]



• zip() is often used in cases where the iterables are assumed to be of equal length. In such cases, it’s

recommended to use the strict=True option. Its output is the same as regular zip():

>>> list(zip(('a', 'b', 'c'), (1, 2, 3), strict=True))

[('a', 1), ('b', 2), ('c', 3)]



Unlike the default behavior, it raises a ValueError if one iterable is exhausted before the others:

>>> for item in zip(range(3), ['fee', 'fi', 'fo', 'fum'], strict=True): ... print(item)

...

(0, 'fee')

(1, 'fi')

(2, 'fo')

Traceback (most recent call last):

...

ValueError: zip() argument 2 is longer than argument 1



Without the strict=True argument, any bug that results in iterables of different lengths will be silenced, possibly manifesting as a hard-to-find bug in another part of the program.

• Shorter iterables can be padded with a constant value to make all the iterables have the same length. This

is done by itertools.zip_longest().

Edge cases: With a single iterable argument, zip() returns an iterator of 1-tuples. With no arguments, it

returns an empty iterator.

Tips and tricks:

• The left-to-right evaluation order of the iterables is guaranteed. This makes possible an idiom for clus-

tering a data series into n-length groups using zip(*[iter(s)]*n, strict=True). This repeats the same iterator n times so that each output tuple has the result of n calls to the iterator. This has the effect of dividing the input into n-length chunks.

• zip() in conjunction with the * operator can be used to unzip a list:

>>> x = [1, 2, 3]

>>> y = [4, 5, 6]

>>> list(zip(x, y))

[(1, 4), (2, 5), (3, 6)]

>>> x2, y2 = zip(*zip(x, y))

>>> x == list(x2) and y == list(y2)

True



Changed in version 3.10: Added the strict argument.

The Python Library Reference, Release 3.13.2



__import__(name, globals=None, locals=None, fromlist=(), level=0)



® Note

This is an advanced function that is not needed in everyday Python programming, unlike importlib.

import_module().



This function is invoked by the import statement. It can be replaced (by importing the builtins module

and assigning to builtins.__import__) in order to change semantics of the import statement, but doing

so is strongly discouraged as it is usually simpler to use import hooks (see PEP 302) to attain the same goals

and does not cause issues with code which assumes the default import implementation is in use. Direct use of

__import__() is also discouraged in favor of importlib.import_module().

The function imports the module name, potentially using the given globals and locals to determine how to

interpret the name in a package context. The fromlist gives the names of objects or submodules that should be

imported from the module given by name. The standard implementation does not use its locals argument at

all and uses its globals only to determine the package context of the import statement.

level specifies whether to use absolute or relative imports. 0 (the default) means only perform absolute imports.

Positive values for level indicate the number of parent directories to search relative to the directory of the

module calling __import__() (see PEP 328 for the details).

When the name variable is of the form package.module, normally, the top-level package (the name up till

the first dot) is returned, not the module named by name. However, when a non-empty fromlist argument is

given, the module named by name is returned.

For example, the statement import spam results in bytecode resembling the following code:

spam = __import__('spam', globals(), locals(), [], 0)



The statement import spam.ham results in this call:

spam = __import__('spam.ham', globals(), locals(), [], 0)



Note how __import__() returns the toplevel module here because this is the object that is bound to a name

by the import statement.

On the other hand, the statement from spam.ham import eggs, sausage as saus results in

_temp = __import__('spam.ham', globals(), locals(), ['eggs', 'sausage'], 0)

eggs = _temp.eggs

saus = _temp.sausage



Here, the spam.ham module is returned from __import__(). From this object, the names to import are

retrieved and assigned to their respective names.

If you simply want to import a module (potentially within a package) by name, use importlib.

import_module().

Changed in version 3.3: Negative values for level are no longer supported (which also changes the default value

to 0).

Changed in version 3.9: When the command line options-E or-I are being used, the environment variable

PYTHONCASEOK is now ignored.



The Python Library Reference, Release 3.13.2





CHAPTER




THREE



BUILT-IN CONSTANTS



A small number of constants live in the built-in namespace. They are:

False

The false value of the bool type. Assignments to False are illegal and raise a SyntaxError.

True

The true value of the bool type. Assignments to True are illegal and raise a SyntaxError.

None

An object frequently used to represent the absence of a value, as when default arguments are not passed to

a function. Assignments to None are illegal and raise a SyntaxError. None is the sole instance of the

NoneType type.

NotImplemented

A special value which should be returned by the binary special methods (e.g. __eq__(), __lt__(),

__add__(), __rsub__(), etc.) to indicate that the operation is not implemented with respect to the other

type; may be returned by the in-place binary special methods (e.g. __imul__(), __iand__(), etc.) for the

same purpose. It should not be evaluated in a boolean context. NotImplemented is the sole instance of the

types.NotImplementedType type.



® Note

When a binary (or in-place) method returns NotImplemented the interpreter will try the reflected operation on the other type (or some other fallback, depending on the operator). If all attempts

return NotImplemented, the interpreter will raise an appropriate exception. Incorrectly returning NotImplemented will result in a misleading error message or the NotImplemented value being re-turned to Python code.

See Implementing the arithmetic operations for examples.



® Note

NotImplementedError and NotImplemented are not interchangeable, even though they have similar

names and purposes. See NotImplementedError for details on when to use it.



Changed in version 3.9: Evaluating NotImplemented in a boolean context is deprecated. While it currently

evaluates as true, it will emit a DeprecationWarning. It will raise a TypeError in a future version of

Python.

Ellipsis

The same as the ellipsis literal “...”. Special value used mostly in conjunction with extended slicing syntax

for user-defined container data types. Ellipsis is the sole instance of the types.EllipsisType type.

__debug__

This constant is true if Python was not started with an-O option. See also the assert statement.





The Python Library Reference, Release 3.13.2




® Note

The names None, False, True and __debug__ cannot be reassigned (assignments to them, even as an attribute

name, raise SyntaxError), so they can be considered “true” constants.



3.1 Constants added by the site module

The site module (which is imported automatically during startup, except if the-S command-line option is given) adds several constants to the built-in namespace. They are useful for the interactive interpreter shell and should not be used in programs.

quit(code=None)

exit(code=None)

Objects that when printed, print a message like “Use quit() or Ctrl-D (i.e. EOF) to exit”, and when called,

raise SystemExit with the specified exit code.

help

Object that when printed, prints the message “Type help() for interactive help, or help(object) for help about

object.”, and when called, acts as described elsewhere.

copyright

credits

Objects that when printed or called, print the text of copyright or credits, respectively.

license

Object that when printed, prints the message “Type license() to see the full license text”, and when called,

displays the full license text in a pager-like fashion (one screen at a time).





CHAPTER




FOUR



BUILT-IN TYPES



The following sections describe the standard types that are built into the interpreter.

The principal built-in types are numerics, sequences, mappings, classes, instances and exceptions.

Some collection classes are mutable. The methods that add, subtract, or rearrange their members in place, and don’t return a specific item, never return the collection instance itself but None.

Some operations are supported by several object types; in particular, practically all objects can be compared for

equality, tested for truth value, and converted to a string (with the repr() function or the slightly different str()

function). The latter function is implicitly used when an object is written by the print() function.



4.1 Truth Value Testing

Any object can be tested for truth value, for use in an if or while condition or as operand of the Boolean operations below.

By default, an object is considered true unless its class defines either a __bool__() method that returns False or a

__len__() 1 method that returns zero, when called with the object. Here are most of the built-in objects considered false:

• constants defined to be false: None and False

• zero of any numeric type: 0, 0.0, 0j, Decimal(0), Fraction(0, 1)

• empty sequences and collections: '', (), [], {}, set(), range(0)

Operations and built-in functions that have a Boolean result always return 0 or False for false and 1 or True for true, unless otherwise stated. (Important exception: the Boolean operations or and and always return one of their operands.)



4.2 Boolean Operations — and, or, not

These are the Boolean operations, ordered by ascending priority:



Operation Result Notes

x or y if x is true, then x, else y (1)

x and y if x is false, then x, else y (2)

not x if x is false, then True, else False (3)



Notes:

(1) This is a short-circuit operator, so it only evaluates the second argument if the first one is false.

(2) This is a short-circuit operator, so it only evaluates the second argument if the first one is true.

1 Additional information on these special methods may be found in the Python Reference Manual (customization).





The Python Library Reference, Release 3.13.2




(3) not has a lower priority than non-Boolean operators, so not a == b is interpreted as not (a == b), and

a == not b is a syntax error.



4.3 Comparisons

There are eight comparison operations in Python. They all have the same priority (which is higher than that of the Boolean operations). Comparisons can be chained arbitrarily; for example, x < y <= z is equivalent to x < y and y <= z, except that y is evaluated only once (but in both cases z is not evaluated at all when x < y is found to be false).

This table summarizes the comparison operations:



Operation Meaning

< strictly less than

<= less than or equal

> strictly greater than

>= greater than or equal

== equal

!= not equal

is object identity

is not negated object identity



Objects of different types, except different numeric types, never compare equal. The == operator is always defined but for some object types (for example, class objects) is equivalent to is. The <, <=, > and >= operators are only

defined where they make sense; for example, they raise a TypeError exception when one of the arguments is a complex number.

Non-identical instances of a class normally compare as non-equal unless the class defines the __eq__() method.

Instances of a class cannot be ordered with respect to other instances of the same class, or other types of object, unless the class defines enough of the methods __lt__(), __le__(), __gt__(), and __ge__() (in general, __lt__() and __eq__() are sufficient, if you want the conventional meanings of the comparison operators).

The behavior of the is and is not operators cannot be customized; also they can be applied to any two objects and never raise an exception.

Two more operations with the same syntactic priority, in and not in, are supported by types that are iterable or implement the __contains__() method.



4.4 Numeric Types — int, float, complex

There are three distinct numeric types: integers, floating-point numbers, and complex numbers. In addition, Booleans are a subtype of integers. Integers have unlimited precision. Floating-point numbers are usually implemented using double in C; information about the precision and internal representation of floating-point numbers for the machine

on which your program is running is available in sys.float_info. Complex numbers have a real and imaginary part, which are each a floating-point number. To extract these parts from a complex number z, use z.real and

z.imag. (The standard library includes the additional numeric types fractions.Fraction, for rationals, and

decimal.Decimal, for floating-point numbers with user-definable precision.)

Numbers are created by numeric literals or as the result of built-in functions and operators. Unadorned integer literals (including hex, octal and binary numbers) yield integers. Numeric literals containing a decimal point or an exponent sign yield floating-point numbers. Appending 'j' or 'J' to a numeric literal yields an imaginary number (a complex number with a zero real part) which you can add to an integer or float to get a complex number with real and imaginary parts.

Python fully supports mixed arithmetic: when a binary arithmetic operator has operands of different numeric types, the operand with the “narrower” type is widened to that of the other, where integer is narrower than floating point,

The Python Library Reference, Release 3.13.2



which is narrower than complex. A comparison between numbers of different types behaves as though the exact

values of those numbers were being compared.2

The constructors int(), float(), and complex() can be used to produce numbers of a specific type.

All numeric types (except complex) support the following operations (for priorities of the operations, see operator-summary):



Operation Result Notes Full documen-

tation

x + y sum of x and y

x - y difference of x and y

x * y product of x and y

x / y quotient of x and y

x // y floored quotient of x and y (1)(2)

x % y remainder of x / y (2)

-x x negated

+x x unchanged

abs(x) absolute value or magnitude of x abs()

int(x) x converted to integer (3)(6) int()

float(x) x converted to floating point (4)(6) float()

complex(re, a complex number with real part re, imaginary part im. im de- (6) complex()

im) faults to zero.

c. conjugate of the complex number c

conjugate()

divmod(x, y) the pair (x // y, x % y) (2) divmod()

pow(x, y) x to the power y (5) pow()

x ** y x to the power y (5)



Notes:

(1) Also referred to as integer division. For operands of type int, the result has type int. For operands of type

float , the result has type float. In general, the result is a whole integer, though the result’s type is not

necessarily int. The result is always rounded towards minus infinity: 1//2 is 0, (-1)//2 is-1, 1//(-2) is

-1, and (-1)//(-2) is 0.

(2) Not for complex numbers. Instead convert to floats using abs() if appropriate.

(3) Conversion from float to int truncates, discarding the fractional part. See functions math.floor() and

math.ceil() for alternative conversions.

(4) float also accepts the strings “nan” and “inf” with an optional prefix “+” or “-” for Not a Number (NaN) and

positive or negative infinity.

(5) Python defines pow(0, 0) and 0 ** 0 to be 1, as is common for programming languages.

(6) The numeric literals accepted include the digits 0 to 9 or any Unicode equivalent (code points with the Nd

property).

See the Unicode Standard for a complete list of code points with the Nd property.

All numbers.Real types (int and float) also include the following operations:



Operation Result

math.trunc(x) x truncated to Integral

round(x[, n]) x rounded to n digits, rounding half to even. If n is omitted, it defaults to 0.

math.floor(x) the greatest Integral <= x

math.ceil(x) the least Integral >= x

2 As a consequence, the list [1, 2] is considered equal to [1.0, 2.0], and similarly for tuples.





The Python Library Reference, Release 3.13.2




For additional numeric operations see the math and cmath modules.



4.4.1 Bitwise Operations on Integer Types

Bitwise operations only make sense for integers. The result of bitwise operations is calculated as though carried out in two’s complement with an infinite number of sign bits.

The priorities of the binary bitwise operations are all lower than the numeric operations and higher than the compar-isons; the unary operation ~ has the same priority as the other unary numeric operations (+ and-).

This table lists the bitwise operations sorted in ascending priority:



Operation Result Notes

x | y bitwise or of x and y (4)

x ^ y bitwise exclusive or of x and y (4)

x & y bitwise and of x and y (4)

x << n x shifted left by n bits (1)(2)

x >> n x shifted right by n bits (1)(3)

~x the bits of x inverted



Notes:

(1) Negative shift counts are illegal and cause a ValueError to be raised.

(2) A left shift by n bits is equivalent to multiplication by pow(2, n).

(3) A right shift by n bits is equivalent to floor division by pow(2, n).

(4) Performing these calculations with at least one extra sign extension bit in a finite two’s complement represen-

tation (a working bit-width of 1 + max(x.bit_length(), y.bit_length()) or more) is sufficient to

get the same result as if there were an infinite number of sign bits.



4.4.2 Additional Methods on Integer Types

The int type implements the numbers.Integral abstract base class. In addition, it provides a few more methods:

int.bit_length()

Return the number of bits necessary to represent an integer in binary, excluding the sign and leading zeros:

>>> n = -37

>>> bin(n)

'-0b100101'

>>> n.bit_length()

6



More precisely, if x is nonzero, then x.bit_length() is the unique positive integer k such that 2**(k-1)

<= abs(x) < 2**k. Equivalently, when abs(x) is small enough to have a correctly rounded logarithm,

then k = 1 + int(log(abs(x), 2)). If x is zero, then x.bit_length() returns 0.

Equivalent to:

def bit_length(self):

s = bin(self) # binary representation: bin(-37) --> '-0b100101' s = s.lstrip('-0b') # remove leading zeros and minus sign return len(s) # len('100101') --> 6



Added in version 3.1.

int.bit_count()

Return the number of ones in the binary representation of the absolute value of the integer. This is also known

as the population count. Example:

The Python Library Reference, Release 3.13.2



>>> n = 19

>>> bin(n)

'0b10011'

>>> n.bit_count()

3

>>> (-n).bit_count()

3



Equivalent to:

def bit_count(self):

return bin(self).count("1")



Added in version 3.10.

int.to_bytes(length=1, byteorder=’big’, *, signed=False)

Return an array of bytes representing an integer.

>>> (1024).to_bytes(2, byteorder='big')

b'\x04\x00'

>>> (1024).to_bytes(10, byteorder='big')

b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'

>>> (-1024).to_bytes(10, byteorder='big', signed=True)

b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'

>>> x = 1000

>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')

b'\xe8\x03'



The integer is represented using length bytes, and defaults to 1. An OverflowError is raised if the integer is

not representable with the given number of bytes.

The byteorder argument determines the byte order used to represent the integer, and defaults to "big". If

byteorder is "big", the most significant byte is at the beginning of the byte array. If byteorder is "little",

the most significant byte is at the end of the byte array.

The signed argument determines whether two’s complement is used to represent the integer. If signed is False

and a negative integer is given, an OverflowError is raised. The default value for signed is False.

The default values can be used to conveniently turn an integer into a single byte object:

>>> (65).to_bytes()

b'A'



However, when using the default arguments, don’t try to convert a value greater than 255 or you’ll get an

OverflowError .

Equivalent to:

def to_bytes(n, length=1, byteorder='big', signed=False):

if byteorder == 'little':

order = range(length)

elif byteorder == 'big':

order = reversed(range(length))

else:

raise ValueError("byteorder must be either 'little' or 'big'")

return bytes((n >> i*8) & 0xff for i in order)



Added in version 3.2.

Changed in version 3.11: Added default argument values for length and byteorder.





The Python Library Reference, Release 3.13.2




classmethod int.from_bytes(bytes, byteorder=’big’, *, signed=False)

Return the integer represented by the given array of bytes.

>>> int.from_bytes(b'\x00\x10', byteorder='big')

16

>>> int.from_bytes(b'\x00\x10', byteorder='little')

4096

>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)

-1024

>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)

64512

>>> int.from_bytes([255, 0, 0], byteorder='big')

16711680



The argument bytes must either be a bytes-like object or an iterable producing bytes.

The byteorder argument determines the byte order used to represent the integer, and defaults to "big". If

byteorder is "big", the most significant byte is at the beginning of the byte array. If byteorder is "little",

the most significant byte is at the end of the byte array. To request the native byte order of the host system,

use sys.byteorder as the byte order value.

The signed argument indicates whether two’s complement is used to represent the integer.

Equivalent to:

def from_bytes(bytes, byteorder='big', signed=False):

if byteorder == 'little':

little_ordered = list(bytes)

elif byteorder == 'big':

little_ordered = list(reversed(bytes))

else:

raise ValueError("byteorder must be either 'little' or 'big'")

n = sum(b << i*8 for i, b in enumerate(little_ordered))

if signed and little_ordered and (little_ordered[-1] & 0x80):

n-= 1 << 8*len(little_ordered)

return n



Added in version 3.2.

Changed in version 3.11: Added default argument value for byteorder.

int.as_integer_ratio()

Return a pair of integers whose ratio is equal to the original integer and has a positive denominator. The integer

ratio of integers (whole numbers) is always the integer as the numerator and 1 as the denominator.

Added in version 3.8.

int.is_integer()

Returns True. Exists for duck type compatibility with float.is_integer().

Added in version 3.12.



4.4.3 Additional Methods on Float

The float type implements the numbers.Real abstract base class. float also has the following additional methods.

float.as_integer_ratio()

Return a pair of integers whose ratio is exactly equal to the original float. The ratio is in lowest terms and has

a positive denominator. Raises OverflowError on infinities and a ValueError on NaNs.





The Python Library Reference, Release 3.13.2




float.is_integer()

Return True if the float instance is finite with integral value, and False otherwise:

>>> (-2.0).is_integer()

True

>>> (3.2).is_integer()

False



Two methods support conversion to and from hexadecimal strings. Since Python’s floats are stored internally as binary numbers, converting a float to or from a decimal string usually involves a small rounding error. In contrast, hexadecimal strings allow exact representation and specification of floating-point numbers. This can be useful when debugging, and in numerical work.

float.hex()

Return a representation of a floating-point number as a hexadecimal string. For finite floating-point numbers,

this representation will always include a leading 0x and a trailing p and exponent.

classmethod float.fromhex(s)

Class method to return the float represented by a hexadecimal string s. The string s may have leading and

trailing whitespace.

Note that float.hex() is an instance method, while float.fromhex() is a class method.

A hexadecimal string takes the form:

[sign] ['0x'] integer ['.' fraction] ['p' exponent]



where the optional sign may by either + or-, integer and fraction are strings of hexadecimal digits, and exponent is a decimal integer with an optional leading sign. Case is not significant, and there must be at least one hexadecimal digit in either the integer or the fraction. This syntax is similar to the syntax specified in section 6.4.4.2

of the C99 standard, and also to the syntax used in Java 1.5 onwards. In particular, the output of float.hex() is usable as a hexadecimal floating-point literal in C or Java code, and hexadecimal strings produced by C’s %a format

character or Java’s Double.toHexString are accepted by float.fromhex().

Note that the exponent is written in decimal rather than hexadecimal, and that it gives the power of 2 by which to multiply the coefficient. For example, the hexadecimal string 0x3.a7p10 represents the floating-point number (3 + 10./16 + 7./16**2) * 2.0**10, or 3740.0:

>>> float.fromhex('0x3.a7p10')

3740.0



Applying the reverse conversion to 3740.0 gives a different hexadecimal string representing the same number:

>>> float.hex(3740.0)

'0x1.d380000000000p+11'



4.4.4 Hashing of numeric types

For numbers x and y, possibly of different types, it’s a requirement that hash(x) == hash(y) whenever x == y (see the __hash__() method documentation for more details). For ease of implementation and efficiency across a

variety of numeric types (including int, float, decimal.Decimal and fractions.Fraction) Python’s hash for numeric types is based on a single mathematical function that’s defined for any rational number, and hence applies

to all instances of int and fractions.Fraction, and all finite instances of float and decimal.Decimal. Essentially, this function is given by reduction modulo P for a fixed prime P. The value of P is made available to

Python as the modulus attribute of sys.hash_info.

CPython implementation detail: Currently, the prime used is P = 2**31 - 1 on machines with 32-bit C longs and P = 2**61 - 1 on machines with 64-bit C longs.

Here are the rules in detail:

The Python Library Reference, Release 3.13.2



• If x = m / n is a nonnegative rational number and n is not divisible by P, define hash(x) as m *

invmod(n, P) % P, where invmod(n, P) gives the inverse of n modulo P.

• If x = m / n is a nonnegative rational number and n is divisible by P (but m is not) then n has no inverse mod-

ulo P and the rule above doesn’t apply; in this case define hash(x) to be the constant value sys.hash_info.

inf .

• If x = m / n is a negative rational number define hash(x) as-hash(-x). If the resulting hash is-1,

replace it with-2.

• The particular values sys.hash_info.inf and-sys.hash_info.inf are used as hash values for positive

infinity or negative infinity (respectively).

• For a complex number z, the hash values of the real and imaginary parts are combined by computing

hash(z.real) + sys.hash_info.imag * hash(z.imag) , reduced modulo 2**sys.hash_info.

width so that it lies in range(-2**(sys.hash_info.width - 1), 2**(sys.hash_info.width -

1)) . Again, if the result is-1, it’s replaced with-2.

To clarify the above rules, here’s some example Python code, equivalent to the built-in hash, for computing the hash

of a rational number, float, or complex:

import sys, math

def hash_fraction(m, n):

"""Compute the hash of a rational number m / n.

Assumes m and n are integers, with n positive.

Equivalent to hash(fractions.Fraction(m, n)).

"""

P = sys.hash_info.modulus

# Remove common factors of P. (Unnecessary if m and n already coprime.)

while m % P == n % P == 0:

m, n = m // P, n // P

if n % P == 0:

hash_value = sys.hash_info.inf

else:

# Fermat's Little Theorem: pow(n, P-1, P) is 1, so # pow(n, P-2, P) gives the inverse of n modulo P.

hash_value = (abs(m) % P) * pow(n, P-2, P) % P

if m < 0:

hash_value = -hash_value

if hash_value == -1:

hash_value = -2

return hash_value

def hash_float(x):

"""Compute the hash of a float x."""

if math.isnan(x):

return object.__hash__(x)

elif math.isinf(x):

return sys.hash_info.inf if x > 0 else-sys.hash_info.inf

else:

return hash_fraction(*x.as_integer_ratio())

def hash_complex(z):

"""Compute the hash of a complex number z."""

(continues on next page)





The Python Library Reference, Release 3.13.2




(continued from previous page)

hash_value = hash_float(z.real) + sys.hash_info.imag * hash_float(z.imag)

# do a signed reduction modulo 2**sys.hash_info.width

M = 2**(sys.hash_info.width-1)

hash_value = (hash_value & (M-1))-(hash_value & M)

if hash_value == -1:

hash_value = -2

return hash_value



4.5 Boolean Type -bool

Booleans represent truth values. The bool type has exactly two constant instances: True and False.

The built-in function bool() converts any value to a boolean, if the value can be interpreted as a truth value (see

section Truth Value Testing above).

For logical operations, use the boolean operators and, or and not. When applying the bitwise operators &, |, ^ to two booleans, they return a bool equivalent to the logical operations “and”, “or”, “xor”. However, the logical operators and, or and != should be preferred over &, | and ^.

Deprecated since version 3.12: The use of the bitwise inversion operator ~ is deprecated and will raise an error in Python 3.16.

bool is a subclass of int (see Numeric Types — int, float, complex). In many numeric contexts, False and True

behave like the integers 0 and 1, respectively. However, relying on this is discouraged; explicitly convert using int() instead.



4.6 Iterator Types

Python supports a concept of iteration over containers. This is implemented using two distinct methods; these are used to allow user-defined classes to support iteration. Sequences, described below in more detail, always support the iteration methods.

One method needs to be defined for container objects to provide iterable support:

container.__iter__()

Return an iterator object. The object is required to support the iterator protocol described below. If a container

supports different types of iteration, additional methods can be provided to specifically request iterators for

those iteration types. (An example of an object supporting multiple forms of iteration would be a tree structure

which supports both breadth-first and depth-first traversal.) This method corresponds to the tp_iter slot of

the type structure for Python objects in the Python/C API.

The iterator objects themselves are required to support the following two methods, which together form the iterator protocol:

iterator.__iter__()

Return the iterator object itself. This is required to allow both containers and iterators to be used with the for

and in statements. This method corresponds to the tp_iter slot of the type structure for Python objects in

the Python/C API.

iterator.__next__()

Return the next item from the iterator. If there are no further items, raise the StopIteration exception.

This method corresponds to the tp_iternext slot of the type structure for Python objects in the Python/C

API.

Python defines several iterator objects to support iteration over general and specific sequence types, dictionaries, and other more specialized forms. The specific types are not important beyond their implementation of the iterator protocol.

Once an iterator’s __next__() method raises StopIteration, it must continue to do so on subsequent calls. Implementations that do not obey this property are deemed broken.





The Python Library Reference, Release 3.13.2




4.6.1 Generator Types

Python’s generators provide a convenient way to implement the iterator protocol. If a container object’s __iter__() method is implemented as a generator, it will automatically return an iterator object (technically, a generator object) supplying the __iter__() and __next__() methods. More information about generators can be found in the documentation for the yield expression.



4.7 Sequence Types — list, tuple, range

There are three basic sequence types: lists, tuples, and range objects. Additional sequence types tailored for process-

ing of binary data and text strings are described in dedicated sections.



4.7.1 Common Sequence Operations

The operations in the following table are supported by most sequence types, both mutable and immutable. The

collections.abc.Sequence ABC is provided to make it easier to correctly implement these operations on cus-tom sequence types.

This table lists the sequence operations sorted in ascending priority. In the table, s and t are sequences of the same type, n, i, j and k are integers and x is an arbitrary object that meets any type and value restrictions imposed by s.

The in and not in operations have the same priorities as the comparison operations. The + (concatenation) and *

(repetition) operations have the same priority as the corresponding numeric operations.3



Operation Result Notes

x in s True if an item of s is equal to x, else False (1)

x not in s False if an item of s is equal to x, else True (1)

s + t the concatenation of s and t (6)(7)

s * n or n * s equivalent to adding s to itself n times (2)(7)

s[i] ith item of s, origin 0 (3)

s[i:j] slice of s from i to j (3)(4)

s[i:j:k] slice of s from i to j with step k (3)(5)

len(s) length of s

min(s) smallest item of s

max(s) largest item of s

s.index(x[, i[, index of the first occurrence of x in s (at or after index i and before index (8)

j]]) j)

s.count(x) total number of occurrences of x in s



Sequences of the same type also support comparisons. In particular, tuples and lists are compared lexicographically by comparing corresponding elements. This means that to compare equal, every element must compare equal and the two sequences must be of the same type and have the same length. (For full details see comparisons in the language reference.)

Forward and reversed iterators over mutable sequences access values using an index. That index will continue to march forward (or backward) even if the underlying sequence is mutated. The iterator terminates only when an

IndexError or a StopIteration is encountered (or when the index drops below zero).

Notes:

(1) While the in and not in operations are used only for simple containment testing in the general case, some

specialised sequences (such as str, bytes and bytearray) also use them for subsequence testing:

>>> "gg" in "eggs"

True

3 They must have since the parser can’t tell the type of the operands.



The Python Library Reference, Release 3.13.2



(2) Values of n less than 0 are treated as 0 (which yields an empty sequence of the same type as s). Note that

items in the sequence s are not copied; they are referenced multiple times. This often haunts new Python

programmers; consider:

>>> lists = [[]] * 3

>>> lists

[[], [], []]

>>> lists[0].append(3)

>>> lists

[[3], [3], [3]]



What has happened is that [[]] is a one-element list containing an empty list, so all three elements of [[]]

* 3 are references to this single empty list. Modifying any of the elements of lists modifies this single list.

You can create a list of different lists this way:

>>> lists = [[] for i in range(3)]

>>> lists[0].append(3)

>>> lists[1].append(5)

>>> lists[2].append(7)

>>> lists

[[3], [5], [7]]



Further explanation is available in the FAQ entry faq-multidimensional-list.

(3) If i or j is negative, the index is relative to the end of sequence s: len(s) + i or len(s) + j is substituted.

But note that-0 is still 0.

(4) The slice of s from i to j is defined as the sequence of items with index k such that i <= k < j. If i or j is

greater than len(s), use len(s). If i is omitted or None, use 0. If j is omitted or None, use len(s). If i is

greater than or equal to j, the slice is empty.

(5) The slice of s from i to j with step k is defined as the sequence of items with index x = i + n*k such that

0 <= n < (j-i)/k. In other words, the indices are i, i+k, i+2*k, i+3*k and so on, stopping when j is

reached (but never including j). When k is positive, i and j are reduced to len(s) if they are greater. When k

is negative, i and j are reduced to len(s) - 1 if they are greater. If i or j are omitted or None, they become

“end” values (which end depends on the sign of k). Note, k cannot be zero. If k is None, it is treated like 1.

(6) Concatenating immutable sequences always results in a new object. This means that building up a sequence by

repeated concatenation will have a quadratic runtime cost in the total sequence length. To get a linear runtime

cost, you must switch to one of the alternatives below:

• if concatenating str objects, you can build a list and use str.join() at the end or else write to an

io.StringIO instance and retrieve its value when complete

• if concatenating bytes objects, you can similarly use bytes.join() or io.BytesIO, or you can do

in-place concatenation with a bytearray object. bytearray objects are mutable and have an efficient overallocation mechanism

• if concatenating tuple objects, extend a list instead

• for other types, investigate the relevant class documentation

(7) Some sequence types (such as range) only support item sequences that follow specific patterns, and hence

don’t support sequence concatenation or repetition.

(8) index raises ValueError when x is not found in s. Not all implementations support passing the additional

arguments i and j. These arguments allow efficient searching of subsections of the sequence. Passing the extra

arguments is roughly equivalent to using s[i:j].index(x), only without copying any data and with the

returned index being relative to the start of the sequence rather than the start of the slice.





The Python Library Reference, Release 3.13.2




4.7.2 Immutable Sequence Types

The only operation that immutable sequence types generally implement that is not also implemented by mutable

sequence types is support for the hash() built-in.

This support allows immutable sequences, such as tuple instances, to be used as dict keys and stored in set and

frozenset instances.

Attempting to hash an immutable sequence that contains unhashable values will result in TypeError.



4.7.3 Mutable Sequence Types

The operations in the following table are defined on mutable sequence types. The collections.abc.

MutableSequence ABC is provided to make it easier to correctly implement these operations on custom sequence types.

In the table s is an instance of a mutable sequence type, t is any iterable object and x is an arbitrary object that meets

any type and value restrictions imposed by s (for example, bytearray only accepts integers that meet the value restriction 0 <= x <= 255).



Operation Result Notes

s[i] = x item i of s is replaced by x

s[i:j] = t slice of s from i to j is replaced by the contents of the iterable t

del s[i:j] same as s[i:j] = []

s[i:j:k] = t the elements of s[i:j:k] are replaced by those of t (1)

del s[i:j:k] removes the elements of s[i:j:k] from the list

s.append(x) appends x to the end of the sequence (same as s[len(s):len(s)] = [x])

s.clear() removes all items from s (same as del s[:]) (5)

s.copy() creates a shallow copy of s (same as s[:]) (5)

s.extend(t) or s extends s with the contents of t (for the most part the same as

+= t s[len(s):len(s)] = t)

s *= n updates s with its contents repeated n times (6)

s.insert(i, x) inserts x into s at the index given by i (same as s[i:i] = [x])

s.pop() or s. retrieves the item at i and also removes it from s (2)

pop(i)

s.remove(x) removes the first item from s where s[i] is equal to x (3)

s.reverse() reverses the items of s in place (4)



Notes:

(1) If k is not equal to 1, t must have the same length as the slice it is replacing.

(2) The optional argument i defaults to-1, so that by default the last item is removed and returned.

(3) remove() raises ValueError when x is not found in s.

(4) The reverse() method modifies the sequence in place for economy of space when reversing a large sequence.

To remind users that it operates by side effect, it does not return the reversed sequence.

(5) clear() and copy() are included for consistency with the interfaces of mutable containers that don’t

support slicing operations (such as dict and set). copy() is not part of the collections.abc.

MutableSequence ABC, but most concrete mutable sequence classes provide it.

Added in version 3.3: clear() and copy() methods.

(6) The value n is an integer, or an object implementing __index__(). Zero and negative values of n clear the

sequence. Items in the sequence are not copied; they are referenced multiple times, as explained for s * n

under Common Sequence Operations.





The Python Library Reference, Release 3.13.2




4.7.4 Lists

Lists are mutable sequences, typically used to store collections of homogeneous items (where the precise degree of similarity will vary by application).

class list( iterable [ ])

Lists may be constructed in several ways:

• Using a pair of square brackets to denote the empty list: []

• Using square brackets, separating items with commas: [a], [a, b, c]

• Using a list comprehension: [x for x in iterable]

• Using the type constructor: list() or list(iterable)

The constructor builds a list whose items are the same and in the same order as iterable’s items. iterable may be

either a sequence, a container that supports iteration, or an iterator object. If iterable is already a list, a copy is

made and returned, similar to iterable[:]. For example, list('abc') returns ['a', 'b', 'c'] and

list( (1, 2, 3) ) returns [1, 2, 3]. If no argument is given, the constructor creates a new empty list,

[].

Many other operations also produce lists, including the sorted() built-in.

Lists implement all of the common and mutable sequence operations. Lists also provide the following additional

method:

sort(*, key=None, reverse=False)

This method sorts the list in place, using only < comparisons between items. Exceptions are not sup-pressed - if any comparison operations fail, the entire sort operation will fail (and the list will likely be left in a partially modified state).

sort() accepts two arguments that can only be passed by keyword (keyword-only arguments):

key specifies a function of one argument that is used to extract a comparison key from each list element (for example, key=str.lower). The key corresponding to each item in the list is calculated once and then used for the entire sorting process. The default value of None means that list items are sorted directly without calculating a separate key value.

The functools.cmp_to_key() utility is available to convert a 2.x style cmp function to a key function.

reverse is a boolean value. If set to True, then the list elements are sorted as if each comparison were reversed.

This method modifies the sequence in place for economy of space when sorting a large sequence. To

remind users that it operates by side effect, it does not return the sorted sequence (use sorted() to explicitly request a new sorted list instance).

The sort() method is guaranteed to be stable. A sort is stable if it guarantees not to change the relative order of elements that compare equal — this is helpful for sorting in multiple passes (for example, sort by department, then by salary grade).

For sorting examples and a brief sorting tutorial, see sortinghowto.

CPython implementation detail: While a list is being sorted, the effect of attempting to mutate, or even inspect, the list is undefined. The C implementation of Python makes the list appear empty for the

duration, and raises ValueError if it can detect that the list has been mutated during a sort.



4.7.5 Tuples

Tuples are immutable sequences, typically used to store collections of heterogeneous data (such as the 2-tuples pro-

duced by the enumerate() built-in). Tuples are also used for cases where an immutable sequence of homogeneous

data is needed (such as allowing storage in a set or dict instance).

class tuple( iterable [ ])

Tuples may be constructed in a number of ways:





The Python Library Reference, Release 3.13.2




• Using a pair of parentheses to denote the empty tuple: ()

• Using a trailing comma for a singleton tuple: a, or (a,)

• Separating items with commas: a, b, c or (a, b, c)

• Using the tuple() built-in: tuple() or tuple(iterable)

The constructor builds a tuple whose items are the same and in the same order as iterable’s items. iterable may

be either a sequence, a container that supports iteration, or an iterator object. If iterable is already a tuple, it

is returned unchanged. For example, tuple('abc') returns ('a', 'b', 'c') and tuple( [1, 2, 3]

) returns (1, 2, 3). If no argument is given, the constructor creates a new empty tuple, ().

Note that it is actually the comma which makes a tuple, not the parentheses. The parentheses are optional,

except in the empty tuple case, or when they are needed to avoid syntactic ambiguity. For example, f(a, b,

c) is a function call with three arguments, while f((a, b, c)) is a function call with a 3-tuple as the sole

argument.

Tuples implement all of the common sequence operations.

For heterogeneous collections of data where access by name is clearer than access by index, collections.

namedtuple() may be a more appropriate choice than a simple tuple object.



4.7.6 Ranges

The range type represents an immutable sequence of numbers and is commonly used for looping a specific number of times in for loops.

class range(stop)

class range(start, stop[, step ])

The arguments to the range constructor must be integers (either built-in int or any object that implements

the __index__() special method). If the step argument is omitted, it defaults to 1. If the start argument is

omitted, it defaults to 0. If step is zero, ValueError is raised.

For a positive step, the contents of a range r are determined by the formula r[i] = start + step*i where

i >= 0 and r[i] < stop.

For a negative step, the contents of the range are still determined by the formula r[i] = start + step*i,

but the constraints are i >= 0 and r[i] > stop.

A range object will be empty if r[0] does not meet the value constraint. Ranges do support negative indices,

but these are interpreted as indexing from the end of the sequence determined by the positive indices.

Ranges containing absolute values larger than sys.maxsize are permitted but some features (such as len())

may raise OverflowError.

Range examples:

>>> list(range(10))

[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

>>> list(range(1, 11))

[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

>>> list(range(0, 30, 5))

[0, 5, 10, 15, 20, 25]

>>> list(range(0, 10, 3))

[0, 3, 6, 9]

>>> list(range(0,-10,-1))

[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]

>>> list(range(0))

[]

>>> list(range(1, 0))

[]





The Python Library Reference, Release 3.13.2




Ranges implement all of the common sequence operations except concatenation and repetition (due to the fact

that range objects can only represent sequences that follow a strict pattern and repetition and concatenation

will usually violate that pattern).

start

The value of the start parameter (or 0 if the parameter was not supplied)

stop

The value of the stop parameter

step

The value of the step parameter (or 1 if the parameter was not supplied)

The advantage of the range type over a regular list or tuple is that a range object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the start, stop and step values, calculating individual items and subranges as needed).

Range objects implement the collections.abc.Sequence ABC, and provide features such as containment tests,

element index lookup, slicing and support for negative indices (see Sequence Types — list, tuple, range):

>>> r = range(0, 20, 2)

>>> r

range(0, 20, 2)

>>> 11 in r

False

>>> 10 in r

True

>>> r.index(10)

5

>>> r[5]

10

>>> r[:5]

range(0, 10, 2)

>>> r[-1]

18



Testing range objects for equality with == and != compares them as sequences. That is, two range objects are considered equal if they represent the same sequence of values. (Note that two range objects that compare equal might

have different start, stop and step attributes, for example range(0) == range(2, 1, 3) or range(0, 3, 2) == range(0, 4, 2).)

Changed in version 3.2: Implement the Sequence ABC. Support slicing and negative indices. Test int objects for membership in constant time instead of iterating through all items.

Changed in version 3.3: Define ‘==’ and ‘!=’ to compare range objects based on the sequence of values they define (instead of comparing based on object identity).

Added the start, stop and step attributes.



µ See also

• The linspace recipe shows how to implement a lazy version of range suitable for floating-point applications.



4.8 Text Sequence Type — str

Textual data in Python is handled with str objects, or strings. Strings are immutable sequences of Unicode code points. String literals are written in a variety of ways:

• Single quotes: 'allows embedded "double" quotes'





The Python Library Reference, Release 3.13.2




• Double quotes: "allows embedded 'single' quotes"

• Triple quoted: '''Three single quotes''', """Three double quotes"""

Triple quoted strings may span multiple lines - all associated whitespace will be included in the string literal.

String literals that are part of a single expression and have only whitespace between them will be implicitly converted to a single string literal. That is, ("spam " "eggs") == "spam eggs".

See strings for more about the various forms of string literal, including supported escape sequences, and the r (“raw”) prefix that disables most escape sequence processing.

Strings may also be created from other objects using the str constructor.

Since there is no separate “character” type, indexing a string produces strings of length 1. That is, for a non-empty string s, s[0] == s[0:1].

There is also no mutable string type, but str.join() or io.StringIO can be used to efficiently construct strings from multiple fragments.

Changed in version 3.3: For backwards compatibility with the Python 2 series, the u prefix is once again permitted on string literals. It has no effect on the meaning of string literals and cannot be combined with the r prefix.

class str(object=”)

class str(object=b”, encoding=’utf-8’, errors=’strict’)

Return a string version of object. If object is not provided, returns the empty string. Otherwise, the behavior

of str() depends on whether encoding or errors is given, as follows.

If neither encoding nor errors is given, str(object) returns type(object).__str__(object), which

is the “informal” or nicely printable string representation of object. For string objects, this is the string itself.

If object does not have a __str__() method, then str() falls back to returning repr(object).

If at least one of encoding or errors is given, object should be a bytes-like object (e.g. bytes or bytearray).

In this case, if object is a bytes (or bytearray) object, then str(bytes, encoding, errors) is equiv-

alent to bytes.decode(encoding, errors). Otherwise, the bytes object underlying the buffer object is

obtained before calling bytes.decode(). See Binary Sequence Types — bytes, bytearray, memoryview and

bufferobjects for information on buffer objects.

Passing a bytes object to str() without the encoding or errors arguments falls under the first case of returning

the informal string representation (see also the-b command-line option to Python). For example:

>>> str(b'Zoot!')

"b'Zoot!'"



For more information on the str class and its methods, see Text Sequence Type — str and the String Methods

section below. To output formatted strings, see the f-strings and Format String Syntax sections. In addition,

see the Text Processing Services section.



4.8.1 String Methods

Strings implement all of the common sequence operations, along with the additional methods described below.

Strings also support two styles of string formatting, one providing a large degree of flexibility and customization

(see str.format(), Format String Syntax and Custom String Formatting) and the other based on C printf style formatting that handles a narrower range of types and is slightly harder to use correctly, but is often faster for the

cases it can handle (printf-style String Formatting).

The Text Processing Services section of the standard library covers a number of other modules that provide various

text related utilities (including regular expression support in the re module).

str.capitalize()

Return a copy of the string with its first character capitalized and the rest lowercased.

Changed in version 3.8: The first character is now put into titlecase rather than uppercase. This means that

characters like digraphs will only have their first letter capitalized, instead of the full character.

The Python Library Reference, Release 3.13.2



str.casefold()

Return a casefolded copy of the string. Casefolded strings may be used for caseless matching.

Casefolding is similar to lowercasing but more aggressive because it is intended to remove all case distinctions

in a string. For example, the German lowercase letter 'ß' is equivalent to "ss". Since it is already lowercase,

lower() would do nothing to 'ß'; casefold() converts it to "ss".

The casefolding algorithm is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard.

Added in version 3.3.

str.center(width[, fillchar ])

Return centered in a string of length width. Padding is done using the specified fillchar (default is an ASCII

space). The original string is returned if width is less than or equal to len(s).

str.count(sub [, start[, end ]])

Return the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional argu-

ments start and end are interpreted as in slice notation.

If sub is empty, returns the number of empty strings between characters which is the length of the string plus

one.

str.encode(encoding=’utf-8’, errors=’strict’)

Return the string encoded to bytes.

encoding defaults to 'utf-8'; see Standard Encodings for possible values.

errors controls how encoding errors are handled. If 'strict' (the default), a UnicodeError

exception is raised. Other possible values are 'ignore', 'replace', 'xmlcharrefreplace',

'backslashreplace' and any other name registered via codecs.register_error(). See Error Han-

dlers for details.

For performance reasons, the value of errors is not checked for validity unless an encoding error actually occurs,

Python Development Mode is enabled or a debug build is used.

Changed in version 3.1: Added support for keyword arguments.

Changed in version 3.9: The value of the errors argument is now checked in Python Development Mode and in

debug mode.

str.endswith(suffix[, start[, end ]])

Return True if the string ends with the specified suffix, otherwise return False. suffix can also be a tuple of

suffixes to look for. With optional start, test beginning at that position. With optional end, stop comparing at

that position.

str.expandtabs(tabsize=8)

Return a copy of the string where all tab characters are replaced by one or more spaces, depending on the

current column and the given tab size. Tab positions occur every tabsize characters (default is 8, giving tab

positions at columns 0, 8, 16 and so on). To expand the string, the current column is set to zero and the string

is examined character by character. If the character is a tab (\t), one or more space characters are inserted in

the result until the current column is equal to the next tab position. (The tab character itself is not copied.) If

the character is a newline (\n) or return (\r), it is copied and the current column is reset to zero. Any other

character is copied unchanged and the current column is incremented by one regardless of how the character

is represented when printed.

>>> '01\t012\t0123\t01234'.expandtabs()

'01 012 0123 01234'

>>> '01\t012\t0123\t01234'.expandtabs(4)

'01 012 0123 01234'



str.find(sub [, start[, end ]])

Return the lowest index in the string where substring sub is found within the slice s[start:end]. Optional

arguments start and end are interpreted as in slice notation. Return-1 if sub is not found.

The Python Library Reference, Release 3.13.2



® Note

The find() method should be used only if you need to know the position of sub. To check if sub is a substring or not, use the in operator:

>>> 'Py' in 'Python'

True



str.format(*args, **kwargs)

Perform a string formatting operation. The string on which this method is called can contain literal text or

replacement fields delimited by braces {}. Each replacement field contains either the numeric index of a

positional argument, or the name of a keyword argument. Returns a copy of the string where each replacement

field is replaced with the string value of the corresponding argument.

>>> "The sum of 1 + 2 is {0}".format(1+2)

'The sum of 1 + 2 is 3'



See Format String Syntax for a description of the various formatting options that can be specified in format

strings.



® Note

When formatting a number (int, float, complex, decimal.Decimal and subclasses) with the n type (ex: '{:n}'.format(1234)), the function temporarily sets the LC_CTYPE locale to the LC_NUMERIC locale to decode decimal_point and thousands_sep fields of localeconv() if they are non-ASCII or longer than 1 byte, and the LC_NUMERIC locale is different than the LC_CTYPE locale. This temporary change affects other threads.



Changed in version 3.7: When formatting a number with the n type, the function sets temporarily the

LC_CTYPE locale to the LC_NUMERIC locale in some cases.

str.format_map(mapping, / )

Similar to str.format(**mapping), except that mapping is used directly and not copied to a dict. This

is useful if for example mapping is a dict subclass:

>>> class Default(dict):

... def __missing__(self, key):

... return key

...

>>> '{name} was born in {country}'.format_map(Default(name='Guido'))

'Guido was born in country'



Added in version 3.2.

str.index(sub [, start[, end ]])

Like find(), but raise ValueError when the substring is not found.

str.isalnum()

Return True if all characters in the string are alphanumeric and there is at least one character, False otherwise.

A character c is alphanumeric if one of the following returns True: c.isalpha(), c.isdecimal(), c.

isdigit(), or c.isnumeric().

str.isalpha()

Return True if all characters in the string are alphabetic and there is at least one character, False otherwise.

Alphabetic characters are those characters defined in the Unicode character database as “Letter”, i.e., those

with general category property being one of “Lm”, “Lt”, “Lu”, “Ll”, or “Lo”. Note that this is different from the

Alphabetic property defined in the section 4.10 ‘Letters, Alphabetic, and Ideographic’ of the Unicode Standard.

The Python Library Reference, Release 3.13.2



str.isascii()

Return True if the string is empty or all characters in the string are ASCII, False otherwise. ASCII characters

have code points in the range U+0000-U+007F.

Added in version 3.7.

str.isdecimal()

Return True if all characters in the string are decimal characters and there is at least one character, False

otherwise. Decimal characters are those that can be used to form numbers in base 10, e.g. U+0660, ARABIC-

INDIC DIGIT ZERO. Formally a decimal character is a character in the Unicode General Category “Nd”.

str.isdigit()

Return True if all characters in the string are digits and there is at least one character, False otherwise. Digits

include decimal characters and digits that need special handling, such as the compatibility superscript digits.

This covers digits which cannot be used to form numbers in base 10, like the Kharosthi numbers. Formally, a

digit is a character that has the property value Numeric_Type=Digit or Numeric_Type=Decimal.

str.isidentifier()

Return True if the string is a valid identifier according to the language definition, section identifiers.

keyword.iskeyword() can be used to test whether string s is a reserved identifier, such as def and class.

Example:

>>> from keyword import iskeyword

>>> 'hello'.isidentifier(), iskeyword('hello')

(True, False)

>>> 'def'.isidentifier(), iskeyword('def')

(True, True)



str.islower()

Return 4 True if all cased characters in the string are lowercase and there is at least one cased character, False

otherwise.

str.isnumeric()

Return True if all characters in the string are numeric characters, and there is at least one character, False

otherwise. Numeric characters include digit characters, and all characters that have the Unicode numeric value

property, e.g. U+2155, VULGAR FRACTION ONE FIFTH. Formally, numeric characters are those with the

property value Numeric_Type=Digit, Numeric_Type=Decimal or Numeric_Type=Numeric.

str.isprintable()

Return True if all characters in the string are printable or the string is empty, False otherwise. Nonprintable

characters are those characters defined in the Unicode character database as “Other” or “Separator”, excepting

the ASCII space (0x20) which is considered printable. (Note that printable characters in this context are those

which should not be escaped when repr() is invoked on a string. It has no bearing on the handling of strings

written to sys.stdout or sys.stderr.)

str.isspace()

Return True if there are only whitespace characters in the string and there is at least one character, False

otherwise.

A character is whitespace if in the Unicode character database (see unicodedata), either its general category

is Zs (“Separator, space”), or its bidirectional class is one of WS, B, or S.

str.istitle()

Return True if the string is a titlecased string and there is at least one character, for example uppercase char-

acters may only follow uncased characters and lowercase characters only cased ones. Return False otherwise.

4 Cased characters are those with general category property being one of “Lu” (Letter, uppercase), “Ll” (Letter, lowercase), or “Lt” (Letter,

titlecase).

The Python Library Reference, Release 3.13.2



str.isupper()

Return Page 55, 4 True if all cased characters in the string are uppercase and there is at least one cased character,

False otherwise.

>>> 'BANANA'.isupper()

True

>>> 'banana'.isupper()

False

>>> 'baNana'.isupper()

False

>>> ' '.isupper()

False



str.join(iterable)

Return a string which is the concatenation of the strings in iterable. A TypeError will be raised if there

are any non-string values in iterable, including bytes objects. The separator between elements is the string

providing this method.

str.ljust(width[, fillchar ])

Return the string left justified in a string of length width. Padding is done using the specified fillchar (default

is an ASCII space). The original string is returned if width is less than or equal to len(s).

str.lower()

Return a copy of the string with all the cased charactersPage 55, 4 converted to lowercase.

The lowercasing algorithm used is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard.

str.lstrip( chars [ ])

Return a copy of the string with leading characters removed. The chars argument is a string specifying the set

of characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The

chars argument is not a prefix; rather, all combinations of its values are stripped:

>>> ' spacious '.lstrip()

'spacious '

>>> 'www.example.com'.lstrip('cmowz.')

'example.com'



See str.removeprefix() for a method that will remove a single prefix string rather than all of a set of

characters. For example:

>>> 'Arthur: three!'.lstrip('Arthur: ')

'ee!'

>>> 'Arthur: three!'.removeprefix('Arthur: ')

'three!'



static str.maketrans(x[, y[, z ]])

This static method returns a translation table usable for str.translate().

If there is only one argument, it must be a dictionary mapping Unicode ordinals (integers) or characters (strings

of length 1) to Unicode ordinals, strings (of arbitrary lengths) or None. Character keys will then be converted

to ordinals.

If there are two arguments, they must be strings of equal length, and in the resulting dictionary, each character

in x will be mapped to the character at the same position in y. If there is a third argument, it must be a string,

whose characters will be mapped to None in the result.

str.partition(sep)

Split the string at the first occurrence of sep, and return a 3-tuple containing the part before the separator, the

separator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing the

string itself, followed by two empty strings.

The Python Library Reference, Release 3.13.2



str.removeprefix(prefix, / )

If the string starts with the prefix string, return string[len(prefix):]. Otherwise, return a copy of the

original string:

>>> 'TestHook'.removeprefix('Test')

'Hook'

>>> 'BaseTestCase'.removeprefix('Test')

'BaseTestCase'



Added in version 3.9.

str.removesuffix(suffix, / )

If the string ends with the suffix string and that suffix is not empty, return string[:-len(suffix)]. Oth-

erwise, return a copy of the original string:

>>> 'MiscTests'.removesuffix('Tests')

'Misc'

>>> 'TmpDirMixin'.removesuffix('Tests')

'TmpDirMixin'



Added in version 3.9.

str.replace(old, new, count=-1)

Return a copy of the string with all occurrences of substring old replaced by new. If count is given, only the

first count occurrences are replaced. If count is not specified or-1, then all occurrences are replaced.

Changed in version 3.13: count is now supported as a keyword argument.

str.rfind(sub [, start[, end ]])

Return the highest index in the string where substring sub is found, such that sub is contained within

s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return-1 on fail-

ure.

str.rindex(sub [, start[, end ]])

Like rfind() but raises ValueError when the substring sub is not found.

str.rjust(width[, fillchar ])

Return the string right justified in a string of length width. Padding is done using the specified fillchar (default

is an ASCII space). The original string is returned if width is less than or equal to len(s).

str.rpartition(sep)

Split the string at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the

separator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing two

empty strings, followed by the string itself.

str.rsplit(sep=None, maxsplit=-1)

Return a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit

splits are done, the rightmost ones. If sep is not specified or None, any whitespace string is a separator. Except

for splitting from the right, rsplit() behaves like split() which is described in detail below.

str.rstrip( chars [ ])

Return a copy of the string with trailing characters removed. The chars argument is a string specifying the set

of characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The

chars argument is not a suffix; rather, all combinations of its values are stripped:

>>> ' spacious '.rstrip()

' spacious'

>>> 'mississippi'.rstrip('ipz')

'mississ'

The Python Library Reference, Release 3.13.2



See str.removesuffix() for a method that will remove a single suffix string rather than all of a set of

characters. For example:

>>> 'Monty Python'.rstrip(' Python')

'M'

>>> 'Monty Python'.removesuffix(' Python')

'Monty'



str.split(sep=None, maxsplit=-1)

Return a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit

splits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or-1, then

there is no limit on the number of splits (all possible splits are made).

If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings (for

example, '1,,2'.split(',') returns ['1', '', '2']). The sep argument may consist of multiple char-

acters as a single delimiter (to split with multiple delimiters, use re.split()). Splitting an empty string with

a specified separator returns [''].

For example:

>>> '1,2,3'.split(',')

['1', '2', '3']

>>> '1,2,3'.split(',', maxsplit=1)

['1', '2,3']

>>> '1,2,,3,'.split(',')

['1', '2', '', '3', '']

>>> '1<>2<>3<4'.split('<>')

['1', '2', '3<4']



If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are

regarded as a single separator, and the result will contain no empty strings at the start or end if the string has

leading or trailing whitespace. Consequently, splitting an empty string or a string consisting of just whitespace

with a None separator returns [].

For example:

>>> '1 2 3'.split()

['1', '2', '3']

>>> '1 2 3'.split(maxsplit=1)

['1', '2 3']

>>> ' 1 2 3 '.split()

['1', '2', '3']



str.splitlines(keepends=False)

Return a list of the lines in the string, breaking at line boundaries. Line breaks are not included in the resulting

list unless keepends is given and true.

This method splits on the following line boundaries. In particular, the boundaries are a superset of universal

newlines.



The Python Library Reference, Release 3.13.2



Representation Description

\n Line Feed

\r Carriage Return

\r\n Carriage Return + Line Feed

\v or \x0b Line Tabulation

\f or \x0c Form Feed

\x1c File Separator

\x1d Group Separator

\x1e Record Separator

\x85 Next Line (C1 Control Code)

\u2028 Line Separator

\u2029 Paragraph Separator



Changed in version 3.2: \v and \f added to list of line boundaries.

For example:

>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()

['ab c', '', 'de fg', 'kl']

>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)

['ab c\n', '\n', 'de fg\r', 'kl\r\n']



Unlike split() when a delimiter string sep is given, this method returns an empty list for the empty string,

and a terminal line break does not result in an extra line:

>>> "".splitlines()

[]

>>> "One line\n".splitlines()

['One line']



For comparison, split('\n') gives:

>>> ''.split('\n')

['']

>>> 'Two lines\n'.split('\n')

['Two lines', '']



str.startswith(prefix[, start[, end ]])

Return True if string starts with the prefix, otherwise return False. prefix can also be a tuple of prefixes to

look for. With optional start, test string beginning at that position. With optional end, stop comparing string

at that position.

str.strip( chars [ ])

Return a copy of the string with the leading and trailing characters removed. The chars argument is a string

specifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing

whitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped:

>>> ' spacious '.strip()

'spacious'

>>> 'www.example.com'.strip('cmowz.')

'example'



The outermost leading and trailing chars argument values are stripped from the string. Characters are removed

from the leading end until reaching a string character that is not contained in the set of characters in chars. A

similar action takes place on the trailing end. For example:



The Python Library Reference, Release 3.13.2



>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'

>>> comment_string.strip('.#! ')

'Section 3.2.1 Issue #32'



str.swapcase()

Return a copy of the string with uppercase characters converted to lowercase and vice versa. Note that it is

not necessarily true that s.swapcase().swapcase() == s.

str.title()

Return a titlecased version of the string where words start with an uppercase character and the remaining

characters are lowercase.

For example:

>>> 'Hello world'.title()

'Hello World'



The algorithm uses a simple language-independent definition of a word as groups of consecutive letters. The

definition works in many contexts but it means that apostrophes in contractions and possessives form word

boundaries, which may not be the desired result:

>>> "they're bill's friends from the UK".title()

"They'Re Bill'S Friends From The Uk"



The string.capwords() function does not have this problem, as it splits words on spaces only.

Alternatively, a workaround for apostrophes can be constructed using regular expressions:

>>> import re

>>> def titlecase(s):

... return re.sub(r"[A-Za-z]+('[A-Za-z]+)?",

... lambda mo: mo.group(0).capitalize(),

... s)

...

>>> titlecase("they're bill's friends.")

"They're Bill's Friends."



str.translate(table)

Return a copy of the string in which each character has been mapped through the given translation table.

The table must be an object that implements indexing via __getitem__(), typically a mapping or sequence.

When indexed by a Unicode ordinal (an integer), the table object can do any of the following: return a Unicode

ordinal or a string, to map the character to one or more other characters; return None, to delete the character

from the return string; or raise a LookupError exception, to map the character to itself.

You can use str.maketrans() to create a translation map from character-to-character mappings in different

formats.

See also the codecs module for a more flexible approach to custom character mappings.

str.upper()

Return a copy of the string with all the cased charactersPage 55, 4 converted to uppercase. Note that s.upper().

isupper() might be False if s contains uncased characters or if the Unicode category of the resulting

character(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter, titlecase).

The uppercasing algorithm used is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard.

str.zfill(width)

Return a copy of the string left filled with ASCII '0' digits to make a string of length width. A leading sign

prefix ('+'/'-') is handled by inserting the padding after the sign character rather than before. The original

string is returned if width is less than or equal to len(s).

For example:





The Python Library Reference, Release 3.13.2




>>> "42".zfill(5)

'00042'

>>> "-42".zfill(5)

'-0042'



4.8.2 printf-style String Formatting



® Note

The formatting operations described here exhibit a variety of quirks that lead to a number of common errors

(such as failing to display tuples and dictionaries correctly). Using the newer formatted string literals, the str.

format() interface, or template strings may help avoid these errors. Each of these alternatives provides their

own trade-offs and benefits of simplicity, flexibility, and/or extensibility.



String objects have one unique built-in operation: the % operator (modulo). This is also known as the string formatting or interpolation operator. Given format % values (where format is a string), % conversion specifications in format are replaced with zero or more elements of values. The effect is similar to using the sprintf() function in the C language. For example:

>>> print('%s has %d quote types.' % ('Python', 2))

Python has 2 quote types.



If 5 format requires a single argument, values may be a single non-tuple object. Otherwise, values must be a tuple with exactly the number of items specified by the format string, or a single mapping object (for example, a dictionary).

A conversion specifier contains two or more characters and has the following components, which must occur in this order:

1. The '%' character, which marks the start of the specifier.

2. Mapping key (optional), consisting of a parenthesised sequence of characters (for example, (somename)).

3. Conversion flags (optional), which affect the result of some conversion types.

4. Minimum field width (optional). If specified as an '*' (asterisk), the actual width is read from the next element

of the tuple in values, and the object to convert comes after the minimum field width and optional precision.

5. Precision (optional), given as a '.' (dot) followed by the precision. If specified as '*' (an asterisk), the actual

precision is read from the next element of the tuple in values, and the value to convert comes after the precision.

6. Length modifier (optional).

7. Conversion type.

When the right argument is a dictionary (or other mapping type), then the formats in the string must include a parenthesised mapping key into that dictionary inserted immediately after the '%' character. The mapping key selects the value to be formatted from the mapping. For example:

>>> print('%(language)s has %(number)03d quote types.' % ... {'language': "Python", "number": 2})

Python has 002 quote types.



In this case no * specifiers may occur in a format (since they require a sequential parameter list).

The conversion flag characters are:

5 To format only a tuple you should therefore provide a singleton tuple whose only element is the tuple to be formatted.



The Python Library Reference, Release 3.13.2



Flag Meaning

'#' The value conversion will use the “alternate form” (where defined below).

'0' The conversion will be zero padded for numeric values.

'-' The converted value is left adjusted (overrides the '0' conversion if both are given).

' ' (a space) A blank should be left before a positive number (or empty string) produced by a signed conver-

sion.

'+' A sign character ('+' or '-') will precede the conversion (overrides a “space” flag).



A length modifier (h, l, or L) may be present, but is ignored as it is not necessary for Python – so e.g. %ld is identical to %d.

The conversion types are:



Con- Meaning Notes

version

'd' Signed integer decimal.

'i' Signed integer decimal.

'o' Signed octal value. (1)

'u' Obsolete type – it is identical to 'd'. (6)

'x' Signed hexadecimal (lowercase). (2)

'X' Signed hexadecimal (uppercase). (2)

'e' Floating-point exponential format (lowercase). (3)

'E' Floating-point exponential format (uppercase). (3)

'f' Floating-point decimal format. (3)

'F' Floating-point decimal format. (3)

'g' Floating-point format. Uses lowercase exponential format if exponent is less than -4 or not less (4)

than precision, decimal format otherwise.

'G' Floating-point format. Uses uppercase exponential format if exponent is less than -4 or not (4)

less than precision, decimal format otherwise.

'c' Single character (accepts integer or single character string).

'r' String (converts any Python object using repr()). (5)

's' String (converts any Python object using str()). (5)

'a' String (converts any Python object using ascii()). (5)

'%' No argument is converted, results in a '%' character in the result.



Notes:

(1) The alternate form causes a leading octal specifier ('0o') to be inserted before the first digit.

(2) The alternate form causes a leading '0x' or '0X' (depending on whether the 'x' or 'X' format was used)

to be inserted before the first digit.

(3) The alternate form causes the result to always contain a decimal point, even if no digits follow it.

The precision determines the number of digits after the decimal point and defaults to 6.

(4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as

they would otherwise be.

The precision determines the number of significant digits before and after the decimal point and defaults to 6.

(5) If precision is N, the output is truncated to N characters.

(6) See PEP 237.

Since Python strings have an explicit length, %s conversions do not assume that '\0' is the end of the string.

Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g conversions.





The Python Library Reference, Release 3.13.2




4.9 Binary Sequence Types — bytes, bytearray, memoryview

The core built-in types for manipulating binary data are bytes and bytearray. They are supported by

memoryview which uses the buffer protocol to access the memory of other binary objects without needing to make a copy.

The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision floating values.



4.9.1 Bytes Objects

Bytes objects are immutable sequences of single bytes. Since many major binary protocols are based on the ASCII text encoding, bytes objects offer several methods that are only valid when working with ASCII compatible data and are closely related to string objects in a variety of other ways.

class bytes( source [[, encoding[, errors ]]])

Firstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:

• Single quotes: b'still allows embedded "double" quotes'

• Double quotes: b"still allows embedded 'single' quotes"

• Triple quoted: b'''3 single quotes''', b"""3 double quotes"""

Only ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any

binary values over 127 must be entered into bytes literals using the appropriate escape sequence.

As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See

strings for more about the various forms of bytes literal, including supported escape sequences.

While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable

sequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate

this restriction will trigger ValueError). This is done deliberately to emphasise that while many binary

formats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms,

this is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary

data formats that are not ASCII compatible will usually lead to data corruption).

In addition to the literal forms, bytes objects can be created in a number of other ways:

• A zero-filled bytes object of a specified length: bytes(10)

• From an iterable of integers: bytes(range(20))

• Copying existing binary data via the buffer protocol: bytes(obj)

Also see the bytes built-in.

Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used

format for describing binary data. Accordingly, the bytes type has an additional class method to read data in

that format:

classmethod fromhex(string)

This bytes class method returns a bytes object, decoding the given string object. The string must contain two hexadecimal digits per byte, with ASCII whitespace being ignored.

>>> bytes.fromhex('2Ef0 F1f2 ')

b'.\xf0\xf1\xf2'



Changed in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string, not just spaces.

A reverse conversion function exists to transform a bytes object into its hexadecimal representation.

hex( sep [[, bytes_per_sep ]])

Return a string object containing two hexadecimal digits for each byte in the instance.





The Python Library Reference, Release 3.13.2




>>> b'\xf0\xf1\xf2'.hex()

'f0f1f2'



If you want to make the hex string easier to read, you can specify a single character separator sep param-eter to include in the output. By default, this separator will be included between each byte. A second optional bytes_per_sep parameter controls the spacing. Positive values calculate the separator position from the right, negative values from the left.

>>> value = b'\xf0\xf1\xf2'

>>> value.hex('-')

'f0-f1-f2'

>>> value.hex('_', 2)

'f0_f1f2'

>>> b'UUDDLRLRAB'.hex(' ',-4)

'55554444 4c524c52 4142'



Added in version 3.5.

Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output.

Since bytes objects are sequences of integers (akin to a tuple), for a bytes object b, b[0] will be an integer, while b[0:1] will be a bytes object of length 1. (This contrasts with text strings, where both indexing and slicing will produce a string of length 1)

The representation of bytes objects uses the literal format (b'...') since it is often more useful than e.g. bytes([46, 46, 46]). You can always convert a bytes object into a list of integers using list(b).



4.9.2 Bytearray Objects

bytearray objects are a mutable counterpart to bytes objects.

class bytearray( source [[, encoding[, errors ]]])

There is no dedicated literal syntax for bytearray objects, instead they are always created by calling the con-

structor:

• Creating an empty instance: bytearray()

• Creating a zero-filled instance with a given length: bytearray(10)

• From an iterable of integers: bytearray(range(20))

• Copying existing binary data via the buffer protocol: bytearray(b'Hi!')

As bytearray objects are mutable, they support the mutable sequence operations in addition to the common

bytes and bytearray operations described in Bytes and Bytearray Operations.

Also see the bytearray built-in.

Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used

format for describing binary data. Accordingly, the bytearray type has an additional class method to read data

in that format:

classmethod fromhex(string)

This bytearray class method returns bytearray object, decoding the given string object. The string must contain two hexadecimal digits per byte, with ASCII whitespace being ignored.

>>> bytearray.fromhex('2Ef0 F1f2 ')

bytearray(b'.\xf0\xf1\xf2')



Changed in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string, not just spaces.

A reverse conversion function exists to transform a bytearray object into its hexadecimal representation.





The Python Library Reference, Release 3.13.2




hex( sep [[, bytes_per_sep ]])

Return a string object containing two hexadecimal digits for each byte in the instance.

>>> bytearray(b'\xf0\xf1\xf2').hex()

'f0f1f2'



Added in version 3.5.

Changed in version 3.8: Similar to bytes.hex(), bytearray.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output.

Since bytearray objects are sequences of integers (akin to a list), for a bytearray object b, b[0] will be an integer, while b[0:1] will be a bytearray object of length 1. (This contrasts with text strings, where both indexing and slicing will produce a string of length 1)

The representation of bytearray objects uses the bytes literal format (bytearray(b'...')) since it is often more useful than e.g. bytearray([46, 46, 46]). You can always convert a bytearray object into a list of integers using list(b).



4.9.3 Bytes and Bytearray Operations

Both bytes and bytearray objects support the common sequence operations. They interoperate not just with operands

of the same type, but with any bytes-like object. Due to this flexibility, they can be freely mixed in operations without causing errors. However, the return type of the result may depend on the order of operands.



® Note

The methods on bytes and bytearray objects don’t accept strings as their arguments, just as the methods on strings

don’t accept bytes as their arguments. For example, you have to write:

a = "abc"

b = a.replace("a", "f")

and:

a = b"abc"

b = a.replace(b"a", b"f")



Some bytes and bytearray operations assume the use of ASCII compatible binary formats, and hence should be avoided when working with arbitrary binary data. These restrictions are covered below.



® Note

Using these ASCII based operations to manipulate binary data that is not stored in an ASCII based format may

lead to data corruption.



The following methods on bytes and bytearray objects can be used with arbitrary binary data.

bytes.count(sub [, start[, end ]])

bytearray.count(sub[, start[, end ]])

Return the number of non-overlapping occurrences of subsequence sub in the range [start, end]. Optional

arguments start and end are interpreted as in slice notation.

The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.

If sub is empty, returns the number of empty slices between characters which is the length of the bytes object

plus one.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.

bytes.removeprefix(prefix, / )

The Python Library Reference, Release 3.13.2



bytearray.removeprefix(prefix, / )

If the binary data starts with the prefix string, return bytes[len(prefix):]. Otherwise, return a copy of

the original binary data:

>>> b'TestHook'.removeprefix(b'Test')

b'Hook'

>>> b'BaseTestCase'.removeprefix(b'Test')

b'BaseTestCase'



The prefix may be any bytes-like object.



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



Added in version 3.9.

bytes.removesuffix(suffix, / )

bytearray.removesuffix(suffix, / )

If the binary data ends with the suffix string and that suffix is not empty, return bytes[:-len(suffix)].

Otherwise, return a copy of the original binary data:

>>> b'MiscTests'.removesuffix(b'Tests')

b'Misc'

>>> b'TmpDirMixin'.removesuffix(b'Tests')

b'TmpDirMixin'



The suffix may be any bytes-like object.



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



Added in version 3.9.

bytes.decode(encoding=’utf-8’, errors=’strict’)

bytearray.decode(encoding=’utf-8’, errors=’strict’)

Return the bytes decoded to a str.

encoding defaults to 'utf-8'; see Standard Encodings for possible values.

errors controls how decoding errors are handled. If 'strict' (the default), a UnicodeError exception

is raised. Other possible values are 'ignore', 'replace', and any other name registered via codecs.

register_error(). See Error Handlers for details.

For performance reasons, the value of errors is not checked for validity unless a decoding error actually occurs,

Python Development Mode is enabled or a debug build is used.



® Note

Passing the encoding argument to str allows decoding any bytes-like object directly, without needing to make a temporary bytes or bytearray object.



Changed in version 3.1: Added support for keyword arguments.

The Python Library Reference, Release 3.13.2



Changed in version 3.9: The value of the errors argument is now checked in Python Development Mode and in

debug mode.

bytes.endswith(suffix[, start[, end ]])

bytearray.endswith(suffix[, start[, end ]])

Return True if the binary data ends with the specified suffix, otherwise return False. suffix can also be a tuple

of suffixes to look for. With optional start, test beginning at that position. With optional end, stop comparing

at that position.

The suffix(es) to search for may be any bytes-like object.

bytes.find(sub [, start[, end ]])

bytearray.find(sub[, start[, end ]])

Return the lowest index in the data where the subsequence sub is found, such that sub is contained in the slice

s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return-1 if sub is not

found.

The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.



® Note

The find() method should be used only if you need to know the position of sub. To check if sub is a substring or not, use the in operator:

>>> b'Py' in b'Python'

True



Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.

bytes.index(sub [, start[, end ]])

bytearray.index(sub[, start[, end ]])

Like find(), but raise ValueError when the subsequence is not found.

The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.

bytes.join(iterable)

bytearray.join(iterable)

Return a bytes or bytearray object which is the concatenation of the binary data sequences in iterable. A

TypeError will be raised if there are any values in iterable that are not bytes-like objects, including str objects.

The separator between elements is the contents of the bytes or bytearray object providing this method.

static bytes.maketrans(from, to)

static bytearray.maketrans(from, to)

This static method returns a translation table usable for bytes.translate() that will map each character

in from into the character at the same position in to; from and to must both be bytes-like objects and have the

same length.

Added in version 3.1.

bytes.partition(sep)

bytearray.partition(sep)

Split the sequence at the first occurrence of sep, and return a 3-tuple containing the part before the separator,

the separator itself or its bytearray copy, and the part after the separator. If the separator is not found, return

a 3-tuple containing a copy of the original sequence, followed by two empty bytes or bytearray objects.

The separator to search for may be any bytes-like object.

bytes.replace(old, new [, count ])

The Python Library Reference, Release 3.13.2



bytearray.replace(old, new [, count ])

Return a copy of the sequence with all occurrences of subsequence old replaced by new. If the optional

argument count is given, only the first count occurrences are replaced.

The subsequence to search for and its replacement may be any bytes-like object.



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.rfind(sub [, start[, end ]])

bytearray.rfind(sub[, start[, end ]])

Return the highest index in the sequence where the subsequence sub is found, such that sub is contained within

s[start:end]. Optional arguments start and end are interpreted as in slice notation. Return-1 on failure.

The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.

bytes.rindex(sub [, start[, end ]])

bytearray.rindex(sub[, start[, end ]])

Like rfind() but raises ValueError when the subsequence sub is not found.

The subsequence to search for may be any bytes-like object or an integer in the range 0 to 255.

Changed in version 3.3: Also accept an integer in the range 0 to 255 as the subsequence.

bytes.rpartition(sep)

bytearray.rpartition(sep)

Split the sequence at the last occurrence of sep, and return a 3-tuple containing the part before the separator,

the separator itself or its bytearray copy, and the part after the separator. If the separator is not found, return

a 3-tuple containing two empty bytes or bytearray objects, followed by a copy of the original sequence.

The separator to search for may be any bytes-like object.

bytes.startswith(prefix [, start[, end ]])

bytearray.startswith(prefix [, start[, end ]])

Return True if the binary data starts with the specified prefix, otherwise return False. prefix can also be

a tuple of prefixes to look for. With optional start, test beginning at that position. With optional end, stop

comparing at that position.

The prefix(es) to search for may be any bytes-like object.

bytes.translate(table, / , delete=b” )

bytearray.translate(table, / , delete=b”)

Return a copy of the bytes or bytearray object where all bytes occurring in the optional argument delete are

removed, and the remaining bytes have been mapped through the given translation table, which must be a bytes

object of length 256.

You can use the bytes.maketrans() method to create a translation table.

Set the table argument to None for translations that only delete characters:

>>> b'read this short text'.translate(None, b'aeiou')

b'rd ths shrt txt'



Changed in version 3.6: delete is now supported as a keyword argument.

The following methods on bytes and bytearray objects have default behaviours that assume the use of ASCII com-patible binary formats, but can still be used with arbitrary binary data by passing appropriate arguments. Note that all of the bytearray methods in this section do not operate in place, and instead produce new objects.

The Python Library Reference, Release 3.13.2



bytes.center(width[, fillbyte ])

bytearray.center(width [, fillbyte ])

Return a copy of the object centered in a sequence of length width. Padding is done using the specified fillbyte

(default is an ASCII space). For bytes objects, the original sequence is returned if width is less than or equal

to len(s).



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.ljust(width[, fillbyte ])

bytearray.ljust(width [, fillbyte ])

Return a copy of the object left justified in a sequence of length width. Padding is done using the specified

fillbyte (default is an ASCII space). For bytes objects, the original sequence is returned if width is less than

or equal to len(s).



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.lstrip( chars [ ])

bytearray.lstrip( chars [ ])

Return a copy of the sequence with specified leading bytes removed. The chars argument is a binary sequence

specifying the set of byte values to be removed - the name refers to the fact this method is usually used with

ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars

argument is not a prefix; rather, all combinations of its values are stripped:

>>> b' spacious '.lstrip()

b'spacious '

>>> b'www.example.com'.lstrip(b'cmowz.')

b'example.com'



The binary sequence of byte values to remove may be any bytes-like object. See removeprefix() for a

method that will remove a single prefix string rather than all of a set of characters. For example:

>>> b'Arthur: three!'.lstrip(b'Arthur: ')

b'ee!'

>>> b'Arthur: three!'.removeprefix(b'Arthur: ')

b'three!'



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.rjust(width[, fillbyte ])

bytearray.rjust(width [, fillbyte ])

Return a copy of the object right justified in a sequence of length width. Padding is done using the specified

fillbyte (default is an ASCII space). For bytes objects, the original sequence is returned if width is less than

or equal to len(s).

The Python Library Reference, Release 3.13.2



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.rsplit(sep=None, maxsplit=-1)

bytearray.rsplit(sep=None, maxsplit=-1)

Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is

given, at most maxsplit splits are done, the rightmost ones. If sep is not specified or None, any subsequence

consisting solely of ASCII whitespace is a separator. Except for splitting from the right, rsplit() behaves

like split() which is described in detail below.

bytes.rstrip( chars [ ])

bytearray.rstrip( chars [ ])

Return a copy of the sequence with specified trailing bytes removed. The chars argument is a binary sequence

specifying the set of byte values to be removed - the name refers to the fact this method is usually used with

ASCII characters. If omitted or None, the chars argument defaults to removing ASCII whitespace. The chars

argument is not a suffix; rather, all combinations of its values are stripped:

>>> b' spacious '.rstrip()

b' spacious'

>>> b'mississippi'.rstrip(b'ipz')

b'mississ'



The binary sequence of byte values to remove may be any bytes-like object. See removesuffix() for a

method that will remove a single suffix string rather than all of a set of characters. For example:

>>> b'Monty Python'.rstrip(b' Python')

b'M'

>>> b'Monty Python'.removesuffix(b' Python')

b'Monty'



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.split(sep=None, maxsplit=-1)

bytearray.split(sep=None, maxsplit=-1)

Split the binary sequence into subsequences of the same type, using sep as the delimiter string. If maxsplit is

given and non-negative, at most maxsplit splits are done (thus, the list will have at most maxsplit+1 elements).

If maxsplit is not specified or is-1, then there is no limit on the number of splits (all possible splits are made).

If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty subsequences

(for example, b'1,,2'.split(b',') returns [b'1', b'', b'2']). The sep argument may consist of a

multibyte sequence as a single delimiter. Splitting an empty sequence with a specified separator returns [b'']

or [bytearray(b'')] depending on the type of object being split. The sep argument may be any bytes-like

object.

For example:

>>> b'1,2,3'.split(b',')

[b'1', b'2', b'3']

>>> b'1,2,3'.split(b',', maxsplit=1)

[b'1', b'2,3']

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> b'1,2,,3,'.split(b',')

[b'1', b'2', b'', b'3', b'']

>>> b'1<>2<>3<4'.split(b'<>')

[b'1', b'2', b'3<4']



If sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive ASCII whitespace

are regarded as a single separator, and the result will contain no empty strings at the start or end if the sequence

has leading or trailing whitespace. Consequently, splitting an empty sequence or a sequence consisting solely

of ASCII whitespace without a specified separator returns [].

For example:

>>> b'1 2 3'.split()

[b'1', b'2', b'3']

>>> b'1 2 3'.split(maxsplit=1)

[b'1', b'2 3']

>>> b' 1 2 3 '.split()

[b'1', b'2', b'3']



bytes.strip( chars [ ])

bytearray.strip( chars [ ])

Return a copy of the sequence with specified leading and trailing bytes removed. The chars argument is a

binary sequence specifying the set of byte values to be removed - the name refers to the fact this method

is usually used with ASCII characters. If omitted or None, the chars argument defaults to removing ASCII

whitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped:

>>> b' spacious '.strip()

b'spacious'

>>> b'www.example.com'.strip(b'cmowz.')

b'example'



The binary sequence of byte values to remove may be any bytes-like object.



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



The following methods on bytes and bytearray objects assume the use of ASCII compatible binary formats and should not be applied to arbitrary binary data. Note that all of the bytearray methods in this section do not operate in place, and instead produce new objects.

bytes.capitalize()

bytearray.capitalize()

Return a copy of the sequence with each byte interpreted as an ASCII character, and the first byte capitalized

and the rest lowercased. Non-ASCII byte values are passed through unchanged.



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.expandtabs(tabsize=8)

The Python Library Reference, Release 3.13.2



bytearray.expandtabs(tabsize=8)

Return a copy of the sequence where all ASCII tab characters are replaced by one or more ASCII spaces,

depending on the current column and the given tab size. Tab positions occur every tabsize bytes (default is

8, giving tab positions at columns 0, 8, 16 and so on). To expand the sequence, the current column is set to

zero and the sequence is examined byte by byte. If the byte is an ASCII tab character (b'\t'), one or more

space characters are inserted in the result until the current column is equal to the next tab position. (The tab

character itself is not copied.) If the current byte is an ASCII newline (b'\n') or carriage return (b'\r'), it

is copied and the current column is reset to zero. Any other byte value is copied unchanged and the current

column is incremented by one regardless of how the byte value is represented when printed:

>>> b'01\t012\t0123\t01234'.expandtabs()

b'01 012 0123 01234'

>>> b'01\t012\t0123\t01234'.expandtabs(4)

b'01 012 0123 01234'



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.isalnum()

bytearray.isalnum()

Return True if all bytes in the sequence are alphabetical ASCII characters or ASCII decimal digits and the

sequence is not empty, False otherwise. Alphabetic ASCII characters are those byte values in the sequence

b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'. ASCII decimal digits are those

byte values in the sequence b'0123456789'.

For example:

>>> b'ABCabc1'.isalnum()

True

>>> b'ABC abc1'.isalnum()

False



bytes.isalpha()

bytearray.isalpha()

Return True if all bytes in the sequence are alphabetic ASCII characters and the sequence is

not empty, False otherwise. Alphabetic ASCII characters are those byte values in the sequence

b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'.

For example:

>>> b'ABCabc'.isalpha()

True

>>> b'ABCabc1'.isalpha()

False



bytes.isascii()

bytearray.isascii()

Return True if the sequence is empty or all bytes in the sequence are ASCII, False otherwise. ASCII bytes

are in the range 0-0x7F.

Added in version 3.7.

bytes.isdigit()



The Python Library Reference, Release 3.13.2



bytearray.isdigit()

Return True if all bytes in the sequence are ASCII decimal digits and the sequence is not empty, False

otherwise. ASCII decimal digits are those byte values in the sequence b'0123456789'.

For example:

>>> b'1234'.isdigit()

True

>>> b'1.23'.isdigit()

False



bytes.islower()

bytearray.islower()

Return True if there is at least one lowercase ASCII character in the sequence and no uppercase ASCII

characters, False otherwise.

For example:

>>> b'hello world'.islower()

True

>>> b'Hello world'.islower()

False



Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'.

Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

bytes.isspace()

bytearray.isspace()

Return True if all bytes in the sequence are ASCII whitespace and the sequence is not empty, False otherwise.

ASCII whitespace characters are those byte values in the sequence b' \t\n\r\x0b\f' (space, tab, newline,

carriage return, vertical tab, form feed).

bytes.istitle()

bytearray.istitle()

Return True if the sequence is ASCII titlecase and the sequence is not empty, False otherwise. See bytes.

title() for more details on the definition of “titlecase”.

For example:

>>> b'Hello World'.istitle()

True

>>> b'Hello world'.istitle()

False



bytes.isupper()

bytearray.isupper()

Return True if there is at least one uppercase alphabetic ASCII character in the sequence and no lowercase

ASCII characters, False otherwise.

For example:

>>> b'HELLO WORLD'.isupper()

True

>>> b'Hello world'.isupper()

False



Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'.

Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

bytes.lower()

The Python Library Reference, Release 3.13.2



bytearray.lower()

Return a copy of the sequence with all the uppercase ASCII characters converted to their corresponding low-

ercase counterpart.

For example:

>>> b'Hello World'.lower()

b'hello world'



Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'.

Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.splitlines(keepends=False)

bytearray.splitlines(keepends=False)

Return a list of the lines in the binary sequence, breaking at ASCII line boundaries. This method uses the

universal newlines approach to splitting lines. Line breaks are not included in the resulting list unless keepends

is given and true.

For example:

>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()

[b'ab c', b'', b'de fg', b'kl']

>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)

[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']



Unlike split() when a delimiter string sep is given, this method returns an empty list for the empty string,

and a terminal line break does not result in an extra line:

>>> b"".split(b'\n'), b"Two lines\n".split(b'\n')

([b''], [b'Two lines', b''])

>>> b"".splitlines(), b"One line\n".splitlines()

([], [b'One line'])



bytes.swapcase()

bytearray.swapcase()

Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding up-

percase counterpart and vice-versa.

For example:

>>> b'Hello World'.swapcase()

b'hELLO wORLD'



Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'.

Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

Unlike str.swapcase(), it is always the case that bin.swapcase().swapcase() == bin for the binary

versions. Case conversions are symmetrical in ASCII, even though that is not generally true for arbitrary

Unicode code points.



® Note

The Python Library Reference, Release 3.13.2



The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.title()

bytearray.title()

Return a titlecased version of the binary sequence where words start with an uppercase ASCII character and

the remaining characters are lowercase. Uncased byte values are left unmodified.

For example:

>>> b'Hello world'.title()

b'Hello World'



Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'.

Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.

All other byte values are uncased.

The algorithm uses a simple language-independent definition of a word as groups of consecutive letters. The

definition works in many contexts but it means that apostrophes in contractions and possessives form word

boundaries, which may not be the desired result:

>>> b"they're bill's friends from the UK".title()

b"They'Re Bill'S Friends From The Uk"



A workaround for apostrophes can be constructed using regular expressions:

>>> import re

>>> def titlecase(s):

... return re.sub(rb"[A-Za-z]+('[A-Za-z]+)?",

... lambda mo: mo.group(0)[0:1].upper() +

... mo.group(0)[1:].lower(),

... s)

...

>>> titlecase(b"they're bill's friends.")

b"They're Bill's Friends."



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.upper()

bytearray.upper()

Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding up-

percase counterpart.

For example:

>>> b'Hello World'.upper()

b'HELLO WORLD'



Lowercase ASCII characters are those byte values in the sequence b'abcdefghijklmnopqrstuvwxyz'.

Uppercase ASCII characters are those byte values in the sequence b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.





The Python Library Reference, Release 3.13.2




® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



bytes.zfill(width)

bytearray.zfill(width)

Return a copy of the sequence left filled with ASCII b'0' digits to make a sequence of length width. A leading

sign prefix (b'+'/ b'-') is handled by inserting the padding after the sign character rather than before. For

bytes objects, the original sequence is returned if width is less than or equal to len(seq).

For example:

>>> b"42".zfill(5)

b'00042'

>>> b"-42".zfill(5)

b'-0042'



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no changes were made.



4.9.4 printf-style Bytes Formatting



® Note

The formatting operations described here exhibit a variety of quirks that lead to a number of common errors (such

as failing to display tuples and dictionaries correctly). If the value being printed may be a tuple or dictionary,

wrap it in a tuple.



Bytes objects (bytes/bytearray) have one unique built-in operation: the % operator (modulo). This is also known as the bytes formatting or interpolation operator. Given format % values (where format is a bytes object), % conversion specifications in format are replaced with zero or more elements of values. The effect is similar to using the sprintf() in the C language.

If Page 61, 5 format requires a single argument, values may be a single non-tuple object. Otherwise, values must be a tuple with exactly the number of items specified by the format bytes object, or a single mapping object (for example, a dictionary).

A conversion specifier contains two or more characters and has the following components, which must occur in this order:

1. The '%' character, which marks the start of the specifier.

2. Mapping key (optional), consisting of a parenthesised sequence of characters (for example, (somename)).

3. Conversion flags (optional), which affect the result of some conversion types.

4. Minimum field width (optional). If specified as an '*' (asterisk), the actual width is read from the next element

of the tuple in values, and the object to convert comes after the minimum field width and optional precision.

5. Precision (optional), given as a '.' (dot) followed by the precision. If specified as '*' (an asterisk), the actual

precision is read from the next element of the tuple in values, and the value to convert comes after the precision.

6. Length modifier (optional).

7. Conversion type.

The Python Library Reference, Release 3.13.2



When the right argument is a dictionary (or other mapping type), then the formats in the bytes object must include a parenthesised mapping key into that dictionary inserted immediately after the '%' character. The mapping key selects the value to be formatted from the mapping. For example:

>>> print(b'%(language)s has %(number)03d quote types.' % ... {b'language': b"Python", b"number": 2})

b'Python has 002 quote types.'



In this case no * specifiers may occur in a format (since they require a sequential parameter list).

The conversion flag characters are:



Flag Meaning

'#' The value conversion will use the “alternate form” (where defined below).

'0' The conversion will be zero padded for numeric values.

'-' The converted value is left adjusted (overrides the '0' conversion if both are given).

' ' (a space) A blank should be left before a positive number (or empty string) produced by a signed conver-

sion.

'+' A sign character ('+' or '-') will precede the conversion (overrides a “space” flag).



A length modifier (h, l, or L) may be present, but is ignored as it is not necessary for Python – so e.g. %ld is identical to %d.

The conversion types are:



Con- Meaning Notes

version

'd' Signed integer decimal.

'i' Signed integer decimal.

'o' Signed octal value. (1)

'u' Obsolete type – it is identical to 'd'. (8)

'x' Signed hexadecimal (lowercase). (2)

'X' Signed hexadecimal (uppercase). (2)

'e' Floating-point exponential format (lowercase). (3)

'E' Floating-point exponential format (uppercase). (3)

'f' Floating-point decimal format. (3)

'F' Floating-point decimal format. (3)

'g' Floating-point format. Uses lowercase exponential format if exponent is less than -4 or not less (4)

than precision, decimal format otherwise.

'G' Floating-point format. Uses uppercase exponential format if exponent is less than -4 or not (4)

less than precision, decimal format otherwise.

'c' Single byte (accepts integer or single byte objects).

'b' Bytes (any object that follows the buffer protocol or has __bytes__()). (5)

's' 's' is an alias for 'b' and should only be used for Python2/3 code bases. (6)

'a' Bytes (converts any Python object using repr(obj).encode('ascii', (5)

'backslashreplace') ).

'r' 'r' is an alias for 'a' and should only be used for Python2/3 code bases. (7)

'%' No argument is converted, results in a '%' character in the result.



Notes:

(1) The alternate form causes a leading octal specifier ('0o') to be inserted before the first digit.

(2) The alternate form causes a leading '0x' or '0X' (depending on whether the 'x' or 'X' format was used)

to be inserted before the first digit.

(3) The alternate form causes the result to always contain a decimal point, even if no digits follow it.

The precision determines the number of digits after the decimal point and defaults to 6.





The Python Library Reference, Release 3.13.2




(4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as

they would otherwise be.

The precision determines the number of significant digits before and after the decimal point and defaults to 6.

(5) If precision is N, the output is truncated to N characters.

(6) b'%s' is deprecated, but will not be removed during the 3.x series.

(7) b'%r' is deprecated, but will not be removed during the 3.x series.

(8) See PEP 237.



® Note

The bytearray version of this method does not operate in place - it always produces a new object, even if no

changes were made.



µ See also

PEP 461- Adding % formatting to bytes and bytearray



Added in version 3.5.



4.9.5 Memory Views

memoryview objects allow Python code to access the internal data of an object that supports the buffer protocol without copying.

class memoryview(object)

Create a memoryview that references object. object must support the buffer protocol. Built-in objects that

support the buffer protocol include bytes and bytearray.

A memoryview has the notion of an element, which is the atomic memory unit handled by the originating

object. For many simple types such as bytes and bytearray, an element is a single byte, but other types

such as array.array may have bigger elements.

len(view) is equal to the length of tolist, which is the nested list representation of the view. If view.ndim

= 1 , this is equal to the number of elements in the view.

Changed in version 3.12: If view.ndim == 0, len(view) now raises TypeError instead of returning 1.

The itemsize attribute will give you the number of bytes in a single element.

A memoryview supports slicing and indexing to expose its data. One-dimensional slicing will result in a

subview:

>>> v = memoryview(b'abcefg')

>>> v[1]

98

>>> v[-1]

103

>>> v[1:4]



>>> bytes(v[1:4])

b'bce'



If format is one of the native format specifiers from the struct module, indexing with an integer or a tuple

of integers is also supported and returns a single element with the correct type. One-dimensional memoryviews

can be indexed with an integer or a one-integer tuple. Multi-dimensional memoryviews can be indexed with

The Python Library Reference, Release 3.13.2



tuples of exactly ndim integers where ndim is the number of dimensions. Zero-dimensional memoryviews can

be indexed with the empty tuple.

Here is an example with a non-byte format:

>>> import array

>>> a = array.array('l', [-11111111, 22222222,-33333333, 44444444])

>>> m = memoryview(a)

>>> m[0]

-11111111

>>> m[-1]

44444444

>>> m[::2].tolist()

[-11111111, -33333333]



If the underlying object is writable, the memoryview supports one-dimensional slice assignment. Resizing is

not allowed:

>>> data = bytearray(b'abcefg')

>>> v = memoryview(data)

>>> v.readonly

False

>>> v[0] = ord(b'z')

>>> data

bytearray(b'zbcefg')

>>> v[1:4] = b'123'

>>> data

bytearray(b'z123fg')

>>> v[2:3] = b'spam'

Traceback (most recent call last):

File "", line 1, in

ValueError: memoryview assignment: lvalue and rvalue have different structures

>>> v[2:6] = b'spam'

>>> data

bytearray(b'z1spam')



One-dimensional memoryviews of hashable (read-only) types with formats ‘B’, ‘b’ or ‘c’ are also hashable. The

hash is defined as hash(m) == hash(m.tobytes()):

>>> v = memoryview(b'abcefg')

>>> hash(v) == hash(b'abcefg')

True

>>> hash(v[2:4]) == hash(b'ce')

True

>>> hash(v[::-2]) == hash(b'abcefg'[::-2])

True



Changed in version 3.3: One-dimensional memoryviews can now be sliced. One-dimensional memoryviews

with formats ‘B’, ‘b’ or ‘c’ are now hashable.

Changed in version 3.4: memoryview is now registered automatically with collections.abc.Sequence

Changed in version 3.5: memoryviews can now be indexed with tuple of integers.

memoryview has several methods:

__eq__(exporter)

A memoryview and a PEP 3118 exporter are equal if their shapes are equivalent and if all corresponding

values are equal when the operands’ respective format codes are interpreted using struct syntax.

For the subset of struct format strings currently supported by tolist(), v and w are equal if v. tolist() == w.tolist():

The Python Library Reference, Release 3.13.2



>>> import array

>>> a = array.array('I', [1, 2, 3, 4, 5])

>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])

>>> c = array.array('b', [5, 3, 1])

>>> x = memoryview(a)

>>> y = memoryview(b)

>>> x == a == y == b

True

>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()

True

>>> z = y[::-2]

>>> z == c

True

>>> z.tolist() == c.tolist()

True



If either format string is not supported by the struct module, then the objects will always compare as unequal (even if the format strings and buffer contents are identical):

>>> from ctypes import BigEndianStructure, c_long

>>> class BEPoint(BigEndianStructure):

... _fields_ = [("x", c_long), ("y", c_long)]

...

>>> point = BEPoint(100, 200)

>>> a = memoryview(point)

>>> b = memoryview(point)

>>> a == point

False

>>> a == b

False



Note that, as with floating-point numbers, v is w does not imply v == w for memoryview objects.

Changed in version 3.3: Previous versions compared the raw memory disregarding the item format and the logical array structure.

tobytes(order=’C’)

Return the data in the buffer as a bytestring. This is equivalent to calling the bytes constructor on the memoryview.

>>> m = memoryview(b"abc")

>>> m.tobytes()

b'abc'

>>> bytes(m)

b'abc'



For non-contiguous arrays the result is equal to the flattened list representation with all elements converted

to bytes. tobytes() supports all format strings, including those that are not in struct module syntax.

Added in version 3.8: order can be {‘C’, ‘F’, ‘A’}. When order is ‘C’ or ‘F’, the data of the original array is converted to C or Fortran order. For contiguous views, ‘A’ returns an exact copy of the physical memory. In particular, in-memory Fortran order is preserved. For non-contiguous views, the data is converted to C first. order=None is the same as order=’C’.

hex( sep [[, bytes_per_sep ]])

Return a string object containing two hexadecimal digits for each byte in the buffer.

>>> m = memoryview(b"abc")

>>> m.hex()

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

'616263'



Added in version 3.5.

Changed in version 3.8: Similar to bytes.hex(), memoryview.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output.

tolist()

Return the data in the buffer as a list of elements.

>>> memoryview(b'abc').tolist()

[97, 98, 99]

>>> import array

>>> a = array.array('d', [1.1, 2.2, 3.3])

>>> m = memoryview(a)

>>> m.tolist()

[1.1, 2.2, 3.3]



Changed in version 3.3: tolist() now supports all single character native formats in struct module syntax as well as multi-dimensional representations.

toreadonly()

Return a readonly version of the memoryview object. The original memoryview object is unchanged.

>>> m = memoryview(bytearray(b'abc'))

>>> mm = m.toreadonly()

>>> mm.tolist()

[97, 98, 99]

>>> mm[0] = 42

Traceback (most recent call last):

File "", line 1, in

TypeError: cannot modify read-only memory

>>> m[0] = 43

>>> mm.tolist()

[43, 98, 99]



Added in version 3.8.

release()

Release the underlying buffer exposed by the memoryview object. Many objects take special actions when

a view is held on them (for example, a bytearray would temporarily forbid resizing); therefore, calling release() is handy to remove these restrictions (and free any dangling resources) as soon as possible.

After this method has been called, any further operation on the view raises a ValueError (except

release() itself which can be called multiple times):

>>> m = memoryview(b'abc')

>>> m.release()

>>> m[0]

Traceback (most recent call last):

File "", line 1, in

ValueError: operation forbidden on released memoryview object



The context management protocol can be used for a similar effect, using the with statement:

>>> with memoryview(b'abc') as m:

... m[0]

...

97

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> m[0]

Traceback (most recent call last):

File "", line 1, in

ValueError: operation forbidden on released memoryview object



Added in version 3.2.

cast(format[, shape ])

Cast a memoryview to a new format or shape. shape defaults to [byte_length//new_itemsize], which means that the result view will be one-dimensional. The return value is a new memoryview, but

the buffer itself is not copied. Supported casts are 1D -> C-contiguous and C-contiguous -> 1D.

The destination format is restricted to a single element native format in struct syntax. One of the formats must be a byte format (‘B’, ‘b’ or ‘c’). The byte length of the result must be the same as the original length. Note that all byte lengths may depend on the operating system.

Cast 1D/long to 1D/unsigned bytes:

>>> import array

>>> a = array.array('l', [1,2,3])

>>> x = memoryview(a)

>>> x.format

'l'

>>> x.itemsize

8

>>> len(x)

3

>>> x.nbytes

24

>>> y = x.cast('B')

>>> y.format

'B'

>>> y.itemsize

1

>>> len(y)

24

>>> y.nbytes

24



Cast 1D/unsigned bytes to 1D/char:

>>> b = bytearray(b'zyz')

>>> x = memoryview(b)

>>> x[0] = b'a'

Traceback (most recent call last):

...

TypeError: memoryview: invalid type for format 'B' >>> y = x.cast('c')

>>> y[0] = b'a'

>>> b

bytearray(b'ayz')



Cast 1D/bytes to 3D/ints to 1D/signed char:

>>> import struct

>>> buf = struct.pack("i"*12, *list(range(12)))

>>> x = memoryview(buf)

>>> y = x.cast('i', shape=[2,2,3])

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> y.tolist()

[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]] >>> y.format

'i'

>>> y.itemsize

4

>>> len(y)

2

>>> y.nbytes

48

>>> z = y.cast('b')

>>> z.format

'b'

>>> z.itemsize

1

>>> len(z)

48

>>> z.nbytes

48



Cast 1D/unsigned long to 2D/unsigned long:

>>> buf = struct.pack("L"*6, *list(range(6)))

>>> x = memoryview(buf)

>>> y = x.cast('L', shape=[2,3])

>>> len(y)

2

>>> y.nbytes

48

>>> y.tolist()

[[0, 1, 2], [3, 4, 5]]



Added in version 3.3.

Changed in version 3.5: The source format is no longer restricted when casting to a byte view.

There are also several readonly attributes available:

obj

The underlying object of the memoryview:

>>> b = bytearray(b'xyz')

>>> m = memoryview(b)

>>> m.obj is b

True



Added in version 3.3.

nbytes

nbytes == product(shape) * itemsize == len(m.tobytes()). This is the amount of

space in bytes that the array would use in a contiguous representation. It is not necessarily equal to len(m) :

>>> import array

>>> a = array.array('i', [1,2,3,4,5])

>>> m = memoryview(a)

>>> len(m)

5

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> m.nbytes

20

>>> y = m[::2]

>>> len(y)

3

>>> y.nbytes

12

>>> len(y.tobytes())

12



Multi-dimensional arrays:

>>> import struct

>>> buf = struct.pack("d"*12, *[1.5*x for x in range(12)])

>>> x = memoryview(buf)

>>> y = x.cast('d', shape=[3,4])

>>> y.tolist()

[[0.0, 1.5, 3.0, 4.5], [6.0, 7.5, 9.0, 10.5], [12.0, 13.5, 15.0, 16.5]] >>> len(y)

3

>>> y.nbytes

96



Added in version 3.3.

readonly

A bool indicating whether the memory is read only.

format

A string containing the format (in struct module style) for each element in the view. A memoryview

can be created from exporters with arbitrary format strings, but some methods (e.g. tolist()) are restricted to native single element formats.

Changed in version 3.3: format 'B' is now handled according to the struct module syntax. This means that memoryview(b'abc')[0] == b'abc'[0] == 97.

itemsize

The size in bytes of each element of the memoryview:

>>> import array, struct

>>> m = memoryview(array.array('H', [32000, 32001, 32002])) >>> m.itemsize

2

>>> m[0]

32000

>>> struct.calcsize('H') == m.itemsize

True



ndim

An integer indicating how many dimensions of a multi-dimensional array the memory represents.

shape

A tuple of integers the length of ndim giving the shape of the memory as an N-dimensional array.

Changed in version 3.3: An empty tuple instead of None when ndim = 0.

strides

A tuple of integers the length of ndim giving the size in bytes to access each element for each dimension of the array.





The Python Library Reference, Release 3.13.2




Changed in version 3.3: An empty tuple instead of None when ndim = 0.

suboffsets

Used internally for PIL-style arrays. The value is informational only.

c_contiguous

A bool indicating whether the memory is C-contiguous.

Added in version 3.3.

f_contiguous

A bool indicating whether the memory is Fortran contiguous.

Added in version 3.3.

contiguous

A bool indicating whether the memory is contiguous.

Added in version 3.3.



4.10 Set Types — set, frozenset

A set object is an unordered collection of distinct hashable objects. Common uses include membership testing, removing duplicates from a sequence, and computing mathematical operations such as intersection, union, differ-

ence, and symmetric difference. (For other containers see the built-in dict, list, and tuple classes, and the

collections module.)

Like other collections, sets support x in set, len(set), and for x in set. Being an unordered collection, sets do not record element position or order of insertion. Accordingly, sets do not support indexing, slicing, or other sequence-like behavior.

There are currently two built-in set types, set and frozenset. The set type is mutable — the contents can be changed using methods like add() and remove(). Since it is mutable, it has no hash value and cannot be used

as either a dictionary key or as an element of another set. The frozenset type is immutable and hashable — its contents cannot be altered after it is created; it can therefore be used as a dictionary key or as an element of another set.

Non-empty sets (not frozensets) can be created by placing a comma-separated list of elements within braces, for

example: {'jack', 'sjoerd'}, in addition to the set constructor.

The constructors for both classes work the same:

class set( iterable [ ])

class frozenset( iterable [ ])

Return a new set or frozenset object whose elements are taken from iterable. The elements of a set must be

hashable. To represent sets of sets, the inner sets must be frozenset objects. If iterable is not specified, a

new empty set is returned.

Sets can be created by several means:

• Use a comma-separated list of elements within braces: {'jack', 'sjoerd'}

• Use a set comprehension: {c for c in 'abracadabra' if c not in 'abc'}

• Use the type constructor: set(), set('foobar'), set(['a', 'b', 'foo'])

Instances of set and frozenset provide the following operations:

len(s)

Return the number of elements in set s (cardinality of s).

x in s

Test x for membership in s.

The Python Library Reference, Release 3.13.2



x not in s

Test x for non-membership in s.

isdisjoint(other)

Return True if the set has no elements in common with other. Sets are disjoint if and only if their intersection is the empty set.

issubset(other)

set <= other

Test whether every element in the set is in other.

set < other

Test whether the set is a proper subset of other, that is, set <= other and set != other.

issuperset(other)

set >= other

Test whether every element in other is in the set.

set > other

Test whether the set is a proper superset of other, that is, set >= other and set != other.

union(*others)

set | other | ...

Return a new set with elements from the set and all others.

intersection(*others)

set & other & ...

Return a new set with elements common to the set and all others.

difference(*others)

set - other - ...

Return a new set with elements in the set that are not in the others.

symmetric_difference(other)

set ^ other

Return a new set with elements in either the set or other but not both.

copy()

Return a shallow copy of the set.

Note, the non-operator versions of union(), intersection(), difference(),

symmetric_difference(), issubset(), and issuperset() methods will accept any iterable as

an argument. In contrast, their operator based counterparts require their arguments to be sets. This precludes

error-prone constructions like set('abc') & 'cbs' in favor of the more readable set('abc').

intersection('cbs') .

Both set and frozenset support set to set comparisons. Two sets are equal if and only if every element of

each set is contained in the other (each is a subset of the other). A set is less than another set if and only if the

first set is a proper subset of the second set (is a subset, but is not equal). A set is greater than another set if

and only if the first set is a proper superset of the second set (is a superset, but is not equal).

Instances of set are compared to instances of frozenset based on their members. For ex-

ample, set('abc') == frozenset('abc') returns True and so does set('abc') in

set([frozenset('abc')]).

The subset and equality comparisons do not generalize to a total ordering function. For example, any two

nonempty disjoint sets are not equal and are not subsets of each other, so all of the following return False:

a , a==b, or a>b.

Since sets only define partial ordering (subset relationships), the output of the list.sort() method is un-

defined for lists of sets.





The Python Library Reference, Release 3.13.2




Set elements, like dictionary keys, must be hashable.

Binary operations that mix set instances with frozenset return the type of the first operand. For example:

frozenset('ab') | set('bc') returns an instance of frozenset.

The following table lists operations available for set that do not apply to immutable instances of frozenset:



update(*others)

set |= other | ...

Update the set, adding elements from all others.

intersection_update(*others)

set &= other & ...

Update the set, keeping only elements found in it and all others.

difference_update(*others)

set -= other | ...

Update the set, removing elements found in others.

symmetric_difference_update(other)

set ^= other

Update the set, keeping only elements found in either set, but not in both.

add(elem)

Add element elem to the set.

remove(elem)

Remove element elem from the set. Raises KeyError if elem is not contained in the set.

discard(elem)

Remove element elem from the set if it is present.

pop()

Remove and return an arbitrary element from the set. Raises KeyError if the set is empty.

clear()

Remove all elements from the set.

Note, the non-operator versions of the update(), intersection_update(), difference_update(),

and symmetric_difference_update() methods will accept any iterable as an argument.

Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To

support searching for an equivalent frozenset, a temporary one is created from elem.



4.11 Mapping Types — dict

A mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only

one standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and

the collections module.)

A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictio-naries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Values that compare equal (such as 1, 1.0, and True) can be used interchangeably to index the same dictionary entry.

class dict(**kwargs)

class dict(mapping, **kwargs)



The Python Library Reference, Release 3.13.2



class dict(iterable, **kwargs)

Return a new dictionary initialized from an optional positional argument and a possibly empty set of keyword

arguments.

Dictionaries can be created by several means:

• Use a comma-separated list of key: value pairs within braces: {'jack': 4098, 'sjoerd':

4127} or {4098: 'jack', 4127: 'sjoerd'}

• Use a dict comprehension: {}, {x: x ** 2 for x in range(10)}

• Use the type constructor: dict(), dict([('foo', 100), ('bar', 200)]), dict(foo=100,

bar=200)

If no positional argument is given, an empty dictionary is created. If a positional argument is given and it

defines a keys() method, a dictionary is created by calling __getitem__() on the argument with each

returned key from the method. Otherwise, the positional argument must be an iterable object. Each item in

the iterable must itself be an iterable with exactly two elements. The first element of each item becomes a key

in the new dictionary, and the second element the corresponding value. If a key occurs more than once, the

last value for that key becomes the corresponding value in the new dictionary.

If keyword arguments are given, the keyword arguments and their values are added to the dictionary created

from the positional argument. If a key being added is already present, the value from the keyword argument

replaces the value from the positional argument.

To illustrate, the following examples all return a dictionary equal to {"one": 1, "two": 2, "three":

3}:

>>> a = dict(one=1, two=2, three=3)

>>> b = {'one': 1, 'two': 2, 'three': 3}

>>> c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))

>>> d = dict([('two', 2), ('one', 1), ('three', 3)])

>>> e = dict({'three': 3, 'one': 1, 'two': 2})

>>> f = dict({'one': 1, 'three': 3}, two=2)

>>> a == b == c == d == e == f

True



Providing keyword arguments as in the first example only works for keys that are valid Python identifiers.

Otherwise, any valid keys can be used.

These are the operations that dictionaries support (and therefore, custom mapping types should support too):

list(d)

Return a list of all the keys used in the dictionary d.

len(d)

Return the number of items in the dictionary d.

d[key]

Return the item of d with key key. Raises a KeyError if key is not in the map.

If a subclass of dict defines a method __missing__() and key is not present, the d[key] operation calls that method with the key key as argument. The d[key] operation then returns or raises what-ever is returned or raised by the __missing__(key) call. No other operations or methods invoke

__missing__(). If __missing__() is not defined, KeyError is raised. __missing__() must be a method; it cannot be an instance variable:

>>> class Counter(dict):

... def __missing__(self, key):

... return 0

...

>>> c = Counter()

>>> c['red']

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

0

>>> c['red'] += 1

>>> c['red']

1



The example above shows part of the implementation of collections.Counter. A different

__missing__ method is used by collections.defaultdict.

d[key] = value

Set d[key] to value.

del d[key]

Remove d[key] from d. Raises a KeyError if key is not in the map.

key in d

Return True if d has a key key, else False.

key not in d

Equivalent to not key in d.

iter(d)

Return an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()).

clear()

Remove all items from the dictionary.

copy()

Return a shallow copy of the dictionary.

classmethod fromkeys(iterable, value=None, / )

Create a new dictionary with keys from iterable and values set to value.

fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values refer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as an empty list. To get distinct values, use a dict comprehension instead.

get(key, default=None)

Return the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,

so that this method never raises a KeyError.

items()

Return a new view of the dictionary’s items ((key, value) pairs). See the documentation of view

objects.

keys()

Return a new view of the dictionary’s keys. See the documentation of view objects.

pop(key[, default ])

If key is in the dictionary, remove it and return its value, else return default. If default is not given and

key is not in the dictionary, a KeyError is raised.

popitem()

Remove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in, first-out) order.

popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the

dictionary is empty, calling popitem() raises a KeyError.

Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an arbitrary key/value pair.

The Python Library Reference, Release 3.13.2



reversed(d)

Return a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()).

Added in version 3.8.

setdefault(key, default=None)

If key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None.

update( other [ ])

Update the dictionary with the key/value pairs from other, overwriting existing keys. Return None.

update() accepts either another object with a keys() method (in which case __getitem__() is called with every key returned from the method) or an iterable of key/value pairs (as tuples or other iterables of length two). If keyword arguments are specified, the dictionary is then updated with those key/value pairs: d.update(red=1, blue=2).

values()

Return a new view of the dictionary’s values. See the documentation of view objects.

An equality comparison between one dict.values() view and another will always return False. This also applies when comparing dict.values() to itself:

>>> d = {'a': 1}

>>> d.values() == d.values()

False



d | other

Create a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys.

Added in version 3.9.

d |= other

Update the dictionary d with keys and values from other, which may be either a mapping or an iterable of key/value pairs. The values of other take priority when d and other share keys.

Added in version 3.9.

Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering).

Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError.

Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after

deletion are inserted at the end.

>>> d = {"one": 1, "two": 2, "three": 3, "four": 4}

>>> d

{'one': 1, 'two': 2, 'three': 3, 'four': 4}

>>> list(d)

['one', 'two', 'three', 'four']

>>> list(d.values())

[1, 2, 3, 4]

>>> d["one"] = 42

>>> d

{'one': 42, 'two': 2, 'three': 3, 'four': 4}

>>> del d["two"]

>>> d["two"] = None

>>> d

{'one': 42, 'three': 3, 'four': 4, 'two': None}



Changed in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-

tation detail of CPython from 3.6.





The Python Library Reference, Release 3.13.2




Dictionaries and dictionary views are reversible.

>>> d = {"one": 1, "two": 2, "three": 3, "four": 4}

>>> d

{'one': 1, 'two': 2, 'three': 3, 'four': 4}

>>> list(reversed(d))

['four', 'three', 'two', 'one']

>>> list(reversed(d.values()))

[4, 3, 2, 1]

>>> list(reversed(d.items()))

[('four', 4), ('three', 3), ('two', 2), ('one', 1)]



Changed in version 3.8: Dictionaries are now reversible.



µ See also

types.MappingProxyType can be used to create a read-only view of a dict.



4.11.1 Dictionary view objects

The objects returned by dict.keys(), dict.values() and dict.items() are view objects. They provide a dynamic view on the dictionary’s entries, which means that when the dictionary changes, the view reflects these changes.

Dictionary views can be iterated over to yield their respective data, and support membership tests:

len(dictview)

Return the number of entries in the dictionary.

iter(dictview)

Return an iterator over the keys, values or items (represented as tuples of (key, value)) in the dictionary.

Keys and values are iterated over in insertion order. This allows the creation of (value, key) pairs using

zip() : pairs = zip(d.values(), d.keys()). Another way to create the same list is pairs = [(v,

k) for (k, v) in d.items()].

Iterating views while adding or deleting entries in the dictionary may raise a RuntimeError or fail to iterate

over all entries.

Changed in version 3.7: Dictionary order is guaranteed to be insertion order.

x in dictview

Return True if x is in the underlying dictionary’s keys, values or items (in the latter case, x should be a (key,

value) tuple).

reversed(dictview)

Return a reverse iterator over the keys, values or items of the dictionary. The view will be iterated in reverse

order of the insertion.

Changed in version 3.8: Dictionary views are now reversible.

dictview.mapping

Return a types.MappingProxyType that wraps the original dictionary to which the view refers.

Added in version 3.10.

Keys views are set-like since their entries are unique and hashable. Items views also have set-like operations since the (key, value) pairs are unique and the keys are hashable. If all values in an items view are hashable as well, then the items view can interoperate with other sets. (Values views are not treated as set-like since the entries are generally

not unique.) For set-like views, all of the operations defined for the abstract base class collections.abc.Set are available (for example, ==, <, or ^). While using set operators, set-like views accept any iterable as the other operand, unlike sets which only accept sets as the input.





The Python Library Reference, Release 3.13.2




An example of dictionary view usage:

>>> dishes = {'eggs': 2, 'sausage': 1, 'bacon': 1, 'spam': 500} >>> keys = dishes.keys()

>>> values = dishes.values()

>>> # iteration

>>> n = 0

>>> for val in values:

... n += val

...

>>> print(n)

504

>>> # keys and values are iterated over in the same order (insertion order) >>> list(keys)

['eggs', 'sausage', 'bacon', 'spam']

>>> list(values)

[2, 1, 1, 500]

>>> # view objects are dynamic and reflect dict changes >>> del dishes['eggs']

>>> del dishes['sausage']

>>> list(keys)

['bacon', 'spam']

>>> # set operations

>>> keys & {'eggs', 'bacon', 'salad'}

{'bacon'}

>>> keys ^ {'sausage', 'juice'} == {'juice', 'sausage', 'bacon', 'spam'} True

>>> keys | ['juice', 'juice', 'juice'] == {'bacon', 'spam', 'juice'} True

>>> # get back a read-only proxy for the original dictionary >>> values.mapping

mappingproxy({'bacon': 1, 'spam': 500})

>>> values.mapping['spam']

500



4.12 Context Manager Types

Python’s with statement supports the concept of a runtime context defined by a context manager. This is implemented using a pair of methods that allow user-defined classes to define a runtime context that is entered before the statement body is executed and exited when the statement ends:

contextmanager.__enter__()

Enter the runtime context and return either this object or another object related to the runtime context. The

value returned by this method is bound to the identifier in the as clause of with statements using this context

manager.

An example of a context manager that returns itself is a file object. File objects return themselves from __en-

ter__() to allow open() to be used as the context expression in a with statement.

An example of a context manager that returns a related object is the one returned by decimal.

localcontext(). These managers set the active decimal context to a copy of the original decimal context

and then return the copy. This allows changes to be made to the current decimal context in the body of the

with statement without affecting code outside the with statement.





The Python Library Reference, Release 3.13.2




contextmanager.__exit__(exc_type, exc_val, exc_tb)

Exit the runtime context and return a Boolean flag indicating if any exception that occurred should be sup-

pressed. If an exception occurred while executing the body of the with statement, the arguments contain the

exception type, value and traceback information. Otherwise, all three arguments are None.

Returning a true value from this method will cause the with statement to suppress the exception and continue

execution with the statement immediately following the with statement. Otherwise the exception continues

propagating after this method has finished executing. Exceptions that occur during execution of this method

will replace any exception that occurred in the body of the with statement.

The exception passed in should never be reraised explicitly - instead, this method should return a false value

to indicate that the method completed successfully and does not want to suppress the raised exception. This

allows context management code to easily detect whether or not an __exit__() method has actually failed.

Python defines several context managers to support easy thread synchronisation, prompt closure of files or other objects, and simpler manipulation of the active decimal arithmetic context. The specific types are not treated specially

beyond their implementation of the context management protocol. See the contextlib module for some examples.

Python’s generators and the contextlib.contextmanager decorator provide a convenient way to implement

these protocols. If a generator function is decorated with the contextlib.contextmanager decorator, it will

return a context manager implementing the necessary __enter__() and __exit__() methods, rather than the iterator produced by an undecorated generator function.

Note that there is no specific slot for any of these methods in the type structure for Python objects in the Python/C API. Extension types wanting to define these methods must provide them as a normal Python accessible method. Compared to the overhead of setting up the runtime context, the overhead of a single class dictionary lookup is negligible.



4.13 Type Annotation Types — Generic Alias, Union

The core built-in types for type annotations are Generic Alias and Union.



4.13.1 Generic Alias Type

GenericAlias objects are generally created by subscripting a class. They are most often used with container classes,

such as list or dict. For example, list[int] is a GenericAlias object created by subscripting the list class

with the argument int. GenericAlias objects are intended primarily for use with type annotations.



® Note

It is generally only possible to subscript a class if the class implements the special method

__class_getitem__() .



A GenericAlias object acts as a proxy for a generic type, implementing parameterized generics.

For a container class, the argument(s) supplied to a subscription of the class may indicate the type(s) of the elements

an object contains. For example, set[bytes] can be used in type annotations to signify a set in which all the

elements are of type bytes.

For a class which defines __class_getitem__() but is not a container, the argument(s) supplied to a subscription

of the class will often indicate the return type(s) of one or more methods defined on an object. For example, regular

expressions can be used on both the str data type and the bytes data type:

• If x = re.search('foo', 'foo'), x will be a re.Match object where the return values of x.group(0)

and x[0] will both be of type str. We can represent this kind of object in type annotations with the

GenericAlias re.Match[str] .

• If y = re.search(b'bar', b'bar'), (note the b for bytes), y will also be an instance of re.Match,

but the return values of y.group(0) and y[0] will both be of type bytes. In type annotations, we would

represent this variety of re.Match objects with re.Match[bytes].

The Python Library Reference, Release 3.13.2



GenericAlias objects are instances of the class types.GenericAlias, which can also be used to create GenericAlias objects directly.

T[X, Y, ...]

Creates a GenericAlias representing a type T parameterized by types X, Y, and more depending on the T

used. For example, a function expecting a list containing float elements:

def average(values: list[float])-> float:

return sum(values) / len(values)



Another example for mapping objects, using a dict, which is a generic type expecting two type parameters

representing the key type and the value type. In this example, the function expects a dict with keys of type

str and values of type int:

def send_post_request(url: str, body: dict[str, int])-> None:

...



The builtin functions isinstance() and issubclass() do not accept GenericAlias types for their second argument:

>>> isinstance([1, 2], list[str])

Traceback (most recent call last):

File "", line 1, in

TypeError: isinstance() argument 2 cannot be a parameterized generic



The Python runtime does not enforce type annotations. This extends to generic types and their type parameters. When creating a container object from a GenericAlias, the elements in the container are not checked against their type. For example, the following code is discouraged, but will run without errors:

>>> t = list[str]

>>> t([1, 2, 3])

[1, 2, 3]



Furthermore, parameterized generics erase type parameters during object creation:

>>> t = list[str]

>>> type(t)



>>> l = t()

>>> type(l)





Calling repr() or str() on a generic shows the parameterized type:

>>> repr(list[int])

'list[int]'

>>> str(list[int])

'list[int]'



The __getitem__() method of generic containers will raise an exception to disallow mistakes like dict[str][str]:

>>> dict[str][str]

Traceback (most recent call last):

...

TypeError: dict[str] is not a generic class

The Python Library Reference, Release 3.13.2



However, such expressions are valid when type variables are used. The index must have as many elements as there

are type variable items in the GenericAlias object’s __args__.

>>> from typing import TypeVar

>>> Y = TypeVar('Y')

>>> dict[str, Y][int]

dict[str, int]



Standard Generic Classes

The following standard library classes support parameterized generics. This list is non-exhaustive.

• tuple

• list

• dict

• set

• frozenset

• type

• collections.deque

• collections.defaultdict

• collections.OrderedDict

• collections.Counter

• collections.ChainMap

• collections.abc.Awaitable

• collections.abc.Coroutine

• collections.abc.AsyncIterable

• collections.abc.AsyncIterator

• collections.abc.AsyncGenerator

• collections.abc.Iterable

• collections.abc.Iterator

• collections.abc.Generator

• collections.abc.Reversible

• collections.abc.Container

• collections.abc.Collection

• collections.abc.Callable

• collections.abc.Set

• collections.abc.MutableSet

• collections.abc.Mapping

• collections.abc.MutableMapping

• collections.abc.Sequence

• collections.abc.MutableSequence

• collections.abc.ByteString

• collections.abc.MappingView

The Python Library Reference, Release 3.13.2



• collections.abc.KeysView

• collections.abc.ItemsView

• collections.abc.ValuesView

• contextlib.AbstractContextManager

• contextlib.AbstractAsyncContextManager

• dataclasses.Field

• functools.cached_property

• functools.partialmethod

• os.PathLike

• queue.LifoQueue

• queue.Queue

• queue.PriorityQueue

• queue.SimpleQueue

• re.Pattern

• re.Match

• shelve.BsdDbShelf

• shelve.DbfilenameShelf

• shelve.Shelf

• types.MappingProxyType

• weakref.WeakKeyDictionary

• weakref.WeakMethod

• weakref.WeakSet

• weakref.WeakValueDictionary



Special Attributes of GenericAlias objects

All parameterized generics implement special read-only attributes.

genericalias.__origin__

This attribute points at the non-parameterized generic class:

>>> list[int].__origin__





genericalias.__args__

This attribute is a tuple (possibly of length 1) of generic types passed to the original __class_getitem__()

of the generic class:

>>> dict[str, list[int]].__args__

(, list[int])



genericalias.__parameters__

This attribute is a lazily computed tuple (possibly empty) of unique type variables found in __args__:





The Python Library Reference, Release 3.13.2




>>> from typing import TypeVar

>>> T = TypeVar('T')

>>> list[T].__parameters__

(~T,)



® Note

A GenericAlias object with typing.ParamSpec parameters may not have correct __parameters__

after substitution because typing.ParamSpec is intended primarily for static type checking.



genericalias.__unpacked__

A boolean that is true if the alias has been unpacked using the * operator (see TypeVarTuple).

Added in version 3.11.



µ See also

PEP 484- Type Hints

Introducing Python’s framework for type annotations.

PEP 585- Type Hinting Generics In Standard Collections

Introducing the ability to natively parameterize standard-library classes, provided they implement the spe-cial class method __class_getitem__().

Generics, user-defined generics and typing.Generic

Documentation on how to implement generic classes that can be parameterized at runtime and understood by static type-checkers.



Added in version 3.9.



4.13.2 Union Type

A union object holds the value of the | (bitwise or) operation on multiple type objects. These types are intended

primarily for type annotations. The union type expression enables cleaner type hinting syntax compared to typing.

Union.

X | Y | ...

Defines a union object which holds types X, Y, and so forth. X | Y means either X or Y. It is equivalent to

typing.Union[X, Y] . For example, the following function expects an argument of type int or float:

def square(number: int | float)-> int | float:

return number ** 2



® Note

The | operand cannot be used at runtime to define unions where one or more members is a forward ref-erence. For example, int | "Foo", where "Foo" is a reference to a class not yet defined, will fail at runtime. For unions which include forward references, present the whole expression as a string, e.g. "int | Foo".



union_object == other

Union objects can be tested for equality with other union objects. Details:

• Unions of unions are flattened:

The Python Library Reference, Release 3.13.2



(int | str) | float == int | str | float



• Redundant types are removed:

int | str | int == int | str



• When comparing unions, the order is ignored:

int | str == str | int



• It is compatible with typing.Union:

int | str == typing.Union[int, str]



• Optional types can be spelled as a union with None:

str | None == typing.Optional[str]



isinstance(obj, union_object)

issubclass(obj, union_object)

Calls to isinstance() and issubclass() are also supported with a union object:

>>> isinstance("", int | str)

True



However, parameterized generics in union objects cannot be checked:

>>> isinstance(1, int | list[int]) # short-circuit evaluation

True

>>> isinstance([1], int | list[int])

Traceback (most recent call last):

...

TypeError: isinstance() argument 2 cannot be a parameterized generic



The user-exposed type for the union object can be accessed from types.UnionType and used for isinstance() checks. An object cannot be instantiated from the type:

>>> import types

>>> isinstance(int | str, types.UnionType)

True

>>> types.UnionType()

Traceback (most recent call last):

File "", line 1, in

TypeError: cannot create 'types.UnionType' instances



® Note

The __or__() method for type objects was added to support the syntax X | Y. If a metaclass implements

__or__(), the Union may override it:

>>> class M(type):

... def __or__(self, other):

... return "Hello"

...

>>> class C(metaclass=M):

... pass

...





The Python Library Reference, Release 3.13.2




>>> C | int

'Hello'

>>> int | C

int | C



µ See also

PEP 604 – PEP proposing the X | Y syntax and the Union type.



Added in version 3.10.



4.14 Other Built-in Types

The interpreter supports several other kinds of objects. Most of these support only one or two operations.



4.14.1 Modules

The only special operation on a module is attribute access: m.name, where m is a module and name accesses a name defined in m’s symbol table. Module attributes can be assigned to. (Note that the import statement is not, strictly speaking, an operation on a module object; import foo does not require a module object named foo to exist, rather it requires an (external) definition for a module named foo somewhere.)

A special attribute of every module is __dict__. This is the dictionary containing the module’s symbol table. Modifying this dictionary will actually change the module’s symbol table, but direct assignment to the __dict__ attribute is not possible (you can write m.__dict__['a'] = 1, which defines m.a to be 1, but you can’t write m.__dict__ = {}). Modifying __dict__ directly is not recommended.

Modules built into the interpreter are written like this: . If loaded from a file, they are written as .



4.14.2 Classes and Class Instances

See objects and class for these.



4.14.3 Functions

Function objects are created by function definitions. The only operation on a function object is to call it:

func(argument-list).

There are really two flavors of function objects: built-in functions and user-defined functions. Both support the same operation (to call the function), but the implementation is different, hence the different object types.

See function for more information.



4.14.4 Methods

Methods are functions that are called using the attribute notation. There are two flavors: built-in methods (such as append() on lists) and class instance method. Built-in methods are described with the types that support them.

If you access a method (a function defined in a class namespace) through an instance, you get a special object: a bound method (also called instance method) object. When called, it will add the self argument to the argument list. Bound methods have two special read-only attributes: m.__self__ is the object on which the method operates, and m.__func__ is the function implementing the method. Calling m(arg-1, arg-2, ..., arg-n) is completely equivalent to calling m.__func__(m.__self__, arg-1, arg-2, ..., arg-n).

Like function objects, bound method objects support getting arbitrary attributes. However, since method attributes are actually stored on the underlying function object (method.__func__), setting method attributes on bound methods The Python Library Reference, Release 3.13.2





is disallowed. Attempting to set an attribute on a method results in an AttributeError being raised. In order to set a method attribute, you need to explicitly set it on the underlying function object:


>>> class C:

... def method(self):

... pass

...

>>> c = C()

>>> c.method.whoami = 'my name is method' # can't set on the method Traceback (most recent call last):

File "", line 1, in

AttributeError: 'method' object has no attribute 'whoami' >>> c.method.__func__.whoami = 'my name is method'

>>> c.method.whoami

'my name is method'



See instance-methods for more information.



4.14.5 Code Objects

Code objects are used by the implementation to represent “pseudo-compiled” executable Python code such as a function body. They differ from function objects because they don’t contain a reference to their global execution

environment. Code objects are returned by the built-in compile() function and can be extracted from function

objects through their __code__ attribute. See also the code module.

Accessing __code__ raises an auditing event object.__getattr__ with arguments obj and "__code__".

A code object can be executed or evaluated by passing it (instead of a source string) to the exec() or eval() built-in functions.

See types for more information.



4.14.6 Type Objects

Type objects represent the various object types. An object’s type is accessed by the built-in function type(). There

are no special operations on types. The standard module types defines names for all standard built-in types.

Types are written like this: .



4.14.7 The Null Object

This object is returned by functions that don’t explicitly return a value. It supports no special operations. There is exactly one null object, named None (a built-in name). type(None)() produces the same singleton.

It is written as None.



4.14.8 The Ellipsis Object

This object is commonly used by slicing (see slicings). It supports no special operations. There is exactly one ellipsis

object, named Ellipsis (a built-in name). type(Ellipsis)() produces the Ellipsis singleton.

It is written as Ellipsis or ....



4.14.9 The NotImplemented Object

This object is returned from comparisons and binary operations when they are asked to operate on types

they don’t support. See comparisons for more information. There is exactly one NotImplemented object. type(NotImplemented)() produces the singleton instance.

It is written as NotImplemented.





The Python Library Reference, Release 3.13.2




4.14.10 Internal Objects

See types for this information. It describes stack frame objects, traceback objects, and slice objects.



4.15 Special Attributes

The implementation adds a few special read-only attributes to several object types, where they are relevant. Some of

these are not reported by the dir() built-in function.

definition.__name__

The name of the class, function, method, descriptor, or generator instance.

definition.__qualname__

The qualified name of the class, function, method, descriptor, or generator instance.

Added in version 3.3.

definition.__module__

The name of the module in which a class or function was defined.

definition.__doc__

The documentation string of a class or function, or None if undefined.

definition.__type_params__

The type parameters of generic classes, functions, and type aliases. For classes and functions that are not

generic, this will be an empty tuple.

Added in version 3.12.



4.16 Integer string conversion length limitation

CPython has a global limit for converting between int and str to mitigate denial of service attacks. This limit only applies to decimal or other non-power-of-two number bases. Hexadecimal, octal, and binary conversions are unlimited. The limit can be configured.

The int type in CPython is an arbitrary length number stored in binary form (commonly known as a “bignum”). There exists no algorithm that can convert a string to a binary integer or a binary integer to a string in linear time, unless the base is a power of 2. Even the best known algorithms for base 10 have sub-quadratic complexity. Converting a large value such as int('1' * 500_000) can take over a second on a fast CPU.

Limiting conversion size offers a practical way to avoid CVE 2020-10735.

The limit is applied to the number of digit characters in the input or output string when a non-linear conversion algorithm would be involved. Underscores and the sign are not counted towards the limit.

When an operation would exceed the limit, a ValueError is raised:

>>> import sys

>>> sys.set_int_max_str_digits(4300) # Illustrative, this is the default. >>> _ = int('2' * 5432)

Traceback (most recent call last):

...

ValueError: Exceeds the limit (4300 digits) for integer string conversion: value␣

, →has 5432 digits; use sys.set_int_max_str_digits() to increase the limit

>>> i = int('2' * 4300)

>>> len(str(i))

4300

>>> i_squared = i*i

>>> len(str(i_squared))

Traceback (most recent call last):

...

(continues on next page)





The Python Library Reference, Release 3.13.2




(continued from previous page)

ValueError: Exceeds the limit (4300 digits) for integer string conversion; use sys.

, →set_int_max_str_digits() to increase the limit

>>> len(hex(i_squared))

7144

>>> assert int(hex(i_squared), base=16) == i*i # Hexadecimal is unlimited.



The default limit is 4300 digits as provided in sys.int_info.default_max_str_digits. The lowest limit that

can be configured is 640 digits as provided in sys.int_info.str_digits_check_threshold.

Verification:

>>> import sys

>>> assert sys.int_info.default_max_str_digits == 4300, sys.int_info >>> assert sys.int_info.str_digits_check_threshold == 640, sys.int_info >>> msg = int('578966293710682886880994035146873798396722250538762761564' ... '9252925514383915483333812743580549779436104706260696366600' ... '571186405732').to_bytes(53, 'big')

...



Added in version 3.11.



4.16.1 Affected APIs

The limitation only applies to potentially slow conversions between int and str or bytes:

• int(string) with default base 10.

• int(string, base) for all bases that are not a power of 2.

• str(integer).

• repr(integer).

• any other string conversion to base 10, for example f"{integer}", "{}".format(integer), or b"%d"

% integer.

The limitations do not apply to functions with a linear algorithm:

• int(string, base) with base 2, 4, 8, 16, or 32.

• int.from_bytes() and int.to_bytes().

• hex(), oct(), bin().

• Format Specification Mini-Language for hex, octal, and binary numbers.

• str to float.

• str to decimal.Decimal.



4.16.2 Configuring the limit

Before Python starts up you can use an environment variable or an interpreter command line flag to configure the limit:

• PYTHONINTMAXSTRDIGITS, e.g. PYTHONINTMAXSTRDIGITS=640 python3 to set the limit to 640 or

PYTHONINTMAXSTRDIGITS=0 python3 to disable the limitation.

•-X int_max_str_digits, e.g. python3 -X int_max_str_digits=640

• sys.flags.int_max_str_digits contains the value of PYTHONINTMAXSTRDIGITS or -X

int_max_str_digits . If both the env var and the-X option are set, the-X option takes precedence. A

value of-1 indicates that both were unset, thus a value of sys.int_info.default_max_str_digits

was used during initialization.

From code, you can inspect the current limit and set a new one using these sys APIs:





The Python Library Reference, Release 3.13.2




• sys.get_int_max_str_digits() and sys.set_int_max_str_digits() are a getter and setter for

the interpreter-wide limit. Subinterpreters have their own limit.

Information about the default and minimum can be found in sys.int_info:

• sys.int_info.default_max_str_digits is the compiled-in default limit.

• sys.int_info.str_digits_check_threshold is the lowest accepted value for the limit (other than 0

which disables it).

Added in version 3.11.



Ϫ Caution

Setting a low limit can lead to problems. While rare, code exists that contains integer constants in decimal in

their source that exceed the minimum threshold. A consequence of setting the limit is that Python source code

containing decimal integer literals longer than the limit will encounter an error during parsing, usually at startup

time or import time or even at installation time - anytime an up to date .pyc does not already exist for the code.

A workaround for source that contains such large constants is to convert them to 0x hexadecimal form as it has

no limit.

Test your application thoroughly if you use a low limit. Ensure your tests run with the limit set early via the

environment or flag so that it applies during startup and even during any installation step that may invoke Python

to precompile .py sources to .pyc files.



4.16.3 Recommended configuration

The default sys.int_info.default_max_str_digits is expected to be reasonable for most applications. If your application requires a different limit, set it from your main entry point using Python version agnostic code as these APIs were added in security patch releases in versions before 3.12.

Example:

>>> import sys

>>> if hasattr(sys, "set_int_max_str_digits"):

... upper_bound = 68000

... lower_bound = 4004

... current_limit = sys.get_int_max_str_digits()

... if current_limit == 0 or current_limit > upper_bound:

... sys.set_int_max_str_digits(upper_bound)

... elif current_limit < lower_bound:

... sys.set_int_max_str_digits(lower_bound)



If you need to disable it entirely, set it to 0.



The Python Library Reference, Release 3.13.2





CHAPTER




FIVE



BUILT-IN EXCEPTIONS



In Python, all exceptions must be instances of a class that derives from BaseException. In a try statement with an except clause that mentions a particular class, that clause also handles any exception classes derived from that class (but not exception classes from which it is derived). Two exception classes that are not related via subclassing are never equivalent, even if they have the same name.

The built-in exceptions listed in this chapter can be generated by the interpreter or built-in functions. Except where mentioned, they have an “associated value” indicating the detailed cause of the error. This may be a string or a tuple of several items of information (e.g., an error code and a string explaining the code). The associated value is usually passed as arguments to the exception class’s constructor.

User code can raise built-in exceptions. This can be used to test an exception handler or to report an error condition “just like” the situation in which the interpreter raises the same exception; but beware that there is nothing to prevent user code from raising an inappropriate error.

The built-in exception classes can be subclassed to define new exceptions; programmers are encouraged to derive new

exceptions from the Exception class or one of its subclasses, and not from BaseException. More information on defining exceptions is available in the Python Tutorial under tut-userexceptions.



5.1 Exception context

Three attributes on exception objects provide information about the context in which the exception was raised:

BaseException.__context__

BaseException.__cause__

BaseException.__suppress_context__

When raising a new exception while another exception is already being handled, the new exception’s

__context__ attribute is automatically set to the handled exception. An exception may be handled when an

except or finally clause, or a with statement, is used.

This implicit exception context can be supplemented with an explicit cause by using from with raise:

raise new_exc from original_exc



The expression following from must be an exception or None. It will be set as __cause__ on the raised excep-

tion. Setting __cause__ also implicitly sets the __suppress_context__ attribute to True, so that using

raise new_exc from None effectively replaces the old exception with the new one for display purposes

(e.g. converting KeyError to AttributeError), while leaving the old exception available in __context__

for introspection when debugging.

The default traceback display code shows these chained exceptions in addition to the traceback for the exception

itself. An explicitly chained exception in __cause__ is always shown when present. An implicitly chained

exception in __context__ is shown only if __cause__ is None and __suppress_context__ is false.

In either case, the exception itself is always shown after any chained exceptions so that the final line of the

traceback always shows the last exception that was raised.





The Python Library Reference, Release 3.13.2




5.2 Inheriting from built-in exceptions

User code can create subclasses that inherit from an exception type. It’s recommended to only subclass one exception type at a time to avoid any possible conflicts between how the bases handle the args attribute, as well as due to possible memory layout incompatibilities.

CPython implementation detail: Most built-in exceptions are implemented in C for efficiency, see: Ob-

jects/exceptions.c. Some have custom memory layouts which makes it impossible to create a subclass that inherits from multiple exception types. The memory layout of a type is an implementation detail and might change between Python versions, leading to new conflicts in the future. Therefore, it’s recommended to avoid subclassing multiple exception types altogether.



5.3 Base classes

The following exceptions are used mostly as base classes for other exceptions.

exception BaseException

The base class for all built-in exceptions. It is not meant to be directly inherited by user-defined classes (for

that, use Exception). If str() is called on an instance of this class, the representation of the argument(s) to

the instance are returned, or the empty string when there were no arguments.

args

The tuple of arguments given to the exception constructor. Some built-in exceptions (like OSError) expect a certain number of arguments and assign a special meaning to the elements of this tuple, while others are usually called only with a single string giving an error message.

with_traceback(tb)

This method sets tb as the new traceback for the exception and returns the exception object. It was more

commonly used before the exception chaining features of PEP 3134 became available. The following ex-ample shows how we can convert an instance of SomeException into an instance of OtherException while preserving the traceback. Once raised, the current frame is pushed onto the traceback of the OtherException, as would have happened to the traceback of the original SomeException had we allowed it to propagate to the caller.

try:

...

except SomeException:

tb = sys.exception().__traceback__

raise OtherException(...).with_traceback(tb)



__traceback__

A writable field that holds the traceback object associated with this exception. See also: raise.

add_note(note)

Add the string note to the exception’s notes which appear in the standard traceback after the exception

string. A TypeError is raised if note is not a string.

Added in version 3.11.

__notes__

A list of the notes of this exception, which were added with add_note(). This attribute is created when

add_note() is called.

Added in version 3.11.

exception Exception

All built-in, non-system-exiting exceptions are derived from this class. All user-defined exceptions should also

be derived from this class.





The Python Library Reference, Release 3.13.2




exception ArithmeticError

The base class for those built-in exceptions that are raised for various arithmetic errors: OverflowError,

ZeroDivisionError , FloatingPointError.

exception BufferError

Raised when a buffer related operation cannot be performed.

exception LookupError

The base class for the exceptions that are raised when a key or index used on a mapping or sequence is invalid:

IndexError, KeyError. This can be raised directly by codecs.lookup().



5.4 Concrete exceptions

The following exceptions are the exceptions that are usually raised.

exception AssertionError

Raised when an assert statement fails.

exception AttributeError

Raised when an attribute reference (see attribute-references) or assignment fails. (When an object does not

support attribute references or attribute assignments at all, TypeError is raised.)

The name and obj attributes can be set using keyword-only arguments to the constructor. When set they

represent the name of the attribute that was attempted to be accessed and the object that was accessed for said

attribute, respectively.

Changed in version 3.10: Added the name and obj attributes.

exception EOFError

Raised when the input() function hits an end-of-file condition (EOF) without reading any data. (N.B.: the

io.IOBase.read() and io.IOBase.readline() methods return an empty string when they hit EOF.)

exception FloatingPointError

Not currently used.

exception GeneratorExit

Raised when a generator or coroutine is closed; see generator.close() and coroutine.close(). It

directly inherits from BaseException instead of Exception since it is technically not an error.

exception ImportError

Raised when the import statement has troubles trying to load a module. Also raised when the “from list” in

from ... import has a name that cannot be found.

The optional name and path keyword-only arguments set the corresponding attributes:

name

The name of the module that was attempted to be imported.

path

The path to any file which triggered the exception.

Changed in version 3.3: Added the name and path attributes.

exception ModuleNotFoundError

A subclass of ImportError which is raised by import when a module could not be located. It is also raised

when None is found in sys.modules.

Added in version 3.6.

exception IndexError

Raised when a sequence subscript is out of range. (Slice indices are silently truncated to fall in the allowed

range; if an index is not an integer, TypeError is raised.)

The Python Library Reference, Release 3.13.2



exception KeyError

Raised when a mapping (dictionary) key is not found in the set of existing keys.

exception KeyboardInterrupt

Raised when the user hits the interrupt key (normally Control-C or Delete). During execution, a check for

interrupts is made regularly. The exception inherits from BaseException so as to not be accidentally caught

by code that catches Exception and thus prevent the interpreter from exiting.



® Note

Catching a KeyboardInterrupt requires special consideration. Because it can be raised at unpredictable points, it may, in some circumstances, leave the running program in an inconsistent state. It is generally

best to allow KeyboardInterrupt to end the program as quickly as possible or avoid raising it entirely.

(See Note on Signal Handlers and Exceptions.)



exception MemoryError

Raised when an operation runs out of memory but the situation may still be rescued (by deleting some objects).

The associated value is a string indicating what kind of (internal) operation ran out of memory. Note that

because of the underlying memory management architecture (C’s malloc() function), the interpreter may

not always be able to completely recover from this situation; it nevertheless raises an exception so that a stack

traceback can be printed, in case a run-away program was the cause.

exception NameError

Raised when a local or global name is not found. This applies only to unqualified names. The associated value

is an error message that includes the name that could not be found.

The name attribute can be set using a keyword-only argument to the constructor. When set it represent the

name of the variable that was attempted to be accessed.

Changed in version 3.10: Added the name attribute.

exception NotImplementedError

This exception is derived from RuntimeError. In user defined base classes, abstract methods should raise

this exception when they require derived classes to override the method, or while the class is being developed

to indicate that the real implementation still needs to be added.



® Note

It should not be used to indicate that an operator or method is not meant to be supported at all – in that

case either leave the operator / method undefined or, if a subclass, set it to None.



® Note

NotImplementedError and NotImplemented are not interchangeable, even though they have similar names and purposes. See NotImplemented for details on when to use it.



exception OSError( arg [ ])

exception OSError(errno, strerror[, filename[, winerror[, filename2 ]]])

This exception is raised when a system function returns a system-related error, including I/O failures such as

“file not found” or “disk full” (not for illegal argument types or other incidental errors).

The second form of the constructor sets the corresponding attributes, described below. The attributes default to

None if not specified. For backwards compatibility, if three arguments are passed, the args attribute contains

only a 2-tuple of the first two constructor arguments.

The Python Library Reference, Release 3.13.2



The constructor often actually returns a subclass of OSError, as described in OS exceptions below. The par-

ticular subclass depends on the final errno value. This behaviour only occurs when constructing OSError

directly or via an alias, and is not inherited when subclassing.

errno

A numeric error code from the C variable errno.

winerror

Under Windows, this gives you the native Windows error code. The errno attribute is then an approxi-mate translation, in POSIX terms, of that native error code.

Under Windows, if the winerror constructor argument is an integer, the errno attribute is determined from the Windows error code, and the errno argument is ignored. On other platforms, the winerror

argument is ignored, and the winerror attribute does not exist.

strerror

The corresponding error message, as provided by the operating system. It is formatted by the C functions perror() under POSIX, and FormatMessage() under Windows.

filename

filename2

For exceptions that involve a file system path (such as open() or os.unlink()), filename is the file

name passed to the function. For functions that involve two file system paths (such as os.rename()),

filename2 corresponds to the second file name passed to the function.

Changed in version 3.3: EnvironmentError, IOError, WindowsError, socket.error, select.

error and mmap.error have been merged into OSError, and the constructor may return a subclass.

Changed in version 3.4: The filename attribute is now the original file name passed to the function, instead

of the name encoded to or decoded from the filesystem encoding and error handler. Also, the filename2

constructor argument and attribute was added.

exception OverflowError

Raised when the result of an arithmetic operation is too large to be represented. This cannot occur for integers

(which would rather raise MemoryError than give up). However, for historical reasons, OverflowError is

sometimes raised for integers that are outside a required range. Because of the lack of standardization of

floating-point exception handling in C, most floating-point operations are not checked.

exception PythonFinalizationError

This exception is derived from RuntimeError. It is raised when an operation is blocked during interpreter

shutdown also known as Python finalization.

Examples of operations which can be blocked with a PythonFinalizationError during the Python final-

ization:

• Creating a new Python thread.

• os.fork().

See also the sys.is_finalizing() function.

Added in version 3.13: Previously, a plain RuntimeError was raised.

exception RecursionError

This exception is derived from RuntimeError. It is raised when the interpreter detects that the maximum

recursion depth (see sys.getrecursionlimit()) is exceeded.

Added in version 3.5: Previously, a plain RuntimeError was raised.

exception ReferenceError

This exception is raised when a weak reference proxy, created by the weakref.proxy() function, is used to

access an attribute of the referent after it has been garbage collected. For more information on weak references,

see the weakref module.

The Python Library Reference, Release 3.13.2



exception RuntimeError

Raised when an error is detected that doesn’t fall in any of the other categories. The associated value is a string

indicating what precisely went wrong.

exception StopIteration

Raised by built-in function next() and an iterator’s __next__() method to signal that there are no further

items produced by the iterator.

value

The exception object has a single attribute value, which is given as an argument when constructing the

exception, and defaults to None.

When a generator or coroutine function returns, a new StopIteration instance is raised, and the value

returned by the function is used as the value parameter to the constructor of the exception.

If a generator code directly or indirectly raises StopIteration, it is converted into a RuntimeError (re-

taining the StopIteration as the new exception’s cause).

Changed in version 3.3: Added value attribute and the ability for generator functions to use it to return a

value.

Changed in version 3.5: Introduced the RuntimeError transformation via from __future__ import

generator_stop, see PEP 479.

Changed in version 3.7: Enable PEP 479 for all code by default: a StopIteration error raised in a generator

is transformed into a RuntimeError.

exception StopAsyncIteration

Must be raised by __anext__() method of an asynchronous iterator object to stop the iteration.

Added in version 3.5.

exception SyntaxError( message, details)

Raised when the parser encounters a syntax error. This may occur in an import statement, in a call to the

built-in functions compile(), exec(), or eval(), or when reading the initial script or standard input (also

interactively).

The str() of the exception instance returns only the error message. Details is a tuple whose members are

also available as separate attributes.

filename

The name of the file the syntax error occurred in.

lineno

Which line number in the file the error occurred in. This is 1-indexed: the first line in the file has a lineno of 1.

offset

The column in the line where the error occurred. This is 1-indexed: the first character in the line has an offset of 1.

text

The source code text involved in the error.

end_lineno

Which line number in the file the error occurred ends in. This is 1-indexed: the first line in the file has a lineno of 1.

end_offset

The column in the end line where the error occurred finishes. This is 1-indexed: the first character in the line has an offset of 1.

For errors in f-string fields, the message is prefixed by “f-string: ” and the offsets are offsets in a text constructed

from the replacement expression. For example, compiling f’Bad {a b} field’ results in this args attribute: (‘f-

string: …’, (‘’, 1, 2, ‘(a b)n’, 1, 5)).

The Python Library Reference, Release 3.13.2



Changed in version 3.10: Added the end_lineno and end_offset attributes.

exception IndentationError

Base class for syntax errors related to incorrect indentation. This is a subclass of SyntaxError.

exception TabError

Raised when indentation contains an inconsistent use of tabs and spaces. This is a subclass of

IndentationError .

exception SystemError

Raised when the interpreter finds an internal error, but the situation does not look so serious to cause it to

abandon all hope. The associated value is a string indicating what went wrong (in low-level terms). In CPython,

this could be raised by incorrectly using Python’s C API, such as returning a NULL value without an exception

set.

If you’re confident that this exception wasn’t your fault, or the fault of a package you’re using, you should

report this to the author or maintainer of your Python interpreter. Be sure to report the version of the Python

interpreter (sys.version; it is also printed at the start of an interactive Python session), the exact error

message (the exception’s associated value) and if possible the source of the program that triggered the error.

exception SystemExit

This exception is raised by the sys.exit() function. It inherits from BaseException instead of

Exception so that it is not accidentally caught by code that catches Exception. This allows the exception

to properly propagate up and cause the interpreter to exit. When it is not handled, the Python interpreter exits;

no stack traceback is printed. The constructor accepts the same optional argument passed to sys.exit(). If

the value is an integer, it specifies the system exit status (passed to C’s exit() function); if it is None, the exit

status is zero; if it has another type (such as a string), the object’s value is printed and the exit status is one.

A call to sys.exit() is translated into an exception so that clean-up handlers (finally clauses of try

statements) can be executed, and so that a debugger can execute a script without running the risk of losing

control. The os._exit() function can be used if it is absolutely positively necessary to exit immediately (for

example, in the child process after a call to os.fork()).

code

The exit status or error message that is passed to the constructor. (Defaults to None.)

exception TypeError

Raised when an operation or function is applied to an object of inappropriate type. The associated value is a

string giving details about the type mismatch.

This exception may be raised by user code to indicate that an attempted operation on an object is not sup-

ported, and is not meant to be. If an object is meant to support a given operation but has not yet provided an

implementation, NotImplementedError is the proper exception to raise.

Passing arguments of the wrong type (e.g. passing a list when an int is expected) should result in a

TypeError, but passing arguments with the wrong value (e.g. a number outside expected boundaries) should

result in a ValueError.

exception UnboundLocalError

Raised when a reference is made to a local variable in a function or method, but no value has been bound to

that variable. This is a subclass of NameError.

exception UnicodeError

Raised when a Unicode-related encoding or decoding error occurs. It is a subclass of ValueError.

UnicodeError has attributes that describe the encoding or decoding error. For example, err.object[err.

start:err.end] gives the particular invalid input that the codec failed on.

encoding

The name of the encoding that raised the error.

reason

A string describing the specific codec error.





The Python Library Reference, Release 3.13.2




object

The object the codec was attempting to encode or decode.

start

The first index of invalid data in object.

end

The index after the last invalid data in object.

exception UnicodeEncodeError

Raised when a Unicode-related error occurs during encoding. It is a subclass of UnicodeError.

exception UnicodeDecodeError

Raised when a Unicode-related error occurs during decoding. It is a subclass of UnicodeError.

exception UnicodeTranslateError

Raised when a Unicode-related error occurs during translating. It is a subclass of UnicodeError.

exception ValueError

Raised when an operation or function receives an argument that has the right type but an inappropriate value,

and the situation is not described by a more precise exception such as IndexError.

exception ZeroDivisionError

Raised when the second argument of a division or modulo operation is zero. The associated value is a string

indicating the type of the operands and the operation.

The following exceptions are kept for compatibility with previous versions; starting from Python 3.3, they are aliases

of OSError.

exception EnvironmentError

exception IOError

exception WindowsError

Only available on Windows.



5.4.1 OS exceptions

The following exceptions are subclasses of OSError, they get raised depending on the system error code.

exception BlockingIOError

Raised when an operation would block on an object (e.g. socket) set for non-blocking operation. Corresponds

to errno EAGAIN, EALREADY, EWOULDBLOCK and EINPROGRESS.

In addition to those of OSError, BlockingIOError can have one more attribute:

characters_written

An integer containing the number of characters written to the stream before it blocked. This attribute is

available when using the buffered I/O classes from the io module.

exception ChildProcessError

Raised when an operation on a child process failed. Corresponds to errno ECHILD.

exception ConnectionError

A base class for connection-related issues.

Subclasses are BrokenPipeError, ConnectionAbortedError, ConnectionRefusedError and

ConnectionResetError .

exception BrokenPipeError

A subclass of ConnectionError, raised when trying to write on a pipe while the other end has been closed,

or trying to write on a socket which has been shutdown for writing. Corresponds to errno EPIPE and

ESHUTDOWN .





The Python Library Reference, Release 3.13.2




exception ConnectionAbortedError

A subclass of ConnectionError, raised when a connection attempt is aborted by the peer. Corresponds to

errno ECONNABORTED.

exception ConnectionRefusedError

A subclass of ConnectionError, raised when a connection attempt is refused by the peer. Corresponds to

errno ECONNREFUSED.

exception ConnectionResetError

A subclass of ConnectionError, raised when a connection is reset by the peer. Corresponds to errno

ECONNRESET .

exception FileExistsError

Raised when trying to create a file or directory which already exists. Corresponds to errno EEXIST.

exception FileNotFoundError

Raised when a file or directory is requested but doesn’t exist. Corresponds to errno ENOENT.

exception InterruptedError

Raised when a system call is interrupted by an incoming signal. Corresponds to errno EINTR.

Changed in version 3.5: Python now retries system calls when a syscall is interrupted by a signal, except if the

signal handler raises an exception (see PEP 475 for the rationale), instead of raising InterruptedError.

exception IsADirectoryError

Raised when a file operation (such as os.remove()) is requested on a directory. Corresponds to errno

EISDIR .

exception NotADirectoryError

Raised when a directory operation (such as os.listdir()) is requested on something which is not a directory.

On most POSIX platforms, it may also be raised if an operation attempts to open or traverse a non-directory

file as if it were a directory. Corresponds to errno ENOTDIR.

exception PermissionError

Raised when trying to run an operation without the adequate access rights - for example filesystem permissions.

Corresponds to errno EACCES, EPERM , and ENOTCAPABLE.

Changed in version 3.11.1: WASI’s ENOTCAPABLE is now mapped to PermissionError.

exception ProcessLookupError

Raised when a given process doesn’t exist. Corresponds to errno ESRCH.

exception TimeoutError

Raised when a system function timed out at the system level. Corresponds to errno ETIMEDOUT.

Added in version 3.3: All the above OSError subclasses were added.



µ See also

PEP 3151- Reworking the OS and IO exception hierarchy



5.5 Warnings

The following exceptions are used as warning categories; see the Warning Categories documentation for more details.



exception Warning

Base class for warning categories.





The Python Library Reference, Release 3.13.2




exception UserWarning

Base class for warnings generated by user code.

exception DeprecationWarning

Base class for warnings about deprecated features when those warnings are intended for other Python devel-

opers.

Ignored by the default warning filters, except in the __main__ module (PEP 565). Enabling the Python

Development Mode shows this warning.

The deprecation policy is described in PEP 387.

exception PendingDeprecationWarning

Base class for warnings about features which are obsolete and expected to be deprecated in the future, but are

not deprecated at the moment.

This class is rarely used as emitting a warning about a possible upcoming deprecation is unusual, and

DeprecationWarning is preferred for already active deprecations.

Ignored by the default warning filters. Enabling the Python Development Mode shows this warning.

The deprecation policy is described in PEP 387.

exception SyntaxWarning

Base class for warnings about dubious syntax.

exception RuntimeWarning

Base class for warnings about dubious runtime behavior.

exception FutureWarning

Base class for warnings about deprecated features when those warnings are intended for end users of applica-

tions that are written in Python.

exception ImportWarning

Base class for warnings about probable mistakes in module imports.

Ignored by the default warning filters. Enabling the Python Development Mode shows this warning.

exception UnicodeWarning

Base class for warnings related to Unicode.

exception EncodingWarning

Base class for warnings related to encodings.

See Opt-in EncodingWarning for details.

Added in version 3.10.

exception BytesWarning

Base class for warnings related to bytes and bytearray.

exception ResourceWarning

Base class for warnings related to resource usage.

Ignored by the default warning filters. Enabling the Python Development Mode shows this warning.

Added in version 3.2.



5.6 Exception groups

The following are used when it is necessary to raise multiple unrelated exceptions. They are part of the exception hierarchy so they can be handled with except like all other exceptions. In addition, they are recognised by except*, which matches their subgroups based on the types of the contained exceptions.

The Python Library Reference, Release 3.13.2



exception ExceptionGroup(msg, excs)

exception BaseExceptionGroup(msg, excs)

Both of these exception types wrap the exceptions in the sequence excs. The msg parameter must be a

string. The difference between the two classes is that BaseExceptionGroup extends BaseException

and it can wrap any exception, while ExceptionGroup extends Exception and it can only wrap sub-

classes of Exception. This design is so that except Exception catches an ExceptionGroup but not

BaseExceptionGroup .

The BaseExceptionGroup constructor returns an ExceptionGroup rather than a BaseExceptionGroup

if all contained exceptions are Exception instances, so it can be used to make the selection automatic. The

ExceptionGroup constructor, on the other hand, raises a TypeError if any contained exception is not an

Exception subclass.

message

The msg argument to the constructor. This is a read-only attribute.

exceptions

A tuple of the exceptions in the excs sequence given to the constructor. This is a read-only attribute.

subgroup(condition)

Returns an exception group that contains only the exceptions from the current group that match condition, or None if the result is empty.

The condition can be an exception type or tuple of exception types, in which case each exception is checked for a match using the same check that is used in an except clause. The condition can also be a callable (other than a type object) that accepts an exception as its single argument and returns true for the exceptions that should be in the subgroup.

The nesting structure of the current exception is preserved in the result, as are the values of its message,

__traceback__, __cause__, __context__ and __notes__ fields. Empty nested groups are omit-ted from the result.

The condition is checked for all exceptions in the nested exception group, including the top-level and any nested exception groups. If the condition is true for such an exception group, it is included in the result in full.

Added in version 3.13: condition can be any callable which is not a type object.

split(condition)

Like subgroup(), but returns the pair (match, rest) where match is subgroup(condition) and rest is the remaining non-matching part.

derive(excs)

Returns an exception group with the same message, but which wraps the exceptions in excs.

This method is used by subgroup() and split(), which are used in various contexts to break up an

exception group. A subclass needs to override it in order to make subgroup() and split() return

instances of the subclass rather than ExceptionGroup.

subgroup() and split() copy the __traceback__, __cause__, __context__ and __notes__

fields from the original exception group to the one returned by derive(), so these fields do not need to

be updated by derive().

>>> class MyGroup(ExceptionGroup):

... def derive(self, excs):

... return MyGroup(self.message, excs)

...

>>> e = MyGroup("eg", [ValueError(1), TypeError(2)])

>>> e.add_note("a note")

>>> e.__context__ = Exception("context")

>>> e.__cause__ = Exception("cause")

(continues on next page)





The Python Library Reference, Release 3.13.2




(continued from previous page)

>>> try:

... raise e

... except Exception as e:

... exc = e

...

>>> match, rest = exc.split(ValueError)

>>> exc, exc.__context__, exc.__cause__, exc.__notes__ (MyGroup('eg', [ValueError(1), TypeError(2)]), Exception('context'),␣

, →Exception('cause'), ['a note'])

>>> match, match.__context__, match.__cause__, match.__notes__ (MyGroup('eg', [ValueError(1)]), Exception('context'), Exception('cause'),␣

, →['a note'])

>>> rest, rest.__context__, rest.__cause__, rest.__notes__ (MyGroup('eg', [TypeError(2)]), Exception('context'), Exception('cause'), [

, →'a note'])

>>> exc.__traceback__ is match.__traceback__ is rest.__traceback__ True



Note that BaseExceptionGroup defines __new__(), so subclasses that need a different constructor signa-

ture need to override that rather than __init__(). For example, the following defines an exception group

subclass which accepts an exit_code and and constructs the group’s message from it.

class Errors(ExceptionGroup):

def __new__(cls, errors, exit_code):

self = super().__new__(Errors, f"exit code: {exit_code}", errors) self.exit_code = exit_code

return self

def derive(self, excs):

return Errors(excs, self.exit_code)



Like ExceptionGroup, any subclass of BaseExceptionGroup which is also a subclass of Exception can

only wrap instances of Exception.

Added in version 3.11.



5.7 Exception hierarchy

The class hierarchy for built-in exceptions is:

BaseException

├── BaseExceptionGroup

├── GeneratorExit

├── KeyboardInterrupt

├── SystemExit

└── Exception

├── ArithmeticError

│ ├── FloatingPointError

│ ├── OverflowError

│ └── ZeroDivisionError

├── AssertionError

├── AttributeError

├── BufferError

├── EOFError

├── ExceptionGroup [BaseExceptionGroup]

├── ImportError

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

│ └── ModuleNotFoundError

├── LookupError

│ ├── IndexError

│ └── KeyError

├── MemoryError

├── NameError

│ └── UnboundLocalError

├── OSError

│ ├── BlockingIOError

│ ├── ChildProcessError

│ ├── ConnectionError

│ │ ├── BrokenPipeError

│ │ ├── ConnectionAbortedError

│ │ ├── ConnectionRefusedError

│ │ └── ConnectionResetError

│ ├── FileExistsError

│ ├── FileNotFoundError

│ ├── InterruptedError

│ ├── IsADirectoryError

│ ├── NotADirectoryError

│ ├── PermissionError

│ ├── ProcessLookupError

│ └── TimeoutError

├── ReferenceError

├── RuntimeError

│ ├── NotImplementedError

│ ├── PythonFinalizationError

│ └── RecursionError

├── StopAsyncIteration

├── StopIteration

├── SyntaxError

│ └── IndentationError

│ └── TabError

├── SystemError

├── TypeError

├── ValueError

│ └── UnicodeError

│ ├── UnicodeDecodeError

│ ├── UnicodeEncodeError

│ └── UnicodeTranslateError

└── Warning

├── BytesWarning

├── DeprecationWarning

├── EncodingWarning

├── FutureWarning

├── ImportWarning

├── PendingDeprecationWarning

├── ResourceWarning

├── RuntimeWarning

├── SyntaxWarning

├── UnicodeWarning

└── UserWarning



The Python Library Reference, Release 3.13.2





CHAPTER




SIX



TEXT PROCESSING SERVICES



The modules described in this chapter provide a wide range of string manipulation operations and other text process-ing services.

The codecs module described under Binary Data Services is also highly relevant to text processing. In addition, see

the documentation for Python’s built-in string type in Text Sequence Type — str.



6.1 string — Common string operations

Source code: Lib/string.py



µ See also

Text Sequence Type — str

String Methods



6.1.1 String constants

The constants defined in this module are:

string.ascii_letters

The concatenation of the ascii_lowercase and ascii_uppercase constants described below. This value

is not locale-dependent.

string.ascii_lowercase

The lowercase letters 'abcdefghijklmnopqrstuvwxyz'. This value is not locale-dependent and will not

change.

string.ascii_uppercase

The uppercase letters 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'. This value is not locale-dependent and will not

change.

string.digits

The string '0123456789'.

string.hexdigits

The string '0123456789abcdefABCDEF'.

string.octdigits

The string '01234567'.

string.punctuation

String of ASCII characters which are considered punctuation characters in the C locale: !"#$%&'()*+,-./

:;<=>?@[\]^_`{|}~ .





The Python Library Reference, Release 3.13.2




string.printable

String of ASCII characters which are considered printable by Python. This is a combination of digits,

ascii_letters, punctuation, and whitespace.



® Note

By design, string.printable.isprintable() returns False. In particular, string.printable

is not printable in the POSIX sense (see LC_CTYPE).



string.whitespace

A string containing all ASCII characters that are considered whitespace. This includes the characters space,

tab, linefeed, return, formfeed, and vertical tab.



6.1.2 Custom String Formatting

The built-in string class provides the ability to do complex variable substitutions and value formatting via the

format() method described in PEP 3101. The Formatter class in the string module allows you to create and

customize your own string formatting behaviors using the same implementation as the built-in format() method.

class string.Formatter

The Formatter class has the following public methods:

format(format_string, / , *args, **kwargs)

The primary API method. It takes a format string and an arbitrary set of positional and keyword argu-

ments. It is just a wrapper that calls vformat().

Changed in version 3.7: A format string argument is now positional-only.

vformat(format_string, args, kwargs)

This function does the actual work of formatting. It is exposed as a separate function for cases where you want to pass in a predefined dictionary of arguments, rather than unpacking and repacking the dictionary

as individual arguments using the *args and **kwargs syntax. vformat() does the work of breaking up the format string into character data and replacement fields. It calls the various methods described below.

In addition, the Formatter defines a number of methods that are intended to be replaced by subclasses:

parse(format_string)

Loop over the format_string and return an iterable of tuples (literal_text, field_name, format_spec, con-

version). This is used by vformat() to break the string into either literal text, or replacement fields.

The values in the tuple conceptually represent a span of literal text followed by a single replacement field. If there is no literal text (which can happen if two replacement fields occur consecutively), then literal_text will be a zero-length string. If there is no replacement field, then the values of field_name, format_spec and conversion will be None.

get_field(field_name, args, kwargs)

Given field_name as returned by parse() (see above), convert it to an object to be formatted. Returns

a tuple (obj, used_key). The default version takes strings of the form defined in PEP 3101, such as

“0[name]” or “label.title”. args and kwargs are as passed in to vformat(). The return value used_key

has the same meaning as the key parameter to get_value().

get_value(key, args, kwargs)

Retrieve a given field value. The key argument will be either an integer or a string. If it is an integer, it represents the index of the positional argument in args; if it is a string, then it represents a named argument in kwargs.

The args parameter is set to the list of positional arguments to vformat(), and the kwargs parameter is set to the dictionary of keyword arguments.





The Python Library Reference, Release 3.13.2




For compound field names, these functions are only called for the first component of the field name; subsequent components are handled through normal attribute and indexing operations.

So for example, the field expression ‘0.name’ would cause get_value() to be called with a key argument

of 0. The name attribute will be looked up after get_value() returns by calling the built-in getattr() function.

If the index or keyword refers to an item that does not exist, then an IndexError or KeyError should be raised.

check_unused_args(used_args, args, kwargs)

Implement checking for unused arguments if desired. The arguments to this function is the set of all argument keys that were actually referred to in the format string (integers for positional arguments, and strings for named arguments), and a reference to the args and kwargs that was passed to vformat. The set

of unused args can be calculated from these parameters. check_unused_args() is assumed to raise an exception if the check fails.

format_field(value, format_spec)

format_field() simply calls the global format() built-in. The method is provided so that subclasses can override it.

convert_field(value, conversion)

Converts the value (returned by get_field()) given a conversion type (as in the tuple returned by the

parse() method). The default version understands ‘s’ (str), ‘r’ (repr) and ‘a’ (ascii) conversion types.



6.1.3 Format String Syntax

The str.format() method and the Formatter class share the same syntax for format strings (although in the

case of Formatter, subclasses can define their own format string syntax). The syntax is related to that of formatted string literals, but it is less sophisticated and, in particular, does not support arbitrary expressions.

Format strings contain “replacement fields” surrounded by curly braces {}. Anything that is not contained in braces is considered literal text, which is copied unchanged to the output. If you need to include a brace character in the literal text, it can be escaped by doubling: {{ and }}.

The grammar for a replacement field is as follows:



replacement_field ::= "{" [field_name] ["!" conversion] [":" format_spec] "}"

field_name ::= arg_name ("." attribute_name | "[" element_index "]")*

arg_name ::= [identifier | digit+]

attribute_name ::= identifier

element_index ::= digit+ | index_string

index_string ::= +

conversion ::= "r" | "s" | "a"

format_spec ::= format-spec:format_spec

In less formal terms, the replacement field can start with a field_name that specifies the object whose value is to be formatted and inserted into the output instead of the replacement field. The field_name is optionally followed by a conversion field, which is preceded by an exclamation point '!', and a format_spec, which is preceded by a colon ':'. These specify a non-default format for the replacement value.

See also the Format Specification Mini-Language section.

The field_name itself begins with an arg_name that is either a number or a keyword. If it’s a number, it refers to a positional argument, and if it’s a keyword, it refers to a named keyword argument. An arg_name is treated as a

number if a call to str.isdecimal() on the string would return true. If the numerical arg_names in a format string are 0, 1, 2, … in sequence, they can all be omitted (not just some) and the numbers 0, 1, 2, … will be automatically inserted in that order. Because arg_name is not quote-delimited, it is not possible to specify arbitrary dictionary keys (e.g., the strings '10' or ':-]') within a format string. The arg_name can be followed by any number of index or

attribute expressions. An expression of the form '.name' selects the named attribute using getattr(), while an expression of the form '[index]' does an index lookup using __getitem__().

The Python Library Reference, Release 3.13.2



Changed in version 3.1: The positional argument specifiers can be omitted for str.format(), so '{} {}'. format(a, b) is equivalent to '{0} {1}'.format(a, b).

Changed in version 3.4: The positional argument specifiers can be omitted for Formatter.

Some simple format string examples:

"First, thou shalt count to {0}" # References first positional argument "Bring me a {}" # Implicitly references the first positional␣

, →argument

"From {} to {}" # Same as "From {0} to {1}"

"My quest is {name}" # References keyword argument 'name' "Weight in tons {0.weight}" # 'weight' attribute of first positional arg "Units destroyed: {players[0]}" # First element of keyword argument 'players'.



The conversion field causes a type coercion before formatting. Normally, the job of formatting a value is done by the __format__() method of the value itself. However, in some cases it is desirable to force a type to be formatted as a string, overriding its own definition of formatting. By converting the value to a string before calling __format__(), the normal formatting logic is bypassed.

Three conversion flags are currently supported: '!s' which calls str() on the value, '!r' which calls repr() and

'!a' which calls ascii().

Some examples:

"Harold's a clever {0!s}" # Calls str() on the argument first "Bring out the holy {name!r}" # Calls repr() on the argument first "More {!a}" # Calls ascii() on the argument first



The format_spec field contains a specification of how the value should be presented, including such details as field width, alignment, padding, decimal precision and so on. Each value type can define its own “formatting mini-language” or interpretation of the format_spec.

Most built-in types support a common formatting mini-language, which is described in the next section.

A format_spec field can also include nested replacement fields within it. These nested replacement fields may contain a field name, conversion flag and format specification, but deeper nesting is not allowed. The replacement fields within the format_spec are substituted before the format_spec string is interpreted. This allows the formatting of a value to be dynamically specified.

See the Format examples section for some examples.



Format Specification Mini-Language

“Format specifications” are used within replacement fields contained within a format string to define how individ-

ual values are presented (see Format String Syntax and f-strings). They can also be passed directly to the built-in

format() function. Each formattable type may define how the format specification is to be interpreted.

Most built-in types implement the following options for format specifications, although some of the formatting options are only supported by the numeric types.

A general convention is that an empty format specification produces the same result as if you had called str() on the value. A non-empty format specification typically modifies the result.

The general form of a standard format specifier is:



format_spec ::= [[fill]align][sign]["z"]["#"]["0"][width][grouping_option]["." precision][

fill ::=

align ::= "<" | ">" | "=" | "^"

sign ::= "+" | "-" | " "

width ::= digit+

grouping_option ::= "_" | ","

The Python Library Reference, Release 3.13.2



precision ::= digit+

type ::= "b" | "c" | "d" | "e" | "E" | "f" | "F" | "g" | "G" | "n" | "o" | "s" | "x" | "X" | "%"

If a valid align value is specified, it can be preceded by a fill character that can be any character and defaults to a space if omitted. It is not possible to use a literal curly brace (”{” or “}”) as the fill character in a formatted string literal

or when using the str.format() method. However, it is possible to insert a curly brace with a nested replacement

field. This limitation doesn’t affect the format() function.

The meaning of the various alignment options is as follows:



Op-Meaning

tion

'<' Forces the field to be left-aligned within the available space (this is the default for most objects).

'>' Forces the field to be right-aligned within the available space (this is the default for numbers).

'=' Forces the padding to be placed after the sign (if any) but before the digits. This is used for printing fields

in the form ‘+000000120’. This alignment option is only valid for numeric types, excluding complex. It becomes the default for numbers when ‘0’ immediately precedes the field width.

'^' Forces the field to be centered within the available space.



Note that unless a minimum field width is defined, the field width will always be the same size as the data to fill it, so that the alignment option has no meaning in this case.

The sign option is only valid for number types, and can be one of the following:



Op- Meaning

tion

'+' indicates that a sign should be used for both positive as well as negative numbers.

'-' indicates that a sign should be used only for negative numbers (this is the default behavior).

space indicates that a leading space should be used on positive numbers, and a minus sign on negative numbers.



The 'z' option coerces negative zero floating-point values to positive zero after rounding to the format precision. This option is only valid for floating-point presentation types.

Changed in version 3.11: Added the 'z' option (see also PEP 682).

The '#' option causes the “alternate form” to be used for the conversion. The alternate form is defined differently for different types. This option is only valid for integer, float and complex types. For integers, when binary, octal, or hexadecimal output is used, this option adds the respective prefix '0b', '0o', '0x', or '0X' to the output value. For float and complex the alternate form causes the result of the conversion to always contain a decimal-point character, even if no digits follow it. Normally, a decimal-point character appears in the result of these conversions only if a digit follows it. In addition, for 'g' and 'G' conversions, trailing zeros are not removed from the result.

The ',' option signals the use of a comma for a thousands separator for floating-point presentation types and for integer presentation type 'd'. For other presentation types, this option is an error. For a locale aware separator, use the 'n' integer presentation type instead.

Changed in version 3.1: Added the ',' option (see also PEP 378).

The '_' option signals the use of an underscore for a thousands separator for floating-point presentation types and for integer presentation type 'd'. For integer presentation types 'b', 'o', 'x', and 'X', underscores will be inserted every 4 digits. For other presentation types, specifying this option is an error.

Changed in version 3.6: Added the '_' option (see also PEP 515).

width is a decimal integer defining the minimum total field width, including any prefixes, separators, and other for-matting characters. If not specified, then the field width will be determined by the content.

When no explicit alignment is given, preceding the width field by a zero ('0') character enables sign-aware zero-

padding for numeric types, excluding complex. This is equivalent to a fill character of '0' with an alignment type of '='.

The Python Library Reference, Release 3.13.2



Changed in version 3.10: Preceding the width field by '0' no longer affects the default alignment for strings.

The precision is a decimal integer indicating how many digits should be displayed after the decimal point for pre-sentation types 'f' and 'F', or before and after the decimal point for presentation types 'g' or 'G'. For string presentation types the field indicates the maximum field size - in other words, how many characters will be used from the field content. The precision is not allowed for integer presentation types.

Finally, the type determines how the data should be presented.

The available string presentation types are:



Type Meaning

's' String format. This is the default type for strings and may be omitted. None The same as 's'.



The available integer presentation types are:



Type Meaning

'b' Binary format. Outputs the number in base 2.

'c' Character. Converts the integer to the corresponding unicode character before printing. 'd' Decimal Integer. Outputs the number in base 10.

'o' Octal format. Outputs the number in base 8.

'x' Hex format. Outputs the number in base 16, using lower-case letters for the digits above 9. 'X' Hex format. Outputs the number in base 16, using upper-case letters for the digits above 9.

In case '#' is specified, the prefix '0x' will be upper-cased to '0X' as well.

'n' Number. This is the same as 'd', except that it uses the current locale setting to insert the

appropriate number separator characters.

None The same as 'd'.



In addition to the above presentation types, integers can be formatted with the floating-point presentation types listed

below (except 'n' and None). When doing so, float() is used to convert the integer to a floating-point number before formatting.

The available presentation types for float and Decimal values are:



The Python Library Reference, Release 3.13.2



Type Meaning

'e' Scientific notation. For a given precision p, formats the number in scientific notation with

the letter ‘e’ separating the coefficient from the exponent. The coefficient has one digit before and p digits after the decimal point, for a total of p + 1 significant digits. With no precision

given, uses a precision of 6 digits after the decimal point for float, and shows all coefficient

digits for Decimal. If p=0, the decimal point is omitted unless the # option is used.

'E' Scientific notation. Same as 'e' except it uses an upper case ‘E’ as the separator character. 'f' Fixed-point notation. For a given precision p, formats the number as a decimal number with

exactly p digits following the decimal point. With no precision given, uses a precision of

6 digits after the decimal point for float, and uses a precision large enough to show all

coefficient digits for Decimal. If p=0, the decimal point is omitted unless the # option is used.

'F' Fixed-point notation. Same as 'f', but converts nan to NAN and inf to INF. 'g' General format. For a given precision p >= 1, this rounds the number to p significant digits

and then formats the result in either fixed-point format or in scientific notation, depending on its magnitude. A precision of 0 is treated as equivalent to a precision of 1. The precise rules are as follows: suppose that the result formatted with presentation type 'e' and precision p-1 would have exponent exp. Then, if m <= exp < p, where m is -4 for

floats and -6 for Decimals, the number is formatted with presentation type 'f' and precision p-1-exp. Otherwise, the number is formatted with presentation type 'e' and precision p-1. In both cases insignificant trailing zeros are removed from the significand, and the decimal point is also removed if there are no remaining digits following it, unless the '#' option is used.

With no precision given, uses a precision of 6 significant digits for float. For Decimal, the coefficient of the result is formed from the coefficient digits of the value; scientific notation is used for values smaller than 1e-6 in absolute value and values where the place value of the least significant digit is larger than 1, and fixed-point notation is used otherwise. Positive and negative infinity, positive and negative zero, and nans, are formatted as inf,-inf, 0,-0 and nan respectively, regardless of the precision.

'G' General format. Same as 'g' except switches to 'E' if the number gets too large. The

representations of infinity and NaN are uppercased, too.

'n' Number. This is the same as 'g', except that it uses the current locale setting to insert the

appropriate number separator characters.

'%' Percentage. Multiplies the number by 100 and displays in fixed ('f') format, followed by a

percent sign.

None For float this is like the 'g' type, except that when fixed-point notation is used to format the

result, it always includes at least one digit past the decimal point, and switches to the scientific notation when exp >= p - 1. When the precision is not specified, the latter will be as large as needed to represent the given value faithfully.

For Decimal, this is the same as either 'g' or 'G' depending on the value of context. capitals for the current decimal context.

The overall effect is to match the output of str() as altered by the other format modifiers.



The result should be correctly rounded to a given precision p of digits after the decimal point. The rounding mode

for float matches that of the round() builtin. For Decimal, the rounding mode of the current context will be used.

The available presentation types for complex are the same as those for float ('%' is not allowed). Both the real and imaginary components of a complex number are formatted as floating-point numbers, according to the specified presentation type. They are separated by the mandatory sign of the imaginary part, the latter being terminated by

a j suffix. If the presentation type is missing, the result will match the output of str() (complex numbers with a non-zero real part are also surrounded by parentheses), possibly altered by other format modifiers.



The Python Library Reference, Release 3.13.2



Format examples

This section contains examples of the str.format() syntax and comparison with the old %-formatting.

In most of the cases the syntax is similar to the old %-formatting, with the addition of the {} and with : used instead of %. For example, '%03.2f' can be translated to '{:03.2f}'.

The new format syntax also supports new and different options, shown in the following examples.

Accessing arguments by position:

>>> '{0}, {1}, {2}'.format('a', 'b', 'c')

'a, b, c'

>>> '{}, {}, {}'.format('a', 'b', 'c') # 3.1+ only

'a, b, c'

>>> '{2}, {1}, {0}'.format('a', 'b', 'c')

'c, b, a'

>>> '{2}, {1}, {0}'.format(*'abc') # unpacking argument sequence 'c, b, a'

>>> '{0}{1}{0}'.format('abra', 'cad') # arguments' indices can be repeated 'abracadabra'



Accessing arguments by name:

>>> 'Coordinates: {latitude}, {longitude}'.format(latitude='37.24N', longitude='-

, →115.81W')

'Coordinates: 37.24N, -115.81W'

>>> coord = {'latitude': '37.24N', 'longitude': '-115.81W'} >>> 'Coordinates: {latitude}, {longitude}'.format(**coord) 'Coordinates: 37.24N, -115.81W'



Accessing arguments’ attributes:

>>> c = 3-5j

>>> ('The complex number {0} is formed from the real part {0.real} ' ... 'and the imaginary part {0.imag}.').format(c)

'The complex number (3-5j) is formed from the real part 3.0 and the imaginary part␣

, →-5.0.'

>>> class Point:

... def __init__(self, x, y):

... self.x, self.y = x, y

... def __str__(self):

... return 'Point({self.x}, {self.y})'.format(self=self) ...

>>> str(Point(4, 2))

'Point(4, 2)'



Accessing arguments’ items:

>>> coord = (3, 5)

>>> 'X: {0[0]}; Y: {0[1]}'.format(coord)

'X: 3; Y: 5'



Replacing %s and %r:

>>> "repr() shows quotes: {!r}; str() doesn't: {!s}".format('test1', 'test2') "repr() shows quotes: 'test1'; str() doesn't: test2"



Aligning the text and specifying a width:

The Python Library Reference, Release 3.13.2



>>> '{:<30}'.format('left aligned')

'left aligned '

>>> '{:>30}'.format('right aligned')

' right aligned'

>>> '{:^30}'.format('centered')

' centered '

>>> '{:*^30}'.format('centered') # use '*' as a fill char '***********centered***********'



Replacing %+f, %-f, and % f and specifying a sign:

>>> '{:+f}; {:+f}'.format(3.14,-3.14) # show it always '+3.140000; -3.140000'

>>> '{: f}; {: f}'.format(3.14,-3.14) # show a space for positive numbers ' 3.140000; -3.140000'

>>> '{:-f}; {:-f}'.format(3.14,-3.14) # show only the minus -- same as '{:f};

, →{:f}'

'3.140000; -3.140000'



Replacing %x and %o and converting the value to different bases:

>>> # format also supports binary numbers

>>> "int: {0:d}; hex: {0:x}; oct: {0:o}; bin: {0:b}".format(42) 'int: 42; hex: 2a; oct: 52; bin: 101010'

>>> # with 0x, 0o, or 0b as prefix:

>>> "int: {0:d}; hex: {0:#x}; oct: {0:#o}; bin: {0:#b}".format(42) 'int: 42; hex: 0x2a; oct: 0o52; bin: 0b101010'



Using the comma as a thousands separator:

>>> '{:,}'.format(1234567890)

'1,234,567,890'



Expressing a percentage:

>>> points = 19

>>> total = 22

>>> 'Correct answers: {:.2%}'.format(points/total)

'Correct answers: 86.36%'



Using type-specific formatting:

>>> import datetime

>>> d = datetime.datetime(2010, 7, 4, 12, 15, 58)

>>> '{:%Y-%m-%d %H:%M:%S}'.format(d)

'2010-07-04 12:15:58'



Nesting arguments and more complex examples:

>>> for align, text in zip('<^>', ['left', 'center', 'right']): ... '{0:{fill}{align}16}'.format(text, fill=align, align=align) ...

'left<<<<<<<<<<<<'

'^^^^^center^^^^^'

'>>>>>>>>>>>right'

>>>

>>> octets = [192, 168, 0, 1]

>>> '{:02X}{:02X}{:02X}{:02X}'.format(*octets)

(continues on next page)





The Python Library Reference, Release 3.13.2




(continued from previous page)

'C0A80001'

>>> int(_, 16)

3232235521

>>>

>>> width = 5

>>> for num in range(5,12):

... for base in 'dXob':

... print('{0:{width}{base}}'.format(num, base=base, width=width), end=' ') ... print()

...

5 5 5 101

6 6 6 110

7 7 7 111

8 8 10 1000

9 9 11 1001

10 A 12 1010

11 B 13 1011



6.1.4 Template strings

Template strings provide simpler string substitutions as described in PEP 292. A primary use case for template strings is for internationalization (i18n) since in that context, the simpler syntax and functionality makes it easier to translate than other built-in string formatting facilities in Python. As an example of a library built on template strings

for i18n, see the flufl.i18n package.

Template strings support $-based substitutions, using the following rules:

• $$ is an escape; it is replaced with a single $.

• $identifier names a substitution placeholder matching a mapping key of "identifier". By default,

"identifier" is restricted to any case-insensitive ASCII alphanumeric string (including underscores) that

starts with an underscore or ASCII letter. The first non-identifier character after the $ character terminates

this placeholder specification.

• ${identifier} is equivalent to $identifier. It is required when valid identifier characters follow the

placeholder but are not part of the placeholder, such as "${noun}ification".

Any other appearance of $ in the string will result in a ValueError being raised.

The string module provides a Template class that implements these rules. The methods of Template are:

class string.Template( template)

The constructor takes a single argument which is the template string.

substitute(mapping={}, / , **kwds)

Performs the template substitution, returning a new string. mapping is any dictionary-like object with keys that match the placeholders in the template. Alternatively, you can provide keyword arguments, where the keywords are the placeholders. When both mapping and kwds are given and there are duplicates, the placeholders from kwds take precedence.

safe_substitute(mapping={}, / , **kwds)

Like substitute(), except that if placeholders are missing from mapping and kwds, instead of raising a

KeyError exception, the original placeholder will appear in the resulting string intact. Also, unlike with

substitute(), any other appearances of the $ will simply return $ instead of raising ValueError.

While other exceptions may still occur, this method is called “safe” because it always tries to return

a usable string instead of raising an exception. In another sense, safe_substitute() may be any-thing other than safe, since it will silently ignore malformed templates containing dangling delimiters, unmatched braces, or placeholders that are not valid Python identifiers.

The Python Library Reference, Release 3.13.2



is_valid()

Returns false if the template has invalid placeholders that will cause substitute() to raise

ValueError.

Added in version 3.11.

get_identifiers()

Returns a list of the valid identifiers in the template, in the order they first appear, ignoring any invalid identifiers.

Added in version 3.11.

Template instances also provide one public data attribute:

template

This is the object passed to the constructor’s template argument. In general, you shouldn’t change it, but read-only access is not enforced.

Here is an example of how to use a Template:

>>> from string import Template

>>> s = Template('$who likes $what')

>>> s.substitute(who='tim', what='kung pao')

'tim likes kung pao'

>>> d = dict(who='tim')

>>> Template('Give $who $100').substitute(d)

Traceback (most recent call last):

...

ValueError: Invalid placeholder in string: line 1, col 11 >>> Template('$who likes $what').substitute(d)

Traceback (most recent call last):

...

KeyError: 'what'

>>> Template('$who likes $what').safe_substitute(d) 'tim likes $what'



Advanced usage: you can derive subclasses of Template to customize the placeholder syntax, delimiter character, or the entire regular expression used to parse template strings. To do this, you can override these class attributes:

• delimiter – This is the literal string describing a placeholder introducing delimiter. The default value is $. Note

that this should not be a regular expression, as the implementation will call re.escape() on this string as

needed. Note further that you cannot change the delimiter after class creation (i.e. a different delimiter must

be set in the subclass’s class namespace).

• idpattern – This is the regular expression describing the pattern for non-braced placeholders. The default value

is the regular expression (?a:[_a-z][_a-z0-9]*). If this is given and braceidpattern is None this pattern

will also apply to braced placeholders.



® Note

Since default flags is re.IGNORECASE, pattern [a-z] can match with some non-ASCII characters. That’s why we use the local a flag here.



Changed in version 3.7: braceidpattern can be used to define separate patterns used inside and outside the

braces.

• braceidpattern – This is like idpattern but describes the pattern for braced placeholders. Defaults to None

which means to fall back to idpattern (i.e. the same pattern is used both inside and outside braces). If given,

this allows you to define different patterns for braced and unbraced placeholders.

Added in version 3.7.





The Python Library Reference, Release 3.13.2




• flags – The regular expression flags that will be applied when compiling the regular expression used for recog-

nizing substitutions. The default value is re.IGNORECASE. Note that re.VERBOSE will always be added to

the flags, so custom idpatterns must follow conventions for verbose regular expressions.

Added in version 3.2.

Alternatively, you can provide the entire regular expression pattern by overriding the class attribute pattern. If you do this, the value must be a regular expression object with four named capturing groups. The capturing groups correspond to the rules given above, along with the invalid placeholder rule:

• escaped – This group matches the escape sequence, e.g. $$, in the default pattern.

• named – This group matches the unbraced placeholder name; it should not include the delimiter in capturing

group.

• braced – This group matches the brace enclosed placeholder name; it should not include either the delimiter

or braces in the capturing group.

• invalid – This group matches any other delimiter pattern (usually a single delimiter), and it should appear last

in the regular expression.

The methods on this class will raise ValueError if the pattern matches the template without one of these named groups matching.



6.1.5 Helper functions

string.capwords(s, sep=None)

Split the argument into words using str.split(), capitalize each word using str.capitalize(), and

join the capitalized words using str.join(). If the optional second argument sep is absent or None, runs of

whitespace characters are replaced by a single space and leading and trailing whitespace are removed, otherwise

sep is used to split and join the words.



6.2 re — Regular expression operations

Source code: Lib/re/



This module provides regular expression matching operations similar to those found in Perl.

Both patterns and strings to be searched can be Unicode strings (str) as well as 8-bit strings (bytes). However, Unicode strings and 8-bit strings cannot be mixed: that is, you cannot match a Unicode string with a bytes pattern or vice-versa; similarly, when asking for a substitution, the replacement string must be of the same type as both the pattern and the search string.

Regular expressions use the backslash character ('\') to indicate special forms or to allow special characters to be used without invoking their special meaning. This collides with Python’s usage of the same character for the same purpose in string literals; for example, to match a literal backslash, one might have to write '\\\\' as the pattern string, because the regular expression must be \\, and each backslash must be expressed as \\ inside a regular Python string literal. Also, please note that any invalid escape sequences in Python’s usage of the backslash in string literals

now generate a SyntaxWarning and in the future this will become a SyntaxError. This behaviour will happen even if it is a valid escape sequence for a regular expression.

The solution is to use Python’s raw string notation for regular expression patterns; backslashes are not handled in any special way in a string literal prefixed with 'r'. So r"\n" is a two-character string containing '\' and 'n', while "\n" is a one-character string containing a newline. Usually patterns will be expressed in Python code using this raw string notation.

It is important to note that most regular expression operations are available as module-level functions and methods

on compiled regular expressions. The functions are shortcuts that don’t require you to compile a regex object first, but miss some fine-tuning parameters.





The Python Library Reference, Release 3.13.2




µ See also

The third-party regex module, which has an API compatible with the standard library re module, but offers

additional functionality and a more thorough Unicode support.



6.2.1 Regular Expression Syntax

A regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing).

Regular expressions can be concatenated to form new regular expressions; if A and B are both regular expressions, then AB is also a regular expression. In general, if a string p matches A and another string q matches B, the string pq will match AB. This holds unless A or B contain low precedence operations; boundary conditions between A and B; or have numbered group references. Thus, complex expressions can easily be constructed from simpler primitive expressions like the ones described here. For details of the theory and implementation of regular expressions, consult

the Friedl book [Frie09], or almost any textbook about compiler construction.

A brief explanation of the format of regular expressions follows. For further information and a gentler presentation, consult the regex-howto.

Regular expressions can contain both special and ordinary characters. Most ordinary characters, like 'A', 'a', or '0', are the simplest regular expressions; they simply match themselves. You can concatenate ordinary characters, so last matches the string 'last'. (In the rest of this section, we’ll write RE’s in this special style, usually without quotes, and strings to be matched 'in single quotes'.)

Some characters, like '|' or '(', are special. Special characters either stand for classes of ordinary characters, or affect how the regular expressions around them are interpreted.

Repetition operators or quantifiers (*, +, ?, {m,n}, etc) cannot be directly nested. This avoids ambiguity with the non-greedy modifier suffix ?, and with other modifiers in other implementations. To apply a second repetition to an inner repetition, parentheses may be used. For example, the expression (?:a{6})* matches any multiple of six 'a' characters.

The special characters are:

.

(Dot.) In the default mode, this matches any character except a newline. If the DOTALL flag has been specified,

this matches any character including a newline. (?s:.) matches any character regardless of flags.

^

(Caret.) Matches the start of the string, and in MULTILINE mode also matches immediately after each newline.

$

Matches the end of the string or just before the newline at the end of the string, and in MULTILINE mode also

matches before a newline. foo matches both ‘foo’ and ‘foobar’, while the regular expression foo$ matches

only ‘foo’. More interestingly, searching for foo.$ in 'foo1\nfoo2\n' matches ‘foo2’ normally, but ‘foo1’

in MULTILINE mode; searching for a single $ in 'foo\n' will find two (empty) matches: one just before the

newline, and one at the end of the string.

*

Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible.

ab* will match ‘a’, ‘ab’, or ‘a’ followed by any number of ‘b’s.

+

Causes the resulting RE to match 1 or more repetitions of the preceding RE. ab+ will match ‘a’ followed by

any non-zero number of ‘b’s; it will not match just ‘a’.

?

Causes the resulting RE to match 0 or 1 repetitions of the preceding RE. ab? will match either ‘a’ or ‘ab’.

*?, +?, ??

The '*', '+', and '?' quantifiers are all greedy; they match as much text as possible. Sometimes this be-

haviour isn’t desired; if the RE <.*> is matched against ' b ', it will match the entire string, and The Python Library Reference, Release 3.13.2



not just ''. Adding ? after the quantifier makes it perform the match in non-greedy or minimal fashion;

as few characters as possible will be matched. Using the RE <.*?> will match only ''.

*+, ++, ?+

Like the '*', '+', and '?' quantifiers, those where '+' is appended also match as many times as possible.

However, unlike the true greedy quantifiers, these do not allow back-tracking when the expression following it

fails to match. These are known as possessive quantifiers. For example, a*a will match 'aaaa' because the

a* will match all 4 'a's, but, when the final 'a' is encountered, the expression is backtracked so that in the

end the a* ends up matching 3 'a's total, and the fourth 'a' is matched by the final 'a'. However, when

a*+a is used to match 'aaaa', the a*+ will match all 4 'a', but when the final 'a' fails to find any more

characters to match, the expression cannot be backtracked and will thus fail to match. x*+, x++ and x?+ are

equivalent to (?>x*), (?>x+) and (?>x?) correspondingly.

Added in version 3.11.

{m}

Specifies that exactly m copies of the previous RE should be matched; fewer matches cause the entire RE not

to match. For example, a{6} will match exactly six 'a' characters, but not five.

{m,n}

Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many

repetitions as possible. For example, a{3,5} will match from 3 to 5 'a' characters. Omitting m specifies

a lower bound of zero, and omitting n specifies an infinite upper bound. As an example, a{4,}b will match

'aaaab' or a thousand 'a' characters followed by a 'b', but not 'aaab'. The comma may not be omitted

or the modifier would be confused with the previously described form.

{m,n}?

Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as few

repetitions as possible. This is the non-greedy version of the previous quantifier. For example, on the 6-

character string 'aaaaaa', a{3,5} will match 5 'a' characters, while a{3,5}? will only match 3 characters.

{m,n}+

Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many

repetitions as possible without establishing any backtracking points. This is the possessive version of the

quantifier above. For example, on the 6-character string 'aaaaaa', a{3,5}+aa attempt to match 5 'a'

characters, then, requiring 2 more 'a's, will need more characters than available and thus fail, while a{3,

5}aa will match with a{3,5} capturing 5, then 4 'a's by backtracking and then the final 2 'a's are matched

by the final aa in the pattern. x{m,n}+ is equivalent to (?>x{m,n}).

Added in version 3.11.

\

Either escapes special characters (permitting you to match characters like '*', '?', and so forth), or signals

a special sequence; special sequences are discussed below.

If you’re not using a raw string to express the pattern, remember that Python also uses the backslash as an

escape sequence in string literals; if the escape sequence isn’t recognized by Python’s parser, the backslash and

subsequent character are included in the resulting string. However, if Python would recognize the resulting

sequence, the backslash should be repeated twice. This is complicated and hard to understand, so it’s highly

recommended that you use raw strings for all but the simplest expressions.

[]

Used to indicate a set of characters. In a set:

• Characters can be listed individually, e.g. [amk] will match 'a', 'm', or 'k'.

• Ranges of characters can be indicated by giving two characters and separating them by a '-', for example

[a-z] will match any lowercase ASCII letter, [0-5][0-9] will match all the two-digits numbers from 00 to 59, and [0-9A-Fa-f] will match any hexadecimal digit. If-is escaped (e.g. [a\-z]) or if it’s placed as the first or last character (e.g. [-a] or [a-]), it will match a literal '-'.

• Special characters lose their special meaning inside sets. For example, [(+*)] will match any of the

literal characters '(', '+', '*', or ')'.

The Python Library Reference, Release 3.13.2



• Character classes such as \w or \S (defined below) are also accepted inside a set, although the characters

they match depend on the flags used.

• Characters that are not within a range can be matched by complementing the set. If the first character of

the set is '^', all the characters that are not in the set will be matched. For example, [^5] will match any character except '5', and [^^] will match any character except '^'. ^ has no special meaning if it’s not the first character in the set.

• To match a literal ']' inside a set, precede it with a backslash, or place it at the beginning of the set.

For example, both [()[\]{}] and []()[{}] will match a right bracket, as well as left bracket, braces, and parentheses.

• Support of nested sets and set operations as in Unicode Technical Standard #18 might be added in the

future. This would change the syntax, so to facilitate this change a FutureWarning will be raised in ambiguous cases for the time being. That includes sets starting with a literal '[' or containing literal character sequences '--', '&&', '~~', and '||'. To avoid a warning escape them with a backslash.

Changed in version 3.7: FutureWarning is raised if a character set contains constructs that will change

semantically in the future.

|

A|B , where A and B can be arbitrary REs, creates a regular expression that will match either A or B. An

arbitrary number of REs can be separated by the '|' in this way. This can be used inside groups (see below)

as well. As the target string is scanned, REs separated by '|' are tried from left to right. When one pattern

completely matches, that branch is accepted. This means that once A matches, B will not be tested further,

even if it would produce a longer overall match. In other words, the '|' operator is never greedy. To match a

literal '|', use \|, or enclose it inside a character class, as in [|].

(...)

Matches whatever regular expression is inside the parentheses, and indicates the start and end of a group; the

contents of a group can be retrieved after a match has been performed, and can be matched later in the string

with the \number special sequence, described below. To match the literals '(' or ')', use \( or \), or

enclose them inside a character class: [(], [)].

(?...)

This is an extension notation (a '?' following a '(' is not meaningful otherwise). The first character after the

'?' determines what the meaning and further syntax of the construct is. Extensions usually do not create a new

group; (?P...) is the only exception to this rule. Following are the currently supported extensions.

(?aiLmsux)

(One or more letters from the set 'a', 'i', 'L', 'm', 's', 'u', 'x'.) The group matches the empty string;

the letters set the corresponding flags for the entire regular expression:

• re.A (ASCII-only matching)

• re.I (ignore case)

• re.L (locale dependent)

• re.M (multi-line)

• re.S (dot matches all)

• re.U (Unicode matching)

• re.X (verbose)

(The flags are described in Module Contents.) This is useful if you wish to include the flags as part of the regular

expression, instead of passing a flag argument to the re.compile() function. Flags should be used first in

the expression string.

Changed in version 3.11: This construction can only be used at the start of the expression.

(?:...)

A non-capturing version of regular parentheses. Matches whatever regular expression is inside the parentheses,

but the substring matched by the group cannot be retrieved after performing a match or referenced later in the

pattern.

The Python Library Reference, Release 3.13.2



(?aiLmsux-imsx:...)

(Zero or more letters from the set 'a', 'i', 'L', 'm', 's', 'u', 'x', optionally followed by '-' followed

by one or more letters from the 'i', 'm', 's', 'x'.) The letters set or remove the corresponding flags for the

part of the expression:

• re.A (ASCII-only matching)

• re.I (ignore case)

• re.L (locale dependent)

• re.M (multi-line)

• re.S (dot matches all)

• re.U (Unicode matching)

• re.X (verbose)

(The flags are described in Module Contents.)

The letters 'a', 'L' and 'u' are mutually exclusive when used as inline flags, so they can’t be combined

or follow '-'. Instead, when one of them appears in an inline group, it overrides the matching mode in the

enclosing group. In Unicode patterns (?a:...) switches to ASCII-only matching, and (?u:...) switches

to Unicode matching (default). In bytes patterns (?L:...) switches to locale dependent matching, and (?

a:...) switches to ASCII-only matching (default). This override is only in effect for the narrow inline group,

and the original matching mode is restored outside of the group.

Added in version 3.6.

Changed in version 3.7: The letters 'a', 'L' and 'u' also can be used in a group.

(?>...)

Attempts to match ... as if it was a separate regular expression, and if successful, continues to match the

rest of the pattern following it. If the subsequent pattern fails to match, the stack can only be unwound to a

point before the (?>...) because once exited, the expression, known as an atomic group, has thrown away

all stack points within itself. Thus, (?>.*). would never match anything because first the .* would match

all characters possible, then, having nothing left to match, the final . would fail to match. Since there are no

stack points saved in the Atomic Group, and there is no stack point before it, the entire expression would thus

fail to match.

Added in version 3.11.

(?P<name>...)

Similar to regular parentheses, but the substring matched by the group is accessible via the symbolic group

name name. Group names must be valid Python identifiers, and in bytes patterns they can only contain bytes

in the ASCII range. Each group name must be defined only once within a regular expression. A symbolic

group is also a numbered group, just as if the group were not named.

Named groups can be referenced in three contexts. If the pattern is (?P['"]).*?(?P=quote)

(i.e. matching a string quoted with either single or double quotes):



Context of reference to group “quote” Ways to reference it

in the same pattern itself

• (?P=quote) (as shown)

• \1



when processing match object m m.group('quote') •

• m.end('quote') (etc.)

in a string passed to the repl argument of re.sub()

• \g

• \g<1>

• \1

The Python Library Reference, Release 3.13.2



Changed in version 3.12: In bytes patterns, group name can only contain bytes in the ASCII range (b'\

x00'-b'\x7f').

(?P=name)

A backreference to a named group; it matches whatever text was matched by the earlier group named name.

(?#...)

A comment; the contents of the parentheses are simply ignored.

(?=...)

Matches if ... matches next, but doesn’t consume any of the string. This is called a lookahead assertion. For

example, Isaac (?=Asimov) will match 'Isaac ' only if it’s followed by 'Asimov'.

(?!...)

Matches if ... doesn’t match next. This is a negative lookahead assertion. For example, Isaac (?!Asimov)

will match 'Isaac ' only if it’s not followed by 'Asimov'.

(?<=...)

Matches if the current position in the string is preceded by a match for ... that ends at the current position.

This is called a positive lookbehind assertion. (?<=abc)def will find a match in 'abcdef', since the look-

behind will back up 3 characters and check if the contained pattern matches. The contained pattern must only

match strings of some fixed length, meaning that abc or a|b are allowed, but a* and a{3,4} are not. Note

that patterns which start with positive lookbehind assertions will not match at the beginning of the string being

searched; you will most likely want to use the search() function rather than the match() function:

>>> import re

>>> m = re.search('(?<=abc)def', 'abcdef')

>>> m.group(0)

'def'



This example looks for a word following a hyphen:

>>> m = re.search(r'(?<=-)\w+', 'spam-egg')

>>> m.group(0)

'egg'



Changed in version 3.5: Added support for group references of fixed length.

(?<!...)

Matches if the current position in the string is not preceded by a match for .... This is called a negative

lookbehind assertion. Similar to positive lookbehind assertions, the contained pattern must only match strings

of some fixed length. Patterns which start with negative lookbehind assertions may match at the beginning of

the string being searched.

(?(id/name)yes-pattern|no-pattern)

Will try to match with yes-pattern if the group with given id or name exists, and with no-pattern if

it doesn’t. no-pattern is optional and can be omitted. For example, (<)?(\w+@\w+(?:\.\w+)+)(?

(1)>|$) is a poor email matching pattern, which will match with '' as well as

'user@host.com', but not with ' nor 'user@host.com>'.

Changed in version 3.12: Group id can only contain ASCII digits. In bytes patterns, group name can only

contain bytes in the ASCII range (b'\x00'-b'\x7f').

The special sequences consist of '\' and a character from the list below. If the ordinary character is not an ASCII digit or an ASCII letter, then the resulting RE will match the second character. For example, \$ matches the character '$'.

\number

Matches the contents of the group of the same number. Groups are numbered starting from 1. For example,

(.+) \1 matches 'the the' or '55 55', but not 'thethe' (note the space after the group). This special

sequence can only be used to match one of the first 99 groups. If the first digit of number is 0, or number is

3 octal digits long, it will not be interpreted as a group match, but as the character with octal value number.

Inside the '[' and ']' of a character class, all numeric escapes are treated as characters.

The Python Library Reference, Release 3.13.2



\A

Matches only at the start of the string.

\b

Matches the empty string, but only at the beginning or end of a word. A word is defined as a sequence of word

characters. Note that formally, \b is defined as the boundary between a \w and a \W character (or vice versa),

or between \w and the beginning or end of the string. This means that r'\bat\b' matches 'at', 'at.',

'(at)' , and 'as at ay' but not 'attempt' or 'atlas'.

The default word characters in Unicode (str) patterns are Unicode alphanumerics and the underscore, but this

can be changed by using the ASCII flag. Word boundaries are determined by the current locale if the LOCALE

flag is used.



® Note

Inside a character range, \b represents the backspace character, for compatibility with Python’s string literals.



\B

Matches the empty string, but only when it is not at the beginning or end of a word. This means that r'at\B'

matches 'athens', 'atom', 'attorney', but not 'at', 'at.', or 'at!'. \B is the opposite of \b, so

word characters in Unicode (str) patterns are Unicode alphanumerics or the underscore, although this can be

changed by using the ASCII flag. Word boundaries are determined by the current locale if the LOCALE flag is

used.



® Note

Note that \B does not match an empty string, which differs from RE implementations in other programming languages such as Perl. This behavior is kept for compatibility reasons.



\d

For Unicode (str) patterns:

Matches any Unicode decimal digit (that is, any character in Unicode character category [Nd]). This includes [0-9], and also many other digit characters.

Matches [0-9] if the ASCII flag is used.

For 8-bit (bytes) patterns:

Matches any decimal digit in the ASCII character set; this is equivalent to [0-9].

\D

Matches any character which is not a decimal digit. This is the opposite of \d.

Matches [^0-9] if the ASCII flag is used.

\s

For Unicode (str) patterns:

Matches Unicode whitespace characters (as defined by str.isspace()). This includes [ \t\n\r\f\ v], and also many other characters, for example the non-breaking spaces mandated by typography rules in many languages.

Matches [ \t\n\r\f\v] if the ASCII flag is used.

For 8-bit (bytes) patterns:

Matches characters considered whitespace in the ASCII character set; this is equivalent to [ \t\n\r\ f\v] .

\S

Matches any character which is not a whitespace character. This is the opposite of \s.

Matches [^ \t\n\r\f\v] if the ASCII flag is used.





The Python Library Reference, Release 3.13.2




\w

For Unicode (str) patterns:

Matches Unicode word characters; this includes all Unicode alphanumeric characters (as defined by str.

isalnum()), as well as the underscore (_).

Matches [a-zA-Z0-9_] if the ASCII flag is used.

For 8-bit (bytes) patterns:

Matches characters considered alphanumeric in the ASCII character set; this is equivalent to

[a-zA-Z0-9_]. If the LOCALE flag is used, matches characters considered alphanumeric in the current locale and the underscore.

\W

Matches any character which is not a word character. This is the opposite of \w. By default, matches non-

underscore (_) characters for which str.isalnum() returns False.

Matches [^a-zA-Z0-9_] if the ASCII flag is used.

If the LOCALE flag is used, matches characters which are neither alphanumeric in the current locale nor the

underscore.

\Z

Matches only at the end of the string.

Most of the escape sequences supported by Python string literals are also accepted by the regular expression parser:

\a \b \f \n

\N \r \t \u

\U \v \x \\



(Note that \b is used to represent word boundaries, and means “backspace” only inside character classes.)

'\u', '\U', and '\N' escape sequences are only recognized in Unicode (str) patterns. In bytes patterns they are errors. Unknown escapes of ASCII letters are reserved for future use and treated as errors.

Octal escapes are included in a limited form. If the first digit is a 0, or if there are three octal digits, it is considered an octal escape. Otherwise, it is a group reference. As for string literals, octal escapes are always at most three digits in length.

Changed in version 3.3: The '\u' and '\U' escape sequences have been added.

Changed in version 3.6: Unknown escapes consisting of '\' and an ASCII letter now are errors.

Changed in version 3.8: The '\N{name}' escape sequence has been added. As in string literals, it expands to the named Unicode character (e.g. '\N{EM DASH}').



6.2.2 Module Contents

The module defines several functions, constants, and an exception. Some of the functions are simplified versions of the full featured methods for compiled regular expressions. Most non-trivial applications always use the compiled form.



Flags

Changed in version 3.6: Flag constants are now instances of RegexFlag, which is a subclass of enum.IntFlag.

class re.RegexFlag

An enum.IntFlag class containing the regex options listed below.

Added in version 3.11: - added to __all__

re.A



The Python Library Reference, Release 3.13.2



re.ASCII

Make \w, \W, \b, \B, \d, \D, \s and \S perform ASCII-only matching instead of full Unicode matching.

This is only meaningful for Unicode (str) patterns, and is ignored for bytes patterns.

Corresponds to the inline flag (?a).



® Note

The U flag still exists for backward compatibility, but is redundant in Python 3 since matches are Unicode

by default for str patterns, and Unicode matching isn’t allowed for bytes patterns. UNICODE and the inline flag (?u) are similarly redundant.



re.DEBUG

Display debug information about compiled expression.

No corresponding inline flag.

re.I

re.IGNORECASE

Perform case-insensitive matching; expressions like [A-Z] will also match lowercase letters. Full Unicode

matching (such as Ü matching ü) also works unless the ASCII flag is used to disable non-ASCII matches. The

current locale does not change the effect of this flag unless the LOCALE flag is also used.

Corresponds to the inline flag (?i).

Note that when the Unicode patterns [a-z] or [A-Z] are used in combination with the IGNORECASE flag,

they will match the 52 ASCII letters and 4 additional non-ASCII letters: ‘İ’ (U+0130, Latin capital letter I with

dot above), ‘ı’ (U+0131, Latin small letter dotless i), ‘ſ’ (U+017F, Latin small letter long s) and ‘K’ (U+212A,

Kelvin sign). If the ASCII flag is used, only letters ‘a’ to ‘z’ and ‘A’ to ‘Z’ are matched.

re.L

re.LOCALE

Make \w, \W, \b, \B and case-insensitive matching dependent on the current locale. This flag can be used

only with bytes patterns.

Corresponds to the inline flag (?L).



Á Warning

This flag is discouraged; consider Unicode matching instead. The locale mechanism is very unreliable as it only handles one “culture” at a time and only works with 8-bit locales. Unicode matching is enabled by default for Unicode (str) patterns and it is able to handle different locales and languages.



Changed in version 3.6: LOCALE can be used only with bytes patterns and is not compatible with ASCII.

Changed in version 3.7: Compiled regular expression objects with the LOCALE flag no longer depend on the

locale at compile time. Only the locale at matching time affects the result of matching.

re.M

re.MULTILINE

When specified, the pattern character '^' matches at the beginning of the string and at the beginning of each

line (immediately following each newline); and the pattern character '$' matches at the end of the string and

at the end of each line (immediately preceding each newline). By default, '^' matches only at the beginning

of the string, and '$' only at the end of the string and immediately before the newline (if any) at the end of

the string.

Corresponds to the inline flag (?m).

The Python Library Reference, Release 3.13.2



re.NOFLAG

Indicates no flag being applied, the value is 0. This flag may be used as a default value for a function keyword

argument or as a base value that will be conditionally ORed with other flags. Example of use as a default value:

def myfunc(text, flag=re.NOFLAG):

return re.match(text, flag)



Added in version 3.11.

re.S

re.DOTALL

Make the '.' special character match any character at all, including a newline; without this flag, '.' will

match anything except a newline.

Corresponds to the inline flag (?s).

re.U

re.UNICODE

In Python 3, Unicode characters are matched by default for str patterns. This flag is therefore redundant with

no effect and is only kept for backward compatibility.

See ASCII to restrict matching to ASCII characters instead.

re.X

re.VERBOSE

This flag allows you to write regular expressions that look nicer and are more readable by allowing you to

visually separate logical sections of the pattern and add comments. Whitespace within the pattern is ignored,

except when in a character class, or when preceded by an unescaped backslash, or within tokens like *?, (?:

or (?P<...>. For example, (? : and * ? are not allowed. When a line contains a # that is not in a character

class and is not preceded by an unescaped backslash, all characters from the leftmost such # through the end

of the line are ignored.

This means that the two following regular expression objects that match a decimal number are functionally

equal:

a = re.compile(r"""\d + # the integral part

\. # the decimal point

\d * # some fractional digits""", re.X)

b = re.compile(r"\d+\.\d*")



Corresponds to the inline flag (?x).



Functions

re.compile(pattern, flags=0)

Compile a regular expression pattern into a regular expression object, which can be used for matching using its

match() , search() and other methods, described below.

The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables,

combined using bitwise OR (the | operator).

The sequence

prog = re.compile(pattern)

result = prog.match(string)



is equivalent to

result = re.match(pattern, string)



The Python Library Reference, Release 3.13.2



but using re.compile() and saving the resulting regular expression object for reuse is more efficient when

the expression will be used several times in a single program.



® Note

The compiled versions of the most recent patterns passed to re.compile() and the module-level match-ing functions are cached, so programs that use only a few regular expressions at a time needn’t worry about compiling regular expressions.



re.search(pattern, string, flags=0)

Scan through string looking for the first location where the regular expression pattern produces a match, and

return a corresponding Match. Return None if no position in the string matches the pattern; note that this is

different from finding a zero-length match at some point in the string.

The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables,

combined using bitwise OR (the | operator).

re.match(pattern, string, flags=0)

If zero or more characters at the beginning of string match the regular expression pattern, return a corresponding

Match . Return None if the string does not match the pattern; note that this is different from a zero-length

match.

Note that even in MULTILINE mode, re.match() will only match at the beginning of the string and not at

the beginning of each line.

If you want to locate a match anywhere in string, use search() instead (see also search() vs. match()).

The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables,

combined using bitwise OR (the | operator).

re.fullmatch(pattern, string, flags=0)

If the whole string matches the regular expression pattern, return a corresponding Match. Return None if the

string does not match the pattern; note that this is different from a zero-length match.

The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables,

combined using bitwise OR (the | operator).

Added in version 3.4.

re.split(pattern, string, maxsplit=0, flags=0)

Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all

groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits

occur, and the remainder of the string is returned as the final element of the list.

>>> re.split(r'\W+', 'Words, words, words.')

['Words', 'words', 'words', '']

>>> re.split(r'(\W+)', 'Words, words, words.')

['Words', ', ', 'words', ', ', 'words', '.', '']

>>> re.split(r'\W+', 'Words, words, words.', maxsplit=1)

['Words', 'words, words.']

>>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE)

['0', '3', '9']



If there are capturing groups in the separator and it matches at the start of the string, the result will start with

an empty string. The same holds for the end of the string:

>>> re.split(r'(\W+)', '...words, words...')

['', '...', 'words', ', ', 'words', '...', '']



That way, separator components are always found at the same relative indices within the result list.

Empty matches for the pattern split the string only when not adjacent to a previous empty match.

The Python Library Reference, Release 3.13.2



>>> re.split(r'\b', 'Words, words, words.')

['', 'Words', ', ', 'words', ', ', 'words', '.']

>>> re.split(r'\W*', '...words...')

['', '', 'w', 'o', 'r', 'd', 's', '', '']

>>> re.split(r'(\W*)', '...words...')

['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', '']



The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables,

combined using bitwise OR (the | operator).

Changed in version 3.1: Added the optional flags argument.

Changed in version 3.7: Added support of splitting on a pattern that could match an empty string.

Deprecated since version 3.13: Passing maxsplit and flags as positional arguments is deprecated. In future

Python versions they will be keyword-only parameters.

re.findall(pattern, string, flags=0)

Return all non-overlapping matches of pattern in string, as a list of strings or tuples. The string is scanned

left-to-right, and matches are returned in the order found. Empty matches are included in the result.

The result depends on the number of capturing groups in the pattern. If there are no groups, return a list of

strings matching the whole pattern. If there is exactly one group, return a list of strings matching that group.

If multiple groups are present, return a list of tuples of strings matching the groups. Non-capturing groups do

not affect the form of the result.

>>> re.findall(r'\bf[a-z]*', 'which foot or hand fell fastest')

['foot', 'fell', 'fastest']

>>> re.findall(r'(\w+)=(\d+)', 'set width=20 and height=10')

[('width', '20'), ('height', '10')]



The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables,

combined using bitwise OR (the | operator).

Changed in version 3.7: Non-empty matches can now start just after a previous empty match.

re.finditer(pattern, string, flags=0)

Return an iterator yielding Match objects over all non-overlapping matches for the RE pattern in string. The

string is scanned left-to-right, and matches are returned in the order found. Empty matches are included in the

result.

The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables,

combined using bitwise OR (the | operator).

Changed in version 3.7: Non-empty matches can now start just after a previous empty match.

re.sub(pattern, repl, string, count=0, flags=0)

Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the

replacement repl. If the pattern isn’t found, string is returned unchanged. repl can be a string or a function; if

it is a string, any backslash escapes in it are processed. That is, \n is converted to a single newline character,

\r is converted to a carriage return, and so forth. Unknown escapes of ASCII letters are reserved for future

use and treated as errors. Other unknown escapes such as \& are left alone. Backreferences, such as \6, are

replaced with the substring matched by group 6 in the pattern. For example:

>>> re.sub(r'def\s+([a-zA-Z_][a-zA-Z_0-9]*)\s*\(\s*\):',

... r'static PyObject*\npy_\1(void)\n{',

... 'def myfunc():')

'static PyObject*\npy_myfunc(void)\n{'



If repl is a function, it is called for every non-overlapping occurrence of pattern. The function takes a single

Match argument, and returns the replacement string. For example:

The Python Library Reference, Release 3.13.2



>>> def dashrepl(matchobj):

... if matchobj.group(0) == '-': return ' '

... else: return '-'

...

>>> re.sub('-{1,2}', dashrepl, 'pro----gram-files')

'pro--gram files'

>>> re.sub(r'\sAND\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE)

'Baked Beans & Spam'



The pattern may be a string or a Pattern.

The optional argument count is the maximum number of pattern occurrences to be replaced; count must be

a non-negative integer. If omitted or zero, all occurrences will be replaced. Empty matches for the pattern

are replaced only when not adjacent to a previous empty match, so sub('x*', '-', 'abxd') returns

'-a-b--d-'.

In string-type repl arguments, in addition to the character escapes and backreferences described above, \

g will use the substring matched by the group named name, as defined by the (?P...) syntax.

\g uses the corresponding group number; \g<2> is therefore equivalent to \2, but isn’t ambiguous

in a replacement such as \g<2>0. \20 would be interpreted as a reference to group 20, not a reference to

group 2 followed by the literal character '0'. The backreference \g<0> substitutes in the entire substring

matched by the RE.

The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables,

combined using bitwise OR (the | operator).

Changed in version 3.1: Added the optional flags argument.

Changed in version 3.5: Unmatched groups are replaced with an empty string.

Changed in version 3.6: Unknown escapes in pattern consisting of '\' and an ASCII letter now are errors.

Changed in version 3.7: Unknown escapes in repl consisting of '\' and an ASCII letter now are errors. Empty

matches for the pattern are replaced when adjacent to a previous non-empty match.

Changed in version 3.12: Group id can only contain ASCII digits. In bytes replacement strings, group name

can only contain bytes in the ASCII range (b'\x00'-b'\x7f').

Deprecated since version 3.13: Passing count and flags as positional arguments is deprecated. In future Python

versions they will be keyword-only parameters.

re.subn( pattern, repl, string, count=0, flags=0)

Perform the same operation as sub(), but return a tuple (new_string, number_of_subs_made).

The expression’s behaviour can be modified by specifying a flags value. Values can be any of the flags variables,

combined using bitwise OR (the | operator).

re.escape(pattern)

Escape special characters in pattern. This is useful if you want to match an arbitrary literal string that may

have regular expression metacharacters in it. For example:

>>> print(re.escape('https://www.python.org'))

https://www\.python\.org

>>> legal_chars = string.ascii_lowercase + string.digits + "!#$%&'*+-.^_`|~:"

>>> print('[%s]+' % re.escape(legal_chars))

[abcdefghijklmnopqrstuvwxyz0123456789!\#\$%\&'\*\+\-\.\^_`\|\~:]+

>>> operators = ['+', '-', '*', '/', '**']

>>> print('|'.join(map(re.escape, sorted(operators, reverse=True))))

/|\-|\+|\*\*|\*





The Python Library Reference, Release 3.13.2




This function must not be used for the replacement string in sub() and subn(), only backslashes should be

escaped. For example:

>>> digits_re = r'\d+'

>>> sample = '/usr/sbin/sendmail - 0 errors, 12 warnings'

>>> print(re.sub(digits_re, digits_re.replace('\\', r'\\'), sample))

/usr/sbin/sendmail - \d+ errors, \d+ warnings



Changed in version 3.3: The '_' character is no longer escaped.

Changed in version 3.7: Only characters that can have special meaning in a regular expression are escaped. As

a result, '!', '"', '%', "'", ',', '/', ':', ';', '<', '=', '>', '@', and "`" are no longer escaped.

re.purge()

Clear the regular expression cache.



Exceptions

exception re.PatternError(msg, pattern=None, pos=None)

Exception raised when a string passed to one of the functions here is not a valid regular expression (for example,

it might contain unmatched parentheses) or when some other error occurs during compilation or matching. It

is never an error if a string contains no match for a pattern. The PatternError instance has the following

additional attributes:

msg

The unformatted error message.

pattern

The regular expression pattern.

pos

The index in pattern where compilation failed (may be None).

lineno

The line corresponding to pos (may be None).

colno

The column corresponding to pos (may be None).

Changed in version 3.5: Added additional attributes.

Changed in version 3.13: PatternError was originally named error; the latter is kept as an alias for back-

ward compatibility.



6.2.3 Regular Expression Objects

class re.Pattern

Compiled regular expression object returned by re.compile().

Changed in version 3.9: re.Pattern supports [] to indicate a Unicode (str) or bytes pattern. See Generic

Alias Type.

Pattern.search(string[, pos[, endpos ]])

Scan through string looking for the first location where this regular expression produces a match, and return a

corresponding Match. Return None if no position in the string matches the pattern; note that this is different

from finding a zero-length match at some point in the string.

The optional second parameter pos gives an index in the string where the search is to start; it defaults to 0.

This is not completely equivalent to slicing the string; the '^' pattern character matches at the real beginning

of the string and at positions just after a newline, but not necessarily at the index where the search is to start.

The optional parameter endpos limits how far the string will be searched; it will be as if the string is endpos char-

acters long, so only the characters from pos to endpos - 1 will be searched for a match. If endpos is less than The Python Library Reference, Release 3.13.2



pos, no match will be found; otherwise, if rx is a compiled regular expression object, rx.search(string,

0, 50) is equivalent to rx.search(string[:50], 0).

>>> pattern = re.compile("d")

>>> pattern.search("dog") # Match at index 0



>>> pattern.search("dog", 1) # No match; search doesn't include the "d"



Pattern.match(string[, pos[, endpos ]])

If zero or more characters at the beginning of string match this regular expression, return a corresponding

Match . Return None if the string does not match the pattern; note that this is different from a zero-length

match.

The optional pos and endpos parameters have the same meaning as for the search() method.

>>> pattern = re.compile("o")

>>> pattern.match("dog") # No match as "o" is not at the start of "dog".

>>> pattern.match("dog", 1) # Match as "o" is the 2nd character of "dog".





If you want to locate a match anywhere in string, use search() instead (see also search() vs. match()).

Pattern.fullmatch(string[, pos[, endpos ]])

If the whole string matches this regular expression, return a corresponding Match. Return None if the string

does not match the pattern; note that this is different from a zero-length match.

The optional pos and endpos parameters have the same meaning as for the search() method.

>>> pattern = re.compile("o[gh]")

>>> pattern.fullmatch("dog") # No match as "o" is not at the start of "dog

, →".

>>> pattern.fullmatch("ogre") # No match as not the full string matches.

>>> pattern.fullmatch("doggie", 1, 3) # Matches within given limits.





Added in version 3.4.

Pattern.split(string, maxsplit=0)

Identical to the split() function, using the compiled pattern.

Pattern.findall(string[, pos[, endpos ]])

Similar to the findall() function, using the compiled pattern, but also accepts optional pos and endpos

parameters that limit the search region like for search().

Pattern.finditer(string[, pos[, endpos ]])

Similar to the finditer() function, using the compiled pattern, but also accepts optional pos and endpos

parameters that limit the search region like for search().

Pattern.sub(repl, string, count=0)

Identical to the sub() function, using the compiled pattern.

Pattern.subn(repl, string, count=0)

Identical to the subn() function, using the compiled pattern.

Pattern.flags

The regex matching flags. This is a combination of the flags given to compile(), any (?...) inline flags in

the pattern, and implicit flags such as UNICODE if the pattern is a Unicode string.

Pattern.groups

The number of capturing groups in the pattern.





The Python Library Reference, Release 3.13.2




Pattern.groupindex

A dictionary mapping any symbolic group names defined by (?P) to group numbers. The dictionary is

empty if no symbolic groups were used in the pattern.

Pattern.pattern

The pattern string from which the pattern object was compiled.

Changed in version 3.7: Added support of copy.copy() and copy.deepcopy(). Compiled regular expression objects are considered atomic.



6.2.4 Match Objects

Match objects always have a boolean value of True. Since match() and search() return None when there is no match, you can test whether there was a match with a simple if statement:

match = re.search(pattern, string)

if match:

process(match)



class re.Match

Match object returned by successful matches and searches.

Changed in version 3.9: re.Match supports [] to indicate a Unicode (str) or bytes match. See Generic Alias

Type.

Match.expand(template)

Return the string obtained by doing backslash substitution on the template string template, as done by the

sub() method. Escapes such as \n are converted to the appropriate characters, and numeric backreferences

(\1, \2) and named backreferences (\g<1>, \g) are replaced by the contents of the corresponding

group. The backreference \g<0> will be replaced by the entire match.

Changed in version 3.5: Unmatched groups are replaced with an empty string.

Match.group( group1 [, ... ])

Returns one or more subgroups of the match. If there is a single argument, the result is a single string; if

there are multiple arguments, the result is a tuple with one item per argument. Without arguments, group1

defaults to zero (the whole match is returned). If a groupN argument is zero, the corresponding return value

is the entire matching string; if it is in the inclusive range [1..99], it is the string matching the corresponding

parenthesized group. If a group number is negative or larger than the number of groups defined in the pattern,

an IndexError exception is raised. If a group is contained in a part of the pattern that did not match, the

corresponding result is None. If a group is contained in a part of the pattern that matched multiple times, the

last match is returned.

>>> m = re.match(r"(\w+) (\w+)", "Isaac Newton, physicist")

>>> m.group(0) # The entire match

'Isaac Newton'

>>> m.group(1) # The first parenthesized subgroup.

'Isaac'

>>> m.group(2) # The second parenthesized subgroup.

'Newton'

>>> m.group(1, 2) # Multiple arguments give us a tuple.

('Isaac', 'Newton')



If the regular expression uses the (?P...) syntax, the groupN arguments may also be strings identify-

ing groups by their group name. If a string argument is not used as a group name in the pattern, an IndexError

exception is raised.

A moderately complicated example:



The Python Library Reference, Release 3.13.2



>>> m = re.match(r"(?P\w+) (?P\w+)", "Malcolm Reynolds")

>>> m.group('first_name')

'Malcolm'

>>> m.group('last_name')

'Reynolds'



Named groups can also be referred to by their index:

>>> m.group(1)

'Malcolm'

>>> m.group(2)

'Reynolds'



If a group matches multiple times, only the last match is accessible:

>>> m = re.match(r"(..)+", "a1b2c3") # Matches 3 times.

>>> m.group(1) # Returns only the last match.

'c3'



Match.__getitem__(g)

This is identical to m.group(g). This allows easier access to an individual group from a match:

>>> m = re.match(r"(\w+) (\w+)", "Isaac Newton, physicist")

>>> m[0] # The entire match

'Isaac Newton'

>>> m[1] # The first parenthesized subgroup.

'Isaac'

>>> m[2] # The second parenthesized subgroup.

'Newton'



Named groups are supported as well:

>>> m = re.match(r"(?P\w+) (?P\w+)", "Isaac Newton")

>>> m['first_name']

'Isaac'

>>> m['last_name']

'Newton'



Added in version 3.6.

Match.groups(default=None)

Return a tuple containing all the subgroups of the match, from 1 up to however many groups are in the pattern.

The default argument is used for groups that did not participate in the match; it defaults to None.

For example:

>>> m = re.match(r"(\d+)\.(\d+)", "24.1632")

>>> m.groups()

('24', '1632')



If we make the decimal place and everything after it optional, not all groups might participate in the match.

These groups will default to None unless the default argument is given:

>>> m = re.match(r"(\d+)\.?(\d+)?", "24")

>>> m.groups() # Second group defaults to None.

('24', None)

>>> m.groups('0') # Now, the second group defaults to '0'.

('24', '0')

The Python Library Reference, Release 3.13.2



Match.groupdict(default=None)

Return a dictionary containing all the named subgroups of the match, keyed by the subgroup name. The default

argument is used for groups that did not participate in the match; it defaults to None. For example:

>>> m = re.match(r"(?P\w+) (?P\w+)", "Malcolm Reynolds")

>>> m.groupdict()

{'first_name': 'Malcolm', 'last_name': 'Reynolds'}



Match.start( group [ ])

Match.end( group [ ])

Return the indices of the start and end of the substring matched by group; group defaults to zero (meaning the

whole matched substring). Return-1 if group exists but did not contribute to the match. For a match object m,

and a group g that did contribute to the match, the substring matched by group g (equivalent to m.group(g))

is

m.string[m.start(g):m.end(g)]



Note that m.start(group) will equal m.end(group) if group matched a null string. For example, after m

= re.search('b(c?)', 'cba'), m.start(0) is 1, m.end(0) is 2, m.start(1) and m.end(1) are

both 2, and m.start(2) raises an IndexError exception.

An example that will remove remove_this from email addresses:

>>> email = "tony@tiremove_thisger.net"

>>> m = re.search("remove_this", email)

>>> email[:m.start()] + email[m.end():]

'tony@tiger.net'



Match.span( group [ ])

For a match m, return the 2-tuple (m.start(group), m.end(group)). Note that if group did not con-

tribute to the match, this is (-1, -1). group defaults to zero, the entire match.

Match.pos

The value of pos which was passed to the search() or match() method of a regex object. This is the index

into the string at which the RE engine started looking for a match.

Match.endpos

The value of endpos which was passed to the search() or match() method of a regex object. This is the

index into the string beyond which the RE engine will not go.

Match.lastindex

The integer index of the last matched capturing group, or None if no group was matched at all. For example,

the expressions (a)b, ((a)(b)), and ((ab)) will have lastindex == 1 if applied to the string 'ab',

while the expression (a)(b) will have lastindex == 2, if applied to the same string.

Match.lastgroup

The name of the last matched capturing group, or None if the group didn’t have a name, or if no group was

matched at all.

Match.re

The regular expression object whose match() or search() method produced this match instance.

Match.string

The string passed to match() or search().

Changed in version 3.7: Added support of copy.copy() and copy.deepcopy(). Match objects are considered atomic.



The Python Library Reference, Release 3.13.2



6.2.5 Regular Expression Examples

Checking for a Pair

In this example, we’ll use the following helper function to display match objects a little more gracefully:

def displaymatch(match):

if match is None:

return None

return ' %r, groups=%r>' % (match.group(), match.groups())



Suppose you are writing a poker program where a player’s hand is represented as a 5-character string with each character representing a card, “a” for ace, “k” for king, “q” for queen, “j” for jack, “t” for 10, and “2” through “9” representing the card with that value.

To see if a given string is a valid hand, one could do the following:

>>> valid = re.compile(r"^[a2-9tjqk]{5}$")

>>> displaymatch(valid.match("akt5q")) # Valid.

""

>>> displaymatch(valid.match("akt5e")) # Invalid.

>>> displaymatch(valid.match("akt")) # Invalid.

>>> displaymatch(valid.match("727ak")) # Valid.

""



That last hand, "727ak", contained a pair, or two of the same valued cards. To match this with a regular expression, one could use backreferences as such:

>>> pair = re.compile(r".*(.).*\1")

>>> displaymatch(pair.match("717ak")) # Pair of 7s.

""

>>> displaymatch(pair.match("718ak")) # No pairs.

>>> displaymatch(pair.match("354aa")) # Pair of aces. ""



To find out what card the pair consists of, one could use the group() method of the match object in the following manner:

>>> pair = re.compile(r".*(.).*\1")

>>> pair.match("717ak").group(1)

'7'

# Error because re.match() returns None, which doesn't have a group() method: >>> pair.match("718ak").group(1)

Traceback (most recent call last):

File "", line 1, in

re.match(r".*(.).*\1", "718ak").group(1)

AttributeError: 'NoneType' object has no attribute 'group'

>>> pair.match("354aa").group(1)

'a'



Simulating scanf()

Python does not currently have an equivalent to scanf(). Regular expressions are generally more powerful, though also more verbose, than scanf() format strings. The table below offers some more-or-less equivalent mappings between scanf() format tokens and regular expressions.



The Python Library Reference, Release 3.13.2



scanf() Token Regular Expression

%c .

%5c .{5}

%d [-+]?\d+

%e, %E, %f, %g [-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?

%i [-+]?(0[xX][\dA-Fa-f]+|0[0-7]*|\d+)

%o [-+]?[0-7]+

%s \S+

%u \d+

%x, %X [-+]?(0[xX])?[\dA-Fa-f]+



To extract the filename and numbers from a string like

/usr/sbin/sendmail-0 errors, 4 warnings



you would use a scanf() format like

%s- %d errors, %d warnings



The equivalent regular expression would be

(\S+)-(\d+) errors, (\d+) warnings



search() vs. match()

Python offers different primitive operations based on regular expressions:

• re.match() checks for a match only at the beginning of the string

• re.search() checks for a match anywhere in the string (this is what Perl does by default)

• re.fullmatch() checks for entire string to be a match

For example:

>>> re.match("c", "abcdef") # No match

>>> re.search("c", "abcdef") # Match



>>> re.fullmatch("p.*n", "python") # Match



>>> re.fullmatch("r.*n", "python") # No match



Regular expressions beginning with '^' can be used with search() to restrict the match at the beginning of the string:

>>> re.match("c", "abcdef") # No match

>>> re.search("^c", "abcdef") # No match

>>> re.search("^a", "abcdef") # Match





Note however that in MULTILINE mode match() only matches at the beginning of the string, whereas using

search() with a regular expression beginning with '^' will match at the beginning of each line.

>>> re.match("X", "A\nB\nX", re.MULTILINE) # No match >>> re.search("^X", "A\nB\nX", re.MULTILINE) # Match





The Python Library Reference, Release 3.13.2



Making a Phonebook

split() splits a string into a list delimited by the passed pattern. The method is invaluable for converting textual data into data structures that can be easily read and modified by Python as demonstrated in the following example that creates a phonebook.

First, here is the input. Normally it may come from a file, here we are using triple-quoted string syntax

>>> text = """Ross McFluff: 834.345.1254 155 Elm Street ...

... Ronald Heathmore: 892.345.3428 436 Finley Avenue ... Frank Burger: 925.541.7625 662 South Dogwood Way ...

...

... Heather Albrecht: 548.326.4584 919 Park Place"""



The entries are separated by one or more newlines. Now we convert the string into a list with each nonempty line having its own entry:

>>> entries = re.split("\n+", text)

>>> entries

['Ross McFluff: 834.345.1254 155 Elm Street',

'Ronald Heathmore: 892.345.3428 436 Finley Avenue', 'Frank Burger: 925.541.7625 662 South Dogwood Way', 'Heather Albrecht: 548.326.4584 919 Park Place']



Finally, split each entry into a list with first name, last name, telephone number, and address. We use the maxsplit

parameter of split() because the address has spaces, our splitting pattern, in it:

>>> [re.split(":? ", entry, maxsplit=3) for entry in entries] [['Ross', 'McFluff', '834.345.1254', '155 Elm Street'], ['Ronald', 'Heathmore', '892.345.3428', '436 Finley Avenue'], ['Frank', 'Burger', '925.541.7625', '662 South Dogwood Way'], ['Heather', 'Albrecht', '548.326.4584', '919 Park Place']]



The :? pattern matches the colon after the last name, so that it does not occur in the result list. With a maxsplit of 4, we could separate the house number from the street name:

>>> [re.split(":? ", entry, maxsplit=4) for entry in entries] [['Ross', 'McFluff', '834.345.1254', '155', 'Elm Street'], ['Ronald', 'Heathmore', '892.345.3428', '436', 'Finley Avenue'], ['Frank', 'Burger', '925.541.7625', '662', 'South Dogwood Way'], ['Heather', 'Albrecht', '548.326.4584', '919', 'Park Place']]



Text Munging

sub() replaces every occurrence of a pattern with a string or the result of a function. This example demonstrates

using sub() with a function to “munge” text, or randomize the order of all the characters in each word of a sentence except for the first and last characters:

>>> def repl(m):

... inner_word = list(m.group(2))

... random.shuffle(inner_word)

... return m.group(1) + "".join(inner_word) + m.group(3)

...

>>> text = "Professor Abdolmalek, please report your absences promptly." >>> re.sub(r"(\w)(\w+)(\w)", repl, text)

'Poefsrosr Aealmlobdk, pslaee reorpt your abnseces plmrptoy.' >>> re.sub(r"(\w)(\w+)(\w)", repl, text)

'Pofsroser Aodlambelk, plasee reoprt yuor asnebces potlmrpy.'

The Python Library Reference, Release 3.13.2



Finding all Adverbs

findall() matches all occurrences of a pattern, not just the first one as search() does. For example, if a writer

wanted to find all of the adverbs in some text, they might use findall() in the following manner:

>>> text = "He was carefully disguised but captured quickly by police." >>> re.findall(r"\w+ly\b", text)

['carefully', 'quickly']



Finding all Adverbs and their Positions

If one wants more information about all matches of a pattern than the matched text, finditer() is useful as it

provides Match objects instead of strings. Continuing with the previous example, if a writer wanted to find all of the

adverbs and their positions in some text, they would use finditer() in the following manner:

>>> text = "He was carefully disguised but captured quickly by police." >>> for m in re.finditer(r"\w+ly\b", text):

... print('%02d-%02d: %s' % (m.start(), m.end(), m.group(0))) 07-16: carefully

40-47: quickly



Raw String Notation

Raw string notation (r"text") keeps regular expressions sane. Without it, every backslash ('\') in a regular ex-pression would have to be prefixed with another one to escape it. For example, the two following lines of code are functionally identical:

>>> re.match(r"\W(.)\1\W", " ff ")



>>> re.match("\\W(.)\\1\\W", " ff ")





When one wants to match a literal backslash, it must be escaped in the regular expression. With raw string nota-tion, this means r"\\". Without raw string notation, one must use "\\\\", making the following lines of code functionally identical:

>>> re.match(r"\\", r"\\")



>>> re.match("\\\\", r"\\")





Writing a Tokenizer

A tokenizer or scanner analyzes a string to categorize groups of characters. This is a useful first step in writing a compiler or interpreter.

The text categories are specified with regular expressions. The technique is to combine those into a single master regular expression and to loop over successive matches:

from typing import NamedTuple

import re

class Token(NamedTuple):

type: str

value: str

line: int

column: int

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

def tokenize(code):

keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'}

token_specification = [

('NUMBER', r'\d+(\.\d*)?'), # Integer or decimal number ('ASSIGN', r':='), # Assignment operator

('END', r';'), # Statement terminator

('ID', r'[A-Za-z]+'), # Identifiers

('OP', r'[+\-*/]'), # Arithmetic operators

('NEWLINE', r'\n'), # Line endings

('SKIP', r'[ \t]+'), # Skip over spaces and tabs

('MISMATCH', r'.'), # Any other character

]

tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)

line_num = 1

line_start = 0

for mo in re.finditer(tok_regex, code):

kind = mo.lastgroup

value = mo.group()

column = mo.start()-line_start

if kind == 'NUMBER':

value = float(value) if '.' in value else int(value)

elif kind == 'ID' and value in keywords:

kind = value

elif kind == 'NEWLINE':

line_start = mo.end()

line_num += 1

continue

elif kind == 'SKIP':

continue

elif kind == 'MISMATCH':

raise RuntimeError(f'{value!r} unexpected on line {line_num}')

yield Token(kind, value, line_num, column)

statements = '''

IF quantity THEN

total := total + price * quantity;

tax := price * 0.05;

ENDIF;

'''

for token in tokenize(statements):

print(token)



The tokenizer produces the following output:

Token(type='IF', value='IF', line=2, column=4)

Token(type='ID', value='quantity', line=2, column=7) Token(type='THEN', value='THEN', line=2, column=16) Token(type='ID', value='total', line=3, column=8)

Token(type='ASSIGN', value=':=', line=3, column=14) Token(type='ID', value='total', line=3, column=17)

Token(type='OP', value='+', line=3, column=23)

Token(type='ID', value='price', line=3, column=25)

Token(type='OP', value='*', line=3, column=31)

Token(type='ID', value='quantity', line=3, column=33) Token(type='END', value=';', line=3, column=41)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

Token(type='ID', value='tax', line=4, column=8)

Token(type='ASSIGN', value=':=', line=4, column=12) Token(type='ID', value='price', line=4, column=15)

Token(type='OP', value='*', line=4, column=21)

Token(type='NUMBER', value=0.05, line=4, column=23) Token(type='END', value=';', line=4, column=27)

Token(type='ENDIF', value='ENDIF', line=5, column=4) Token(type='END', value=';', line=5, column=9)



6.3 difflib — Helpers for computing deltas

Source code: Lib/difflib.py



This module provides classes and functions for comparing sequences. It can be used for example, for comparing files, and can produce information about file differences in various formats, including HTML and context and unified diffs.

For comparing directories and files, see also, the filecmp module.

class difflib.SequenceMatcher

This is a flexible class for comparing pairs of sequences of any type, so long as the sequence elements are

hashable. The basic algorithm predates, and is a little fancier than, an algorithm published in the late 1980’s by

Ratcliff and Obershelp under the hyperbolic name “gestalt pattern matching.” The idea is to find the longest

contiguous matching subsequence that contains no “junk” elements; these “junk” elements are ones that are

uninteresting in some sense, such as blank lines or whitespace. (Handling junk is an extension to the Ratcliff

and Obershelp algorithm.) The same idea is then applied recursively to the pieces of the sequences to the left

and to the right of the matching subsequence. This does not yield minimal edit sequences, but does tend to

yield matches that “look right” to people.

Timing: The basic Ratcliff-Obershelp algorithm is cubic time in the worst case and quadratic time in the

expected case. SequenceMatcher is quadratic time for the worst case and has expected-case behavior de-

pendent in a complicated way on how many elements the sequences have in common; best case time is linear.

Automatic junk heuristic: SequenceMatcher supports a heuristic that automatically treats certain se-

quence items as junk. The heuristic counts how many times each individual item appears in the sequence.

If an item’s duplicates (after the first one) account for more than 1% of the sequence and the sequence is

at least 200 items long, this item is marked as “popular” and is treated as junk for the purpose of sequence

matching. This heuristic can be turned off by setting the autojunk argument to False when creating the

SequenceMatcher .

Changed in version 3.2: Added the autojunk parameter.

class difflib.Differ

This is a class for comparing sequences of lines of text, and producing human-readable differences or deltas.

Differ uses SequenceMatcher both to compare sequences of lines, and to compare sequences of characters

within similar (near-matching) lines.

Each line of a Differ delta begins with a two-letter code:



Code Meaning

'- ' line unique to sequence 1

'+ ' line unique to sequence 2

' ' line common to both sequences

'? ' line not present in either input sequence



Lines beginning with ‘?’ attempt to guide the eye to intraline differences, and were not present in either input

sequence. These lines can be confusing if the sequences contain whitespace characters, such as spaces, tabs or

line breaks.

The Python Library Reference, Release 3.13.2



class difflib.HtmlDiff

This class can be used to create an HTML table (or a complete HTML file containing the table) showing a

side by side, line by line comparison of text with inter-line and intra-line change highlights. The table can be

generated in either full or contextual difference mode.

The constructor for this class is:

__init__(tabsize=8, wrapcolumn=None, linejunk=None, charjunk=IS_CHARACTER_JUNK )

Initializes instance of HtmlDiff.

tabsize is an optional keyword argument to specify tab stop spacing and defaults to 8.

wrapcolumn is an optional keyword to specify column number where lines are broken and wrapped, defaults to None where lines are not wrapped.

linejunk and charjunk are optional keyword arguments passed into ndiff() (used by HtmlDiff to

generate the side by side HTML differences). See ndiff() documentation for argument default values and descriptions.

The following methods are public:

make_file(fromlines, tolines, fromdesc=”, todesc=”, context=False, numlines=5, *, charset=’utf-8’ )

Compares fromlines and tolines (lists of strings) and returns a string which is a complete HTML file containing a table showing line by line differences with inter-line and intra-line changes highlighted.

fromdesc and todesc are optional keyword arguments to specify from/to file column header strings (both default to an empty string).

context and numlines are both optional keyword arguments. Set context to True when contextual dif-ferences are to be shown, else the default is False to show the full files. numlines defaults to 5. When context is True numlines controls the number of context lines which surround the difference highlights. When context is False numlines controls the number of lines which are shown before a difference high-light when using the “next” hyperlinks (setting to zero would cause the “next” hyperlinks to place the next difference highlight at the top of the browser without any leading context).



® Note

fromdesc and todesc are interpreted as unescaped HTML and should be properly escaped while re-ceiving input from untrusted sources.



Changed in version 3.5: charset keyword-only argument was added. The default charset of HTML doc-ument changed from 'ISO-8859-1' to 'utf-8'.

make_table(fromlines, tolines, fromdesc=”, todesc=”, context=False, numlines=5)

Compares fromlines and tolines (lists of strings) and returns a string which is a complete HTML table showing line by line differences with inter-line and intra-line changes highlighted.

The arguments for this method are the same as those for the make_file() method.

difflib.context_diff(a, b, fromfile=”, tofile=”, fromfiledate=”, tofiledate=” , n=3, lineterm=’\n’)

Compare a and b (lists of strings); return a delta (a generator generating the delta lines) in context diff format.

Context diffs are a compact way of showing just the lines that have changed plus a few lines of context. The

changes are shown in a before/after style. The number of context lines is set by n which defaults to three.

By default, the diff control lines (those with *** or---) are created with a trailing newline. This is helpful so

that inputs created from io.IOBase.readlines() result in diffs that are suitable for use with io.IOBase.

writelines() since both the inputs and outputs have trailing newlines.

For inputs that do not have trailing newlines, set the lineterm argument to "" so that the output will be uniformly

newline free.



The Python Library Reference, Release 3.13.2



The context diff format normally has a header for filenames and modification times. Any or all of these may

be specified using strings for fromfile, tofile, fromfiledate, and tofiledate. The modification times are normally

expressed in the ISO 8601 format. If not specified, the strings default to blanks.

>>> import sys

>>> from difflib import *

>>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']

>>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']

>>> sys.stdout.writelines(context_diff(s1, s2, fromfile='before.py',

... tofile='after.py'))

*** before.py

--- after.py

***************

*** 1,4 ****

! bacon

! eggs

! ham

guido

--- 1,4 ----

! python

! eggy

! hamster

guido



See A command-line interface to difflib for a more detailed example.

difflib.get_close_matches(word, possibilities, n=3, cutoff=0.6)

Return a list of the best “good enough” matches. word is a sequence for which close matches are desired

(typically a string), and possibilities is a list of sequences against which to match word (typically a list of

strings).

Optional argument n (default 3) is the maximum number of close matches to return; n must be greater than 0.

Optional argument cutoff (default 0.6) is a float in the range [0, 1]. Possibilities that don’t score at least that

similar to word are ignored.

The best (no more than n) matches among the possibilities are returned in a list, sorted by similarity score,

most similar first.

>>> get_close_matches('appel', ['ape', 'apple', 'peach', 'puppy'])

['apple', 'ape']

>>> import keyword

>>> get_close_matches('wheel', keyword.kwlist)

['while']

>>> get_close_matches('pineapple', keyword.kwlist)

[]

>>> get_close_matches('accept', keyword.kwlist)

['except']



difflib.ndiff(a, b, linejunk=None, charjunk=IS_CHARACTER_JUNK )

Compare a and b (lists of strings); return a Differ-style delta (a generator generating the delta lines).

Optional keyword parameters linejunk and charjunk are filtering functions (or None):

linejunk: A function that accepts a single string argument, and returns true if the string is junk, or false if not.

The default is None. There is also a module-level function IS_LINE_JUNK(), which filters out lines without

visible characters, except for at most one pound character ('#') – however the underlying SequenceMatcher

class does a dynamic analysis of which lines are so frequent as to constitute noise, and this usually works better

than using this function.

charjunk: A function that accepts a character (a string of length 1), and returns if the character is junk, or false

if not. The default is module-level function IS_CHARACTER_JUNK(), which filters out whitespace characters The Python Library Reference, Release 3.13.2



(a blank or tab; it’s a bad idea to include newline in this!).

>>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),

... 'ore\ntree\nemu\n'.splitlines(keepends=True))

>>> print(''.join(diff), end="")

- one

? ^

+ ore

? ^

- two

- three

? -

+ tree

+ emu



difflib.restore(sequence, which)

Return one of the two sequences that generated a delta.

Given a sequence produced by Differ.compare() or ndiff(), extract lines originating from file 1 or 2

(parameter which), stripping off line prefixes.

Example:

>>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),

... 'ore\ntree\nemu\n'.splitlines(keepends=True))

>>> diff = list(diff) # materialize the generated delta into a list

>>> print(''.join(restore(diff, 1)), end="")

one

two

three

>>> print(''.join(restore(diff, 2)), end="")

ore

tree

emu



difflib.unified_diff(a, b, fromfile=”, tofile=”, fromfiledate=”, tofiledate=” , n=3, lineterm=’\n’)

Compare a and b (lists of strings); return a delta (a generator generating the delta lines) in unified diff format.

Unified diffs are a compact way of showing just the lines that have changed plus a few lines of context. The

changes are shown in an inline style (instead of separate before/after blocks). The number of context lines is

set by n which defaults to three.

By default, the diff control lines (those with---, +++, or @@) are created with a trailing newline. This is

helpful so that inputs created from io.IOBase.readlines() result in diffs that are suitable for use with

io.IOBase.writelines() since both the inputs and outputs have trailing newlines.

For inputs that do not have trailing newlines, set the lineterm argument to "" so that the output will be uniformly

newline free.

The unified diff format normally has a header for filenames and modification times. Any or all of these may

be specified using strings for fromfile, tofile, fromfiledate, and tofiledate. The modification times are normally

expressed in the ISO 8601 format. If not specified, the strings default to blanks.

>>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']

>>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']

>>> sys.stdout.writelines(unified_diff(s1, s2, fromfile='before.py', tofile=

, →'after.py'))

--- before.py

+++ after.py

@@ -1,4 +1,4 @@

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

-bacon

-eggs

-ham

+python

+eggy

+hamster

guido



See A command-line interface to difflib for a more detailed example.

difflib.diff_bytes(dfunc, a, b, fromfile=b” , tofile=b”, fromfiledate=b”, tofiledate=b”, n=3, lineterm=b’\n’)

Compare a and b (lists of bytes objects) using dfunc; yield a sequence of delta lines (also bytes) in the format

returned by dfunc. dfunc must be a callable, typically either unified_diff() or context_diff().

Allows you to compare data with unknown or inconsistent encoding. All inputs except n must be bytes objects,

not str. Works by losslessly converting all inputs (except n) to str, and calling dfunc(a, b, fromfile,

tofile, fromfiledate, tofiledate, n, lineterm) . The output of dfunc is then converted back

to bytes, so the delta lines that you receive have the same unknown/inconsistent encodings as a and b.

Added in version 3.5.

difflib.IS_LINE_JUNK(line)

Return True for ignorable lines. The line line is ignorable if line is blank or contains a single '#', otherwise

it is not ignorable. Used as a default for parameter linejunk in ndiff() in older versions.

difflib.IS_CHARACTER_JUNK(ch)

Return True for ignorable characters. The character ch is ignorable if ch is a space or tab, otherwise it is not

ignorable. Used as a default for parameter charjunk in ndiff().



µ See also

Pattern Matching: The Gestalt Approach

Discussion of a similar algorithm by John W. Ratcliff and D. E. Metzener. This was published in Dr.

Dobb’s Journal in July, 1988.



6.3.1 SequenceMatcher Objects

The SequenceMatcher class has this constructor:

class difflib.SequenceMatcher(isjunk=None, a=”, b=”, autojunk=True)

Optional argument isjunk must be None (the default) or a one-argument function that takes a sequence element

and returns true if and only if the element is “junk” and should be ignored. Passing None for isjunk is equivalent

to passing lambda x: False; in other words, no elements are ignored. For example, pass:

lambda x: x in " \t"



if you’re comparing lines as sequences of characters, and don’t want to synch up on blanks or hard tabs.

The optional arguments a and b are sequences to be compared; both default to empty strings. The elements of

both sequences must be hashable.

The optional argument autojunk can be used to disable the automatic junk heuristic.

Changed in version 3.2: Added the autojunk parameter.

SequenceMatcher objects get three data attributes: bjunk is the set of elements of b for which isjunk is True;

bpopular is the set of non-junk elements considered popular by the heuristic (if it is not disabled); b2j is a dict

mapping the remaining elements of b to a list of positions where they occur. All three are reset whenever b is

reset with set_seqs() or set_seq2().

Added in version 3.2: The bjunk and bpopular attributes.

The Python Library Reference, Release 3.13.2



SequenceMatcher objects have the following methods:

set_seqs(a, b)

Set the two sequences to be compared.

SequenceMatcher computes and caches detailed information about the second sequence, so if you want to

compare one sequence against many sequences, use set_seq2() to set the commonly used sequence once

and call set_seq1() repeatedly, once for each of the other sequences.

set_seq1(a)

Set the first sequence to be compared. The second sequence to be compared is not changed.

set_seq2(b)

Set the second sequence to be compared. The first sequence to be compared is not changed.

find_longest_match(alo=0, ahi=None, blo=0, bhi=None)

Find longest matching block in a[alo:ahi] and b[blo:bhi].

If isjunk was omitted or None, find_longest_match() returns (i, j, k) such that a[i:i+k] is equal to b[j:j+k], where alo <= i <= i+k <= ahi and blo <= j <= j+k <= bhi. For all (i', j', k') meeting those conditions, the additional conditions k >= k', i <= i', and if i == i', j <= j' are also met. In other words, of all maximal matching blocks, return one that starts earliest in a, and of all those maximal matching blocks that start earliest in a, return the one that starts earliest in b.

>>> s = SequenceMatcher(None, " abcd", "abcd abcd")

>>> s.find_longest_match(0, 5, 0, 9)

Match(a=0, b=4, size=5)



If isjunk was provided, first the longest matching block is determined as above, but with the additional restriction that no junk element appears in the block. Then that block is extended as far as possible by matching (only) junk elements on both sides. So the resulting block never matches on junk except as identical junk happens to be adjacent to an interesting match.

Here’s the same example as before, but considering blanks to be junk. That prevents ' abcd' from matching the ' abcd' at the tail end of the second sequence directly. Instead only the 'abcd' can match, and matches the leftmost 'abcd' in the second sequence:

>>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd") >>> s.find_longest_match(0, 5, 0, 9)

Match(a=1, b=0, size=4)



If no blocks match, this returns (alo, blo, 0).

This method returns a named tuple Match(a, b, size).

Changed in version 3.9: Added default arguments.

get_matching_blocks()

Return list of triples describing non-overlapping matching subsequences. Each triple is of the form (i, j, n) , and means that a[i:i+n] == b[j:j+n]. The triples are monotonically increasing in i and j.

The last triple is a dummy, and has the value (len(a), len(b), 0). It is the only triple with n == 0. If (i, j, n) and (i', j', n') are adjacent triples in the list, and the second is not the last triple in the list, then i+n < i' or j+n < j'; in other words, adjacent triples always describe non-adjacent equal blocks.

>>> s = SequenceMatcher(None, "abxcd", "abcd")

>>> s.get_matching_blocks()

[Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]



The Python Library Reference, Release 3.13.2



get_opcodes()

Return list of 5-tuples describing how to turn a into b. Each tuple is of the form (tag, i1, i2, j1, j2) . The first tuple has i1 == j1 == 0, and remaining tuples have i1 equal to the i2 from the preceding tuple, and, likewise, j1 equal to the previous j2.

The tag values are strings, with these meanings:



Value Meaning

'replace' a[i1:i2] should be replaced by b[j1:j2].

'delete' a[i1:i2] should be deleted. Note that j1 == j2 in this case. 'insert' b[j1:j2] should be inserted at a[i1:i1]. Note that i1 == i2 in this case. 'equal' a[i1:i2] == b[j1:j2] (the sub-sequences are equal).



For example:

>>> a = "qabxcd"

>>> b = "abycdf"

>>> s = SequenceMatcher(None, a, b)

>>> for tag, i1, i2, j1, j2 in s.get_opcodes():

... print('{:7} a[{}:{}] --> b[{}:{}] {!r:>8}--> {!r}'.format( ... tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2]))

delete a[0:1] --> b[0:0] 'q' --> ''

equal a[1:3] --> b[0:2] 'ab' --> 'ab'

replace a[3:4] --> b[2:3] 'x' --> 'y'

equal a[4:6] --> b[3:5] 'cd' --> 'cd'

insert a[6:6] --> b[5:6] '' --> 'f'



get_grouped_opcodes(n=3)

Return a generator of groups with up to n lines of context.

Starting with the groups returned by get_opcodes(), this method splits out smaller change clusters and eliminates intervening ranges which have no changes.

The groups are returned in the same format as get_opcodes().

ratio()

Return a measure of the sequences’ similarity as a float in the range [0, 1].

Where T is the total number of elements in both sequences, and M is the number of matches, this is 2.0*M / T. Note that this is 1.0 if the sequences are identical, and 0.0 if they have nothing in common.

This is expensive to compute if get_matching_blocks() or get_opcodes() hasn’t already been

called, in which case you may want to try quick_ratio() or real_quick_ratio() first to get an upper bound.



® Note

Caution: The result of a ratio() call may depend on the order of the arguments. For instance:

>>> SequenceMatcher(None, 'tide', 'diet').ratio()

0.25

>>> SequenceMatcher(None, 'diet', 'tide').ratio()

0.5



quick_ratio()

Return an upper bound on ratio() relatively quickly.

The Python Library Reference, Release 3.13.2



real_quick_ratio()

Return an upper bound on ratio() very quickly.

The three methods that return the ratio of matching to total characters can give different results due to differing levels

of approximation, although quick_ratio() and real_quick_ratio() are always at least as large as ratio():

>>> s = SequenceMatcher(None, "abcd", "bcde")

>>> s.ratio()

0.75

>>> s.quick_ratio()

0.75

>>> s.real_quick_ratio()

1.0



6.3.2 SequenceMatcher Examples

This example compares two strings, considering blanks to be “junk”:

>>> s = SequenceMatcher(lambda x: x == " ",

... "private Thread currentThread;",

... "private volatile Thread currentThread;")



ratio() returns a float in [0, 1], measuring the similarity of the sequences. As a rule of thumb, a ratio() value over 0.6 means the sequences are close matches:

>>> print(round(s.ratio(), 3))

0.866



If you’re only interested in where the sequences match, get_matching_blocks() is handy:

>>> for block in s.get_matching_blocks():

... print("a[%d] and b[%d] match for %d elements" % block) a[0] and b[0] match for 8 elements

a[8] and b[17] match for 21 elements

a[29] and b[38] match for 0 elements



Note that the last tuple returned by get_matching_blocks() is always a dummy, (len(a), len(b), 0), and this is the only case in which the last tuple element (number of elements matched) is 0.

If you want to know how to change the first sequence into the second, use get_opcodes():

>>> for opcode in s.get_opcodes():

... print("%6s a[%d:%d] b[%d:%d]" % opcode)

equal a[0:8] b[0:8]

insert a[8:8] b[8:17]

equal a[8:29] b[17:38]



µ See also

• The get_close_matches() function in this module which shows how simple code building on

SequenceMatcher can be used to do useful work.

• Simple version control recipe for a small application built with SequenceMatcher.



The Python Library Reference, Release 3.13.2



6.3.3 Differ Objects

Note that Differ-generated deltas make no claim to be minimal diffs. To the contrary, minimal diffs are often counter-intuitive, because they synch up anywhere possible, sometimes accidental matches 100 pages apart. Re-stricting synch points to contiguous matches preserves some notion of locality, at the occasional cost of producing a longer diff.

The Differ class has this constructor:

class difflib.Differ(linejunk=None, charjunk=None)

Optional keyword parameters linejunk and charjunk are for filter functions (or None):

linejunk: A function that accepts a single string argument, and returns true if the string is junk. The default is

None , meaning that no line is considered junk.

charjunk: A function that accepts a single character argument (a string of length 1), and returns true if the

character is junk. The default is None, meaning that no character is considered junk.

These junk-filtering functions speed up matching to find differences and do not cause any differing lines or

characters to be ignored. Read the description of the find_longest_match() method’s isjunk parameter

for an explanation.

Differ objects are used (deltas generated) via a single method:

compare(a, b)

Compare two sequences of lines, and generate the delta (a sequence of lines).

Each sequence must contain individual single-line strings ending with newlines. Such sequences can

be obtained from the readlines() method of file-like objects. The delta generated also consists of

newline-terminated strings, ready to be printed as-is via the writelines() method of a file-like object.



6.3.4 Differ Example

This example compares two texts. First we set up the texts, sequences of individual single-line strings ending with

newlines (such sequences can also be obtained from the readlines() method of file-like objects):

>>> text1 = ''' 1. Beautiful is better than ugly.

... 2. Explicit is better than implicit.

... 3. Simple is better than complex.

... 4. Complex is better than complicated.

... '''.splitlines(keepends=True)

>>> len(text1)

4

>>> text1[0][-1]

'\n'

>>> text2 = ''' 1. Beautiful is better than ugly.

... 3. Simple is better than complex.

... 4. Complicated is better than complex.

... 5. Flat is better than nested.

... '''.splitlines(keepends=True)



Next we instantiate a Differ object:

>>> d = Differ()



Note that when instantiating a Differ object we may pass functions to filter out line and character “junk.” See the

Differ() constructor for details.

Finally, we compare the two:

>>> result = list(d.compare(text1, text2))



result is a list of strings, so let’s pretty-print it:

The Python Library Reference, Release 3.13.2



>>> from pprint import pprint

>>> pprint(result)

[' 1. Beautiful is better than ugly.\n',

'- 2. Explicit is better than implicit.\n',

'- 3. Simple is better than complex.\n',

'+ 3. Simple is better than complex.\n',

'? ++\n',

'- 4. Complex is better than complicated.\n',

'? ^ ---- ^\n',

'+ 4. Complicated is better than complex.\n',

'? ++++ ^ ^\n',

'+ 5. Flat is better than nested.\n']



As a single multi-line string it looks like this:

>>> import sys

>>> sys.stdout.writelines(result)

1. Beautiful is better than ugly.

- 2. Explicit is better than implicit.

- 3. Simple is better than complex.

+ 3. Simple is better than complex.

? ++

- 4. Complex is better than complicated.

? ^ ---- ^

+ 4. Complicated is better than complex.

? ++++ ^ ^

+ 5. Flat is better than nested.



6.3.5 A command-line interface to difflib

This example shows how to use difflib to create a diff-like utility.

""" Command line interface to difflib.py providing diffs in four formats:

* ndiff: lists every line and highlights interline changes. * context: highlights clusters of changes in a before/after format. * unified: highlights clusters of changes in an inline format. * html: generates side by side comparison with change highlights.

"""

import sys, os, difflib, argparse

from datetime import datetime, timezone

def file_mtime(path):

t = datetime.fromtimestamp(os.stat(path).st_mtime,

timezone.utc)

return t.astimezone().isoformat()

def main():

parser = argparse.ArgumentParser()

parser.add_argument('-c', action='store_true', default=False,

help='Produce a context format diff (default)')

parser.add_argument('-u', action='store_true', default=False,

help='Produce a unified format diff')

parser.add_argument('-m', action='store_true', default=False,

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

help='Produce HTML side by side diff '

'(can use -c and -l in conjunction)')

parser.add_argument('-n', action='store_true', default=False,

help='Produce a ndiff format diff')

parser.add_argument('-l', '--lines', type=int, default=3,

help='Set number of context lines (default 3)')

parser.add_argument('fromfile')

parser.add_argument('tofile')

options = parser.parse_args()

n = options.lines

fromfile = options.fromfile

tofile = options.tofile

fromdate = file_mtime(fromfile)

todate = file_mtime(tofile)

with open(fromfile) as ff:

fromlines = ff.readlines()

with open(tofile) as tf:

tolines = tf.readlines()

if options.u:

diff = difflib.unified_diff(fromlines, tolines, fromfile, tofile, fromdate,

, → todate, n=n)

elif options.n:

diff = difflib.ndiff(fromlines, tolines)

elif options.m:

diff = difflib.HtmlDiff().make_file(fromlines,tolines,fromfile,tofile,

, →context=options.c,numlines=n)

else:

diff = difflib.context_diff(fromlines, tolines, fromfile, tofile, fromdate,

, → todate, n=n)

sys.stdout.writelines(diff)

if __name__ == '__main__':

main()



6.3.6 ndiff example

This example shows how to use difflib.ndiff().

"""ndiff [-q] file1 file2

or

ndiff (-r1 | -r2) < ndiff_output > file1_or_file2

Print a human-friendly file difference report to stdout. Both inter-and intra-line differences are noted. In the second form, recreate file1 (-r1) or file2 (-r2) on stdout, from an ndiff report on stdin.

In the first form, if -q ("quiet") is not specified, the first two lines of output are

-: file1

+: file2

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

Each remaining line begins with a two-letter code:

"- " line unique to file1

"+ " line unique to file2

" " line common to both files

"? " line not present in either input file

Lines beginning with "? " attempt to guide the eye to intraline differences, and were not present in either input file. These lines can be confusing if the source files contain tab characters.

The first file can be recovered by retaining only lines that begin with " " or "- ", and deleting those 2-character prefixes; use ndiff with -r1.

The second file can be recovered similarly, but by retaining only " " and "+ " lines; use ndiff with -r2; or, on Unix, the second file can be recovered by piping the output through

sed -n '/^[+ ] /s/^..//p'

"""

__version__ = 1, 7, 0

import difflib, sys

def fail(msg):

out = sys.stderr.write

out(msg + "\n\n")

out(__doc__)

return 0

# open a file & return the file object; gripe and return 0 if it # couldn't be opened

def fopen(fname):

try:

return open(fname)

except IOError as detail:

return fail("couldn't open " + fname + ": " + str(detail))

# open two files & spray the diff to stdout; return false iff a problem def fcompare(f1name, f2name):

f1 = fopen(f1name)

f2 = fopen(f2name)

if not f1 or not f2:

return 0

a = f1.readlines(); f1.close()

b = f2.readlines(); f2.close()

for line in difflib.ndiff(a, b):

print(line, end=' ')

return 1

# crack args (sys.argv[1:] is normal) & compare;

# return false iff a problem



(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

def main(args):

import getopt

try:

opts, args = getopt.getopt(args, "qr:")

except getopt.error as detail:

return fail(str(detail))

noisy = 1

qseen = rseen = 0

for opt, val in opts:

if opt == "-q":

qseen = 1

noisy = 0

elif opt == "-r":

rseen = 1

whichfile = val

if qseen and rseen:

return fail("can't specify both -q and -r")

if rseen:

if args:

return fail("no args allowed with -r option")

if whichfile in ("1", "2"):

restore(whichfile)

return 1

return fail("-r value must be 1 or 2")

if len(args) != 2:

return fail("need 2 filename args")

f1name, f2name = args

if noisy:

print('-:', f1name)

print('+:', f2name)

return fcompare(f1name, f2name)

# read ndiff output from stdin, and print file1 (which=='1') or # file2 (which=='2') to stdout

def restore(which):

restored = difflib.restore(sys.stdin.readlines(), which)

sys.stdout.writelines(restored)

if __name__ == '__main__':

main(sys.argv[1:])



6.4 textwrap — Text wrapping and filling

Source code: Lib/textwrap.py



The textwrap module provides some convenience functions, as well as TextWrapper, the class that does all the work. If you’re just wrapping or filling one or two text strings, the convenience functions should be good enough;

otherwise, you should use an instance of TextWrapper for efficiency.

textwrap.wrap(text, width=70, *, initial_indent=”, subsequent_indent=”, expand_tabs=True,

replace_whitespace=True, fix_sentence_endings=False, break_long_words=True, drop_whitespace=True, break_on_hyphens=True, tabsize=8, max_lines=None, placeholder=’ [...]’)

Wraps the single paragraph in text (a string) so every line is at most width characters long. Returns a list of The Python Library Reference, Release 3.13.2



output lines, without final newlines.

Optional keyword arguments correspond to the instance attributes of TextWrapper, documented below.

See the TextWrapper.wrap() method for additional details on how wrap() behaves.

textwrap.fill(text, width=70, *, initial_indent=”, subsequent_indent=”, expand_tabs=True,

replace_whitespace=True, fix_sentence_endings=False, break_long_words=True, drop_whitespace=True, break_on_hyphens=True, tabsize=8, max_lines=None, placeholder=’ [...]’)

Wraps the single paragraph in text, and returns a single string containing the wrapped paragraph. fill() is

shorthand for

"\n".join(wrap(text, ...))



In particular, fill() accepts exactly the same keyword arguments as wrap().

textwrap.shorten(text, width, *, fix_sentence_endings=False, break_long_words=True,

break_on_hyphens=True, placeholder=’ [...]’)

Collapse and truncate the given text to fit in the given width.

First the whitespace in text is collapsed (all whitespace is replaced by single spaces). If the result fits in the

width, it is returned. Otherwise, enough words are dropped from the end so that the remaining words plus the

placeholder fit within width:

>>> textwrap.shorten("Hello world!", width=12)

'Hello world!'

>>> textwrap.shorten("Hello world!", width=11)

'Hello [...]'

>>> textwrap.shorten("Hello world", width=10, placeholder="...")

'Hello...'



Optional keyword arguments correspond to the instance attributes of TextWrapper, documented below. Note

that the whitespace is collapsed before the text is passed to the TextWrapper fill() function, so changing

the value of tabsize, expand_tabs, drop_whitespace, and replace_whitespace will have no effect.

Added in version 3.4.

textwrap.dedent(text)

Remove any common leading whitespace from every line in text.

This can be used to make triple-quoted strings line up with the left edge of the display, while still presenting

them in the source code in indented form.

Note that tabs and spaces are both treated as whitespace, but they are not equal: the lines " hello" and

"\thello" are considered to have no common leading whitespace.

Lines containing only whitespace are ignored in the input and normalized to a single newline character in the

output.

For example:

def test():

# end first line with \ to avoid the empty line!

s = '''\

hello

world

'''

print(repr(s)) # prints ' hello\n world\n '

print(repr(dedent(s))) # prints 'hello\n world\n'



The Python Library Reference, Release 3.13.2



textwrap.indent(text, prefix, predicate=None)

Add prefix to the beginning of selected lines in text.

Lines are separated by calling text.splitlines(True).

By default, prefix is added to all lines that do not consist solely of whitespace (including any line endings).

For example:

>>> s = 'hello\n\n \nworld'

>>> indent(s, ' ')

' hello\n\n \n world'



The optional predicate argument can be used to control which lines are indented. For example, it is easy to add

prefix to even empty and whitespace-only lines:

>>> print(indent(s, '+ ', lambda line: True))

+ hello

+

+

+ world



Added in version 3.3.

wrap(), fill() and shorten() work by creating a TextWrapper instance and calling a single method on it.

That instance is not reused, so for applications that process many text strings using wrap() and/or fill(), it may

be more efficient to create your own TextWrapper object.

Text is preferably wrapped on whitespaces and right after the hyphens in hyphenated words; only then will long words

be broken if necessary, unless TextWrapper.break_long_words is set to false.

class textwrap.TextWrapper(**kwargs)

The TextWrapper constructor accepts a number of optional keyword arguments. Each keyword argument

corresponds to an instance attribute, so for example

wrapper = TextWrapper(initial_indent="* ")



is the same as

wrapper = TextWrapper()

wrapper.initial_indent = "* "



You can reuse the same TextWrapper object many times, and you can change any of its options through

direct assignment to instance attributes between uses.

The TextWrapper instance attributes (and keyword arguments to the constructor) are as follows:

width

(default: 70) The maximum length of wrapped lines. As long as there are no individual words in the

input text longer than width, TextWrapper guarantees that no output line will be longer than width characters.

expand_tabs

(default: True) If true, then all tab characters in text will be expanded to spaces using the expandtabs() method of text.

tabsize

(default: 8) If expand_tabs is true, then all tab characters in text will be expanded to zero or more spaces, depending on the current column and the given tab size.

Added in version 3.3.

The Python Library Reference, Release 3.13.2



replace_whitespace

(default: True) If true, after tab expansion but before wrapping, the wrap() method will replace each whitespace character with a single space. The whitespace characters replaced are as follows: tab, newline, vertical tab, formfeed, and carriage return ('\t\n\v\f\r').



® Note

If expand_tabs is false and replace_whitespace is true, each tab character will be replaced by a single space, which is not the same as tab expansion.



® Note

If replace_whitespace is false, newlines may appear in the middle of a line and cause strange

output. For this reason, text should be split into paragraphs (using str.splitlines() or similar) which are wrapped separately.



drop_whitespace

(default: True) If true, whitespace at the beginning and ending of every line (after wrapping but before indenting) is dropped. Whitespace at the beginning of the paragraph, however, is not dropped if non-whitespace follows it. If whitespace being dropped takes up an entire line, the whole line is dropped.

initial_indent

(default: '') String that will be prepended to the first line of wrapped output. Counts towards the length of the first line. The empty string is not indented.

subsequent_indent

(default: '') String that will be prepended to all lines of wrapped output except the first. Counts towards the length of each line except the first.

fix_sentence_endings

(default: False) If true, TextWrapper attempts to detect sentence endings and ensure that sentences are always separated by exactly two spaces. This is generally desired for text in a monospaced font. However, the sentence detection algorithm is imperfect: it assumes that a sentence ending consists of a lowercase letter followed by one of '.', '!', or '?', possibly followed by one of '"' or "'", followed by a space. One problem with this algorithm is that it is unable to detect the difference between “Dr.” in

[...] Dr. Frankenstein's monster [...]



and “Spot.” in

[...] See Spot. See Spot run [...]



fix_sentence_endings is false by default.

Since the sentence detection algorithm relies on string.lowercase for the definition of “lowercase letter”, and a convention of using two spaces after a period to separate sentences on the same line, it is specific to English-language texts.

break_long_words

(default: True) If true, then words longer than width will be broken in order to ensure that no lines

are longer than width. If it is false, long words will not be broken, and some lines may be longer than

width . (Long words will be put on a line by themselves, in order to minimize the amount by which

width is exceeded.)

break_on_hyphens

(default: True) If true, wrapping will occur preferably on whitespaces and right after hyphens in com-pound words, as it is customary in English. If false, only whitespaces will be considered as potentially

The Python Library Reference, Release 3.13.2



good places for line breaks, but you need to set break_long_words to false if you want truly insecable words. Default behaviour in previous versions was to always allow breaking hyphenated words.

max_lines

(default: None) If not None, then the output will contain at most max_lines lines, with placeholder appearing at the end of the output.

Added in version 3.4.

placeholder

(default: ' [...]') String that will appear at the end of the output text if it has been truncated.

Added in version 3.4.

TextWrapper also provides some public methods, analogous to the module-level convenience functions:

wrap(text)

Wraps the single paragraph in text (a string) so every line is at most width characters long. All wrapping

options are taken from instance attributes of the TextWrapper instance. Returns a list of output lines, without final newlines. If the wrapped output has no content, the returned list is empty.

fill(text)

Wraps the single paragraph in text, and returns a single string containing the wrapped paragraph.



6.5 unicodedata — Unicode Database



This module provides access to the Unicode Character Database (UCD) which defines character properties for all

Unicode characters. The data contained in this database is compiled from the UCD version 15.1.0.

The module uses the same names and symbols as defined by Unicode Standard Annex #44, “Unicode Character

Database”. It defines the following functions:

unicodedata.lookup(name)

Look up character by name. If a character with the given name is found, return the corresponding character.

If not found, KeyError is raised.

Changed in version 3.3: Support for name aliases1 2 and named sequences has been added.

unicodedata.name(chr[, default ])

Returns the name assigned to the character chr as a string. If no name is defined, default is returned, or, if not

given, ValueError is raised.

unicodedata.decimal(chr [, default ])

Returns the decimal value assigned to the character chr as integer. If no such value is defined, default is

returned, or, if not given, ValueError is raised.

unicodedata.digit(chr [, default ])

Returns the digit value assigned to the character chr as integer. If no such value is defined, default is returned,

or, if not given, ValueError is raised.

unicodedata.numeric(chr [, default ])

Returns the numeric value assigned to the character chr as float. If no such value is defined, default is returned,

or, if not given, ValueError is raised.

unicodedata.category(chr)

Returns the general category assigned to the character chr as string.

1 https://www.unicode.org/Public/15.1.0/ucd/NameAliases.txt

2 https://www.unicode.org/Public/15.1.0/ucd/NamedSequences.txt

The Python Library Reference, Release 3.13.2



unicodedata.bidirectional(chr)

Returns the bidirectional class assigned to the character chr as string. If no such value is defined, an empty

string is returned.

unicodedata.combining( chr)

Returns the canonical combining class assigned to the character chr as integer. Returns 0 if no combining class

is defined.

unicodedata.east_asian_width(chr)

Returns the east asian width assigned to the character chr as string.

unicodedata.mirrored(chr)

Returns the mirrored property assigned to the character chr as integer. Returns 1 if the character has been

identified as a “mirrored” character in bidirectional text, 0 otherwise.

unicodedata.decomposition(chr)

Returns the character decomposition mapping assigned to the character chr as string. An empty string is

returned in case no such mapping is defined.

unicodedata.normalize( form, unistr)

Return the normal form form for the Unicode string unistr. Valid values for form are ‘NFC’, ‘NFKC’, ‘NFD’,

and ‘NFKD’.

The Unicode standard defines various normalization forms of a Unicode string, based on the definition of

canonical equivalence and compatibility equivalence. In Unicode, several characters can be expressed in vari-

ous way. For example, the character U+00C7 (LATIN CAPITAL LETTER C WITH CEDILLA) can also be

expressed as the sequence U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING CEDILLA).

For each character, there are two normal forms: normal form C and normal form D. Normal form D (NFD) is

also known as canonical decomposition, and translates each character into its decomposed form. Normal form

C (NFC) first applies a canonical decomposition, then composes pre-combined characters again.

In addition to these two forms, there are two additional normal forms based on compatibility equivalence. In

Unicode, certain characters are supported which normally would be unified with other characters. For example,

U+2160 (ROMAN NUMERAL ONE) is really the same thing as U+0049 (LATIN CAPITAL LETTER I).

However, it is supported in Unicode for compatibility with existing character sets (e.g. gb2312).

The normal form KD (NFKD) will apply the compatibility decomposition, i.e. replace all compatibility char-

acters with their equivalents. The normal form KC (NFKC) first applies the compatibility decomposition,

followed by the canonical composition.

Even if two unicode strings are normalized and look the same to a human reader, if one has combining char-

acters and the other doesn’t, they may not compare equal.

unicodedata.is_normalized(form, unistr)

Return whether the Unicode string unistr is in the normal form form. Valid values for form are ‘NFC’, ‘NFKC’,

‘NFD’, and ‘NFKD’.

Added in version 3.8.

In addition, the module exposes the following constant:

unicodedata.unidata_version

The version of the Unicode database used in this module.

unicodedata.ucd_3_2_0

This is an object that has the same methods as the entire module, but uses the Unicode database version 3.2

instead, for applications that require this specific version of the Unicode database (such as IDNA).

Examples:

>>> import unicodedata

>>> unicodedata.lookup('LEFT CURLY BRACKET')

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

'{'

>>> unicodedata.name('/')

'SOLIDUS'

>>> unicodedata.decimal('9')

9

>>> unicodedata.decimal('a')

Traceback (most recent call last):

File "", line 1, in

ValueError: not a decimal

>>> unicodedata.category('A') # 'L'etter, 'u'ppercase 'Lu'

>>> unicodedata.bidirectional('\u0660') # 'A'rabic, 'N'umber 'AN'



6.6 stringprep — Internet String Preparation

Source code: Lib/stringprep.py



When identifying things (such as host names) in the internet, it is often necessary to compare such identifications for “equality”. Exactly how this comparison is executed may depend on the application domain, e.g. whether it should be case-insensitive or not. It may be also necessary to restrict the possible identifications, to allow only identifications consisting of “printable” characters.

RFC 3454 defines a procedure for “preparing” Unicode strings in internet protocols. Before passing strings onto the wire, they are processed with the preparation procedure, after which they have a certain normalized form. The RFC defines a set of tables, which can be combined into profiles. Each profile must define which tables it uses, and what other optional parts of the stringprep procedure are part of the profile. One example of a stringprep profile is nameprep, which is used for internationalized domain names.

The module stringprep only exposes the tables from RFC 3454. As these tables would be very large to represent as dictionaries or lists, the module uses the Unicode character database internally. The module source code itself was generated using the mkstringprep.py utility.

As a result, these tables are exposed as functions, not as data structures. There are two kinds of tables in the RFC: sets

and mappings. For a set, stringprep provides the “characteristic function”, i.e. a function that returns True if the parameter is part of the set. For mappings, it provides the mapping function: given the key, it returns the associated value. Below is a list of all functions available in the module.

stringprep.in_table_a1(code)

Determine whether code is in tableA.1 (Unassigned code points in Unicode 3.2).

stringprep.in_table_b1(code)

Determine whether code is in tableB.1 (Commonly mapped to nothing).

stringprep.map_table_b2(code)

Return the mapped value for code according to tableB.2 (Mapping for case-folding used with NFKC).

stringprep.map_table_b3(code)

Return the mapped value for code according to tableB.3 (Mapping for case-folding used with no normalization).

stringprep.in_table_c11(code)

Determine whether code is in tableC.1.1 (ASCII space characters).

stringprep.in_table_c12(code)

Determine whether code is in tableC.1.2 (Non-ASCII space characters).

stringprep.in_table_c11_c12(code)

Determine whether code is in tableC.1 (Space characters, union of C.1.1 and C.1.2).

The Python Library Reference, Release 3.13.2



stringprep.in_table_c21(code)

Determine whether code is in tableC.2.1 (ASCII control characters).

stringprep.in_table_c22(code)

Determine whether code is in tableC.2.2 (Non-ASCII control characters).

stringprep.in_table_c21_c22(code)

Determine whether code is in tableC.2 (Control characters, union of C.2.1 and C.2.2).

stringprep.in_table_c3(code)

Determine whether code is in tableC.3 (Private use).

stringprep.in_table_c4(code)

Determine whether code is in tableC.4 (Non-character code points).

stringprep.in_table_c5(code)

Determine whether code is in tableC.5 (Surrogate codes).

stringprep.in_table_c6(code)

Determine whether code is in tableC.6 (Inappropriate for plain text).

stringprep.in_table_c7(code)

Determine whether code is in tableC.7 (Inappropriate for canonical representation).

stringprep.in_table_c8(code)

Determine whether code is in tableC.8 (Change display properties or are deprecated).

stringprep.in_table_c9(code)

Determine whether code is in tableC.9 (Tagging characters).

stringprep.in_table_d1(code)

Determine whether code is in tableD.1 (Characters with bidirectional property “R” or “AL”).

stringprep.in_table_d2(code)

Determine whether code is in tableD.2 (Characters with bidirectional property “L”).



6.7 readline — GNU readline interface



The readline module defines a number of functions to facilitate completion and reading/writing of history files

from the Python interpreter. This module can be used directly, or via the rlcompleter module, which supports completion of Python identifiers at the interactive prompt. Settings made using this module affect the behaviour of

both the interpreter’s interactive prompt and the prompts offered by the built-in input() function.

Readline keybindings may be configured via an initialization file, typically .inputrc in your home directory. See

Readline Init File in the GNU Readline manual for information about the format and allowable constructs of that file, and the capabilities of the Readline library in general.

Availability: not Android, not iOS, not WASI.

This module is not supported on mobile platforms or WebAssembly platforms.



® Note

The underlying Readline library API may be implemented by the editline (libedit) library instead of GNU

readline. On macOS the readline module detects which library is being used at run time.

The configuration file for editline is different from that of GNU readline. If you programmatically load

configuration strings you can use backend to determine which library is being used.

The Python Library Reference, Release 3.13.2



If you use editline/libedit readline emulation on macOS, the initialization file located in your home direc-

tory is named .editrc. For example, the following content in ~/.editrc will turn ON vi keybindings and

TAB completion:

python:bind-v

python:bind ^I rl_complete

Also note that different libraries may use different history file formats. When switching the underlying library,

existing history files may become unusable.



readline.backend

The name of the underlying Readline library being used, either "readline" or "editline".

Added in version 3.13.



6.7.1 Init file

The following functions relate to the init file and user configuration:

readline.parse_and_bind(string)

Execute the init line provided in the string argument. This calls rl_parse_and_bind() in the underlying

library.

readline.read_init_file( filename [ ])

Execute a readline initialization file. The default filename is the last filename used. This calls

rl_read_init_file() in the underlying library.



6.7.2 Line buffer

The following functions operate on the line buffer:

readline.get_line_buffer()

Return the current contents of the line buffer (rl_line_buffer in the underlying library).

readline.insert_text(string)

Insert text into the line buffer at the cursor position. This calls rl_insert_text() in the underlying library,

but ignores the return value.

readline.redisplay()

Change what’s displayed on the screen to reflect the current contents of the line buffer. This calls

rl_redisplay() in the underlying library.



6.7.3 History file

The following functions operate on a history file:

readline.read_history_file( filename [ ])

Load a readline history file, and append it to the history list. The default filename is ~/.history. This calls

read_history() in the underlying library.

readline.write_history_file( filename [ ])

Save the history list to a readline history file, overwriting any existing file. The default filename is ~/.history.

This calls write_history() in the underlying library.

readline.append_history_file(nelements[, filename ])

Append the last nelements items of history to a file. The default filename is ~/.history. The file must

already exist. This calls append_history() in the underlying library. This function only exists if Python

was compiled for a version of the library that supports it.

Added in version 3.5.

The Python Library Reference, Release 3.13.2



readline.get_history_length()

readline.set_history_length(length)

Set or return the desired number of lines to save in the history file. The write_history_file() function

uses this value to truncate the history file, by calling history_truncate_file() in the underlying library.

Negative values imply unlimited history file size.



6.7.4 History list

The following functions operate on a global history list:

readline.clear_history()

Clear the current history. This calls clear_history() in the underlying library. The Python function only

exists if Python was compiled for a version of the library that supports it.

readline.get_current_history_length()

Return the number of items currently in the history. (This is different from get_history_length(), which

returns the maximum number of lines that will be written to a history file.)

readline.get_history_item(index)

Return the current contents of history item at index. The item index is one-based. This calls history_get()

in the underlying library.

readline.remove_history_item(pos)

Remove history item specified by its position from the history. The position is zero-based. This calls

remove_history() in the underlying library.

readline.replace_history_item(pos, line)

Replace history item specified by its position with line. The position is zero-based. This calls

replace_history_entry() in the underlying library.

readline.add_history(line)

Append line to the history buffer, as if it was the last line typed. This calls add_history() in the underlying

library.

readline.set_auto_history(enabled)

Enable or disable automatic calls to add_history() when reading input via readline. The enabled argument

should be a Boolean value that when true, enables auto history, and that when false, disables auto history.

Added in version 3.6.

CPython implementation detail: Auto history is enabled by default, and changes to this do not persist across

multiple sessions.



6.7.5 Startup hooks

readline.set_startup_hook( function [ ])

Set or remove the function invoked by the rl_startup_hook callback of the underlying library. If function

is specified, it will be used as the new hook function; if omitted or None, any function already installed is

removed. The hook is called with no arguments just before readline prints the first prompt.

readline.set_pre_input_hook( function [ ])

Set or remove the function invoked by the rl_pre_input_hook callback of the underlying library. If function

is specified, it will be used as the new hook function; if omitted or None, any function already installed is

removed. The hook is called with no arguments after the first prompt has been printed and just before readline

starts reading input characters. This function only exists if Python was compiled for a version of the library

that supports it.



The Python Library Reference, Release 3.13.2



6.7.6 Completion

The following functions relate to implementing a custom word completion function. This is typically operated by the Tab key, and can suggest and automatically complete a word being typed. By default, Readline is set up to be used by

rlcompleter to complete Python identifiers for the interactive interpreter. If the readline module is to be used with a custom completer, a different set of word delimiters should be set.

readline.set_completer( function [ ])

Set or remove the completer function. If function is specified, it will be used as the new completer function;

if omitted or None, any completer function already installed is removed. The completer function is called as

function(text, state) , for state in 0, 1, 2, …, until it returns a non-string value. It should return the

next possible completion starting with text.

The installed completer function is invoked by the entry_func callback passed to

rl_completion_matches() in the underlying library. The text string comes from the first parame-

ter to the rl_attempted_completion_function callback of the underlying library.

readline.get_completer()

Get the completer function, or None if no completer function has been set.

readline.get_completion_type()

Get the type of completion being attempted. This returns the rl_completion_type variable in the under-

lying library as an integer.

readline.get_begidx()

readline.get_endidx()

Get the beginning or ending index of the completion scope. These indexes are the start and end arguments

passed to the rl_attempted_completion_function callback of the underlying library. The values may

be different in the same input editing scenario based on the underlying C readline implementation. Ex: libedit

is known to behave differently than libreadline.

readline.set_completer_delims(string)

readline.get_completer_delims()

Set or get the word delimiters for completion. These determine the start of the word to be considered for

completion (the completion scope). These functions access the rl_completer_word_break_characters

variable in the underlying library.

readline.set_completion_display_matches_hook( function [ ])

Set or remove the completion display function. If function is specified, it will be used as the new completion

display function; if omitted or None, any completion display function already installed is removed. This sets or

clears the rl_completion_display_matches_hook callback in the underlying library. The completion

display function is called as function(substitution, [matches], longest_match_length) once

each time matches need to be displayed.



6.7.7 Example

The following example demonstrates how to use the readline module’s history reading and writing functions to automatically load and save a history file named .python_history from the user’s home directory. The code below would normally be executed automatically during interactive sessions from the user’s PYTHONSTARTUP file.

import atexit

import os

import readline

histfile = os.path.join(os.path.expanduser("~"), ".python_history") try:

readline.read_history_file(histfile)

# default history len is -1 (infinite), which may grow unruly

readline.set_history_length(1000)

except FileNotFoundError:

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

pass

atexit.register(readline.write_history_file, histfile)



This code is actually automatically run when Python is run in interactive mode (see Readline configuration).

The following example achieves the same goal but supports concurrent interactive sessions, by only appending the new history.

import atexit

import os

import readline

histfile = os.path.join(os.path.expanduser("~"), ".python_history")

try:

readline.read_history_file(histfile)

h_len = readline.get_current_history_length()

except FileNotFoundError:

open(histfile, 'wb').close()

h_len = 0

def save(prev_h_len, histfile):

new_h_len = readline.get_current_history_length()

readline.set_history_length(1000)

readline.append_history_file(new_h_len-prev_h_len, histfile)

atexit.register(save, h_len, histfile)



The following example extends the code.InteractiveConsole class to support history save/restore.

import atexit

import code

import os

import readline

class HistoryConsole(code.InteractiveConsole):

def __init__(self, locals=None, filename="",

histfile=os.path.expanduser("~/.console-history")):

code.InteractiveConsole.__init__(self, locals, filename) self.init_history(histfile)

def init_history(self, histfile):

readline.parse_and_bind("tab: complete")

if hasattr(readline, "read_history_file"):

try:

readline.read_history_file(histfile)

except FileNotFoundError:

pass

atexit.register(self.save_history, histfile)

def save_history(self, histfile):

readline.set_history_length(1000)

readline.write_history_file(histfile)



The Python Library Reference, Release 3.13.2



6.8 rlcompleter — Completion function for GNU readline

Source code: Lib/rlcompleter.py



The rlcompleter module defines a completion function suitable to be passed to set_completer() in the

readline module.

When this module is imported on a Unix platform with the readline module available, an instance of the

Completer class is automatically created and its complete() method is set as the readline completer. The method provides completion of valid Python identifiers and keywords.

Example:

>>> import rlcompleter

>>> import readline

>>> readline.parse_and_bind("tab: complete")

>>> readline. <TAB PRESSED>

readline.__doc__ readline.get_line_buffer( readline.read_init_file( readline.__file__ readline.insert_text( readline.set_completer( readline.__name__ readline.parse_and_bind(

>>> readline.



The rlcompleter module is designed for use with Python’s interactive mode. Unless Python is run with the-S

option, the module is automatically imported and configured (see Readline configuration).

On platforms without readline, the Completer class defined by this module can still be used for custom purposes.



class rlcompleter.Completer

Completer objects have the following method:

complete(text, state)

Return the next possible completion for text.

When called by the readline module, this method is called successively with state == 0, 1, 2, ... until the method returns None.

If called for text that doesn’t include a period character ('.'), it will complete from names currently

defined in __main__, builtins and keywords (as defined by the keyword module).

If called for a dotted name, it will try to evaluate anything without obvious side-effects (functions will not be evaluated, but it can generate calls to __getattr__()) up to the last part, and find matches for

the rest via the dir() function. Any exception raised during the evaluation of the expression is caught,

silenced and None is returned.



The Python Library Reference, Release 3.13.2





CHAPTER




SEVEN



BINARY DATA SERVICES



The modules described in this chapter provide some basic services operations for manipulation of binary data. Other operations on binary data, specifically in relation to file formats and network protocols, are described in the relevant sections.

Some libraries described under Text Processing Services also work with either ASCII-compatible binary formats (for

example, re) or all binary data (for example, difflib).

In addition, see the documentation for Python’s built-in binary data types in Binary Sequence Types — bytes, bytearray,

memoryview.



7.1 struct — Interpret bytes as packed binary data

Source code: Lib/struct.py



This module converts between Python values and C structs represented as Python bytes objects. Compact format

strings describe the intended conversions to/from Python values. The module’s functions and objects can be used for two largely distinct applications, data exchange with external sources (files or network connections), or data transfer between the Python application and the C layer.



® Note

When no prefix character is given, native mode is the default. It packs or unpacks data based on the platform

and compiler on which the Python interpreter was built. The result of packing a given C struct includes pad

bytes which maintain proper alignment for the C types involved; similarly, alignment is taken into account when

unpacking. In contrast, when communicating data between external sources, the programmer is responsible for

defining byte ordering and padding between elements. See Byte Order, Size, and Alignment for details.



Several struct functions (and methods of Struct) take a buffer argument. This refers to objects that implement the bufferobjects and provide either a readable or read-writable buffer. The most common types used for that purpose are

bytes and bytearray, but many other types that can be viewed as an array of bytes implement the buffer protocol,

so that they can be read/filled without additional copying from a bytes object.



7.1.1 Functions and Exceptions

The module defines the following exception and functions:

exception struct.error

Exception raised on various occasions; argument is a string describing what is wrong.

struct.pack(format, v1, v2, ...)

Return a bytes object containing the values v1, v2, … packed according to the format string format. The

arguments must match the values required by the format exactly.

The Python Library Reference, Release 3.13.2



struct.pack_into(format, buffer, offset, v1, v2, ...)

Pack the values v1, v2, … according to the format string format and write the packed bytes into the writable

buffer buffer starting at position offset. Note that offset is a required argument.

struct.unpack(format, buffer)

Unpack from the buffer buffer (presumably packed by pack(format, ...)) according to the format string

format. The result is a tuple even if it contains exactly one item. The buffer’s size in bytes must match the size

required by the format, as reflected by calcsize().

struct.unpack_from(format, / , buffer, offset=0)

Unpack from buffer starting at position offset, according to the format string format. The result is a tuple even

if it contains exactly one item. The buffer’s size in bytes, starting at position offset, must be at least the size

required by the format, as reflected by calcsize().

struct.iter_unpack(format, buffer)

Iteratively unpack from the buffer buffer according to the format string format. This function returns an iterator

which will read equally sized chunks from the buffer until all its contents have been consumed. The buffer’s

size in bytes must be a multiple of the size required by the format, as reflected by calcsize().

Each iteration yields a tuple as specified by the format string.

Added in version 3.4.

struct.calcsize(format)

Return the size of the struct (and hence of the bytes object produced by pack(format, ...)) corresponding

to the format string format.



7.1.2 Format Strings

Format strings describe the data layout when packing and unpacking data. They are built up from format characters,

which specify the type of data being packed/unpacked. In addition, special characters control the byte order, size and

alignment. Each format string consists of an optional prefix character which describes the overall properties of the data and one or more format characters which describe the actual data values and padding.



Byte Order, Size, and Alignment

By default, C types are represented in the machine’s native format and byte order, and properly aligned by skipping pad bytes if necessary (according to the rules used by the C compiler). This behavior is chosen so that the bytes of a packed struct correspond exactly to the memory layout of the corresponding C struct. Whether to use native byte ordering and padding or standard formats depends on the application.

Alternatively, the first character of the format string can be used to indicate the byte order, size and alignment of the packed data, according to the following table:



Character Byte order Size Alignment

@ native native native

= native standard none

< little-endian standard none

> big-endian standard none

! network (= big-endian) standard none



If the first character is not one of these, '@' is assumed.



® Note

The number 1023 (0x3ff in hexadecimal) has the following byte representations:

• 03 ff in big-endian (>)

The Python Library Reference, Release 3.13.2



• ff 03 in little-endian (<)

Python example:

>>> import struct

>>> struct.pack('>h', 1023)

b'\x03\xff'

>>> struct.pack(', 1023)

b'\xff\x03'



Native byte order is big-endian or little-endian, depending on the host system. For example, Intel x86, AMD64 (x86-

64), and Apple M1 are little-endian; IBM z and many legacy architectures are big-endian. Use sys.byteorder to check the endianness of your system.

Native size and alignment are determined using the C compiler’s sizeof expression. This is always combined with native byte order.

Standard size depends only on the format character; see the table in the Format Characters section.

Note the difference between '@' and '=': both use native byte order, but the size and alignment of the latter is standardized.

The form '!' represents the network byte order which is always big-endian as defined in IETF RFC 1700.

There is no way to indicate non-native byte order (force byte-swapping); use the appropriate choice of '<' or '>'.

Notes:

(1) Padding is only automatically added between successive structure members. No padding is added at the be-

ginning or the end of the encoded struct.

(2) No padding is added when using non-native size and alignment, e.g. with ‘<’, ‘>’, ‘=’, and ‘!’.

(3) To align the end of a structure to the alignment requirement of a particular type, end the format with the code

for that type with a repeat count of zero. See Examples.



Format Characters

Format characters have the following meaning; the conversion between C and Python values should be obvious given their types. The ‘Standard size’ column refers to the size of the packed value in bytes when using standard size; that is, when the format string starts with one of '<', '>', '!' or '='. When using native size, the size of the packed value is platform-dependent.



The Python Library Reference, Release 3.13.2



Format C Type Python type Standard size Notes

x pad byte no value (7)

c char bytes of length 1 1

b signed char integer 1 (1), (2)

B unsigned char integer 1 (2)

? _Bool bool 1 (1)

h short integer 2 (2)

H unsigned short integer 2 (2)

i int integer 4 (2)

I unsigned int integer 4 (2)

l long integer 4 (2)

L unsigned long integer 4 (2)

q long long integer 8 (2)

Q unsigned long long integer 8 (2)

n ssize_t integer (3)

N size_t integer (3)

e (6) float 2 (4)

f float float 4 (4)

d double float 8 (4)

s char[] bytes (9)

p char[] bytes (8)

P void* integer (5)



Changed in version 3.3: Added support for the 'n' and 'N' formats.

Changed in version 3.6: Added support for the 'e' format.

Notes:

(1) The '?' conversion code corresponds to the _Bool type defined by C standards since C99. In standard mode,

it is represented by one byte.

(2) When attempting to pack a non-integer using any of the integer conversion codes, if the non-integer has a

__index__() method then that method is called to convert the argument to an integer before packing.

Changed in version 3.2: Added use of the __index__() method for non-integers.

(3) The 'n' and 'N' conversion codes are only available for the native size (selected as the default or with the

'@' byte order character). For the standard size, you can use whichever of the other integer formats fits your

application.

(4) For the 'f', 'd' and 'e' conversion codes, the packed representation uses the IEEE 754 binary32, binary64

or binary16 format (for 'f', 'd' or 'e' respectively), regardless of the floating-point format used by the

platform.

(5) The 'P' format character is only available for the native byte ordering (selected as the default or with the '@'

byte order character). The byte order character '=' chooses to use little- or big-endian ordering based on the

host system. The struct module does not interpret this as native ordering, so the 'P' format is not available.

(6) The IEEE 754 binary16 “half precision” type was introduced in the 2008 revision of the IEEE 754 standard. It

has a sign bit, a 5-bit exponent and 11-bit precision (with 10 bits explicitly stored), and can represent numbers

between approximately 6.1e-05 and 6.5e+04 at full precision. This type is not widely supported by C

compilers: on a typical machine, an unsigned short can be used for storage, but not for math operations. See

the Wikipedia page on the half-precision floating-point format for more information.

(7) When packing, 'x' inserts one NUL byte.

(8) The 'p' format character encodes a “Pascal string”, meaning a short variable-length string stored in a fixed

number of bytes, given by the count. The first byte stored is the length of the string, or 255, whichever is

smaller. The bytes of the string follow. If the string passed in to pack() is too long (longer than the count

minus 1), only the leading count-1 bytes of the string are stored. If the string is shorter than count-1, it

The Python Library Reference, Release 3.13.2



is padded with null bytes so that exactly count bytes in all are used. Note that for unpack(), the 'p' format

character consumes count bytes, but that the string returned can never contain more than 255 bytes.

(9) For the 's' format character, the count is interpreted as the length of the bytes, not a repeat count like for the

other format characters; for example, '10s' means a single 10-byte string mapping to or from a single Python

byte string, while '10c' means 10 separate one byte character elements (e.g., cccccccccc) mapping to or

from ten different Python byte objects. (See Examples for a concrete demonstration of the difference.) If a

count is not given, it defaults to 1. For packing, the string is truncated or padded with null bytes as appropriate

to make it fit. For unpacking, the resulting bytes object always has exactly the specified number of bytes. As

a special case, '0s' means a single, empty string (while '0c' means 0 characters).

A format character may be preceded by an integral repeat count. For example, the format string '4h' means exactly the same as 'hhhh'.

Whitespace characters between formats are ignored; a count and its format must not contain whitespace though.

When packing a value x using one of the integer formats ('b', 'B', 'h', 'H', 'i', 'I', 'l', 'L', 'q', 'Q'), if

x is outside the valid range for that format then struct.error is raised.

Changed in version 3.1: Previously, some of the integer formats wrapped out-of-range values and raised

DeprecationWarning instead of struct.error.

For the '?' format character, the return value is either True or False. When packing, the truth value of the argument object is used. Either 0 or 1 in the native or standard bool representation will be packed, and any non-zero value will be True when unpacking.



Examples



® Note

Native byte order examples (designated by the '@' format prefix or lack of any prefix character) may not match

what the reader’s machine produces as that depends on the platform and compiler.



Pack and unpack integers of three different sizes, using big endian ordering:

>>> from struct import *

>>> pack(">bhl", 1, 2, 3)

b'\x01\x00\x02\x00\x00\x00\x03'

>>> unpack('>bhl', b'\x01\x00\x02\x00\x00\x00\x03')

(1, 2, 3)

>>> calcsize('>bhl')

7



Attempt to pack an integer which is too large for the defined field:

>>> pack(">h", 99999)

Traceback (most recent call last):

File "", line 1, in

struct.error: 'h' format requires -32768 <= number <= 32767



Demonstrate the difference between 's' and 'c' format characters:

>>> pack("@ccc", b'1', b'2', b'3')

b'123'

>>> pack("@3s", b'123')

b'123'



Unpacked fields can be named by assigning them to variables or by wrapping the result in a named tuple:



The Python Library Reference, Release 3.13.2



>>> record = b'raymond \x32\x12\x08\x01\x08'

>>> name, serialnum, school, gradelevel = unpack('<10sHHb', record)

>>> from collections import namedtuple

>>> Student = namedtuple('Student', 'name serialnum school gradelevel') >>> Student._make(unpack('<10sHHb', record))

Student(name=b'raymond ', serialnum=4658, school=264, gradelevel=8)



The ordering of format characters may have an impact on size in native mode since padding is implicit. In standard mode, the user is responsible for inserting any desired padding. Note in the first pack call below that three NUL bytes were added after the packed '#' to align the following integer on a four-byte boundary. In this example, the output was produced on a little endian machine:

>>> pack('@ci', b'#', 0x12131415)

b'#\x00\x00\x00\x15\x14\x13\x12'

>>> pack('@ic', 0x12131415, b'#')

b'\x15\x14\x13\x12#'

>>> calcsize('@ci')

8

>>> calcsize('@ic')

5



The following format 'llh0l' results in two pad bytes being added at the end, assuming the platform’s longs are aligned on 4-byte boundaries:

>>> pack('@llh0l', 1, 2, 3)

b'\x00\x00\x00\x01\x00\x00\x00\x02\x00\x03\x00\x00'



µ See also

Module array

Packed binary storage of homogeneous data.

Module json

JSON encoder and decoder.

Module pickle

Python object serialization.



7.1.3 Applications

Two main applications for the struct module exist, data interchange between Python and C code within an ap-

plication or another application compiled using the same compiler (native formats), and data interchange between

applications using agreed upon data layout (standard formats). Generally speaking, the format strings constructed for these two domains are distinct.



Native Formats

When constructing format strings which mimic native layouts, the compiler and machine architecture determine byte ordering and padding. In such cases, the @ format character should be used to specify native byte ordering and data sizes. Internal pad bytes are normally inserted automatically. It is possible that a zero-repeat format code will be needed at the end of a format string to round up to the correct byte boundary for proper alignment of consecutive chunks of data.

Consider these two simple examples (on a 64-bit, little-endian machine):

>>> calcsize('@lhl')

24

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> calcsize('@llh')

18



Data is not padded to an 8-byte boundary at the end of the second format string without the use of extra padding. A zero-repeat format code solves that problem:

>>> calcsize('@llh0l')

24



The 'x' format code can be used to specify the repeat, but for native formats it is better to use a zero-repeat format like '0l'.

By default, native byte ordering and alignment is used, but it is better to be explicit and use the '@' prefix character.



Standard Formats

When exchanging data beyond your process such as networking or storage, be precise. Specify the exact byte order, size, and alignment. Do not assume they match the native order of a particular machine. For example, network byte order is big-endian, while many popular CPUs are little-endian. By defining this explicitly, the user need not care about the specifics of the platform their code is running on. The first character should typically be < or > (or !). Padding is the responsibility of the programmer. The zero-repeat format character won’t work. Instead, the user must explicitly add 'x' pad bytes where needed. Revisiting the examples from the previous section, we have:

>>> calcsize(')

24

>>> pack(', 1, 2, 3) == pack('@lhl', 1, 2, 3)

True

>>> calcsize('@llh')

18

>>> pack('@llh', 1, 2, 3) == pack(', 1, 2, 3)

True

>>> calcsize(')

24

>>> calcsize('@llh0l')

24

>>> pack('@llh0l', 1, 2, 3) == pack(', 1, 2, 3)

True



The above results (executed on a 64-bit machine) aren’t guaranteed to match when executed on different machines. For example, the examples below were executed on a 32-bit machine:

>>> calcsize(')

24

>>> calcsize('@llh0l')

12

>>> pack('@llh0l', 1, 2, 3) == pack(', 1, 2, 3)

False



7.1.4 Classes

The struct module also defines the following type:

class struct.Struct(format)

Return a new Struct object which writes and reads binary data according to the format string format. Creating

a Struct object once and calling its methods is more efficient than calling module-level functions with the

same format since the format string is only compiled once.

The Python Library Reference, Release 3.13.2



® Note

The compiled versions of the most recent format strings passed to the module-level functions are cached,

so programs that use only a few format strings needn’t worry about reusing a single Struct instance.



Compiled Struct objects support the following methods and attributes:

pack(v1, v2, ...)

Identical to the pack() function, using the compiled format. (len(result) will equal size.)

pack_into(buffer, offset, v1, v2, ...)

Identical to the pack_into() function, using the compiled format.

unpack(buffer)

Identical to the unpack() function, using the compiled format. The buffer’s size in bytes must equal

size .

unpack_from(buffer, offset=0)

Identical to the unpack_from() function, using the compiled format. The buffer’s size in bytes, starting

at position offset, must be at least size.

iter_unpack(buffer)

Identical to the iter_unpack() function, using the compiled format. The buffer’s size in bytes must be

a multiple of size.

Added in version 3.4.

format

The format string used to construct this Struct object.

Changed in version 3.7: The format string type is now str instead of bytes.

size

The calculated size of the struct (and hence of the bytes object produced by the pack() method) corre-

sponding to format.

Changed in version 3.13: The repr() of structs has changed. It is now:

>>> Struct('i')

Struct('i')



7.2 codecs — Codec registry and base classes

Source code: Lib/codecs.py



This module defines base classes for standard Python codecs (encoders and decoders) and provides access to the internal Python codec registry, which manages the codec and error handling lookup process. Most standard codecs

are text encodings, which encode text to bytes (and decode bytes to text), but there are also codecs provided that encode text to text, and bytes to bytes. Custom codecs may encode and decode between arbitrary types, but some

module features are restricted to be used specifically with text encodings or with codecs that encode to bytes.

The module defines the following functions for encoding and decoding with any codec:

codecs.encode(obj, encoding=’utf-8’, errors=’strict’)

Encodes obj using the codec registered for encoding.

Errors may be given to set the desired error handling scheme. The default error handler is 'strict' meaning

that encoding errors raise ValueError (or a more codec specific subclass, such as UnicodeEncodeError).

Refer to Codec Base Classes for more information on codec error handling.

The Python Library Reference, Release 3.13.2



codecs.decode(obj, encoding=’utf-8’, errors=’strict’)

Decodes obj using the codec registered for encoding.

Errors may be given to set the desired error handling scheme. The default error handler is 'strict' meaning

that decoding errors raise ValueError (or a more codec specific subclass, such as UnicodeDecodeError).

Refer to Codec Base Classes for more information on codec error handling.

The full details for each codec can also be looked up directly:

codecs.lookup(encoding)

Looks up the codec info in the Python codec registry and returns a CodecInfo object as defined below.

Encodings are first looked up in the registry’s cache. If not found, the list of registered search functions is

scanned. If no CodecInfo object is found, a LookupError is raised. Otherwise, the CodecInfo object is

stored in the cache and returned to the caller.

class codecs.CodecInfo(encode, decode, streamreader=None, streamwriter=None, incrementalencoder=None,

incrementaldecoder=None, name=None)

Codec details when looking up the codec registry. The constructor arguments are stored in attributes of the

same name:

name

The name of the encoding.

encode

decode

The stateless encoding and decoding functions. These must be functions or methods which have the

same interface as the encode() and decode() methods of Codec instances (see Codec Interface). The functions or methods are expected to work in a stateless mode.

incrementalencoder

incrementaldecoder

Incremental encoder and decoder classes or factory functions. These have to provide the interface de-

fined by the base classes IncrementalEncoder and IncrementalDecoder, respectively. Incremen-tal codecs can maintain state.

streamwriter

streamreader

Stream writer and reader classes or factory functions. These have to provide the interface defined by the

base classes StreamWriter and StreamReader, respectively. Stream codecs can maintain state.

To simplify access to the various codec components, the module provides these additional functions which use

lookup() for the codec lookup:

codecs.getencoder(encoding)

Look up the codec for the given encoding and return its encoder function.

Raises a LookupError in case the encoding cannot be found.

codecs.getdecoder(encoding)

Look up the codec for the given encoding and return its decoder function.

Raises a LookupError in case the encoding cannot be found.

codecs.getincrementalencoder(encoding)

Look up the codec for the given encoding and return its incremental encoder class or factory function.

Raises a LookupError in case the encoding cannot be found or the codec doesn’t support an incremental

encoder.



The Python Library Reference, Release 3.13.2



codecs.getincrementaldecoder(encoding)

Look up the codec for the given encoding and return its incremental decoder class or factory function.

Raises a LookupError in case the encoding cannot be found or the codec doesn’t support an incremental

decoder.

codecs.getreader(encoding)

Look up the codec for the given encoding and return its StreamReader class or factory function.

Raises a LookupError in case the encoding cannot be found.

codecs.getwriter(encoding)

Look up the codec for the given encoding and return its StreamWriter class or factory function.

Raises a LookupError in case the encoding cannot be found.

Custom codecs are made available by registering a suitable codec search function:

codecs.register(search_function)

Register a codec search function. Search functions are expected to take one argument, being the encoding

name in all lower case letters with hyphens and spaces converted to underscores, and return a CodecInfo

object. In case a search function cannot find a given encoding, it should return None.

Changed in version 3.9: Hyphens and spaces are converted to underscore.

codecs.unregister(search_function)

Unregister a codec search function and clear the registry’s cache. If the search function is not registered, do

nothing.

Added in version 3.10.

While the builtin open() and the associated io module are the recommended approach for working with encoded text files, this module provides additional utility functions and classes that allow the use of a wider range of codecs when working with binary files:

codecs.open(filename, mode=’r’ , encoding=None, errors=’strict’, buffering=-1)

Open an encoded file using the given mode and return an instance of StreamReaderWriter, providing

transparent encoding/decoding. The default file mode is 'r', meaning to open the file in read mode.



® Note

If encoding is not None, then the underlying encoded files are always opened in binary mode. No automatic conversion of '\n' is done on reading and writing. The mode argument may be any binary mode acceptable

to the built-in open() function; the 'b' is automatically added.



encoding specifies the encoding which is to be used for the file. Any encoding that encodes to and decodes

from bytes is allowed, and the data types supported by the file methods depend on the codec used.

errors may be given to define the error handling. It defaults to 'strict' which causes a ValueError to be

raised in case an encoding error occurs.

buffering has the same meaning as for the built-in open() function. It defaults to -1 which means that the

default buffer size will be used.

Changed in version 3.11: The 'U' mode has been removed.

codecs.EncodedFile(file, data_encoding, file_encoding=None, errors=’strict’)

Return a StreamRecoder instance, a wrapped version of file which provides transparent transcoding. The

original file is closed when the wrapped version is closed.

Data written to the wrapped file is decoded according to the given data_encoding and then written to the original

file as bytes using file_encoding. Bytes read from the original file are decoded according to file_encoding, and

the result is encoded using data_encoding.

If file_encoding is not given, it defaults to data_encoding.

The Python Library Reference, Release 3.13.2



errors may be given to define the error handling. It defaults to 'strict', which causes ValueError to be

raised in case an encoding error occurs.

codecs.iterencode(iterator, encoding, errors=’strict’, **kwargs)

Uses an incremental encoder to iteratively encode the input provided by iterator. This function is a generator.

The errors argument (as well as any other keyword argument) is passed through to the incremental encoder.

This function requires that the codec accept text str objects to encode. Therefore it does not support bytes-

to-bytes encoders such as base64_codec.

codecs.iterdecode(iterator, encoding, errors=’strict’, **kwargs)

Uses an incremental decoder to iteratively decode the input provided by iterator. This function is a generator.

The errors argument (as well as any other keyword argument) is passed through to the incremental decoder.

This function requires that the codec accept bytes objects to decode. Therefore it does not support text-to-text

encoders such as rot_13, although rot_13 may be used equivalently with iterencode().

The module also provides the following constants which are useful for reading and writing to platform dependent files:

codecs.BOM

codecs.BOM_BE

codecs.BOM_LE

codecs.BOM_UTF8

codecs.BOM_UTF16

codecs.BOM_UTF16_BE

codecs.BOM_UTF16_LE

codecs.BOM_UTF32

codecs.BOM_UTF32_BE

codecs.BOM_UTF32_LE

These constants define various byte sequences, being Unicode byte order marks (BOMs) for several encodings.

They are used in UTF-16 and UTF-32 data streams to indicate the byte order used, and in UTF-8 as a Unicode

signature. BOM_UTF16 is either BOM_UTF16_BE or BOM_UTF16_LE depending on the platform’s native byte

order, BOM is an alias for BOM_UTF16, BOM_LE for BOM_UTF16_LE and BOM_BE for BOM_UTF16_BE. The

others represent the BOM in UTF-8 and UTF-32 encodings.



7.2.1 Codec Base Classes

The codecs module defines a set of base classes which define the interfaces for working with codec objects, and can also be used as the basis for custom codec implementations.

Each codec has to define four interfaces to make it usable as codec in Python: stateless encoder, stateless decoder, stream reader and stream writer. The stream reader and writers typically reuse the stateless encoder/decoder to implement the file protocols. Codec authors also need to define how the codec will handle encoding and decoding errors.



Error Handlers

To simplify and standardize error handling, codecs may implement different error handling schemes by accepting the errors string argument:

>>> 'German ß, ♬'.encode(encoding='ascii', errors='backslashreplace') b'German \\xdf, \\u266c'

>>> 'German ß, ♬'.encode(encoding='ascii', errors='xmlcharrefreplace') b'German ß, ♬'



The following error handlers can be used with all Python Standard Encodings codecs:

The Python Library Reference, Release 3.13.2



Value Meaning

'strict' Raise UnicodeError (or a subclass), this is the default. Implemented in

strict_errors().

'ignore' Ignore the malformed data and continue without further notice. Implemented in

ignore_errors().

'replace' Replace with a replacement marker. On encoding, use ? (ASCII character). On

decoding, use � (U+FFFD, the official REPLACEMENT CHARACTER).

Implemented in replace_errors().

'backslashreplace' Replace with backslashed escape sequences. On encoding, use hexadecimal form of

Unicode code point with formats \xhh \uxxxx \Uxxxxxxxx. On decoding, use hexadecimal form of byte value with format \xhh. Implemented in

backslashreplace_errors() .

'surrogateescape' On decoding, replace byte with individual surrogate code ranging from U+DC80 to

U+DCFF. This code will then be turned back into the same byte when the

'surrogateescape' error handler is used when encoding the data. (See PEP

383 for more.)



The following error handlers are only applicable to encoding (within text encodings):



Value Meaning

'xmlcharrefreplace' Replace with XML/HTML numeric character reference, which is a decimal form of Unicode

code point with format &#num;. Implemented in xmlcharrefreplace_errors().

'namereplace' Replace with \N{...} escape sequences, what appears in the braces is the Name property from

Unicode Character Database. Implemented in namereplace_errors().



In addition, the following error handler is specific to the given codecs:



Value Codecs Meaning

'surrogatepass' utf-8, utf-16, utf-32, utf- Allow encoding and decoding surrogate code point (U+D800-U+DFFF) as

16-be, utf-16-le, utf-32- normal code point. Otherwise these codecs treat the presence of surrogate

be, utf-32-le code point in str as an error.



Added in version 3.1: The 'surrogateescape' and 'surrogatepass' error handlers.

Changed in version 3.4: The 'surrogatepass' error handler now works with utf-16* and utf-32* codecs.

Added in version 3.5: The 'namereplace' error handler.

Changed in version 3.5: The 'backslashreplace' error handler now works with decoding and translating.

The set of allowed values can be extended by registering a new named error handler:

codecs.register_error( name, error_handler)

Register the error handling function error_handler under the name name. The error_handler argument will be

called during encoding and decoding in case of an error, when name is specified as the errors parameter.

For encoding, error_handler will be called with a UnicodeEncodeError instance, which contains informa-

tion about the location of the error. The error handler must either raise this or a different exception, or return

a tuple with a replacement for the unencodable part of the input and a position where encoding should con-

tinue. The replacement may be either str or bytes. If the replacement is bytes, the encoder will simply copy

them into the output buffer. If the replacement is a string, the encoder will encode the replacement. Encoding

continues on original input at the specified position. Negative position values will be treated as being relative

to the end of the input string. If the resulting position is out of bound an IndexError will be raised.

Decoding and translating works similarly, except UnicodeDecodeError or UnicodeTranslateError will

be passed to the handler and that the replacement from the error handler will be put into the output directly.

The Python Library Reference, Release 3.13.2



Previously registered error handlers (including the standard error handlers) can be looked up by name:

codecs.lookup_error(name)

Return the error handler previously registered under the name name.

Raises a LookupError in case the handler cannot be found.

The following standard error handlers are also made available as module level functions:

codecs.strict_errors(exception)

Implements the 'strict' error handling.

Each encoding or decoding error raises a UnicodeError.

codecs.ignore_errors(exception)

Implements the 'ignore' error handling.

Malformed data is ignored; encoding or decoding is continued without further notice.

codecs.replace_errors( exception)

Implements the 'replace' error handling.

Substitutes ? (ASCII character) for encoding errors or � (U+FFFD, the official REPLACEMENT CHAR-

ACTER) for decoding errors.

codecs.backslashreplace_errors(exception)

Implements the 'backslashreplace' error handling.

Malformed data is replaced by a backslashed escape sequence. On encoding, use the hexadecimal form of

Unicode code point with formats \xhh \uxxxx \Uxxxxxxxx. On decoding, use the hexadecimal form of

byte value with format \xhh.

Changed in version 3.5: Works with decoding and translating.

codecs.xmlcharrefreplace_errors(exception)

Implements the 'xmlcharrefreplace' error handling (for encoding within text encoding only).

The unencodable character is replaced by an appropriate XML/HTML numeric character reference, which is

a decimal form of Unicode code point with format &#num; .

codecs.namereplace_errors(exception)

Implements the 'namereplace' error handling (for encoding within text encoding only).

The unencodable character is replaced by a \N{...} escape sequence. The set of characters that appear in

the braces is the Name property from Unicode Character Database. For example, the German lowercase letter

'ß' will be converted to byte sequence \N{LATIN SMALL LETTER SHARP S} .

Added in version 3.5.



Stateless Encoding and Decoding

The base Codec class defines these methods which also define the function interfaces of the stateless encoder and decoder:

class codecs.Codec

encode(input, errors=’strict’)

Encodes the object input and returns a tuple (output object, length consumed). For instance, text encoding converts a string object to a bytes object using a particular character set encoding (e.g., cp1252 or iso-8859-1).

The errors argument defines the error handling to apply. It defaults to 'strict' handling.

The method may not store state in the Codec instance. Use StreamWriter for codecs which have to keep state in order to make encoding efficient.

The encoder must be able to handle zero length input and return an empty object of the output object type in this situation.

The Python Library Reference, Release 3.13.2



decode(input, errors=’strict’)

Decodes the object input and returns a tuple (output object, length consumed). For instance, for a text

encoding, decoding converts a bytes object encoded using a particular character set encoding to a string object.

For text encodings and bytes-to-bytes codecs, input must be a bytes object or one which provides the read-only buffer interface – for example, buffer objects and memory mapped files.

The errors argument defines the error handling to apply. It defaults to 'strict' handling.

The method may not store state in the Codec instance. Use StreamReader for codecs which have to keep state in order to make decoding efficient.

The decoder must be able to handle zero length input and return an empty object of the output object type in this situation.



Incremental Encoding and Decoding

The IncrementalEncoder and IncrementalDecoder classes provide the basic interface for incremental en-coding and decoding. Encoding/decoding the input isn’t done with one call to the stateless encoder/decoder function,

but with multiple calls to the encode()/decode() method of the incremental encoder/decoder. The incremental encoder/decoder keeps track of the encoding/decoding process during method calls.

The joined output of calls to the encode()/decode() method is the same as if all the single inputs were joined into one, and this input was encoded/decoded with the stateless encoder/decoder.



IncrementalEncoder Objects

The IncrementalEncoder class is used for encoding an input in multiple steps. It defines the following methods which every incremental encoder must define in order to be compatible with the Python codec registry.

class codecs.IncrementalEncoder(errors=’strict’)

Constructor for an IncrementalEncoder instance.

All incremental encoders must provide this constructor interface. They are free to add additional keyword

arguments, but only the ones defined here are used by the Python codec registry.

The IncrementalEncoder may implement different error handling schemes by providing the errors keyword

argument. See Error Handlers for possible values.

The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it

possible to switch between different error handling strategies during the lifetime of the IncrementalEncoder

object.

encode(object, final=False)

Encodes object (taking the current state of the encoder into account) and returns the resulting encoded

object. If this is the last call to encode() final must be true (the default is false).

reset()

Reset the encoder to the initial state. The output is discarded: call .encode(object, final=True), passing an empty byte or text string if necessary, to reset the encoder and to get the output.

getstate()

Return the current state of the encoder which must be an integer. The implementation should make sure that 0 is the most common state. (States that are more complicated than integers can be converted into an integer by marshaling/pickling the state and encoding the bytes of the resulting string into an integer.)

setstate(state)

Set the state of the encoder to state. state must be an encoder state returned by getstate().



The Python Library Reference, Release 3.13.2



IncrementalDecoder Objects

The IncrementalDecoder class is used for decoding an input in multiple steps. It defines the following methods which every incremental decoder must define in order to be compatible with the Python codec registry.

class codecs.IncrementalDecoder(errors=’strict’)

Constructor for an IncrementalDecoder instance.

All incremental decoders must provide this constructor interface. They are free to add additional keyword

arguments, but only the ones defined here are used by the Python codec registry.

The IncrementalDecoder may implement different error handling schemes by providing the errors keyword

argument. See Error Handlers for possible values.

The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it

possible to switch between different error handling strategies during the lifetime of the IncrementalDecoder

object.

decode(object, final=False)

Decodes object (taking the current state of the decoder into account) and returns the resulting decoded

object. If this is the last call to decode() final must be true (the default is false). If final is true the decoder must decode the input completely and must flush all buffers. If this isn’t possible (e.g. because of incomplete byte sequences at the end of the input) it must initiate error handling just like in the stateless case (which might raise an exception).

reset()

Reset the decoder to the initial state.

getstate()

Return the current state of the decoder. This must be a tuple with two items, the first must be the buffer containing the still undecoded input. The second must be an integer and can be additional state info. (The implementation should make sure that 0 is the most common additional state info.) If this additional state info is 0 it must be possible to set the decoder to the state which has no input buffered and 0 as the additional state info, so that feeding the previously buffered input to the decoder returns it to the previous state without producing any output. (Additional state info that is more complicated than integers can be converted into an integer by marshaling/pickling the info and encoding the bytes of the resulting string into an integer.)

setstate(state)

Set the state of the decoder to state. state must be a decoder state returned by getstate().



Stream Encoding and Decoding

The StreamWriter and StreamReader classes provide generic working interfaces which can be used to implement new encoding submodules very easily. See encodings.utf_8 for an example of how this is done.



StreamWriter Objects

The StreamWriter class is a subclass of Codec and defines the following methods which every stream writer must define in order to be compatible with the Python codec registry.

class codecs.StreamWriter(stream, errors=’strict’)

Constructor for a StreamWriter instance.

All stream writers must provide this constructor interface. They are free to add additional keyword arguments,

but only the ones defined here are used by the Python codec registry.

The stream argument must be a file-like object open for writing text or binary data, as appropriate for the

specific codec.

The StreamWriter may implement different error handling schemes by providing the errors keyword argu-

ment. See Error Handlers for the standard error handlers the underlying stream codec may support.

The Python Library Reference, Release 3.13.2



The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it

possible to switch between different error handling strategies during the lifetime of the StreamWriter object.



write(object)

Writes the object’s contents encoded to the stream.

writelines(list)

Writes the concatenated iterable of strings to the stream (possibly by reusing the write() method). Infinite or very large iterables are not supported. The standard bytes-to-bytes codecs do not support this method.

reset()

Resets the codec buffers used for keeping internal state.

Calling this method should ensure that the data on the output is put into a clean state that allows appending of new fresh data without having to rescan the whole stream to recover state.

In addition to the above methods, the StreamWriter must also inherit all other methods and attributes from the underlying stream.



StreamReader Objects

The StreamReader class is a subclass of Codec and defines the following methods which every stream reader must define in order to be compatible with the Python codec registry.

class codecs.StreamReader(stream, errors=’strict’)

Constructor for a StreamReader instance.

All stream readers must provide this constructor interface. They are free to add additional keyword arguments,

but only the ones defined here are used by the Python codec registry.

The stream argument must be a file-like object open for reading text or binary data, as appropriate for the

specific codec.

The StreamReader may implement different error handling schemes by providing the errors keyword argu-

ment. See Error Handlers for the standard error handlers the underlying stream codec may support.

The errors argument will be assigned to an attribute of the same name. Assigning to this attribute makes it

possible to switch between different error handling strategies during the lifetime of the StreamReader object.

The set of allowed values for the errors argument can be extended with register_error().

read(size=-1, chars=-1, firstline=False)

Decodes data from the stream and returns the resulting object.

The chars argument indicates the number of decoded code points or bytes to return. The read() method will never return more data than requested, but it might return less, if there is not enough available.

The size argument indicates the approximate maximum number of encoded bytes or code points to read for decoding. The decoder can modify this setting as appropriate. The default value -1 indicates to read and decode as much as possible. This parameter is intended to prevent having to decode huge files in one step.

The firstline flag indicates that it would be sufficient to only return the first line, if there are decoding errors on later lines.

The method should use a greedy read strategy meaning that it should read as much data as is allowed within the definition of the encoding and the given size, e.g. if optional encoding endings or state markers are available on the stream, these should be read too.

readline(size=None, keepends=True)

Read one line from the input stream and return the decoded data.

size, if given, is passed as size argument to the stream’s read() method.

The Python Library Reference, Release 3.13.2



If keepends is false line-endings will be stripped from the lines returned.

readlines(sizehint=None, keepends=True)

Read all lines available on the input stream and return them as a list of lines.

Line-endings are implemented using the codec’s decode() method and are included in the list entries if keepends is true.

sizehint, if given, is passed as the size argument to the stream’s read() method.

reset()

Resets the codec buffers used for keeping internal state.

Note that no stream repositioning should take place. This method is primarily intended to be able to recover from decoding errors.

In addition to the above methods, the StreamReader must also inherit all other methods and attributes from the underlying stream.



StreamReaderWriter Objects

The StreamReaderWriter is a convenience class that allows wrapping streams which work in both read and write modes.

The design is such that one can use the factory functions returned by the lookup() function to construct the instance.



class codecs.StreamReaderWriter(stream, Reader, Writer, errors=’strict’)

Creates a StreamReaderWriter instance. stream must be a file-like object. Reader and Writer must be

factory functions or classes providing the StreamReader and StreamWriter interface resp. Error handling

is done in the same way as defined for the stream readers and writers.

StreamReaderWriter instances define the combined interfaces of StreamReader and StreamWriter classes. They inherit all other methods and attributes from the underlying stream.



StreamRecoder Objects

The StreamRecoder translates data from one encoding to another, which is sometimes useful when dealing with different encoding environments.

The design is such that one can use the factory functions returned by the lookup() function to construct the instance.



class codecs.StreamRecoder(stream, encode, decode, Reader, Writer, errors=’strict’)

Creates a StreamRecoder instance which implements a two-way conversion: encode and decode work on

the frontend — the data visible to code calling read() and write(), while Reader and Writer work on the

backend — the data in stream.

You can use these objects to do transparent transcodings, e.g., from Latin-1 to UTF-8 and back.

The stream argument must be a file-like object.

The encode and decode arguments must adhere to the Codec interface. Reader and Writer must be factory

functions or classes providing objects of the StreamReader and StreamWriter interface respectively.

Error handling is done in the same way as defined for the stream readers and writers.

StreamRecoder instances define the combined interfaces of StreamReader and StreamWriter classes. They inherit all other methods and attributes from the underlying stream.



7.2.2 Encodings and Unicode

Strings are stored internally as sequences of code points in range U+0000–U+10FFFF. (See PEP 393 for more details about the implementation.) Once a string object is used outside of CPU and memory, endianness and how these arrays are stored as bytes become an issue. As with other codecs, serialising a string into a sequence of bytes is known as The Python Library Reference, Release 3.13.2



encoding, and recreating the string from the sequence of bytes is known as decoding. There are a variety of different

text serialisation codecs, which are collectivity referred to as text encodings.

The simplest text encoding (called 'latin-1' or 'iso-8859-1') maps the code points 0–255 to the bytes 0x0– 0xff, which means that a string object that contains code points above U+00FF can’t be encoded with this codec.

Doing so will raise a UnicodeEncodeError that looks like the following (although the details of the error mes-sage may differ): UnicodeEncodeError: 'latin-1' codec can't encode character '\u1234' in position 3: ordinal not in range(256).

There’s another group of encodings (the so called charmap encodings) that choose a different subset of all Unicode code points and how these code points are mapped to the bytes 0x0–0xff. To see how this is done simply open e.g. encodings/cp1252.py (which is an encoding that is used primarily on Windows). There’s a string constant with 256 characters that shows you which character is mapped to which byte value.

All of these encodings can only encode 256 of the 1114112 code points defined in Unicode. A simple and straight-forward way that can store each Unicode code point, is to store each code point as four consecutive bytes. There are two possibilities: store the bytes in big endian or in little endian order. These two encodings are called UTF-32-BE and UTF-32-LE respectively. Their disadvantage is that if e.g. you use UTF-32-BE on a little endian machine you will always have to swap bytes on encoding and decoding. UTF-32 avoids this problem: bytes will always be in natural endianness. When these bytes are read by a CPU with a different endianness, then bytes have to be swapped though. To be able to detect the endianness of a UTF-16 or UTF-32 byte sequence, there’s the so called BOM (“Byte Order Mark”). This is the Unicode character U+FEFF. This character can be prepended to every UTF-16 or UTF-32 byte sequence. The byte swapped version of this character (0xFFFE) is an illegal character that may not appear in a Unicode text. So when the first character in a UTF-16 or UTF-32 byte sequence appears to be a U+FFFE the bytes have to be swapped on decoding. Unfortunately the character U+FEFF had a second purpose as a ZERO WIDTH NO-BREAK SPACE: a character that has no width and doesn’t allow a word to be split. It can e.g. be used to give hints to a ligature algorithm. With Unicode 4.0 using U+FEFF as a ZERO WIDTH NO-BREAK SPACE has been deprecated (with U+2060 (WORD JOINER) assuming this role). Nevertheless Unicode software still must be able to handle U+FEFF in both roles: as a BOM it’s a device to determine the storage layout of the encoded bytes, and vanishes once the byte sequence has been decoded into a string; as a ZERO WIDTH NO-BREAK SPACE it’s a normal character that will be decoded like any other.

There’s another encoding that is able to encode the full range of Unicode characters: UTF-8. UTF-8 is an 8-bit encoding, which means there are no issues with byte order in UTF-8. Each byte in a UTF-8 byte sequence consists of two parts: marker bits (the most significant bits) and payload bits. The marker bits are a sequence of zero to four 1 bits followed by a 0 bit. Unicode characters are encoded like this (with x being payload bits, which when concatenated give the Unicode character):



Range Encoding

U-00000000 … U-0000007F 0xxxxxxx

U-00000080 … U-000007FF 110xxxxx 10xxxxxx

U-00000800 … U-0000FFFF 1110xxxx 10xxxxxx 10xxxxxx

U-00010000 … U-0010FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx



The least significant bit of the Unicode character is the rightmost x bit.

As UTF-8 is an 8-bit encoding no BOM is required and any U+FEFF character in the decoded string (even if it’s the first character) is treated as a ZERO WIDTH NO-BREAK SPACE.

Without external information it’s impossible to reliably determine which encoding was used for encoding a string. Each charmap encoding can decode any random byte sequence. However that’s not possible with UTF-8, as UTF-8 byte sequences have a structure that doesn’t allow arbitrary byte sequences. To increase the reliability with which a UTF-8 encoding can be detected, Microsoft invented a variant of UTF-8 (that Python calls "utf-8-sig") for its Notepad program: Before any of the Unicode characters is written to the file, a UTF-8 encoded BOM (which looks like this as a byte sequence: 0xef, 0xbb, 0xbf) is written. As it’s rather improbable that any charmap encoded file starts with these byte values (which would e.g. map to

LATIN SMALL LETTER I WITH DIAERESIS

RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK

INVERTED QUESTION MARK

The Python Library Reference, Release 3.13.2



in iso-8859-1), this increases the probability that a utf-8-sig encoding can be correctly guessed from the byte sequence. So here the BOM is not used to be able to determine the byte order used for generating the byte sequence, but as a signature that helps in guessing the encoding. On encoding the utf-8-sig codec will write 0xef, 0xbb, 0xbf as the first three bytes to the file. On decoding utf-8-sig will skip those three bytes if they appear as the first three bytes in the file. In UTF-8, the use of the BOM is discouraged and should generally be avoided.



7.2.3 Standard Encodings

Python comes with a number of codecs built-in, either implemented as C functions or with dictionaries as mapping tables. The following table lists the codecs by name, together with a few common aliases, and the languages for which the encoding is likely used. Neither the list of aliases nor the list of languages is meant to be exhaustive. Notice that spelling alternatives that only differ in case or use a hyphen instead of an underscore are also valid aliases; therefore, e.g. 'utf-8' is a valid alias for the 'utf_8' codec.

CPython implementation detail: Some common encodings can bypass the codecs lookup machinery to improve performance. These optimization opportunities are only recognized by CPython for a limited set of (case insensitive) aliases: utf-8, utf8, latin-1, latin1, iso-8859-1, iso8859-1, mbcs (Windows only), ascii, us-ascii, utf-16, utf16, utf-32, utf32, and the same using underscores instead of dashes. Using alternative aliases for these encodings may result in slower execution.

Changed in version 3.6: Optimization opportunity recognized for us-ascii.

Many of the character sets support the same languages. They vary in individual characters (e.g. whether the EURO SIGN is supported or not), and in the assignment of characters to code positions. For the European languages in particular, the following variants typically exist:

• an ISO 8859 codeset

• a Microsoft Windows code page, which is typically derived from an 8859 codeset, but replaces control char-

acters with additional graphic characters

• an IBM EBCDIC code page

• an IBM PC code page, which is ASCII compatible



Codec Aliases Languages

ascii 646, us-ascii English

big5 big5-tw, csbig5 Traditional Chinese

big5hkscs big5-hkscs, hkscs Traditional Chinese

cp037 IBM037, IBM039 English

cp273 273, IBM273, csIBM273 German

Added in version 3.4.

cp424 EBCDIC-CP-HE, IBM424 Hebrew

cp437 437, IBM437 English

cp500 EBCDIC-CP-BE, EBCDIC-CP- Western Europe

CH, IBM500

cp720 Arabic

cp737 Greek

cp775 IBM775 Baltic languages

cp850 850, IBM850 Western Europe

cp852 852, IBM852 Central and Eastern Europe

cp855 855, IBM855 Bulgarian, Byelorussian, Macedo-

nian, Russian, Serbian

cp856 Hebrew

cp857 857, IBM857 Turkish

cp858 858, IBM858 Western Europe

cp860 860, IBM860 Portuguese

cp861 861, CP-IS, IBM861 Icelandic

cp862 862, IBM862 Hebrew

cp863 863, IBM863 Canadian

continues on next page

The Python Library Reference, Release 3.13.2



Table 1 – continued from previous page

Codec Aliases Languages

cp864 IBM864 Arabic

cp865 865, IBM865 Danish, Norwegian

cp866 866, IBM866 Russian

cp869 869, CP-GR, IBM869 Greek

cp874 Thai

cp875 Greek

cp932 932, ms932, mskanji, ms-kanji, Japanese

windows-31j

cp949 949, ms949, uhc Korean

cp950 950, ms950 Traditional Chinese

cp1006 Urdu

cp1026 ibm1026 Turkish

cp1125 1125, ibm1125, cp866u, ruscii Ukrainian

Added in version 3.4.

cp1140 ibm1140 Western Europe

cp1250 windows-1250 Central and Eastern Europe

cp1251 windows-1251 Bulgarian, Byelorussian, Macedo-

nian, Russian, Serbian

cp1252 windows-1252 Western Europe

cp1253 windows-1253 Greek

cp1254 windows-1254 Turkish

cp1255 windows-1255 Hebrew

cp1256 windows-1256 Arabic

cp1257 windows-1257 Baltic languages

cp1258 windows-1258 Vietnamese

euc_jp eucjp, ujis, u-jis Japanese

euc_jis_2004 jisx0213, eucjis2004 Japanese

euc_jisx0213 eucjisx0213 Japanese

euc_kr euckr, korean, ksc5601, ks_c- Korean

5601, ks_c-5601-1987, ksx1001,

ks_x-1001

gb2312 chinese, csiso58gb231280, euc- Simplified Chinese

cn, euccn, eucgb2312-cn, gb2312-

1980, gb2312-80, iso-ir-58

gbk 936, cp936, ms936 Unified Chinese

gb18030 gb18030-2000 Unified Chinese

hz hzgb, hz-gb, hz-gb-2312 Simplified Chinese

iso2022_jp csiso2022jp, iso2022jp, iso-2022- Japanese

jp

iso2022_jp_1 iso2022jp-1, iso-2022-jp-1 Japanese

iso2022_jp_2 iso2022jp-2, iso-2022-jp-2 Japanese, Korean, Simplified Chi-

nese, Western Europe, Greek

iso2022_jp_2004 iso2022jp-2004, iso-2022-jp- Japanese

2004

iso2022_jp_3 iso2022jp-3, iso-2022-jp-3 Japanese

iso2022_jp_ext iso2022jp-ext, iso-2022-jp-ext Japanese

iso2022_kr csiso2022kr, iso2022kr, iso-2022- Korean

kr

latin_1 iso-8859-1, iso8859-1, 8859, Western Europe

cp819, latin, latin1, L1

iso8859_2 iso-8859-2, latin2, L2 Central and Eastern Europe

iso8859_3 iso-8859-3, latin3, L3 Esperanto, Maltese

iso8859_4 iso-8859-4, latin4, L4 Baltic languages

iso8859_5 iso-8859-5, cyrillic Bulgarian, Byelorussian, Macedo-

nian, Russian, Serbian

continues on next page

The Python Library Reference, Release 3.13.2



Table 1 – continued from previous page

Codec Aliases Languages

iso8859_6 iso-8859-6, arabic Arabic

iso8859_7 iso-8859-7, greek, greek8 Greek

iso8859_8 iso-8859-8, hebrew Hebrew

iso8859_9 iso-8859-9, latin5, L5 Turkish

iso8859_10 iso-8859-10, latin6, L6 Nordic languages

iso8859_11 iso-8859-11, thai Thai languages

iso8859_13 iso-8859-13, latin7, L7 Baltic languages

iso8859_14 iso-8859-14, latin8, L8 Celtic languages

iso8859_15 iso-8859-15, latin9, L9 Western Europe

iso8859_16 iso-8859-16, latin10, L10 South-Eastern Europe

johab cp1361, ms1361 Korean

koi8_r Russian

koi8_t Tajik

Added in version 3.5.

koi8_u Ukrainian

kz1048 kz_1048, strk1048_2002, rk1048 Kazakh

Added in version 3.5.

mac_cyrillic maccyrillic Bulgarian, Byelorussian, Macedo-

nian, Russian, Serbian

mac_greek macgreek Greek

mac_iceland maciceland Icelandic

mac_latin2 maclatin2, maccentraleurope, Central and Eastern Europe

mac_centeuro

mac_roman macroman, macintosh Western Europe

mac_turkish macturkish Turkish

ptcp154 csptcp154, pt154, cp154, cyrillic- Kazakh

asian

shift_jis csshiftjis, shiftjis, sjis, s_jis Japanese

shift_jis_2004 shiftjis2004, sjis_2004, sjis2004 Japanese

shift_jisx0213 shiftjisx0213, sjisx0213, Japanese

s_jisx0213

utf_32 U32, utf32 all languages

utf_32_be UTF-32BE all languages

utf_32_le UTF-32LE all languages

utf_16 U16, utf16 all languages

utf_16_be UTF-16BE all languages

utf_16_le UTF-16LE all languages

utf_7 U7, unicode-1-1-utf-7 all languages

utf_8 U8, UTF, utf8, cp65001 all languages

utf_8_sig all languages



Changed in version 3.4: The utf-16* and utf-32* encoders no longer allow surrogate code points (U+D800–U+DFFF) to be encoded. The utf-32* decoders no longer decode byte sequences that correspond to surrogate code points.

Changed in version 3.8: cp65001 is now an alias to utf_8.



7.2.4 Python Specific Encodings

A number of predefined codecs are specific to Python, so their codec names have no meaning outside Python. These are listed in the tables below based on the expected input and output types (note that while text encodings are the most common use case for codecs, the underlying codec infrastructure supports arbitrary data transforms rather than just text encodings). For asymmetric codecs, the stated meaning describes the encoding direction.



The Python Library Reference, Release 3.13.2



Text Encodings

The following codecs provide str to bytes encoding and bytes-like object to str decoding, similar to the Unicode text encodings.



Codec Aliases Meaning

idna Implement RFC 3490, see

also encodings.idna. Only

errors='strict' is supported.

mbcs ansi, dbcs Windows only: Encode the

operand according to the ANSI

codepage (CP_ACP).

oem Windows only: Encode the

operand according to the OEM

codepage (CP_OEMCP).

Added in version 3.6.

palmos Encoding of PalmOS 3.5.

punycode Implement RFC 3492. Stateful

codecs are not supported.

raw_unicode_escape Latin-1 encoding with \uXXXX

and \UXXXXXXXX for other code

points. Existing backslashes are

not escaped in any way. It is used

in the Python pickle protocol.

undefined Raise an exception for all conver-

sions, even empty strings. The er-

ror handler is ignored.

unicode_escape Encoding suitable as the contents

of a Unicode literal in ASCII-

encoded Python source code, ex-

cept that quotes are not escaped.

Decode from Latin-1 source code.

Beware that Python source code

actually uses UTF-8 by default.



Changed in version 3.8: “unicode_internal” codec is removed.



Binary Transforms

The following codecs provide binary transforms: bytes-like object to bytes mappings. They are not supported by

bytes.decode() (which only produces str output).



The Python Library Reference, Release 3.13.2



Codec Aliases Meaning Encoder / decoder

base64_codec1 base64, Convert the operand to multiline MIME base64 (the base64.

base_64 result always includes a trailing '\n'). encodebytes() /

Changed in version 3.4: accepts any bytes-like object base64.

as input for encoding and decoding decodebytes()

bz2_codec bz2 Compress the operand using bz2. bz2.compress()

/ bz2.

decompress()

hex_codec hex Convert the operand to hexadecimal representation, binascii.

with two digits per byte. b2a_hex() /

binascii.

a2b_hex()

quopri_codec quopri, Convert the operand to MIME quoted printable. quopri.

quotedprint- encode() with

able, quotetabs=True

quoted_printable / quopri.

decode()

uu_codec uu Convert the operand using uuencode.

zlib_codec zip, zlib Compress the operand using gzip. zlib.

compress() /

zlib.

decompress()



Added in version 3.2: Restoration of the binary transforms.

Changed in version 3.4: Restoration of the aliases for the binary transforms.



Text Transforms

The following codec provides a text transform: a str to str mapping. It is not supported by str.encode() (which

only produces bytes output).



Codec Aliases Meaning

rot_13 rot13 Return the Caesar-cypher encryption of the operand.



Added in version 3.2: Restoration of the rot_13 text transform.

Changed in version 3.4: Restoration of the rot13 alias.



7.2.5 encodings.idna — Internationalized Domain Names in Applications

This module implements RFC 3490 (Internationalized Domain Names in Applications) and RFC 3492 (Nameprep: A Stringprep Profile for Internationalized Domain Names (IDN)). It builds upon the punycode encoding and

stringprep.

If you need the IDNA 2008 standard from RFC 5891 and RFC 5895, use the third-party idna module.

These RFCs together define a protocol to support non-ASCII characters in domain names. A domain name containing non-ASCII characters (such as www.Alliancefrançaise.nu) is converted into an ASCII-compatible encoding (ACE, such as www.xn--alliancefranaise-npb.nu). The ACE form of the domain name is then used in all places where arbitrary characters are not allowed by the protocol, such as DNS queries, HTTP Host fields, and so on. This conversion is carried out in the application; if possible invisible to the user: The application should transparently convert Unicode domain labels to IDNA on the wire, and convert back ACE labels to Unicode before presenting them to the user.

1 In addition to bytes-like objects, 'base64_codec' also accepts ASCII-only instances of str for decoding The Python Library Reference, Release 3.13.2



Python supports this conversion in several ways: the idna codec performs conversion between Unicode and ACE,

separating an input string into labels based on the separator characters defined in section 3.1 of RFC 3490 and converting each label to ACE as required, and conversely separating an input byte string into labels based on the .

separator and converting any ACE labels found into unicode. Furthermore, the socket module transparently con-verts Unicode host names to ACE, so that applications need not be concerned about converting host names themselves when they pass them to the socket module. On top of that, modules that have host names as function parameters,

such as http.client and ftplib, accept Unicode host names (http.client then also transparently sends an IDNA hostname in the Host field if it sends that field at all).

When receiving host names from the wire (such as in reverse name lookup), no automatic conversion to Unicode is performed: applications wishing to present such host names to the user should decode them to Unicode.

The module encodings.idna also implements the nameprep procedure, which performs certain normalizations on host names, to achieve case-insensitivity of international domain names, and to unify similar characters. The nameprep functions can be used directly if desired.

encodings.idna.nameprep(label)

Return the nameprepped version of label. The implementation currently assumes query strings, so

AllowUnassigned is true.

encodings.idna.ToASCII(label)

Convert a label to ASCII, as specified in RFC 3490. UseSTD3ASCIIRules is assumed to be false.

encodings.idna.ToUnicode(label)

Convert a label to Unicode, as specified in RFC 3490.



7.2.6 encodings.mbcs — Windows ANSI codepage

This module implements the ANSI codepage (CP_ACP).

Availability: Windows.

Changed in version 3.2: Before 3.2, the errors argument was ignored; 'replace' was always used to encode, and 'ignore' to decode.

Changed in version 3.3: Support any error handler.



7.2.7 encodings.utf_8_sig — UTF-8 codec with BOM signature

This module implements a variant of the UTF-8 codec. On encoding, a UTF-8 encoded BOM will be prepended to the UTF-8 encoded bytes. For the stateful encoder this is only done once (on the first write to the byte stream). On decoding, an optional UTF-8 encoded BOM at the start of the data will be skipped.





CHAPTER




EIGHT



DATA TYPES



The modules described in this chapter provide a variety of specialized data types such as dates and times, fixed-type arrays, heap queues, double-ended queues, and enumerations.

Python also provides some built-in data types, in particular, dict, list, set and frozenset, and tuple. The

str class is used to hold Unicode strings, and the bytes and bytearray classes are used to hold binary data.

The following modules are documented in this chapter:



8.1 datetime — Basic date and time types

Source code: Lib/datetime.py



The datetime module supplies classes for manipulating dates and times.

While date and time arithmetic is supported, the focus of the implementation is on efficient attribute extraction for output formatting and manipulation.



b Tip

Skip to the format codes.



µ See also

Module calendar

General calendar related functions.

Module time

Time access and conversions.

Module zoneinfo

Concrete time zones representing the IANA time zone database.

Package dateutil

Third-party library with expanded time zone and parsing support.

Package DateType

Third-party library that introduces distinct static types to e.g. allow static type checkers to differentiate between naive and aware datetimes.



8.1.1 Aware and Naive Objects

Date and time objects may be categorized as “aware” or “naive” depending on whether or not they include time zone information.

The Python Library Reference, Release 3.13.2



With sufficient knowledge of applicable algorithmic and political time adjustments, such as time zone and daylight saving time information, an aware object can locate itself relative to other aware objects. An aware object represents

a specific moment in time that is not open to interpretation.1

A naive object does not contain enough information to unambiguously locate itself relative to other date/time objects. Whether a naive object represents Coordinated Universal Time (UTC), local time, or time in some other time zone is purely up to the program, just like it is up to the program whether a particular number represents metres, miles, or mass. Naive objects are easy to understand and to work with, at the cost of ignoring some aspects of reality.

For applications requiring aware objects, datetime and time objects have an optional time zone information at-

tribute, tzinfo, that can be set to an instance of a subclass of the abstract tzinfo class. These tzinfo objects capture information about the offset from UTC time, the time zone name, and whether daylight saving time is in effect.

Only one concrete tzinfo class, the timezone class, is supplied by the datetime module. The timezone class can represent simple time zones with fixed offsets from UTC, such as UTC itself or North American EST and EDT time zones. Supporting time zones at deeper levels of detail is up to the application. The rules for time adjustment across the world are more political than rational, change frequently, and there is no standard suitable for every application aside from UTC.



8.1.2 Constants

The datetime module exports the following constants:

datetime.MINYEAR

The smallest year number allowed in a date or datetime object. MINYEAR is 1.

datetime.MAXYEAR

The largest year number allowed in a date or datetime object. MAXYEAR is 9999.

datetime.UTC

Alias for the UTC time zone singleton datetime.timezone.utc.

Added in version 3.11.



8.1.3 Available Types

class datetime.date

An idealized naive date, assuming the current Gregorian calendar always was, and always will be, in effect.

Attributes: year, month, and day.

class datetime.time

An idealized time, independent of any particular day, assuming that every day has exactly 24*60*60 seconds.

(There is no notion of “leap seconds” here.) Attributes: hour, minute, second, microsecond, and tzinfo.

class datetime.datetime

A combination of a date and a time. Attributes: year, month, day, hour, minute, second, microsecond,

and tzinfo.

class datetime.timedelta

A duration expressing the difference between two datetime or date instances to microsecond resolution.

class datetime.tzinfo

An abstract base class for time zone information objects. These are used by the datetime and time classes

to provide a customizable notion of time adjustment (for example, to account for time zone and/or daylight

saving time).

class datetime.timezone

A class that implements the tzinfo abstract base class as a fixed offset from the UTC.

Added in version 3.2.

1 If, that is, we ignore the effects of Relativity

The Python Library Reference, Release 3.13.2



Objects of these types are immutable.

Subclass relationships:

object

timedelta

tzinfo

timezone

time

date

datetime



Common Properties

The date, datetime, time, and timezone types share these common features:

• Objects of these types are immutable.

• Objects of these types are hashable, meaning that they can be used as dictionary keys.

• Objects of these types support efficient pickling via the pickle module.



Determining if an Object is Aware or Naive

Objects of the date type are always naive.

An object of type time or datetime may be aware or naive.

A datetime object d is aware if both of the following hold:

1. d.tzinfo is not None

2. d.tzinfo.utcoffset(d) does not return None

Otherwise, d is naive.

A time object t is aware if both of the following hold:

1. t.tzinfo is not None

2. t.tzinfo.utcoffset(None) does not return None.

Otherwise, t is naive.

The distinction between aware and naive doesn’t apply to timedelta objects.



8.1.4 timedelta Objects

A timedelta object represents a duration, the difference between two datetime or date instances.

class datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0,

weeks=0)

All arguments are optional and default to 0. Arguments may be integers or floats, and may be positive or

negative.

Only days, seconds and microseconds are stored internally. Arguments are converted to those units:

• A millisecond is converted to 1000 microseconds.

• A minute is converted to 60 seconds.

• An hour is converted to 3600 seconds.

• A week is converted to 7 days.

and days, seconds and microseconds are then normalized so that the representation is unique, with

• 0 <= microseconds < 1000000

The Python Library Reference, Release 3.13.2



• 0 <= seconds < 3600*24 (the number of seconds in one day)

•-999999999 <= days <= 999999999

The following example illustrates how any arguments besides days, seconds and microseconds are “merged”

and normalized into those three resulting attributes:

>>> from datetime import timedelta

>>> delta = timedelta(

... days=50,

... seconds=27,

... microseconds=10,

... milliseconds=29000,

... minutes=5,

... hours=8,

... weeks=2

... )

>>> # Only days, seconds, and microseconds remain

>>> delta

datetime.timedelta(days=64, seconds=29156, microseconds=10)



If any argument is a float and there are fractional microseconds, the fractional microseconds left over from

all arguments are combined and their sum is rounded to the nearest microsecond using round-half-to-even

tiebreaker. If no argument is a float, the conversion and normalization processes are exact (no information is

lost).

If the normalized value of days lies outside the indicated range, OverflowError is raised.

Note that normalization of negative values may be surprising at first. For example:

>>> from datetime import timedelta

>>> d = timedelta(microseconds=-1)

>>> (d.days, d.seconds, d.microseconds)

(-1, 86399, 999999)



Class attributes:

timedelta.min

The most negative timedelta object, timedelta(-999999999).

timedelta.max

The most positive timedelta object, timedelta(days=999999999, hours=23, minutes=59,

seconds=59, microseconds=999999) .

timedelta.resolution

The smallest possible difference between non-equal timedelta objects, timedelta(microseconds=1).

Note that, because of normalization, timedelta.max is greater than-timedelta.min.-timedelta.max is not

representable as a timedelta object.

Instance attributes (read-only):

timedelta.days

Between -999,999,999 and 999,999,999 inclusive.

timedelta.seconds

Between 0 and 86,399 inclusive.



Ϫ Caution

It is a somewhat common bug for code to unintentionally use this attribute when it is actually intended to

get a total_seconds() value instead:

The Python Library Reference, Release 3.13.2



>>> from datetime import timedelta

>>> duration = timedelta(seconds=11235813)

>>> duration.days, duration.seconds

(130, 3813)

>>> duration.total_seconds()

11235813.0



timedelta.microseconds

Between 0 and 999,999 inclusive.

Supported operations:



Operation Result

t1 = t2 + t3 Sum of t2 and t3. Afterwards t1 - t2 == t3 and t1 - t3 == t2 are true. (1)

t1 = t2 - t3 Difference of t2 and t3. Afterwards t1 == t2 - t3 and t2 == t1 + t3 are

true. (1)(6)

t1 = t2 * i or t1 Delta multiplied by an integer. Afterwards t1 // i == t2 is true, provided i !=

= i * t2 0.

In general, t1 * i == t1 * (i-1) + t1 is true. (1)

t1 = t2 * f or t1 Delta multiplied by a float. The result is rounded to the nearest multiple of

= f * t2 timedelta.resolution using round-half-to-even.

f = t2 / t3 Division (3) of overall duration t2 by interval unit t3. Returns a float object.

t1 = t2 / f or t1 Delta divided by a float or an int. The result is rounded to the nearest multiple of

= t2 / i timedelta.resolution using round-half-to-even.

t1 = t2 // i or t1 The floor is computed and the remainder (if any) is thrown away. In the second case,

= t2 // t3 an integer is returned. (3)

t1 = t2 % t3 The remainder is computed as a timedelta object. (3)

q, r = divmod(t1, Computes the quotient and the remainder: q = t1 // t2 (3) and r = t1 % t2.

t2) q is an integer and r is a timedelta object.

+t1 Returns a timedelta object with the same value. (2)

-t1 Equivalent to timedelta(-t1.days, -t1.seconds, -t1.microseconds),

and to t1 * -1. (1)(4)

abs(t) Equivalent to +t when t.days >= 0, and to-t when t.days < 0. (2)

str(t) Returns a string in the form [D day[s], ][H]H:MM:SS[.UUUUUU], where D is

negative for negative t. (5)

repr(t) Returns a string representation of the timedelta object as a constructor call with

canonical attribute values.



Notes:

(1) This is exact but may overflow.

(2) This is exact and cannot overflow.

(3) Division by zero raises ZeroDivisionError.

(4)-timedelta.max is not representable as a timedelta object.

(5) String representations of timedelta objects are normalized similarly to their internal representation. This

leads to somewhat unusual results for negative timedeltas. For example:

>>> timedelta(hours=-5)

datetime.timedelta(days=-1, seconds=68400)

>>> print(_)

-1 day, 19:00:00



(6) The expression t2 - t3 will always be equal to the expression t2 + (-t3) except when t3 is equal to

timedelta.max; in that case the former will produce a result while the latter will overflow.

The Python Library Reference, Release 3.13.2



In addition to the operations listed above, timedelta objects support certain additions and subtractions with date

and datetime objects (see below).

Changed in version 3.2: Floor division and true division of a timedelta object by another timedelta object

are now supported, as are remainder operations and the divmod() function. True division and multiplication of a

timedelta object by a float object are now supported.

timedelta objects support equality and order comparisons.

In Boolean contexts, a timedelta object is considered to be true if and only if it isn’t equal to timedelta(0).

Instance methods:

timedelta.total_seconds()

Return the total number of seconds contained in the duration. Equivalent to td /

timedelta(seconds=1) . For interval units other than seconds, use the division form directly (e.g.

td / timedelta(microseconds=1)).

Note that for very large time intervals (greater than 270 years on most platforms) this method will lose mi-

crosecond accuracy.

Added in version 3.2.



Examples of usage: timedelta

An additional example of normalization:

>>> # Components of another_year add up to exactly 365 days >>> from datetime import timedelta

>>> year = timedelta(days=365)

>>> another_year = timedelta(weeks=40, days=84, hours=23, ... minutes=50, seconds=600)

>>> year == another_year

True

>>> year.total_seconds()

31536000.0



Examples of timedelta arithmetic:

>>> from datetime import timedelta

>>> year = timedelta(days=365)

>>> ten_years = 10 * year

>>> ten_years

datetime.timedelta(days=3650)

>>> ten_years.days // 365

10

>>> nine_years = ten_years-year

>>> nine_years

datetime.timedelta(days=3285)

>>> three_years = nine_years // 3

>>> three_years, three_years.days // 365

(datetime.timedelta(days=1095), 3)



8.1.5 date Objects

A date object represents a date (year, month and day) in an idealized calendar, the current Gregorian calendar indefinitely extended in both directions.

January 1 of year 1 is called day number 1, January 2 of year 1 is called day number 2, and so on.2

2 This matches the definition of the “proleptic Gregorian” calendar in Dershowitz and Reingold’s book Calendrical Calculations, where it’s the

base calendar for all computations. See the book for algorithms for converting between proleptic Gregorian ordinals and many other calendar systems.

The Python Library Reference, Release 3.13.2



class datetime.date(year, month, day)

All arguments are required. Arguments must be integers, in the following ranges:

• MINYEAR <= year <= MAXYEAR

• 1 <= month <= 12

• 1 <= day <= number of days in the given month and year

If an argument outside those ranges is given, ValueError is raised.

Other constructors, all class methods:

classmethod date.today()

Return the current local date.

This is equivalent to date.fromtimestamp(time.time()).

classmethod date.fromtimestamp(timestamp)

Return the local date corresponding to the POSIX timestamp, such as is returned by time.time().

This may raise OverflowError, if the timestamp is out of the range of values supported by the platform

C localtime() function, and OSError on localtime() failure. It’s common for this to be restricted to

years from 1970 through 2038. Note that on non-POSIX systems that include leap seconds in their notion of

a timestamp, leap seconds are ignored by fromtimestamp().

Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range

of values supported by the platform C localtime() function. Raise OSError instead of ValueError on

localtime() failure.

classmethod date.fromordinal(ordinal)

Return the date corresponding to the proleptic Gregorian ordinal, where January 1 of year 1 has ordinal 1.

ValueError is raised unless 1 <= ordinal <= date.max.toordinal(). For any date d, date.

fromordinal(d.toordinal()) == d .

classmethod date.fromisoformat(date_string)

Return a date corresponding to a date_string given in any valid ISO 8601 format, with the following exceptions:

1. Reduced precision dates are not currently supported (YYYY-MM, YYYY).

2. Extended date representations are not currently supported (±YYYYYY-MM-DD).

3. Ordinal dates are not currently supported (YYYY-OOO).

Examples:

>>> from datetime import date

>>> date.fromisoformat('2019-12-04')

datetime.date(2019, 12, 4)

>>> date.fromisoformat('20191204')

datetime.date(2019, 12, 4)

>>> date.fromisoformat('2021-W01-1')

datetime.date(2021, 1, 4)



Added in version 3.7.

Changed in version 3.11: Previously, this method only supported the format YYYY-MM-DD.

classmethod date.fromisocalendar(year, week, day)

Return a date corresponding to the ISO calendar date specified by year, week and day. This is the inverse of

the function date.isocalendar().

Added in version 3.8.

Class attributes:

The Python Library Reference, Release 3.13.2



date.min

The earliest representable date, date(MINYEAR, 1, 1).

date.max

The latest representable date, date(MAXYEAR, 12, 31).

date.resolution

The smallest possible difference between non-equal date objects, timedelta(days=1).

Instance attributes (read-only):

date.year

Between MINYEAR and MAXYEAR inclusive.

date.month

Between 1 and 12 inclusive.

date.day

Between 1 and the number of days in the given month of the given year.

Supported operations:



Operation Result

date2 = date1 + timedelta date2 will be timedelta.days days after date1.

(1)

date2 = date1 - timedelta Computes date2 such that date2 + timedelta ==

date1 . (2)

timedelta = date1 - date2 (3)

Equality comparison. (4)

date1 == date2

date1 != date2



Order comparison. (5)

date1 < date2

date1 > date2

date1 <= date2

date1 >= date2



Notes:

(1) date2 is moved forward in time if timedelta.days > 0, or backward if timedelta.days < 0. After-

ward date2 - date1 == timedelta.days. timedelta.seconds and timedelta.microseconds

are ignored. OverflowError is raised if date2.year would be smaller than MINYEAR or larger than

MAXYEAR .

(2) timedelta.seconds and timedelta.microseconds are ignored.

(3) This is exact, and cannot overflow. timedelta.seconds and timedelta.microseconds are 0, and

date2 + timedelta == date1 after.

(4) date objects are equal if they represent the same date.

date objects that are not also datetime instances are never equal to datetime objects, even if they represent

the same date.

(5) date1 is considered less than date2 when date1 precedes date2 in time. In other words, date1 < date2 if

and only if date1.toordinal() < date2.toordinal().

Order comparison between a date object that is not also a datetime instance and a datetime object raises

TypeError.

The Python Library Reference, Release 3.13.2



Changed in version 3.13: Comparison between datetime object and an instance of the date subclass that is not a datetime subclass no longer converts the latter to date, ignoring the time part and the time zone. The default behavior can be changed by overriding the special comparison methods in subclasses.

In Boolean contexts, all date objects are considered to be true.

Instance methods:

date.replace(year=self.year, month=self.month, day=self.day)

Return a date with the same value, except for those parameters given new values by whichever keyword argu-

ments are specified.

Example:

>>> from datetime import date

>>> d = date(2002, 12, 31)

>>> d.replace(day=26)

datetime.date(2002, 12, 26)



date objects are also supported by generic function copy.replace().

date.timetuple()

Return a time.struct_time such as returned by time.localtime().

The hours, minutes and seconds are 0, and the DST flag is -1.

d.timetuple() is equivalent to:

time.struct_time((d.year, d.month, d.day, 0, 0, 0, d.weekday(), yday,-1))



where yday = d.toordinal() - date(d.year, 1, 1).toordinal() + 1 is the day number

within the current year starting with 1 for January 1st.

date.toordinal()

Return the proleptic Gregorian ordinal of the date, where January 1 of year 1 has ordinal 1. For any date

object d, date.fromordinal(d.toordinal()) == d.

date.weekday()

Return the day of the week as an integer, where Monday is 0 and Sunday is 6. For example, date(2002,

12, 4).weekday() == 2 , a Wednesday. See also isoweekday().

date.isoweekday()

Return the day of the week as an integer, where Monday is 1 and Sunday is 7. For example, date(2002,

12, 4).isoweekday() == 3, a Wednesday. See also weekday(), isocalendar().

date.isocalendar()

Return a named tuple object with three components: year, week and weekday.

The ISO calendar is a widely used variant of the Gregorian calendar. 3

The ISO year consists of 52 or 53 full weeks, and where a week starts on a Monday and ends on a Sunday. The

first week of an ISO year is the first (Gregorian) calendar week of a year containing a Thursday. This is called

week number 1, and the ISO year of that Thursday is the same as its Gregorian year.

For example, 2004 begins on a Thursday, so the first week of ISO year 2004 begins on Monday, 29 Dec 2003

and ends on Sunday, 4 Jan 2004:

>>> from datetime import date

>>> date(2003, 12, 29).isocalendar()

datetime.IsoCalendarDate(year=2004, week=1, weekday=1)

>>> date(2004, 1, 4).isocalendar()

datetime.IsoCalendarDate(year=2004, week=1, weekday=7)

3 See R. H. van Gent’s guide to the mathematics of the ISO 8601 calendar for a good explanation.

The Python Library Reference, Release 3.13.2



Changed in version 3.9: Result changed from a tuple to a named tuple.

date.isoformat()

Return a string representing the date in ISO 8601 format, YYYY-MM-DD:

>>> from datetime import date

>>> date(2002, 12, 4).isoformat()

'2002-12-04'



date.__str__()

For a date d, str(d) is equivalent to d.isoformat().

date.ctime()

Return a string representing the date:

>>> from datetime import date

>>> date(2002, 12, 4).ctime()

'Wed Dec 4 00:00:00 2002'



d.ctime() is equivalent to:

time.ctime(time.mktime(d.timetuple()))



on platforms where the native C ctime() function (which time.ctime() invokes, but which date.

ctime() does not invoke) conforms to the C standard.

date.strftime(format)

Return a string representing the date, controlled by an explicit format string. Format codes referring to hours,

minutes or seconds will see 0 values. See also strftime() and strptime() Behavior and date.isoformat().

date.__format__(format)

Same as date.strftime(). This makes it possible to specify a format string for a date object in format-

ted string literals and when using str.format(). See also strftime() and strptime() Behavior and date.

isoformat().



Examples of Usage: date

Example of counting days to an event:

>>> import time

>>> from datetime import date

>>> today = date.today()

>>> today

datetime.date(2007, 12, 5)

>>> today == date.fromtimestamp(time.time())

True

>>> my_birthday = date(today.year, 6, 24)

>>> if my_birthday < today:

... my_birthday = my_birthday.replace(year=today.year + 1) ...

>>> my_birthday

datetime.date(2008, 6, 24)

>>> time_to_birthday = abs(my_birthday-today)

>>> time_to_birthday.days

202



More examples of working with date:



The Python Library Reference, Release 3.13.2



>>> from datetime import date

>>> d = date.fromordinal(730920) # 730920th day after 1. 1. 0001 >>> d

datetime.date(2002, 3, 11)

>>> # Methods related to formatting string output

>>> d.isoformat()

'2002-03-11'

>>> d.strftime("%d/%m/%y")

'11/03/02'

>>> d.strftime("%A %d. %B %Y")

'Monday 11. March 2002'

>>> d.ctime()

'Mon Mar 11 00:00:00 2002'

>>> 'The {1} is {0:%d}, the {2} is {0:%B}.'.format(d, "day", "month") 'The day is 11, the month is March.'

>>> # Methods for to extracting 'components' under different calendars >>> t = d.timetuple()

>>> for i in t:

... print(i)

2002 # year

3 # month

11 # day

0

0

0

0 # weekday (0 = Monday)

70 # 70th day in the year

-1

>>> ic = d.isocalendar()

>>> for i in ic:

... print(i)

2002 # ISO year

11 # ISO week number

1 # ISO day number ( 1 = Monday )

>>> # A date object is immutable; all operations produce a new object >>> d.replace(year=2005)

datetime.date(2005, 3, 11)



8.1.6 datetime Objects

A datetime object is a single object containing all the information from a date object and a time object.

Like a date object, datetime assumes the current Gregorian calendar extended in both directions; like a time

object, datetime assumes there are exactly 3600*24 seconds in every day.

Constructor:

class datetime.datetime(year, month, day, hour=0, minute=0, second=0, microsecond=0, tzinfo=None, *,

fold=0)

The year, month and day arguments are required. tzinfo may be None, or an instance of a tzinfo subclass.

The remaining arguments must be integers in the following ranges:

• MINYEAR <= year <= MAXYEAR,

• 1 <= month <= 12,

• 1 <= day <= number of days in the given month and year, The Python Library Reference, Release 3.13.2



• 0 <= hour < 24,

• 0 <= minute < 60,

• 0 <= second < 60,

• 0 <= microsecond < 1000000,

• fold in [0, 1].

If an argument outside those ranges is given, ValueError is raised.

Changed in version 3.6: Added the fold parameter.

Other constructors, all class methods:

classmethod datetime.today()

Return the current local date and time, with tzinfo None.

Equivalent to:

datetime.fromtimestamp(time.time())



See also now(), fromtimestamp().

This method is functionally equivalent to now(), but without a tz parameter.

classmethod datetime.now(tz=None)

Return the current local date and time.

If optional argument tz is None or not specified, this is like today(), but, if possible, supplies more precision

than can be gotten from going through a time.time() timestamp (for example, this may be possible on

platforms supplying the C gettimeofday() function).

If tz is not None, it must be an instance of a tzinfo subclass, and the current date and time are converted to

tz’s time zone.

This function is preferred over today() and utcnow().



® Note

Subsequent calls to datetime.now() may return the same instant depending on the precision of the underlying clock.



classmethod datetime.utcnow()

Return the current UTC date and time, with tzinfo None.

This is like now(), but returns the current UTC date and time, as a naive datetime object. An aware current

UTC datetime can be obtained by calling datetime.now(timezone.utc). See also now().



Á Warning

Because naive datetime objects are treated by many datetime methods as local times, it is preferred to use aware datetimes to represent times in UTC. As such, the recommended way to create an object representing the current time in UTC is by calling datetime.now(timezone.utc).



Deprecated since version 3.12: Use datetime.now() with UTC instead.

classmethod datetime.fromtimestamp(timestamp, tz=None)

Return the local date and time corresponding to the POSIX timestamp, such as is returned by time.time().

If optional argument tz is None or not specified, the timestamp is converted to the platform’s local date and

time, and the returned datetime object is naive.

If tz is not None, it must be an instance of a tzinfo subclass, and the timestamp is converted to tz’s time zone.

The Python Library Reference, Release 3.13.2



fromtimestamp() may raise OverflowError, if the timestamp is out of the range of values supported

by the platform C localtime() or gmtime() functions, and OSError on localtime() or gmtime()

failure. It’s common for this to be restricted to years in 1970 through 2038. Note that on non-POSIX systems

that include leap seconds in their notion of a timestamp, leap seconds are ignored by fromtimestamp(), and

then it’s possible to have two timestamps differing by a second that yield identical datetime objects. This

method is preferred over utcfromtimestamp().

Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range

of values supported by the platform C localtime() or gmtime() functions. Raise OSError instead of

ValueError on localtime() or gmtime() failure.

Changed in version 3.6: fromtimestamp() may return instances with fold set to 1.

classmethod datetime.utcfromtimestamp(timestamp)

Return the UTC datetime corresponding to the POSIX timestamp, with tzinfo None. (The resulting object

is naive.)

This may raise OverflowError, if the timestamp is out of the range of values supported by the platform C

gmtime() function, and OSError on gmtime() failure. It’s common for this to be restricted to years in 1970

through 2038.

To get an aware datetime object, call fromtimestamp():

datetime.fromtimestamp(timestamp, timezone.utc)



On the POSIX compliant platforms, it is equivalent to the following expression:

datetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=timestamp)



except the latter formula always supports the full years range: between MINYEAR and MAXYEAR inclusive.



Á Warning

Because naive datetime objects are treated by many datetime methods as local times, it is preferred to use aware datetimes to represent times in UTC. As such, the recommended way to create an ob-ject representing a specific timestamp in UTC is by calling datetime.fromtimestamp(timestamp, tz=timezone.utc).



Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range

of values supported by the platform C gmtime() function. Raise OSError instead of ValueError on

gmtime() failure.

Deprecated since version 3.12: Use datetime.fromtimestamp() with UTC instead.

classmethod datetime.fromordinal(ordinal)

Return the datetime corresponding to the proleptic Gregorian ordinal, where January 1 of year 1 has ordinal

1. ValueError is raised unless 1 <= ordinal <= datetime.max.toordinal(). The hour, minute,

second and microsecond of the result are all 0, and tzinfo is None.

classmethod datetime.combine(date, time, tzinfo=time.tzinfo)

Return a new datetime object whose date components are equal to the given date object’s, and whose time

components are equal to the given time object’s. If the tzinfo argument is provided, its value is used to set

the tzinfo attribute of the result, otherwise the tzinfo attribute of the time argument is used. If the date

argument is a datetime object, its time components and tzinfo attributes are ignored.

For any datetime object d, d == datetime.combine(d.date(), d.time(), d.tzinfo).

Changed in version 3.6: Added the tzinfo argument.

classmethod datetime.fromisoformat(date_string)

Return a datetime corresponding to a date_string in any valid ISO 8601 format, with the following exceptions:

1. Time zone offsets may have fractional seconds.

The Python Library Reference, Release 3.13.2



2. The T separator may be replaced by any single unicode character.

3. Fractional hours and minutes are not supported.

4. Reduced precision dates are not currently supported (YYYY-MM, YYYY).

5. Extended date representations are not currently supported (±YYYYYY-MM-DD).

6. Ordinal dates are not currently supported (YYYY-OOO).

Examples:

>>> from datetime import datetime

>>> datetime.fromisoformat('2011-11-04')

datetime.datetime(2011, 11, 4, 0, 0)

>>> datetime.fromisoformat('20111104')

datetime.datetime(2011, 11, 4, 0, 0)

>>> datetime.fromisoformat('2011-11-04T00:05:23')

datetime.datetime(2011, 11, 4, 0, 5, 23)

>>> datetime.fromisoformat('2011-11-04T00:05:23Z')

datetime.datetime(2011, 11, 4, 0, 5, 23, tzinfo=datetime.timezone.utc)

>>> datetime.fromisoformat('20111104T000523')

datetime.datetime(2011, 11, 4, 0, 5, 23)

>>> datetime.fromisoformat('2011-W01-2T00:05:23.283')

datetime.datetime(2011, 1, 4, 0, 5, 23, 283000)

>>> datetime.fromisoformat('2011-11-04 00:05:23.283')

datetime.datetime(2011, 11, 4, 0, 5, 23, 283000)

>>> datetime.fromisoformat('2011-11-04 00:05:23.283+00:00')

datetime.datetime(2011, 11, 4, 0, 5, 23, 283000, tzinfo=datetime.timezone.utc)

>>> datetime.fromisoformat('2011-11-04T00:05:23+04:00')

datetime.datetime(2011, 11, 4, 0, 5, 23,

tzinfo=datetime.timezone(datetime.timedelta(seconds=14400)))



Added in version 3.7.

Changed in version 3.11: Previously, this method only supported formats that could be emitted by date.

isoformat() or datetime.isoformat().

classmethod datetime.fromisocalendar(year, week, day)

Return a datetime corresponding to the ISO calendar date specified by year, week and day. The non-date

components of the datetime are populated with their normal default values. This is the inverse of the function

datetime.isocalendar().

Added in version 3.8.

classmethod datetime.strptime(date_string, format)

Return a datetime corresponding to date_string, parsed according to format.

If format does not contain microseconds or time zone information, this is equivalent to:

datetime(*(time.strptime(date_string, format)[0:6]))



ValueError is raised if the date_string and format can’t be parsed by time.strptime() or if it returns a

value which isn’t a time tuple. See also strftime() and strptime() Behavior and datetime.fromisoformat().

Changed in version 3.13: If format specifies a day of month without a year a DeprecationWarning is now

emitted. This is to avoid a quadrennial leap year bug in code seeking to parse only a month and day as the

default year used in absence of one in the format is not a leap year. Such format values may raise an error as

of Python 3.15. The workaround is to always include a year in your format. If parsing date_string values that

do not have a year, explicitly add a year that is a leap year before parsing:

>>> from datetime import datetime

>>> date_string = "02/29"

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> when = datetime.strptime(f"{date_string};1984", "%m/%d;%Y") # Avoids leap␣

, →year bug.

>>> when.strftime("%B %d")

'February 29'



Class attributes:

datetime.min

The earliest representable datetime, datetime(MINYEAR, 1, 1, tzinfo=None).

datetime.max

The latest representable datetime, datetime(MAXYEAR, 12, 31, 23, 59, 59, 999999,

tzinfo=None).

datetime.resolution

The smallest possible difference between non-equal datetime objects, timedelta(microseconds=1).

Instance attributes (read-only):

datetime.year

Between MINYEAR and MAXYEAR inclusive.

datetime.month

Between 1 and 12 inclusive.

datetime.day

Between 1 and the number of days in the given month of the given year.

datetime.hour

In range(24).

datetime.minute

In range(60).

datetime.second

In range(60).

datetime.microsecond

In range(1000000).

datetime.tzinfo

The object passed as the tzinfo argument to the datetime constructor, or None if none was passed.

datetime.fold

In [0, 1]. Used to disambiguate wall times during a repeated interval. (A repeated interval occurs when

clocks are rolled back at the end of daylight saving time or when the UTC offset for the current zone is decreased

for political reasons.) The values 0 and 1 represent, respectively, the earlier and later of the two moments with

the same wall time representation.

Added in version 3.6.

Supported operations:



The Python Library Reference, Release 3.13.2



Operation Result

datetime2 = datetime1 + timedelta (1)

datetime2 = datetime1 - timedelta (2)

timedelta = datetime1 - datetime2 (3)

Equality comparison. (4)

datetime1 == datetime2

datetime1 != datetime2

Order comparison. (5)

datetime1 < datetime2

datetime1 > datetime2

datetime1 <= datetime2

datetime1 >= datetime2



(1) datetime2 is a duration of timedelta removed from datetime1, moving forward in time if timedelta.

days > 0, or backward if timedelta.days < 0. The result has the same tzinfo attribute as the

input datetime, and datetime2 - datetime1 == timedelta after. OverflowError is raised if

datetime2.year would be smaller than MINYEAR or larger than MAXYEAR. Note that no time zone ad-

justments are done even if the input is an aware object.

(2) Computes the datetime2 such that datetime2 + timedelta == datetime1. As for addition, the result

has the same tzinfo attribute as the input datetime, and no time zone adjustments are done even if the input

is aware.

(3) Subtraction of a datetime from a datetime is defined only if both operands are naive, or if both are aware.

If one is aware and the other is naive, TypeError is raised.

If both are naive, or both are aware and have the same tzinfo attribute, the tzinfo attributes are ignored, and

the result is a timedelta object t such that datetime2 + t == datetime1. No time zone adjustments

are done in this case.

If both are aware and have different tzinfo attributes, a-b acts as if a and b were first converted

to naive UTC datetimes. The result is (a.replace(tzinfo=None) - a.utcoffset()) - (b.

replace(tzinfo=None) - b.utcoffset()) except that the implementation never overflows.

(4) datetime objects are equal if they represent the same date and time, taking into account the time zone.

Naive and aware datetime objects are never equal.

If both comparands are aware, and have the same tzinfo attribute, the tzinfo and fold attributes are

ignored and the base datetimes are compared. If both comparands are aware and have different tzinfo

attributes, the comparison acts as comparands were first converted to UTC datetimes except that the imple-

mentation never overflows. datetime instances in a repeated interval are never equal to datetime instances

in other time zone.

(5) datetime1 is considered less than datetime2 when datetime1 precedes datetime2 in time, taking into account the

time zone.

Order comparison between naive and aware datetime objects raises TypeError.

If both comparands are aware, and have the same tzinfo attribute, the tzinfo and fold attributes are

ignored and the base datetimes are compared. If both comparands are aware and have different tzinfo

attributes, the comparison acts as comparands were first converted to UTC datetimes except that the imple-

mentation never overflows.

Changed in version 3.3: Equality comparisons between aware and naive datetime instances don’t raise TypeError.

Changed in version 3.13: Comparison between datetime object and an instance of the date subclass that is not a datetime subclass no longer converts the latter to date, ignoring the time part and the time zone. The default behavior can be changed by overriding the special comparison methods in subclasses.

The Python Library Reference, Release 3.13.2



Instance methods:

datetime.date()

Return date object with same year, month and day.

datetime.time()

Return time object with same hour, minute, second, microsecond and fold. tzinfo is None. See also method

timetz().

Changed in version 3.6: The fold value is copied to the returned time object.

datetime.timetz()

Return time object with same hour, minute, second, microsecond, fold, and tzinfo attributes. See also method

time() .

Changed in version 3.6: The fold value is copied to the returned time object.

datetime.replace(year=self.year, month=self.month, day=self.day, hour=self.hour, minute=self.minute,

second=self.second, microsecond=self.microsecond, tzinfo=self.tzinfo, *, fold=0)

Return a datetime with the same attributes, except for those attributes given new values by whichever keyword

arguments are specified. Note that tzinfo=None can be specified to create a naive datetime from an aware

datetime with no conversion of date and time data.

datetime objects are also supported by generic function copy.replace().

Changed in version 3.6: Added the fold parameter.

datetime.astimezone(tz=None)

Return a datetime object with new tzinfo attribute tz, adjusting the date and time data so the result is the

same UTC time as self, but in tz’s local time.

If provided, tz must be an instance of a tzinfo subclass, and its utcoffset() and dst() methods must not

return None. If self is naive, it is presumed to represent time in the system time zone.

If called without arguments (or with tz=None) the system local time zone is assumed for the target time zone.

The .tzinfo attribute of the converted datetime instance will be set to an instance of timezone with the

zone name and offset obtained from the OS.

If self.tzinfo is tz, self.astimezone(tz) is equal to self: no adjustment of date or time data is per-

formed. Else the result is local time in the time zone tz, representing the same UTC time as self: after astz

= dt.astimezone(tz) , astz - astz.utcoffset() will have the same date and time data as dt -

dt.utcoffset().

If you merely want to attach a timezone object tz to a datetime dt without adjustment of date and time data,

use dt.replace(tzinfo=tz). If you merely want to remove the timezone object from an aware datetime

dt without conversion of date and time data, use dt.replace(tzinfo=None).

Note that the default tzinfo.fromutc() method can be overridden in a tzinfo subclass to affect the result

returned by astimezone(). Ignoring error cases, astimezone() acts like:

def astimezone(self, tz):

if self.tzinfo is tz:

return self

# Convert self to UTC, and attach the new timezone object. utc = (self-self.utcoffset()).replace(tzinfo=tz)

# Convert from UTC to tz's local time.

return tz.fromutc(utc)



Changed in version 3.3: tz now can be omitted.

Changed in version 3.6: The astimezone() method can now be called on naive instances that are presumed

to represent system local time.



The Python Library Reference, Release 3.13.2



datetime.utcoffset()

If tzinfo is None, returns None, else returns self.tzinfo.utcoffset(self), and raises an exception

if the latter doesn’t return None or a timedelta object with magnitude less than one day.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes.

datetime.dst()

If tzinfo is None, returns None, else returns self.tzinfo.dst(self), and raises an exception if the

latter doesn’t return None or a timedelta object with magnitude less than one day.

Changed in version 3.7: The DST offset is not restricted to a whole number of minutes.

datetime.tzname()

If tzinfo is None, returns None, else returns self.tzinfo.tzname(self), raises an exception if the

latter doesn’t return None or a string object,

datetime.timetuple()

Return a time.struct_time such as returned by time.localtime().

d.timetuple() is equivalent to:

time.struct_time((d.year, d.month, d.day,

d.hour, d.minute, d.second,

d.weekday(), yday, dst))



where yday = d.toordinal() - date(d.year, 1, 1).toordinal() + 1 is the day number

within the current year starting with 1 for January 1st. The tm_isdst flag of the result is set according

to the dst() method: tzinfo is None or dst() returns None, tm_isdst is set to-1; else if dst() returns

a non-zero value, tm_isdst is set to 1; else tm_isdst is set to 0.

datetime.utctimetuple()

If datetime instance d is naive, this is the same as d.timetuple() except that tm_isdst is forced to 0

regardless of what d.dst() returns. DST is never in effect for a UTC time.

If d is aware, d is normalized to UTC time, by subtracting d.utcoffset(), and a time.struct_time for

the normalized time is returned. tm_isdst is forced to 0. Note that an OverflowError may be raised if

d.year was MINYEAR or MAXYEAR and UTC adjustment spills over a year boundary.



Á Warning

Because naive datetime objects are treated by many datetime methods as local times, it is preferred

to use aware datetimes to represent times in UTC; as a result, using datetime.utctimetuple() may give misleading results. If you have a naive datetime representing UTC, use datetime.

replace(tzinfo=timezone.utc) to make it aware, at which point you can use datetime.

timetuple() .



datetime.toordinal()

Return the proleptic Gregorian ordinal of the date. The same as self.date().toordinal().

datetime.timestamp()

Return POSIX timestamp corresponding to the datetime instance. The return value is a float similar to

that returned by time.time().

Naive datetime instances are assumed to represent local time and this method relies on the platform

C mktime() function to perform the conversion. Since datetime supports wider range of values than

mktime() on many platforms, this method may raise OverflowError or OSError for times far in the

past or far in the future.

For aware datetime instances, the return value is computed as:

The Python Library Reference, Release 3.13.2



(dt-datetime(1970, 1, 1, tzinfo=timezone.utc)).total_seconds()



Added in version 3.3.

Changed in version 3.6: The timestamp() method uses the fold attribute to disambiguate the times during

a repeated interval.



® Note

There is no method to obtain the POSIX timestamp directly from a naive datetime instance representing UTC time. If your application uses this convention and your system time zone is not set to UTC, you can obtain the POSIX timestamp by supplying tzinfo=timezone.utc:

timestamp = dt.replace(tzinfo=timezone.utc).timestamp()

or by calculating the timestamp directly:

timestamp = (dt-datetime(1970, 1, 1)) / timedelta(seconds=1)



datetime.weekday()

Return the day of the week as an integer, where Monday is 0 and Sunday is 6. The same as self.date().

weekday(). See also isoweekday().

datetime.isoweekday()

Return the day of the week as an integer, where Monday is 1 and Sunday is 7. The same as self.date().

isoweekday(). See also weekday(), isocalendar().

datetime.isocalendar()

Return a named tuple with three components: year, week and weekday. The same as self.date().

isocalendar().

datetime.isoformat(sep=’T’ , timespec=’auto’)

Return a string representing the date and time in ISO 8601 format:

• YYYY-MM-DDTHH:MM:SS.ffffff, if microsecond is not 0

• YYYY-MM-DDTHH:MM:SS, if microsecond is 0

If utcoffset() does not return None, a string is appended, giving the UTC offset:

• YYYY-MM-DDTHH:MM:SS.ffffff+HH:MM[:SS[.ffffff]], if microsecond is not 0

• YYYY-MM-DDTHH:MM:SS+HH:MM[:SS[.ffffff]], if microsecond is 0

Examples:

>>> from datetime import datetime, timezone

>>> datetime(2019, 5, 18, 15, 17, 8, 132263).isoformat()

'2019-05-18T15:17:08.132263'

>>> datetime(2019, 5, 18, 15, 17, tzinfo=timezone.utc).isoformat()

'2019-05-18T15:17:00+00:00'



The optional argument sep (default 'T') is a one-character separator, placed between the date and time portions

of the result. For example:

>>> from datetime import tzinfo, timedelta, datetime

>>> class TZ(tzinfo):

... """A time zone with an arbitrary, constant -06:39 offset."""

... def utcoffset(self, dt):

... return timedelta(hours=-6, minutes=-39)

...

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> datetime(2002, 12, 25, tzinfo=TZ()).isoformat(' ')

'2002-12-25 00:00:00-06:39'

>>> datetime(2009, 11, 27, microsecond=100, tzinfo=TZ()).isoformat()

'2009-11-27T00:00:00.000100-06:39'



The optional argument timespec specifies the number of additional components of the time to include (the

default is 'auto'). It can be one of the following:

• 'auto': Same as 'seconds' if microsecond is 0, same as 'microseconds' otherwise.

• 'hours': Include the hour in the two-digit HH format.

• 'minutes': Include hour and minute in HH:MM format.

• 'seconds': Include hour, minute, and second in HH:MM:SS format.

• 'milliseconds': Include full time, but truncate fractional second part to milliseconds. HH:MM:SS.

sss format.

• 'microseconds': Include full time in HH:MM:SS.ffffff format.



® Note

Excluded time components are truncated, not rounded.



ValueError will be raised on an invalid timespec argument:

>>> from datetime import datetime

>>> datetime.now().isoformat(timespec='minutes')

'2002-12-25T00:00'

>>> dt = datetime(2015, 1, 1, 12, 30, 59, 0)

>>> dt.isoformat(timespec='microseconds')

'2015-01-01T12:30:59.000000'



Changed in version 3.6: Added the timespec parameter.

datetime.__str__()

For a datetime instance d, str(d) is equivalent to d.isoformat(' ').

datetime.ctime()

Return a string representing the date and time:

>>> from datetime import datetime

>>> datetime(2002, 12, 4, 20, 30, 40).ctime()

'Wed Dec 4 20:30:40 2002'



The output string will not include time zone information, regardless of whether the input is aware or naive.

d.ctime() is equivalent to:

time.ctime(time.mktime(d.timetuple()))



on platforms where the native C ctime() function (which time.ctime() invokes, but which datetime.

ctime() does not invoke) conforms to the C standard.

datetime.strftime(format)

Return a string representing the date and time, controlled by an explicit format string. See also strftime() and

strptime() Behavior and datetime.isoformat().



The Python Library Reference, Release 3.13.2



datetime.__format__(format)

Same as datetime.strftime(). This makes it possible to specify a format string for a datetime object

in formatted string literals and when using str.format(). See also strftime() and strptime() Behavior and

datetime.isoformat() .



Examples of Usage: datetime

Examples of working with datetime objects:

>>> from datetime import datetime, date, time, timezone

>>> # Using datetime.combine()

>>> d = date(2005, 7, 14)

>>> t = time(12, 30)

>>> datetime.combine(d, t)

datetime.datetime(2005, 7, 14, 12, 30)

>>> # Using datetime.now()

>>> datetime.now()

datetime.datetime(2007, 12, 6, 16, 29, 43, 79043) # GMT +1 >>> datetime.now(timezone.utc)

datetime.datetime(2007, 12, 6, 15, 29, 43, 79060, tzinfo=datetime.timezone.utc)

>>> # Using datetime.strptime()

>>> dt = datetime.strptime("21/11/06 16:30", "%d/%m/%y %H:%M") >>> dt

datetime.datetime(2006, 11, 21, 16, 30)

>>> # Using datetime.timetuple() to get tuple of all attributes >>> tt = dt.timetuple()

>>> for it in tt:

... print(it)

...

2006 # year

11 # month

21 # day

16 # hour

30 # minute

0 # second

1 # weekday (0 = Monday)

325 # number of days since 1st January

-1 # dst - method tzinfo.dst() returned None

>>> # Date in ISO format

>>> ic = dt.isocalendar()

>>> for it in ic:

... print(it)

...

2006 # ISO year

47 # ISO week

2 # ISO weekday

>>> # Formatting a datetime

>>> dt.strftime("%A, %d. %B %Y %I:%M%p")

'Tuesday, 21. November 2006 04:30PM'

>>> 'The {1} is {0:%d}, the {2} is {0:%B}, the {3} is {0:%I:%M%p}.'.format(dt, "day

, →", "month", "time")

'The day is 21, the month is November, the time is 04:30PM.'

The Python Library Reference, Release 3.13.2



The example below defines a tzinfo subclass capturing time zone information for Kabul, Afghanistan, which used +4 UTC until 1945 and then +4:30 UTC thereafter:

from datetime import timedelta, datetime, tzinfo, timezone

class KabulTz(tzinfo):

# Kabul used +4 until 1945, when they moved to +4:30

UTC_MOVE_DATE = datetime(1944, 12, 31, 20, tzinfo=timezone.utc)

def utcoffset(self, dt):

if dt.year < 1945:

return timedelta(hours=4)

elif (1945, 1, 1, 0, 0) <= dt.timetuple()[:5] < (1945, 1, 1, 0, 30):

# An ambiguous ("imaginary") half-hour range representing # a 'fold' in time due to the shift from +4 to +4:30. # If dt falls in the imaginary range, use fold to decide how # to resolve. See PEP495.

return timedelta(hours=4, minutes=(30 if dt.fold else 0))

else:

return timedelta(hours=4, minutes=30)

def fromutc(self, dt):

# Follow same validations as in datetime.tzinfo

if not isinstance(dt, datetime):

raise TypeError("fromutc() requires a datetime argument")

if dt.tzinfo is not self:

raise ValueError("dt.tzinfo is not self")

# A custom implementation is required for fromutc as # the input to this function is a datetime with utc values # but with a tzinfo set to self.

# See datetime.astimezone or fromtimestamp.

if dt.replace(tzinfo=timezone.utc) >= self.UTC_MOVE_DATE:

return dt + timedelta(hours=4, minutes=30)

else:

return dt + timedelta(hours=4)

def dst(self, dt):

# Kabul does not observe daylight saving time.

return timedelta(0)

def tzname(self, dt):

if dt >= self.UTC_MOVE_DATE:

return "+04:30"

return "+04"



Usage of KabulTz from above:

>>> tz1 = KabulTz()

>>> # Datetime before the change

>>> dt1 = datetime(1900, 11, 21, 16, 30, tzinfo=tz1)

>>> print(dt1.utcoffset())

4:00:00

>>> # Datetime after the change

>>> dt2 = datetime(2006, 6, 14, 13, 0, tzinfo=tz1)

>>> print(dt2.utcoffset())

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

4:30:00

>>> # Convert datetime to another time zone

>>> dt3 = dt2.astimezone(timezone.utc)

>>> dt3

datetime.datetime(2006, 6, 14, 8, 30, tzinfo=datetime.timezone.utc) >>> dt2

datetime.datetime(2006, 6, 14, 13, 0, tzinfo=KabulTz()) >>> dt2 == dt3

True



8.1.7 time Objects

A time object represents a (local) time of day, independent of any particular day, and subject to adjustment via a

tzinfo object.

class datetime.time(hour=0, minute=0, second=0, microsecond=0, tzinfo=None, *, fold=0)

All arguments are optional. tzinfo may be None, or an instance of a tzinfo subclass. The remaining arguments

must be integers in the following ranges:

• 0 <= hour < 24,

• 0 <= minute < 60,

• 0 <= second < 60,

• 0 <= microsecond < 1000000,

• fold in [0, 1].

If an argument outside those ranges is given, ValueError is raised. All default to 0 except tzinfo, which

defaults to None.

Class attributes:

time.min

The earliest representable time, time(0, 0, 0, 0).

time.max

The latest representable time, time(23, 59, 59, 999999).

time.resolution

The smallest possible difference between non-equal time objects, timedelta(microseconds=1), although

note that arithmetic on time objects is not supported.

Instance attributes (read-only):

time.hour

In range(24).

time.minute

In range(60).

time.second

In range(60).

time.microsecond

In range(1000000).

time.tzinfo

The object passed as the tzinfo argument to the time constructor, or None if none was passed.

The Python Library Reference, Release 3.13.2



time.fold

In [0, 1]. Used to disambiguate wall times during a repeated interval. (A repeated interval occurs when

clocks are rolled back at the end of daylight saving time or when the UTC offset for the current zone is decreased

for political reasons.) The values 0 and 1 represent, respectively, the earlier and later of the two moments with

the same wall time representation.

Added in version 3.6.

time objects support equality and order comparisons, where a is considered less than b when a precedes b in time.

Naive and aware time objects are never equal. Order comparison between naive and aware time objects raises

TypeError.

If both comparands are aware, and have the same tzinfo attribute, the tzinfo and fold attributes are ignored and the base times are compared. If both comparands are aware and have different tzinfo attributes, the comparands are first adjusted by subtracting their UTC offsets (obtained from self.utcoffset()).

Changed in version 3.3: Equality comparisons between aware and naive time instances don’t raise TypeError.

In Boolean contexts, a time object is always considered to be true.

Changed in version 3.5: Before Python 3.5, a time object was considered to be false if it represented midnight in

UTC. This behavior was considered obscure and error-prone and has been removed in Python 3.5. See bpo-13936 for full details.

Other constructor:

classmethod time.fromisoformat(time_string)

Return a time corresponding to a time_string in any valid ISO 8601 format, with the following exceptions:

1. Time zone offsets may have fractional seconds.

2. The leading T, normally required in cases where there may be ambiguity between a date and a time, is

not required.

3. Fractional seconds may have any number of digits (anything beyond 6 will be truncated).

4. Fractional hours and minutes are not supported.

Examples:

>>> from datetime import time

>>> time.fromisoformat('04:23:01')

datetime.time(4, 23, 1)

>>> time.fromisoformat('T04:23:01')

datetime.time(4, 23, 1)

>>> time.fromisoformat('T042301')

datetime.time(4, 23, 1)

>>> time.fromisoformat('04:23:01.000384')

datetime.time(4, 23, 1, 384)

>>> time.fromisoformat('04:23:01,000384')

datetime.time(4, 23, 1, 384)

>>> time.fromisoformat('04:23:01+04:00')

datetime.time(4, 23, 1, tzinfo=datetime.timezone(datetime.

, →timedelta(seconds=14400)))

>>> time.fromisoformat('04:23:01Z')

datetime.time(4, 23, 1, tzinfo=datetime.timezone.utc)

>>> time.fromisoformat('04:23:01+00:00')

datetime.time(4, 23, 1, tzinfo=datetime.timezone.utc)



Added in version 3.7.

Changed in version 3.11: Previously, this method only supported formats that could be emitted by time.

isoformat().

Instance methods:

The Python Library Reference, Release 3.13.2



time.replace(hour=self.hour, minute=self.minute, second=self.second, microsecond=self.microsecond,

tzinfo=self.tzinfo, *, fold=0)

Return a time with the same value, except for those attributes given new values by whichever keyword argu-

ments are specified. Note that tzinfo=None can be specified to create a naive time from an aware time,

without conversion of the time data.

time objects are also supported by generic function copy.replace().

Changed in version 3.6: Added the fold parameter.

time.isoformat(timespec=’auto’)

Return a string representing the time in ISO 8601 format, one of:

• HH:MM:SS.ffffff, if microsecond is not 0

• HH:MM:SS, if microsecond is 0

• HH:MM:SS.ffffff+HH:MM[:SS[.ffffff]], if utcoffset() does not return None

• HH:MM:SS+HH:MM[:SS[.ffffff]], if microsecond is 0 and utcoffset() does not return None

The optional argument timespec specifies the number of additional components of the time to include (the

default is 'auto'). It can be one of the following:

• 'auto': Same as 'seconds' if microsecond is 0, same as 'microseconds' otherwise.

• 'hours': Include the hour in the two-digit HH format.

• 'minutes': Include hour and minute in HH:MM format.

• 'seconds': Include hour, minute, and second in HH:MM:SS format.

• 'milliseconds': Include full time, but truncate fractional second part to milliseconds. HH:MM:SS.

sss format.

• 'microseconds': Include full time in HH:MM:SS.ffffff format.



® Note

Excluded time components are truncated, not rounded.



ValueError will be raised on an invalid timespec argument.

Example:

>>> from datetime import time

>>> time(hour=12, minute=34, second=56, microsecond=123456).isoformat(timespec=

, →'minutes')

'12:34'

>>> dt = time(hour=12, minute=34, second=56, microsecond=0)

>>> dt.isoformat(timespec='microseconds')

'12:34:56.000000'

>>> dt.isoformat(timespec='auto')

'12:34:56'



Changed in version 3.6: Added the timespec parameter.

time.__str__()

For a time t, str(t) is equivalent to t.isoformat().

time.strftime(format)

Return a string representing the time, controlled by an explicit format string. See also strftime() and strptime()

Behavior and time.isoformat().

The Python Library Reference, Release 3.13.2



time.__format__(format)

Same as time.strftime(). This makes it possible to specify a format string for a time object in format-

ted string literals and when using str.format(). See also strftime() and strptime() Behavior and time.

isoformat().

time.utcoffset()

If tzinfo is None, returns None, else returns self.tzinfo.utcoffset(None), and raises an exception

if the latter doesn’t return None or a timedelta object with magnitude less than one day.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes.

time.dst()

If tzinfo is None, returns None, else returns self.tzinfo.dst(None), and raises an exception if the

latter doesn’t return None, or a timedelta object with magnitude less than one day.

Changed in version 3.7: The DST offset is not restricted to a whole number of minutes.

time.tzname()

If tzinfo is None, returns None, else returns self.tzinfo.tzname(None), or raises an exception if the

latter doesn’t return None or a string object.



Examples of Usage: time

Examples of working with a time object:

>>> from datetime import time, tzinfo, timedelta

>>> class TZ1(tzinfo):

... def utcoffset(self, dt):

... return timedelta(hours=1)

... def dst(self, dt):

... return timedelta(0)

... def tzname(self,dt):

... return "+01:00"

... def __repr__(self):

... return f"{self.__class__.__name__}()"

...

>>> t = time(12, 10, 30, tzinfo=TZ1())

>>> t

datetime.time(12, 10, 30, tzinfo=TZ1())

>>> t.isoformat()

'12:10:30+01:00'

>>> t.dst()

datetime.timedelta(0)

>>> t.tzname()

'+01:00'

>>> t.strftime("%H:%M:%S %Z")

'12:10:30 +01:00'

>>> 'The {} is {:%H:%M}.'.format("time", t)

'The time is 12:10.'



8.1.8 tzinfo Objects

class datetime.tzinfo

This is an abstract base class, meaning that this class should not be instantiated directly. Define a subclass of

tzinfo to capture information about a particular time zone.

An instance of (a concrete subclass of) tzinfo can be passed to the constructors for datetime and time

objects. The latter objects view their attributes as being in local time, and the tzinfo object supports methods

revealing offset of local time from UTC, the name of the time zone, and DST offset, all relative to a date or

time object passed to them.

The Python Library Reference, Release 3.13.2



You need to derive a concrete subclass, and (at least) supply implementations of the standard tzinfo methods

needed by the datetime methods you use. The datetime module provides timezone, a simple concrete

subclass of tzinfo which can represent time zones with fixed offset from UTC such as UTC itself or North

American EST and EDT.

Special requirement for pickling: A tzinfo subclass must have an __init__() method that can be called

with no arguments, otherwise it can be pickled but possibly not unpickled again. This is a technical requirement

that may be relaxed in the future.

A concrete subclass of tzinfo may need to implement the following methods. Exactly which methods are

needed depends on the uses made of aware datetime objects. If in doubt, simply implement all of them.

tzinfo.utcoffset(dt)

Return offset of local time from UTC, as a timedelta object that is positive east of UTC. If local time is

west of UTC, this should be negative.

This represents the total offset from UTC; for example, if a tzinfo object represents both time zone

and DST adjustments, utcoffset() should return their sum. If the UTC offset isn’t known, return

None . Else the value returned must be a timedelta object strictly between-timedelta(hours=24)

and timedelta(hours=24) (the magnitude of the offset must be less than one day). Most implementations

of utcoffset() will probably look like one of these two:

return CONSTANT # fixed-offset class

return CONSTANT + self.dst(dt) # daylight-aware class



If utcoffset() does not return None, dst() should not return None either.

The default implementation of utcoffset() raises NotImplementedError.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes.

tzinfo.dst(dt)

Return the daylight saving time (DST) adjustment, as a timedelta object or None if DST information isn’t

known.

Return timedelta(0) if DST is not in effect. If DST is in effect, return the offset as a timedelta object

(see utcoffset() for details). Note that DST offset, if applicable, has already been added to the UTC offset

returned by utcoffset(), so there’s no need to consult dst() unless you’re interested in obtaining DST info

separately. For example, datetime.timetuple() calls its tzinfo attribute’s dst() method to determine

how the tm_isdst flag should be set, and tzinfo.fromutc() calls dst() to account for DST changes

when crossing time zones.

An instance tz of a tzinfo subclass that models both standard and daylight times must be consistent in this

sense:

tz.utcoffset(dt) - tz.dst(dt)

must return the same result for every datetime dt with dt.tzinfo == tz. For sane tzinfo subclasses,

this expression yields the time zone’s “standard offset”, which should not depend on the date or the time, but

only on geographic location. The implementation of datetime.astimezone() relies on this, but cannot

detect violations; it’s the programmer’s responsibility to ensure it. If a tzinfo subclass cannot guarantee

this, it may be able to override the default implementation of tzinfo.fromutc() to work correctly with

astimezone() regardless.

Most implementations of dst() will probably look like one of these two:

def dst(self, dt):

# a fixed-offset class: doesn't account for DST

return timedelta(0)



or:



The Python Library Reference, Release 3.13.2



def dst(self, dt):

# Code to set dston and dstoff to the time zone's DST # transition times based on the input dt.year, and expressed # in standard local time.

if dston <= dt.replace(tzinfo=None) < dstoff:

return timedelta(hours=1)

else:

return timedelta(0)



The default implementation of dst() raises NotImplementedError.

Changed in version 3.7: The DST offset is not restricted to a whole number of minutes.

tzinfo.tzname(dt)

Return the time zone name corresponding to the datetime object dt, as a string. Nothing about string names is

defined by the datetime module, and there’s no requirement that it mean anything in particular. For example,

"GMT" , "UTC", "-500", "-5:00", "EDT", "US/Eastern", "America/New York" are all valid replies.

Return None if a string name isn’t known. Note that this is a method rather than a fixed string primarily

because some tzinfo subclasses will wish to return different names depending on the specific value of dt

passed, especially if the tzinfo class is accounting for daylight time.

The default implementation of tzname() raises NotImplementedError.

These methods are called by a datetime or time object, in response to their methods of the same names. A

datetime object passes itself as the argument, and a time object passes None as the argument. A tzinfo subclass’s

methods should therefore be prepared to accept a dt argument of None, or of class datetime.

When None is passed, it’s up to the class designer to decide the best response. For example, returning None is

appropriate if the class wishes to say that time objects don’t participate in the tzinfo protocols. It may be more useful for utcoffset(None) to return the standard UTC offset, as there is no other convention for discovering the standard offset.

When a datetime object is passed in response to a datetime method, dt.tzinfo is the same object as self.

tzinfo methods can rely on this, unless user code calls tzinfo methods directly. The intent is that the tzinfo methods interpret dt as being in local time, and not need worry about objects in other time zones.

There is one more tzinfo method that a subclass may wish to override:

tzinfo.fromutc(dt)

This is called from the default datetime.astimezone() implementation. When called from that, dt.

tzinfo is self, and dt’s date and time data are to be viewed as expressing a UTC time. The purpose of

fromutc() is to adjust the date and time data, returning an equivalent datetime in self’s local time.

Most tzinfo subclasses should be able to inherit the default fromutc() implementation without problems.

It’s strong enough to handle fixed-offset time zones, and time zones accounting for both standard and daylight

time, and the latter even if the DST transition times differ in different years. An example of a time zone the

default fromutc() implementation may not handle correctly in all cases is one where the standard offset

(from UTC) depends on the specific date and time passed, which can happen for political reasons. The default

implementations of astimezone() and fromutc() may not produce the result you want if the result is one

of the hours straddling the moment the standard offset changes.

Skipping code for error cases, the default fromutc() implementation acts like:

def fromutc(self, dt):

# raise ValueError error if dt.tzinfo is not self

dtoff = dt.utcoffset()

dtdst = dt.dst()

# raise ValueError if dtoff is None or dtdst is None delta = dtoff-dtdst # this is self's standard offset

if delta:

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

dt += delta # convert to standard local time

dtdst = dt.dst()

# raise ValueError if dtdst is None

if dtdst:

return dt + dtdst

else:

return dt



In the following tzinfo_examples.py file there are some examples of tzinfo classes:

from datetime import tzinfo, timedelta, datetime

ZERO = timedelta(0)

HOUR = timedelta(hours=1)

SECOND = timedelta(seconds=1)

# A class capturing the platform's idea of local time. # (May result in wrong values on historical times in # timezones where UTC offset and/or the DST rules had # changed in the past.)

import time as _time

STDOFFSET = timedelta(seconds = -_time.timezone)

if _time.daylight:

DSTOFFSET = timedelta(seconds = -_time.altzone)

else:

DSTOFFSET = STDOFFSET

DSTDIFF = DSTOFFSET-STDOFFSET

class LocalTimezone(tzinfo):

def fromutc(self, dt):

assert dt.tzinfo is self

stamp = (dt-datetime(1970, 1, 1, tzinfo=self)) // SECOND args = _time.localtime(stamp)[:6]

dst_diff = DSTDIFF // SECOND

# Detect fold

fold = (args == _time.localtime(stamp-dst_diff))

return datetime(*args, microsecond=dt.microsecond,

tzinfo=self, fold=fold)

def utcoffset(self, dt):

if self._isdst(dt):

return DSTOFFSET

else:

return STDOFFSET

def dst(self, dt):

if self._isdst(dt):

return DSTDIFF

else:

return ZERO

def tzname(self, dt):

return _time.tzname[self._isdst(dt)]

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)



def _isdst(self, dt):

tt = (dt.year, dt.month, dt.day,

dt.hour, dt.minute, dt.second,

dt.weekday(), 0, 0)

stamp = _time.mktime(tt)

tt = _time.localtime(stamp)

return tt.tm_isdst > 0

Local = LocalTimezone()



# A complete implementation of current DST rules for major US time zones.

def first_sunday_on_or_after(dt):

days_to_go = 6-dt.weekday()

if days_to_go:

dt += timedelta(days_to_go)

return dt



# US DST Rules

#

# This is a simplified (i.e., wrong for a few cases) set of rules for US # DST start and end times. For a complete and up-to-date set of DST rules # and timezone definitions, visit the Olson Database (or try pytz): # http://www.twinsun.com/tz/tz-link.htm

# https://sourceforge.net/projects/pytz/ (might not be up-to-date) #

# In the US, since 2007, DST starts at 2am (standard time) on the second # Sunday in March, which is the first Sunday on or after Mar 8. DSTSTART_2007 = datetime(1, 3, 8, 2)

# and ends at 2am (DST time) on the first Sunday of Nov. DSTEND_2007 = datetime(1, 11, 1, 2)

# From 1987 to 2006, DST used to start at 2am (standard time) on the first # Sunday in April and to end at 2am (DST time) on the last # Sunday of October, which is the first Sunday on or after Oct 25. DSTSTART_1987_2006 = datetime(1, 4, 1, 2)

DSTEND_1987_2006 = datetime(1, 10, 25, 2)

# From 1967 to 1986, DST used to start at 2am (standard time) on the last # Sunday in April (the one on or after April 24) and to end at 2am (DST time) # on the last Sunday of October, which is the first Sunday # on or after Oct 25.

DSTSTART_1967_1986 = datetime(1, 4, 24, 2)

DSTEND_1967_1986 = DSTEND_1987_2006

def us_dst_range(year):

# Find start and end times for US DST. For years before 1967, return

# start = end for no DST.

if 2006 < year:

dststart, dstend = DSTSTART_2007, DSTEND_2007

elif 1986 < year < 2007:

dststart, dstend = DSTSTART_1987_2006, DSTEND_1987_2006

elif 1966 < year < 1987:

dststart, dstend = DSTSTART_1967_1986, DSTEND_1967_1986

else:

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

return (datetime(year, 1, 1), ) * 2

start = first_sunday_on_or_after(dststart.replace(year=year))

end = first_sunday_on_or_after(dstend.replace(year=year))

return start, end



class USTimeZone(tzinfo):

def __init__(self, hours, reprname, stdname, dstname):

self.stdoffset = timedelta(hours=hours)

self.reprname = reprname

self.stdname = stdname

self.dstname = dstname

def __repr__(self):

return self.reprname

def tzname(self, dt):

if self.dst(dt):

return self.dstname

else:

return self.stdname

def utcoffset(self, dt):

return self.stdoffset + self.dst(dt)

def dst(self, dt):

if dt is None or dt.tzinfo is None:

# An exception may be sensible here, in one or both cases. # It depends on how you want to treat them. The default # fromutc() implementation (called by the default astimezone() # implementation) passes a datetime with dt.tzinfo is self. return ZERO

assert dt.tzinfo is self

start, end = us_dst_range(dt.year)

# Can't compare naive to aware objects, so strip the timezone from # dt first.

dt = dt.replace(tzinfo=None)

if start + HOUR <= dt < end-HOUR:

# DST is in effect.

return HOUR

if end-HOUR <= dt < end:

# Fold (an ambiguous hour): use dt.fold to disambiguate. return ZERO if dt.fold else HOUR

if start <= dt < start + HOUR:

# Gap (a non-existent hour): reverse the fold rule. return HOUR if dt.fold else ZERO

# DST is off.

return ZERO

def fromutc(self, dt):

assert dt.tzinfo is self

start, end = us_dst_range(dt.year)

start = start.replace(tzinfo=self)

end = end.replace(tzinfo=self)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

std_time = dt + self.stdoffset

dst_time = std_time + HOUR

if end <= dst_time < end + HOUR:

# Repeated hour

return std_time.replace(fold=1)

if std_time < start or dst_time >= end:

# Standard time

return std_time

if start <= std_time < end-HOUR:

# Daylight saving time

return dst_time



Eastern = USTimeZone(-5, "Eastern", "EST", "EDT")

Central = USTimeZone(-6, "Central", "CST", "CDT")

Mountain = USTimeZone(-7, "Mountain", "MST", "MDT")

Pacific = USTimeZone(-8, "Pacific", "PST", "PDT")



Note that there are unavoidable subtleties twice per year in a tzinfo subclass accounting for both standard and daylight time, at the DST transition points. For concreteness, consider US Eastern (UTC -0500), where EDT begins the minute after 1:59 (EST) on the second Sunday in March, and ends the minute after 1:59 (EDT) on the first Sunday in November:

UTC 3:MM 4:MM 5:MM 6:MM 7:MM 8:MM

EST 22:MM 23:MM 0:MM 1:MM 2:MM 3:MM

EDT 23:MM 0:MM 1:MM 2:MM 3:MM 4:MM

start 22:MM 23:MM 0:MM 1:MM 3:MM 4:MM

end 23:MM 0:MM 1:MM 1:MM 2:MM 3:MM



When DST starts (the “start” line), the local wall clock leaps from 1:59 to 3:00. A wall time of the form 2:MM doesn’t really make sense on that day, so astimezone(Eastern) won’t deliver a result with hour == 2 on the day DST begins. For example, at the Spring forward transition of 2016, we get:

>>> from datetime import datetime, timezone

>>> from tzinfo_examples import HOUR, Eastern

>>> u0 = datetime(2016, 3, 13, 5, tzinfo=timezone.utc)

>>> for i in range(4):

... u = u0 + i*HOUR

... t = u.astimezone(Eastern)

... print(u.time(), 'UTC =', t.time(), t.tzname())

...

05:00:00 UTC = 00:00:00 EST

06:00:00 UTC = 01:00:00 EST

07:00:00 UTC = 03:00:00 EDT

08:00:00 UTC = 04:00:00 EDT



When DST ends (the “end” line), there’s a potentially worse problem: there’s an hour that can’t be spelled unambigu-ously in local wall time: the last hour of daylight time. In Eastern, that’s times of the form 5:MM UTC on the day daylight time ends. The local wall clock leaps from 1:59 (daylight time) back to 1:00 (standard time) again. Local

times of the form 1:MM are ambiguous. astimezone() mimics the local clock’s behavior by mapping two adjacent UTC hours into the same local hour then. In the Eastern example, UTC times of the form 5:MM and 6:MM both

map to 1:MM when converted to Eastern, but earlier times have the fold attribute set to 0 and the later times have it set to 1. For example, at the Fall back transition of 2016, we get:



The Python Library Reference, Release 3.13.2



>>> u0 = datetime(2016, 11, 6, 4, tzinfo=timezone.utc)

>>> for i in range(4):

... u = u0 + i*HOUR

... t = u.astimezone(Eastern)

... print(u.time(), 'UTC =', t.time(), t.tzname(), t.fold) ...

04:00:00 UTC = 00:00:00 EDT 0

05:00:00 UTC = 01:00:00 EDT 0

06:00:00 UTC = 01:00:00 EST 1

07:00:00 UTC = 02:00:00 EST 0



Note that the datetime instances that differ only by the value of the fold attribute are considered equal in com-parisons.

Applications that can’t bear wall-time ambiguities should explicitly check the value of the fold attribute or avoid

using hybrid tzinfo subclasses; there are no ambiguities when using timezone, or any other fixed-offset tzinfo subclass (such as a class representing only EST (fixed offset -5 hours), or only EDT (fixed offset -4 hours)).



µ See also

zoneinfo

The datetime module has a basic timezone class (for handling arbitrary fixed offsets from

UTC) and its timezone.utc attribute (a UTC timezone instance).

zoneinfo brings the IANA time zone database (also known as the Olson database) to Python, and its usage is recommended.

IANA time zone database

The Time Zone Database (often called tz, tzdata or zoneinfo) contains code and data that represent the history of local time for many representative locations around the globe. It is updated periodically to reflect changes made by political bodies to time zone boundaries, UTC offsets, and daylight-saving rules.



8.1.9 timezone Objects

The timezone class is a subclass of tzinfo, each instance of which represents a time zone defined by a fixed offset from UTC.

Objects of this class cannot be used to represent time zone information in the locations where different offsets are used in different days of the year or where historical changes have been made to civil time.

class datetime.timezone(offset, name=None)

The offset argument must be specified as a timedelta object representing the difference between the local

time and UTC. It must be strictly between-timedelta(hours=24) and timedelta(hours=24), other-

wise ValueError is raised.

The name argument is optional. If specified it must be a string that will be used as the value returned by the

datetime.tzname() method.

Added in version 3.2.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes.

timezone.utcoffset(dt)

Return the fixed value specified when the timezone instance is constructed.

The dt argument is ignored. The return value is a timedelta instance equal to the difference between the

local time and UTC.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes.



The Python Library Reference, Release 3.13.2



timezone.tzname(dt)

Return the fixed value specified when the timezone instance is constructed.

If name is not provided in the constructor, the name returned by tzname(dt) is generated from the value of

the offset as follows. If offset is timedelta(0), the name is “UTC”, otherwise it is a string in the format

UTC±HH:MM, where ± is the sign of offset, HH and MM are two digits of offset.hours and offset.

minutes respectively.

Changed in version 3.6: Name generated from offset=timedelta(0) is now plain 'UTC', not

'UTC+00:00'.

timezone.dst(dt)

Always returns None.

timezone.fromutc(dt)

Return dt + offset. The dt argument must be an aware datetime instance, with tzinfo set to self.

Class attributes:

timezone.utc

The UTC time zone, timezone(timedelta(0)).



8.1.10 strftime() and strptime() Behavior

date, datetime, and time objects all support a strftime(format) method, to create a string representing the time under the control of an explicit format string.

Conversely, the datetime.strptime() class method creates a datetime object from a string representing a date and time and a corresponding format string.

The table below provides a high-level comparison of strftime() versus strptime():



strftime strptime

Usage Convert object to a string according to a Parse a string into a datetime object given a corre-

given format sponding format

Type of Instance method Class method

method

Method of date; datetime; time datetime

Signature strftime(format) strptime(date_string, format)



strftime() and strptime() Format Codes

These methods accept format codes that can be used to parse and format dates:

>>> datetime.strptime('31/01/22 23:59:59.999999',

... '%d/%m/%y %H:%M:%S.%f')

datetime.datetime(2022, 1, 31, 23, 59, 59, 999999) >>> _.strftime('%a %d %b %Y, %I:%M%p')

'Mon 31 Jan 2022, 11:59PM'



The following is a list of all the format codes that the 1989 C standard requires, and these work on all platforms with a standard C implementation.



The Python Library Reference, Release 3.13.2



Directive Meaning Example Notes

%a Weekday as locale’s ab- (1)

breviated name.

Sun, Mon, …, Sat

(en_US);

So, Mo, …, Sa (de_DE)

%A Weekday as locale’s full (1)

name.

Sunday, Monday, …,

Saturday (en_US);

Sonntag, Montag, …,

Samstag (de_DE)

%w Weekday as a decimal 0, 1, …, 6

number, where 0 is Sun-

day and 6 is Saturday.

%d Day of the month as 01, 02, …, 31 (9)

a zero-padded decimal

number.

%b Month as locale’s abbrevi- (1)

ated name.

Jan, Feb, …, Dec

(en_US);

Jan, Feb, …, Dez

(de_DE)

%B Month as locale’s full (1)

name.

January, February, …,

December (en_US);

Januar, Februar, …,

Dezember (de_DE)

%m Month as a zero-padded 01, 02, …, 12 (9)

decimal number.

%y Year without century as 00, 01, …, 99 (9)

a zero-padded decimal

number.

%Y Year with century as a 0001, 0002, …, 2013, (2)

decimal number. 2014, …, 9998, 9999

%H Hour (24-hour clock) as 00, 01, …, 23 (9)

a zero-padded decimal

number.

%I Hour (12-hour clock) as 01, 02, …, 12 (9)

a zero-padded decimal

number.

%p Locale’s equivalent of ei- (1), (3)

ther AM or PM.

AM, PM (en_US);

am, pm (de_DE)

%M Minute as a zero-padded 00, 01, …, 59 (9)

decimal number.

%S Second as a zero-padded 00, 01, …, 59 (4), (9)

decimal number.

%f Microsecond as a decimal 000000, 000001, …, (5)

number, zero-padded to 6 999999

digits.

%z UTC offset in the form (empty), +0000, -0400, (6)

8.1. datetime — Basic date and time types ±HHMM[SS[.ffffff]] +1030, +063415, - 237

The Python Library Reference, Release 3.13.2



Several additional directives not required by the C89 standard are included for convenience. These parameters all correspond to ISO 8601 date values.



Di- Meaning Example Notes

rec-

tive

%G ISO 8601 year with century representing the year that contains 0001, 0002, …, 2013, 2014, …, (8)

the greater part of the ISO week (%V). 9998, 9999

%u ISO 8601 weekday as a decimal number where 1 is Monday. 1, 2, …, 7

%V ISO 8601 week as a decimal number with Monday as the first 01, 02, …, 53 (8),

day of the week. Week 01 is the week containing Jan 4. (9)

%:z UTC offset in the form ±HH:MM[:SS[.ffffff]] (empty (empty), +00:00, -04:00, +10:30, (6)

string if the object is naive). +06:34:15, -03:07:12.345216



These may not be available on all platforms when used with the strftime() method. The ISO 8601 year and ISO

8601 week directives are not interchangeable with the year and week number directives above. Calling strptime()

with incomplete or ambiguous ISO 8601 directives will raise a ValueError.

The full set of format codes supported varies across platforms, because Python calls the platform C library’s strftime() function, and platform variations are common. To see the full set of format codes supported on your

platform, consult the strftime(3) documentation. There are also differences between platforms in handling of unsupported format specifiers.

Added in version 3.6: %G, %u and %V were added.

Added in version 3.12: %:z was added.



Technical Detail

Broadly speaking, d.strftime(fmt) acts like the time module’s time.strftime(fmt, d.timetuple())

although not all objects support a timetuple() method.

For the datetime.strptime() class method, the default value is 1900-01-01T00:00:00.000: any components

not specified in the format string will be pulled from the default value.4

Using datetime.strptime(date_string, format) is equivalent to:

datetime(*(time.strptime(date_string, format)[0:6]))



except when the format includes sub-second components or time zone offset information, which are supported in datetime.strptime but are discarded by time.strptime.

For time objects, the format codes for year, month, and day should not be used, as time objects have no such values. If they’re used anyway, 1900 is substituted for the year, and 1 for the month and day.

For date objects, the format codes for hours, minutes, seconds, and microseconds should not be used, as date objects have no such values. If they’re used anyway, 0 is substituted for them.

For the same reason, handling of format strings containing Unicode code points that can’t be represented in the charset of the current locale is also platform-dependent. On some platforms such code points are preserved intact in

the output, while on others strftime may raise UnicodeError or return an empty string instead.

Notes:

(1) Because the format depends on the current locale, care should be taken when making assumptions about the

output value. Field orderings will vary (for example, “month/day/year” versus “day/month/year”), and the

output may contain non-ASCII characters.

(2) The strptime() method can parse years in the full [1, 9999] range, but years < 1000 must be zero-filled to

4-digit width.

Changed in version 3.2: In previous versions, strftime() method was restricted to years >= 1900.

4 Passing datetime.strptime('Feb 29', '%b %d') will fail since 1900 is not a leap year.

The Python Library Reference, Release 3.13.2



Changed in version 3.3: In version 3.2, strftime() method was restricted to years >= 1000.

(3) When used with the strptime() method, the %p directive only affects the output hour field if the %I directive

is used to parse the hour.

(4) Unlike the time module, the datetime module does not support leap seconds.

(5) When used with the strptime() method, the %f directive accepts from one to six digits and zero pads on

the right. %f is an extension to the set of format characters in the C standard (but implemented separately in

datetime objects, and therefore always available).

(6) For a naive object, the %z, %:z and %Z format codes are replaced by empty strings.

For an aware object:

%z

utcoffset() is transformed into a string of the form ±HHMM[SS[.ffffff]], where HH is a 2-digit string giving the number of UTC offset hours, MM is a 2-digit string giving the number of UTC offset minutes, SS is a 2-digit string giving the number of UTC offset seconds and ffffff is a 6-digit string giving the number of UTC offset microseconds. The ffffff part is omitted when the offset is a whole number of seconds and both the ffffff and the SS part is omitted when the offset is a whole number

of minutes. For example, if utcoffset() returns timedelta(hours=-3, minutes=-30), %z is replaced with the string '-0330'.

Changed in version 3.7: The UTC offset is not restricted to a whole number of minutes.

Changed in version 3.7: When the %z directive is provided to the strptime() method, the UTC offsets can

have a colon as a separator between hours, minutes and seconds. For example, '+01:00:00' will be parsed

as an offset of one hour. In addition, providing 'Z' is identical to '+00:00'.

%:z

Behaves exactly as %z, but has a colon separator added between hours, minutes and seconds.

%Z

In strftime(), %Z is replaced by an empty string if tzname() returns None; otherwise %Z is replaced by the returned value, which must be a string.

strptime() only accepts certain values for %Z:

1. any value in time.tzname for your machine’s locale

2. the hard-coded values UTC and GMT

So someone living in Japan may have JST, UTC, and GMT as valid values, but probably not EST. It will raise ValueError for invalid values.

Changed in version 3.2: When the %z directive is provided to the strptime() method, an aware datetime

object will be produced. The tzinfo of the result will be set to a timezone instance.

(7) When used with the strptime() method, %U and %W are only used in calculations when the day of the week

and the calendar year (%Y) are specified.

(8) Similar to %U and %W, %V is only used in calculations when the day of the week and the ISO year (%G) are

specified in a strptime() format string. Also note that %G and %Y are not interchangeable.

(9) When used with the strptime() method, the leading zero is optional for formats %d, %m, %H, %I, %M, %S,

%j, %U, %W, and %V. Format %y does require a leading zero.

(10) When parsing a month and day using strptime(), always include a year in the format. If the value you need

to parse lacks a year, append an explicit dummy leap year. Otherwise your code will raise an exception when

it encounters leap day because the default year used by the parser is not a leap year. Users run into this bug

every four years…

>>> month_day = "02/29"

>>> datetime.strptime(f"{month_day};1984", "%m/%d;%Y") # No leap year bug.

datetime.datetime(1984, 2, 29, 0, 0)

The Python Library Reference, Release 3.13.2



Deprecated since version 3.13, will be removed in version 3.15: strptime() calls using a format string

containing a day of month without a year now emit a DeprecationWarning. In 3.15 or later we may change

this into an error or change the default year to a leap year. See gh-70647.



8.2 zoneinfo — IANA time zone support

Added in version 3.9.

Source code: Lib/zoneinfo



The zoneinfo module provides a concrete time zone implementation to support the IANA time zone database as

originally specified in PEP 615. By default, zoneinfo uses the system’s time zone data if available; if no system

time zone data is available, the library will fall back to using the first-party tzdata package available on PyPI.



µ See also

Module: datetime

Provides the time and datetime types with which the ZoneInfo class is designed to be used.

Package tzdata

First-party package maintained by the CPython core developers to supply time zone data via PyPI.



Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.



8.2.1 Using ZoneInfo

ZoneInfo is a concrete implementation of the datetime.tzinfo abstract base class, and is intended to be attached

to tzinfo, either via the constructor, the datetime.replace method or datetime.astimezone:

>>> from zoneinfo import ZoneInfo

>>> from datetime import datetime, timedelta

>>> dt = datetime(2020, 10, 31, 12, tzinfo=ZoneInfo("America/Los_Angeles")) >>> print(dt)

2020-10-31 12:00:00-07:00

>>> dt.tzname()

'PDT'



Datetimes constructed in this way are compatible with datetime arithmetic and handle daylight saving time transitions with no further intervention:

>>> dt_add = dt + timedelta(days=1)

>>> print(dt_add)

2020-11-01 12:00:00-08:00

>>> dt_add.tzname()

'PST'



These time zones also support the fold attribute introduced in PEP 495. During offset transitions which induce ambiguous times (such as a daylight saving time to standard time transition), the offset from before the transition is used when fold=0, and the offset after the transition is used when fold=1, for example:

The Python Library Reference, Release 3.13.2



>>> dt = datetime(2020, 11, 1, 1, tzinfo=ZoneInfo("America/Los_Angeles")) >>> print(dt)

2020-11-01 01:00:00-07:00

>>> print(dt.replace(fold=1))

2020-11-01 01:00:00-08:00



When converting from another time zone, the fold will be set to the correct value:

>>> from datetime import timezone

>>> LOS_ANGELES = ZoneInfo("America/Los_Angeles")

>>> dt_utc = datetime(2020, 11, 1, 8, tzinfo=timezone.utc)

>>> # Before the PDT -> PST transition

>>> print(dt_utc.astimezone(LOS_ANGELES))

2020-11-01 01:00:00-07:00

>>> # After the PDT -> PST transition

>>> print((dt_utc + timedelta(hours=1)).astimezone(LOS_ANGELES)) 2020-11-01 01:00:00-08:00



8.2.2 Data sources

The zoneinfo module does not directly provide time zone data, and instead pulls time zone information from

the system time zone database or the first-party PyPI package tzdata, if available. Some systems, including notably Windows systems, do not have an IANA database available, and so for projects targeting cross-platform compatibility that require time zone data, it is recommended to declare a dependency on tzdata. If neither system data nor tzdata

are available, all calls to ZoneInfo will raise ZoneInfoNotFoundError.



Configuring the data sources

When ZoneInfo(key) is called, the constructor first searches the directories specified in TZPATH for a file matching key, and on failure looks for a match in the tzdata package. This behavior can be configured in three ways:

1. The default TZPATH when not otherwise specified can be configured at compile time.

2. TZPATH can be configured using an environment variable.

3. At runtime, the search path can be manipulated using the reset_tzpath() function.



Compile-time configuration

The default TZPATH includes several common deployment locations for the time zone database (except on Win-dows, where there are no “well-known” locations for time zone data). On POSIX systems, downstream distribu-tors and those building Python from source who know where their system time zone data is deployed may change the default time zone path by specifying the compile-time option TZPATH (or, more likely, the configure flag

--with-tzpath), which should be a string delimited by os.pathsep.

On all platforms, the configured value is available as the TZPATH key in sysconfig.get_config_var().



Environment configuration

When initializing TZPATH (either at import time or whenever reset_tzpath() is called with no arguments), the zoneinfo module will use the environment variable PYTHONTZPATH, if it exists, to set the search path.

PYTHONTZPATH

This is an os.pathsep-separated string containing the time zone search path to use. It must consist of

only absolute rather than relative paths. Relative components specified in PYTHONTZPATH will not be used,

but otherwise the behavior when a relative path is specified is implementation-defined; CPython will raise The Python Library Reference, Release 3.13.2



InvalidTZPathWarning , but other implementations are free to silently ignore the erroneous component or

raise an exception.

To set the system to ignore the system data and use the tzdata package instead, set PYTHONTZPATH="".



Runtime configuration

The TZ search path can also be configured at runtime using the reset_tzpath() function. This is generally not an advisable operation, though it is reasonable to use it in test functions that require the use of a specific time zone path (or require disabling access to the system time zones).



8.2.3 The ZoneInfo class

class zoneinfo.ZoneInfo(key)

A concrete datetime.tzinfo subclass that represents an IANA time zone specified by the string key. Calls

to the primary constructor will always return objects that compare identically; put another way, barring cache

invalidation via ZoneInfo.clear_cache(), for all values of key, the following assertion will always be

true:

a = ZoneInfo(key)

b = ZoneInfo(key)

assert a is b



key must be in the form of a relative, normalized POSIX path, with no up-level references. The constructor

will raise ValueError if a non-conforming key is passed.

If no file matching key is found, the constructor will raise ZoneInfoNotFoundError.

The ZoneInfo class has two alternate constructors:

classmethod ZoneInfo.from_file(fobj, / , key=None)

Constructs a ZoneInfo object from a file-like object returning bytes (e.g. a file opened in binary mode or an

io.BytesIO object). Unlike the primary constructor, this always constructs a new object.

The key parameter sets the name of the zone for the purposes of __str__() and __repr__().

Objects created via this constructor cannot be pickled (see pickling).

classmethod ZoneInfo.no_cache(key)

An alternate constructor that bypasses the constructor’s cache. It is identical to the primary constructor, but

returns a new object on each call. This is most likely to be useful for testing or demonstration purposes, but it

can also be used to create a system with a different cache invalidation strategy.

Objects created via this constructor will also bypass the cache of a deserializing process when unpickled.



Ϫ Caution

Using this constructor may change the semantics of your datetimes in surprising ways, only use it if you know that you need to.



The following class methods are also available:

classmethod ZoneInfo.clear_cache(*, only_keys=None)

A method for invalidating the cache on the ZoneInfo class. If no arguments are passed, all caches are inval-

idated and the next call to the primary constructor for each key will return a new instance.

If an iterable of key names is passed to the only_keys parameter, only the specified keys will be removed

from the cache. Keys passed to only_keys but not found in the cache are ignored.



The Python Library Reference, Release 3.13.2



Á Warning

Invoking this function may change the semantics of datetimes using ZoneInfo in surprising ways; this modifies module state and thus may have wide-ranging effects. Only use it if you know that you need to.



The class has one attribute:

ZoneInfo.key

This is a read-only attribute that returns the value of key passed to the constructor, which should be a lookup

key in the IANA time zone database (e.g. America/New_York, Europe/Paris or Asia/Tokyo).

For zones constructed from file without specifying a key parameter, this will be set to None.



® Note

Although it is a somewhat common practice to expose these to end users, these values are designed to be primary keys for representing the relevant zones and not necessarily user-facing elements. Projects like CLDR (the Unicode Common Locale Data Repository) can be used to get more user-friendly strings from these keys.



String representations

The string representation returned when calling str on a ZoneInfo object defaults to using the ZoneInfo.key attribute (see the note on usage in the attribute documentation):

>>> zone = ZoneInfo("Pacific/Kwajalein")

>>> str(zone)

'Pacific/Kwajalein'

>>> dt = datetime(2020, 4, 1, 3, 15, tzinfo=zone)

>>> f"{dt.isoformat()} [{dt.tzinfo}]"

'2020-04-01T03:15:00+12:00 [Pacific/Kwajalein]'



For objects constructed from a file without specifying a key parameter, str falls back to calling repr(). ZoneInfo’s repr is implementation-defined and not necessarily stable between versions, but it is guaranteed not to be a valid ZoneInfo key.



Pickle serialization

Rather than serializing all transition data, ZoneInfo objects are serialized by key, and ZoneInfo objects constructed from files (even those with a value for key specified) cannot be pickled.

The behavior of a ZoneInfo file depends on how it was constructed:

1. ZoneInfo(key): When constructed with the primary constructor, a ZoneInfo object is serialized by key,

and when deserialized, the deserializing process uses the primary and thus it is expected that these are expected

to be the same object as other references to the same time zone. For example, if europe_berlin_pkl is a

string containing a pickle constructed from ZoneInfo("Europe/Berlin"), one would expect the following

behavior:

>>> a = ZoneInfo("Europe/Berlin")

>>> b = pickle.loads(europe_berlin_pkl)

>>> a is b

True



2. ZoneInfo.no_cache(key): When constructed from the cache-bypassing constructor, the ZoneInfo ob-

ject is also serialized by key, but when deserialized, the deserializing process uses the cache bypassing

constructor. If europe_berlin_pkl_nc is a string containing a pickle constructed from ZoneInfo.

no_cache("Europe/Berlin"), one would expect the following behavior:

The Python Library Reference, Release 3.13.2



>>> a = ZoneInfo("Europe/Berlin")

>>> b = pickle.loads(europe_berlin_pkl_nc)

>>> a is b

False



3. ZoneInfo.from_file(fobj, /, key=None): When constructed from a file, the ZoneInfo object raises

an exception on pickling. If an end user wants to pickle a ZoneInfo constructed from a file, it is recommended

that they use a wrapper type or a custom serialization function: either serializing by key or storing the contents

of the file object and serializing that.

This method of serialization requires that the time zone data for the required key be available on both the serializing and deserializing side, similar to the way that references to classes and functions are expected to exist in both the serializing and deserializing environments. It also means that no guarantees are made about the consistency of results when unpickling a ZoneInfo pickled in an environment with a different version of the time zone data.



8.2.4 Functions

zoneinfo.available_timezones()

Get a set containing all the valid keys for IANA time zones available anywhere on the time zone path. This is

recalculated on every call to the function.

This function only includes canonical zone names and does not include “special” zones such as those under the

posix/ and right/ directories, or the posixrules zone.



Ϫ Caution

This function may open a large number of files, as the best way to determine if a file on the time zone path is a valid time zone is to read the “magic string” at the beginning.



® Note

These values are not designed to be exposed to end-users; for user facing elements, applications should use something like CLDR (the Unicode Common Locale Data Repository) to get more user-friendly strings.

See also the cautionary note on ZoneInfo.key.



zoneinfo.reset_tzpath( to=None)

Sets or resets the time zone search path (TZPATH) for the module. When called with no arguments, TZPATH

is set to the default value.

Calling reset_tzpath will not invalidate the ZoneInfo cache, and so calls to the primary ZoneInfo con-

structor will only use the new TZPATH in the case of a cache miss.

The to parameter must be a sequence of strings or os.PathLike and not a string, all of which must be

absolute paths. ValueError will be raised if something other than an absolute path is passed.



8.2.5 Globals

zoneinfo.TZPATH

A read-only sequence representing the time zone search path – when constructing a ZoneInfo from a key,

the key is joined to each entry in the TZPATH, and the first file found is used.

TZPATH may contain only absolute paths, never relative paths, regardless of how it is configured.

The object that zoneinfo.TZPATH points to may change in response to a call to reset_tzpath(), so it

is recommended to use zoneinfo.TZPATH rather than importing TZPATH from zoneinfo or assigning a

long-lived variable to zoneinfo.TZPATH.

For more information on configuring the time zone search path, see Configuring the data sources.

The Python Library Reference, Release 3.13.2



8.2.6 Exceptions and warnings

exception zoneinfo.ZoneInfoNotFoundError

Raised when construction of a ZoneInfo object fails because the specified key could not be found on the

system. This is a subclass of KeyError.

exception zoneinfo.InvalidTZPathWarning

Raised when PYTHONTZPATH contains an invalid component that will be filtered out, such as a relative path.



8.3 calendar — General calendar-related functions

Source code: Lib/calendar.py



This module allows you to output calendars like the Unix cal program, and provides additional useful functions related to the calendar. By default, these calendars have Monday as the first day of the week, and Sunday as the last

(the European convention). Use setfirstweekday() to set the first day of the week to Sunday (6) or to any other

weekday. Parameters that specify dates are given as integers. For related functionality, see also the datetime and

time modules.

The functions and classes defined in this module use an idealized calendar, the current Gregorian calendar extended indefinitely in both directions. This matches the definition of the “proleptic Gregorian” calendar in Dershowitz and Reingold’s book “Calendrical Calculations”, where it’s the base calendar for all computations. Zero and negative years are interpreted as prescribed by the ISO 8601 standard. Year 0 is 1 BC, year -1 is 2 BC, and so on.

class calendar.Calendar(firstweekday=0)

Creates a Calendar object. firstweekday is an integer specifying the first day of the week. MONDAY is 0 (the

default), SUNDAY is 6.

A Calendar object provides several methods that can be used for preparing the calendar data for formatting.

This class doesn’t do any formatting itself. This is the job of subclasses.

Calendar instances have the following methods and attributes:

firstweekday

The first weekday as an integer (0–6).

This property can also be set and read using setfirstweekday() and getfirstweekday() respec-tively.

getfirstweekday()

Return an int for the current first weekday (0–6).

Identical to reading the firstweekday property.

setfirstweekday(firstweekday)

Set the first weekday to firstweekday, passed as an int (0–6)

Identical to setting the firstweekday property.

iterweekdays()

Return an iterator for the week day numbers that will be used for one week. The first value from the

iterator will be the same as the value of the firstweekday property.

itermonthdates(year, month)

Return an iterator for the month month (1–12) in the year year. This iterator will return all days (as

datetime.date objects) for the month and all days before the start of the month or after the end of the month that are required to get a complete week.

itermonthdays(year, month)

Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted

by the datetime.date range. Days returned will simply be day of the month numbers. For the days outside of the specified month, the day number is 0.

The Python Library Reference, Release 3.13.2



itermonthdays2(year, month)

Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted

by the datetime.date range. Days returned will be tuples consisting of a day of the month number and a week day number.

itermonthdays3(year, month)

Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted

by the datetime.date range. Days returned will be tuples consisting of a year, a month and a day of the month numbers.

Added in version 3.7.

itermonthdays4(year, month)

Return an iterator for the month month in the year year similar to itermonthdates(), but not restricted

by the datetime.date range. Days returned will be tuples consisting of a year, a month, a day of the month, and a day of the week numbers.

Added in version 3.7.

monthdatescalendar(year, month)

Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven

datetime.date objects.

monthdays2calendar(year, month)

Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven tuples of day numbers and weekday numbers.

monthdayscalendar(year, month)

Return a list of the weeks in the month month of the year as full weeks. Weeks are lists of seven day numbers.

yeardatescalendar(year, width=3)

Return the data for the specified year ready for formatting. The return value is a list of month rows. Each month row contains up to width months (defaulting to 3). Each month contains between 4 and 6 weeks

and each week contains 1–7 days. Days are datetime.date objects.

yeardays2calendar(year, width=3)

Return the data for the specified year ready for formatting (similar to yeardatescalendar()). Entries in the week lists are tuples of day numbers and weekday numbers. Day numbers outside this month are zero.

yeardayscalendar( year, width=3)

Return the data for the specified year ready for formatting (similar to yeardatescalendar()). Entries in the week lists are day numbers. Day numbers outside this month are zero.

class calendar.TextCalendar(firstweekday=0)

This class can be used to generate plain text calendars.

TextCalendar instances have the following methods:

formatday(theday, weekday, width)

Return a string representing a single day formatted with the given width. If theday is 0, return a string of spaces of the specified width, representing an empty day. The weekday parameter is unused.

formatweek(theweek, w=0)

Return a single week in a string with no newline. If w is provided, it specifies the width of the date columns, which are centered. Depends on the first weekday as specified in the constructor or set by the

setfirstweekday() method.

formatweekday(weekday, width)

Return a string representing the name of a single weekday formatted to the specified width. The weekday parameter is an integer representing the day of the week, where 0 is Monday and 6 is Sunday.

The Python Library Reference, Release 3.13.2



formatweekheader( width)

Return a string containing the header row of weekday names, formatted with the given width for each column. The names depend on the locale settings and are padded to the specified width.

formatmonth(theyear, themonth, w=0, l=0)

Return a month’s calendar in a multi-line string. If w is provided, it specifies the width of the date columns, which are centered. If l is given, it specifies the number of lines that each week will use. Depends on the

first weekday as specified in the constructor or set by the setfirstweekday() method.

formatmonthname(theyear, themonth, width=0, withyear=True)

Return a string representing the month’s name centered within the specified width. If withyear is True, include the year in the output. The theyear and themonth parameters specify the year and month for the name to be formatted respectively.

prmonth(theyear, themonth, w=0, l=0)

Print a month’s calendar as returned by formatmonth().

formatyear(theyear, w=2, l=1, c=6, m=3)

Return a m-column calendar for an entire year as a multi-line string. Optional parameters w, l, and c are for date column width, lines per week, and number of spaces between month columns, respectively.

Depends on the first weekday as specified in the constructor or set by the setfirstweekday() method. The earliest year for which a calendar can be generated is platform-dependent.

pryear(theyear, w=2, l=1, c=6, m=3)

Print the calendar for an entire year as returned by formatyear().

class calendar.HTMLCalendar(firstweekday=0)

This class can be used to generate HTML calendars.

HTMLCalendar instances have the following methods:

formatmonth(theyear, themonth, withyear=True)

Return a month’s calendar as an HTML table. If withyear is true the year will be included in the header, otherwise just the month name will be used.

formatyear(theyear, width=3)

Return a year’s calendar as an HTML table. width (defaulting to 3) specifies the number of months per row.

formatyearpage(theyear, width=3, css=’calendar.css’, encoding=None)

Return a year’s calendar as a complete HTML page. width (defaulting to 3) specifies the number of

months per row. css is the name for the cascading style sheet to be used. None can be passed if no style sheet should be used. encoding specifies the encoding to be used for the output (defaulting to the system default encoding).

formatmonthname(theyear, themonth, withyear=True)

Return a month name as an HTML table row. If withyear is true the year will be included in the row, otherwise just the month name will be used.

HTMLCalendar has the following attributes you can override to customize the CSS classes used by the calen-

dar:

cssclasses

A list of CSS classes used for each weekday. The default class list is:

cssclasses = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"]



more styles can be added for each day:

cssclasses = ["mon text-bold", "tue", "wed", "thu", "fri", "sat", "sun red

, →"]

The Python Library Reference, Release 3.13.2



Note that the length of this list must be seven items.

cssclass_noday

The CSS class for a weekday occurring in the previous or coming month.

Added in version 3.7.

cssclasses_weekday_head

A list of CSS classes used for weekday names in the header row. The default is the same as cssclasses.

Added in version 3.7.

cssclass_month_head

The month’s head CSS class (used by formatmonthname()). The default value is "month".

Added in version 3.7.

cssclass_month

The CSS class for the whole month’s table (used by formatmonth()). The default value is "month".

Added in version 3.7.

cssclass_year

The CSS class for the whole year’s table of tables (used by formatyear()). The default value is "year".

Added in version 3.7.

cssclass_year_head

The CSS class for the table head for the whole year (used by formatyear()). The default value is "year" .

Added in version 3.7.

Note that although the naming for the above described class attributes is singular (e.g. cssclass_month

cssclass_noday), one can replace the single CSS class with a space separated list of CSS classes, for ex-

ample:

"text-bold text-red"



Here is an example how HTMLCalendar can be customized:

class CustomHTMLCal(calendar.HTMLCalendar):

cssclasses = [style + " text-nowrap" for style in

calendar.HTMLCalendar.cssclasses]

cssclass_month_head = "text-center month-head"

cssclass_month = "text-center month"

cssclass_year = "text-italic lead"



class calendar.LocaleTextCalendar(firstweekday=0, locale=None)

This subclass of TextCalendar can be passed a locale name in the constructor and will return month and

weekday names in the specified locale.

class calendar.LocaleHTMLCalendar(firstweekday=0, locale=None)

This subclass of HTMLCalendar can be passed a locale name in the constructor and will return month and

weekday names in the specified locale.



® Note

The constructor, formatweekday() and formatmonthname() methods of these two classes temporarily

change the LC_TIME locale to the given locale. Because the current locale is a process-wide setting, they are

not thread-safe.



For simple text calendars this module provides the following functions.

The Python Library Reference, Release 3.13.2



calendar.setfirstweekday(weekday)

Sets the weekday (0 is Monday, 6 is Sunday) to start each week. The values MONDAY, TUESDAY , WEDNESDAY,

THURSDAY , FRIDAY, SATURDAY, and SUNDAY are provided for convenience. For example, to set the first

weekday to Sunday:

import calendar

calendar.setfirstweekday(calendar.SUNDAY)



calendar.firstweekday()

Returns the current setting for the weekday to start each week.

calendar.isleap(year)

Returns True if year is a leap year, otherwise False.

calendar.leapdays(y1, y2)

Returns the number of leap years in the range from y1 to y2 (exclusive), where y1 and y2 are years.

This function works for ranges spanning a century change.

calendar.weekday(year, month, day)

Returns the day of the week (0 is Monday) for year (1970–…), month (1–12), day (1–31).

calendar.weekheader(n)

Return a header containing abbreviated weekday names. n specifies the width in characters for one weekday.

calendar.monthrange(year, month)

Returns weekday of first day of the month and number of days in month, for the specified year and month.

calendar.monthcalendar(year, month)

Returns a matrix representing a month’s calendar. Each row represents a week; days outside of the month are

represented by zeros. Each week begins with Monday unless set by setfirstweekday().

calendar.prmonth(theyear, themonth, w=0, l=0)

Prints a month’s calendar as returned by month().

calendar.month(theyear, themonth, w=0, l=0)

Returns a month’s calendar in a multi-line string using the formatmonth() of the TextCalendar class.

calendar.prcal(year, w=0, l=0, c=6, m=3)

Prints the calendar for an entire year as returned by calendar().

calendar.calendar(year, w=2, l=1, c=6, m=3)

Returns a 3-column calendar for an entire year as a multi-line string using the formatyear() of the

TextCalendar class.

calendar.timegm(tuple)

An unrelated but handy function that takes a time tuple such as returned by the gmtime() function in the

time module, and returns the corresponding Unix timestamp value, assuming an epoch of 1970, and the

POSIX encoding. In fact, time.gmtime() and timegm() are each others’ inverse.

The calendar module exports the following data attributes:

calendar.day_name

A sequence that represents the days of the week in the current locale, where Monday is day number 0.

>>> import calendar

>>> list(calendar.day_name)

['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']



calendar.day_abbr

A sequence that represents the abbreviated days of the week in the current locale, where Mon is day number

0.

The Python Library Reference, Release 3.13.2



>>> import calendar

>>> list(calendar.day_abbr)

['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']



calendar.MONDAY

calendar.TUESDAY

calendar.WEDNESDAY

calendar.THURSDAY

calendar.FRIDAY

calendar.SATURDAY

calendar.SUNDAY

Aliases for the days of the week, where MONDAY is 0 and SUNDAY is 6.

Added in version 3.12.

class calendar.Day

Enumeration defining days of the week as integer constants. The members of this enumeration are exported

to the module scope as MONDAY through SUNDAY.

Added in version 3.12.

calendar.month_name

A sequence that represents the months of the year in the current locale. This follows normal convention of

January being month number 1, so it has a length of 13 and month_name[0] is the empty string.

>>> import calendar

>>> list(calendar.month_name)

['', 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August',

, →'September', 'October', 'November', 'December']



calendar.month_abbr

A sequence that represents the abbreviated months of the year in the current locale. This follows normal

convention of January being month number 1, so it has a length of 13 and month_abbr[0] is the empty

string.

>>> import calendar

>>> list(calendar.month_abbr)

['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov

, →', 'Dec']



calendar.JANUARY

calendar.FEBRUARY

calendar.MARCH

calendar.APRIL

calendar.MAY

calendar.JUNE

calendar.JULY

calendar.AUGUST

calendar.SEPTEMBER

calendar.OCTOBER

calendar.NOVEMBER

calendar.DECEMBER

Aliases for the months of the year, where JANUARY is 1 and DECEMBER is 12.

Added in version 3.12.

The Python Library Reference, Release 3.13.2



class calendar.Month

Enumeration defining months of the year as integer constants. The members of this enumeration are exported

to the module scope as JANUARY through DECEMBER.

Added in version 3.12.

The calendar module defines the following exceptions:

exception calendar.IllegalMonthError(month)

A subclass of ValueError, raised when the given month number is outside of the range 1-12 (inclusive).

month

The invalid month number.

exception calendar.IllegalWeekdayError(weekday)

A subclass of ValueError, raised when the given weekday number is outside of the range 0-6 (inclusive).

weekday

The invalid weekday number.



µ See also

Module datetime

Object-oriented interface to dates and times with similar functionality to the time module.

Module time

Low-level time related functions.



8.3.1 Command-Line Usage

Added in version 2.5.

The calendar module can be executed as a script from the command line to interactively print a calendar.

python -m calendar [-h] [-L LOCALE] [-e ENCODING] [-t {text,html}]

[-w WIDTH] [-l LINES] [-s SPACING] [-m MONTHS] [-c CSS] [-f FIRST_WEEKDAY] [year] [month]



For example, to print a calendar for the year 2000:

$ python -m calendar 2000

2000

January February March

Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su

1 2 1 2 3 4 5 6 1 2 3 4 5

3 4 5 6 7 8 9 7 8 9 10 11 12 13 6 7 8 9 10 11 12

10 11 12 13 14 15 16 14 15 16 17 18 19 20 13 14 15 16 17 18 19 17 18 19 20 21 22 23 21 22 23 24 25 26 27 20 21 22 23 24 25 26 24 25 26 27 28 29 30 28 29 27 28 29 30 31

31

April May June

Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su

1 2 1 2 3 4 5 6 7 1 2 3 4

3 4 5 6 7 8 9 8 9 10 11 12 13 14 5 6 7 8 9 10 11

10 11 12 13 14 15 16 15 16 17 18 19 20 21 12 13 14 15 16 17 18 17 18 19 20 21 22 23 22 23 24 25 26 27 28 19 20 21 22 23 24 25 24 25 26 27 28 29 30 29 30 31 26 27 28 29 30

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

July August September

Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su

1 2 1 2 3 4 5 6 1 2 3

3 4 5 6 7 8 9 7 8 9 10 11 12 13 4 5 6 7 8 9 10

10 11 12 13 14 15 16 14 15 16 17 18 19 20 11 12 13 14 15 16 17 17 18 19 20 21 22 23 21 22 23 24 25 26 27 18 19 20 21 22 23 24 24 25 26 27 28 29 30 28 29 30 31 25 26 27 28 29 30

31

October November December

Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su

1 1 2 3 4 5 1 2 3

2 3 4 5 6 7 8 6 7 8 9 10 11 12 4 5 6 7 8 9 10

9 10 11 12 13 14 15 13 14 15 16 17 18 19 11 12 13 14 15 16 17

16 17 18 19 20 21 22 20 21 22 23 24 25 26 18 19 20 21 22 23 24 23 24 25 26 27 28 29 27 28 29 30 25 26 27 28 29 30 31 30 31



The following options are accepted:

--help,-h

Show the help message and exit.

--locale LOCALE,-L LOCALE

The locale to use for month and weekday names. Defaults to English.

--encoding ENCODING,-e ENCODING

The encoding to use for output.--encoding is required if--locale is set.

--type {text,html},-t {text,html}

Print the calendar to the terminal as text, or as an HTML document.

--first-weekday FIRST_WEEKDAY,-f FIRST_WEEKDAY

The weekday to start each week. Must be a number between 0 (Monday) and 6 (Sunday). Defaults to 0.

Added in version 3.13.

year

The year to print the calendar for. Defaults to the current year.

month

The month of the specified year to print the calendar for. Must be a number between 1 and 12, and may only

be used in text mode. Defaults to printing a calendar for the full year.

Text-mode options:

--width WIDTH,-w WIDTH

The width of the date column in terminal columns. The date is printed centred in the column. Any value lower

than 2 is ignored. Defaults to 2.

--lines LINES,-l LINES

The number of lines for each week in terminal rows. The date is printed top-aligned. Any value lower than 1

is ignored. Defaults to 1.

--spacing SPACING,-s SPACING

The space between months in columns. Any value lower than 2 is ignored. Defaults to 6.

--months MONTHS,-m MONTHS

The number of months printed per row. Defaults to 3.

HTML-mode options:

The Python Library Reference, Release 3.13.2



--css CSS,-c CSS

The path of a CSS stylesheet to use for the calendar. This must either be relative to the generated HTML, or

an absolute HTTP or file:/// URL.



8.4 collections — Container datatypes

Source code: Lib/collections/__init__.py



This module implements specialized container datatypes providing alternatives to Python’s general purpose built-in

containers, dict, list, set, and tuple.



namedtuple() factory function for creating tuple subclasses with named fields

deque list-like container with fast appends and pops on either end

ChainMap dict-like class for creating a single view of multiple mappings

Counter dict subclass for counting hashable objects

OrderedDict dict subclass that remembers the order entries were added

defaultdict dict subclass that calls a factory function to supply missing values

UserDict wrapper around dictionary objects for easier dict subclassing

UserList wrapper around list objects for easier list subclassing

UserString wrapper around string objects for easier string subclassing



8.4.1 ChainMap objects

Added in version 3.3.

A ChainMap class is provided for quickly linking a number of mappings so they can be treated as a single unit. It is

often much faster than creating a new dictionary and running multiple update() calls.

The class can be used to simulate nested scopes and is useful in templating.

class collections.ChainMap(*maps)

A ChainMap groups multiple dicts or other mappings together to create a single, updateable view. If no maps

are specified, a single empty dictionary is provided so that a new chain always has at least one mapping.

The underlying mappings are stored in a list. That list is public and can be accessed or updated using the maps

attribute. There is no other state.

Lookups search the underlying mappings successively until a key is found. In contrast, writes, updates, and

deletions only operate on the first mapping.

A ChainMap incorporates the underlying mappings by reference. So, if one of the underlying mappings gets

updated, those changes will be reflected in ChainMap.

All of the usual dictionary methods are supported. In addition, there is a maps attribute, a method for creating

new subcontexts, and a property for accessing all but the first mapping:

maps

A user updateable list of mappings. The list is ordered from first-searched to last-searched. It is the only stored state and can be modified to change which mappings are searched. The list should always contain at least one mapping.

new_child(m=None, **kwargs)

Returns a new ChainMap containing a new map followed by all of the maps in the current instance. If m is specified, it becomes the new map at the front of the list of mappings; if not specified, an empty dict is used, so that a call to d.new_child() is equivalent to: ChainMap({}, *d.maps). If any keyword arguments are specified, they update passed map or new empty dict. This method is used for creating subcontexts that can be updated without altering values in any of the parent mappings.

Changed in version 3.4: The optional m parameter was added.

The Python Library Reference, Release 3.13.2



Changed in version 3.10: Keyword arguments support was added.

parents

Property returning a new ChainMap containing all of the maps in the current instance except the first one. This is useful for skipping the first map in the search. Use cases are similar to those for the nonlocal

keyword used in nested scopes. The use cases also parallel those for the built-in super() function. A reference to d.parents is equivalent to: ChainMap(*d.maps[1:]).

Note, the iteration order of a ChainMap is determined by scanning the mappings last to first:

>>> baseline = {'music': 'bach', 'art': 'rembrandt'}

>>> adjustments = {'art': 'van gogh', 'opera': 'carmen'}

>>> list(ChainMap(adjustments, baseline))

['music', 'art', 'opera']



This gives the same ordering as a series of dict.update() calls starting with the last mapping:

>>> combined = baseline.copy()

>>> combined.update(adjustments)

>>> list(combined)

['music', 'art', 'opera']



Changed in version 3.9: Added support for | and |= operators, specified in PEP 584.



µ See also

• The MultiContext class in the Enthought CodeTools package has options to support writing to any mapping

in the chain.

• Django’s Context class for templating is a read-only chain of mappings. It also features pushing and popping

of contexts similar to the new_child() method and the parents property.

• The Nested Contexts recipe has options to control whether writes and other mutations apply only to the

first mapping or to any mapping in the chain.

• A greatly simplified read-only version of Chainmap.



ChainMap Examples and Recipes

This section shows various approaches to working with chained maps.

Example of simulating Python’s internal lookup chain:

import builtins

pylookup = ChainMap(locals(), globals(), vars(builtins))



Example of letting user specified command-line arguments take precedence over environment variables which in turn take precedence over default values:

import os, argparse

defaults = {'color': 'red', 'user': 'guest'}

parser = argparse.ArgumentParser()

parser.add_argument('-u', '--user')

parser.add_argument('-c', '--color')

namespace = parser.parse_args()

command_line_args = {k: v for k, v in vars(namespace).items() if v is not None}

combined = ChainMap(command_line_args, os.environ, defaults)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

print(combined['color'])

print(combined['user'])



Example patterns for using the ChainMap class to simulate nested contexts:

c = ChainMap() # Create root context

d = c.new_child() # Create nested child context

e = c.new_child() # Child of c, independent from d

e.maps[0] # Current context dictionary -- like Python's locals() e.maps[-1] # Root context -- like Python's globals() e.parents # Enclosing context chain -- like Python's nonlocals

d['x'] = 1 # Set value in current context

d['x'] # Get first key in the chain of contexts

del d['x'] # Delete from current context

list(d) # All nested values

k in d # Check all nested values

len(d) # Number of nested values

d.items() # All nested items

dict(d) # Flatten into a regular dictionary



The ChainMap class only makes updates (writes and deletions) to the first mapping in the chain while lookups will search the full chain. However, if deep writes and deletions are desired, it is easy to make a subclass that updates keys found deeper in the chain:

class DeepChainMap(ChainMap):

'Variant of ChainMap that allows direct updates to inner scopes'

def __setitem__(self, key, value):

for mapping in self.maps:

if key in mapping:

mapping[key] = value

return

self.maps[0][key] = value

def __delitem__(self, key):

for mapping in self.maps:

if key in mapping:

del mapping[key]

return

raise KeyError(key)

>>> d = DeepChainMap({'zebra': 'black'}, {'elephant': 'blue'}, {'lion': 'yellow'}) >>> d['lion'] = 'orange' # update an existing key two levels down >>> d['snake'] = 'red' # new keys get added to the topmost dict >>> del d['elephant'] # remove an existing key one level down >>> d # display result

DeepChainMap({'zebra': 'black', 'snake': 'red'}, {}, {'lion': 'orange'})



8.4.2 Counter objects

A counter tool is provided to support convenient and rapid tallies. For example:

>>> # Tally occurrences of words in a list

>>> cnt = Counter()

>>> for word in ['red', 'blue', 'red', 'green', 'blue', 'blue']:

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... cnt[word] += 1

...

>>> cnt

Counter({'blue': 3, 'red': 2, 'green': 1})

>>> # Find the ten most common words in Hamlet

>>> import re

>>> words = re.findall(r'\w+', open('hamlet.txt').read().lower()) >>> Counter(words).most_common(10)

[('the', 1143), ('and', 966), ('to', 762), ('of', 669), ('i', 631),

('you', 554), ('a', 546), ('my', 514), ('hamlet', 471), ('in', 451)]



class collections.Counter( iterable-or-mapping [ ])

A Counter is a dict subclass for counting hashable objects. It is a collection where elements are stored as

dictionary keys and their counts are stored as dictionary values. Counts are allowed to be any integer value

including zero or negative counts. The Counter class is similar to bags or multisets in other languages.

Elements are counted from an iterable or initialized from another mapping (or counter):

>>> c = Counter() # a new, empty counter

>>> c = Counter('gallahad') # a new counter from an iterable

>>> c = Counter({'red': 4, 'blue': 2}) # a new counter from a mapping

>>> c = Counter(cats=4, dogs=8) # a new counter from keyword args



Counter objects have a dictionary interface except that they return a zero count for missing items instead of

raising a KeyError:

>>> c = Counter(['eggs', 'ham'])

>>> c['bacon'] # count of a missing element is␣

, →zero

0



Setting a count to zero does not remove an element from a counter. Use del to remove it entirely:

>>> c['sausage'] = 0 # counter entry with a zero count

>>> del c['sausage'] # del actually removes the entry



Added in version 3.1.

Changed in version 3.7: As a dict subclass, Counter inherited the capability to remember insertion order.

Math operations on Counter objects also preserve order. Results are ordered according to when an element is

first encountered in the left operand and then by the order encountered in the right operand.

Counter objects support additional methods beyond those available for all dictionaries:

elements()

Return an iterator over elements repeating each as many times as its count. Elements are returned in the

order first encountered. If an element’s count is less than one, elements() will ignore it.

>>> c = Counter(a=4, b=2, c=0, d=-2)

>>> sorted(c.elements())

['a', 'a', 'a', 'a', 'b', 'b']



most_common( n [ ])

Return a list of the n most common elements and their counts from the most common to the least. If n is

omitted or None, most_common() returns all elements in the counter. Elements with equal counts are ordered in the order first encountered:

The Python Library Reference, Release 3.13.2



>>> Counter('abracadabra').most_common(3)

[('a', 5), ('b', 2), ('r', 2)]



subtract( iterable-or-mapping [ ])

Elements are subtracted from an iterable or from another mapping (or counter). Like dict.update() but subtracts counts instead of replacing them. Both inputs and outputs may be zero or negative.

>>> c = Counter(a=4, b=2, c=0, d=-2)

>>> d = Counter(a=1, b=2, c=3, d=4)

>>> c.subtract(d)

>>> c

Counter({'a': 3, 'b': 0, 'c': -3, 'd': -6})



Added in version 3.2.

total()

Compute the sum of the counts.

>>> c = Counter(a=10, b=5, c=0)

>>> c.total()

15



Added in version 3.10.

The usual dictionary methods are available for Counter objects except for two which work differently for

counters.

fromkeys(iterable)

This class method is not implemented for Counter objects.

update( iterable-or-mapping [ ])

Elements are counted from an iterable or added-in from another mapping (or counter). Like dict.

update() but adds counts instead of replacing them. Also, the iterable is expected to be a sequence of elements, not a sequence of (key, value) pairs.

Counters support rich comparison operators for equality, subset, and superset relationships: ==, !=, <, <=, >, >=. All of those tests treat missing elements as having zero counts so that Counter(a=1) == Counter(a=1, b=0) returns true.

Changed in version 3.10: Rich comparison operations were added.

Changed in version 3.10: In equality tests, missing elements are treated as having zero counts. Formerly,

Counter(a=3) and Counter(a=3, b=0) were considered distinct.

Common patterns for working with Counter objects:

c.total() # total of all counts

c.clear() # reset all counts

list(c) # list unique elements

set(c) # convert to a set

dict(c) # convert to a regular dictionary

c.items() # access the (elem, cnt) pairs

Counter(dict(list_of_pairs)) # convert from a list of (elem, cnt) pairs c.most_common()[:-n-1:-1] # n least common elements +c # remove zero and negative counts



Several mathematical operations are provided for combining Counter objects to produce multisets (counters that have counts greater than zero). Addition and subtraction combine counters by adding or subtracting the counts of corresponding elements. Intersection and union return the minimum and maximum of corresponding counts. Equality and inclusion compare corresponding counts. Each operation can accept inputs with signed counts, but the output will exclude results with counts of zero or less.

The Python Library Reference, Release 3.13.2



>>> c = Counter(a=3, b=1)

>>> d = Counter(a=1, b=2)

>>> c + d # add two counters together: c[x] + d[x]

Counter({'a': 4, 'b': 3})

>>> c-d # subtract (keeping only positive counts)

Counter({'a': 2})

>>> c & d # intersection: min(c[x], d[x])

Counter({'a': 1, 'b': 1})

>>> c | d # union: max(c[x], d[x])

Counter({'a': 3, 'b': 2})

>>> c == d # equality: c[x] == d[x]

False

>>> c <= d # inclusion: c[x] <= d[x]

False



Unary addition and subtraction are shortcuts for adding an empty counter or subtracting from an empty counter.

>>> c = Counter(a=2, b=-4)

>>> +c

Counter({'a': 2})

>>>-c

Counter({'b': 4})



Added in version 3.3: Added support for unary plus, unary minus, and in-place multiset operations.



® Note

Counters were primarily designed to work with positive integers to represent running counts; however, care was

taken to not unnecessarily preclude use cases needing other types or negative values. To help with those use

cases, this section documents the minimum range and type restrictions.

• The Counter class itself is a dictionary subclass with no restrictions on its keys and values. The values

are intended to be numbers representing counts, but you could store anything in the value field.

• The most_common() method requires only that the values be orderable.

• For in-place operations such as c[key] += 1, the value type need only support addition and subtraction.

So fractions, floats, and decimals would work and negative values are supported. The same is also true for

update() and subtract() which allow negative and zero values for both inputs and outputs.

• The multiset methods are designed only for use cases with positive values. The inputs may be negative or

zero, but only outputs with positive values are created. There are no type restrictions, but the value type needs to support addition, subtraction, and comparison.

• The elements() method requires integer counts. It ignores zero and negative counts.



µ See also

• Bag class in Smalltalk.

• Wikipedia entry for Multisets.

• C++ multisets tutorial with examples.

• For mathematical operations on multisets and their use cases, see Knuth, Donald. The Art of Computer

Programming Volume II, Section 4.6.3, Exercise 19.

• To enumerate all distinct multisets of a given size over a given set of elements, see itertools.

combinations_with_replacement():

The Python Library Reference, Release 3.13.2



map(Counter, combinations_with_replacement('ABC', 2)) # --> AA AB AC BB BC␣

, →CC



8.4.3 deque objects

class collections.deque( iterable [[, maxlen ]])

Returns a new deque object initialized left-to-right (using append()) with data from iterable. If iterable is not

specified, the new deque is empty.

Deques are a generalization of stacks and queues (the name is pronounced “deck” and is short for “double-

ended queue”). Deques support thread-safe, memory efficient appends and pops from either side of the deque

with approximately the same O(1) performance in either direction.

Though list objects support similar operations, they are optimized for fast fixed-length operations and incur

O(n) memory movement costs for pop(0) and insert(0, v) operations which change both the size and

position of the underlying data representation.

If maxlen is not specified or is None, deques may grow to an arbitrary length. Otherwise, the deque is bounded

to the specified maximum length. Once a bounded length deque is full, when new items are added, a corre-

sponding number of items are discarded from the opposite end. Bounded length deques provide functionality

similar to the tail filter in Unix. They are also useful for tracking transactions and other pools of data where

only the most recent activity is of interest.

Deque objects support the following methods:

append(x)

Add x to the right side of the deque.

appendleft(x)

Add x to the left side of the deque.

clear()

Remove all elements from the deque leaving it with length 0.

copy()

Create a shallow copy of the deque.

Added in version 3.5.

count(x)

Count the number of deque elements equal to x.

Added in version 3.2.

extend(iterable)

Extend the right side of the deque by appending elements from the iterable argument.

extendleft(iterable)

Extend the left side of the deque by appending elements from iterable. Note, the series of left appends results in reversing the order of elements in the iterable argument.

index(x [, start[, stop ]])

Return the position of x in the deque (at or after index start and before index stop). Returns the first

match or raises ValueError if not found.

Added in version 3.5.

insert(i, x)

Insert x into the deque at position i.

If the insertion would cause a bounded deque to grow beyond maxlen, an IndexError is raised.

Added in version 3.5.

The Python Library Reference, Release 3.13.2



pop()

Remove and return an element from the right side of the deque. If no elements are present, raises an

IndexError.

popleft()

Remove and return an element from the left side of the deque. If no elements are present, raises an

IndexError.

remove(value)

Remove the first occurrence of value. If not found, raises a ValueError.

reverse()

Reverse the elements of the deque in-place and then return None.

Added in version 3.2.

rotate(n=1)

Rotate the deque n steps to the right. If n is negative, rotate to the left.

When the deque is not empty, rotating one step to the right is equivalent to d.appendleft(d.pop()), and rotating one step to the left is equivalent to d.append(d.popleft()).

Deque objects also provide one read-only attribute:

maxlen

Maximum size of a deque or None if unbounded.

Added in version 3.1.

In addition to the above, deques support iteration, pickling, len(d), reversed(d), copy.copy(d), copy. deepcopy(d), membership testing with the in operator, and subscript references such as d[0] to access the first element. Indexed access is O(1) at both ends but slows to O(n) in the middle. For fast random access, use lists instead.

Starting in version 3.5, deques support __add__(), __mul__(), and __imul__().

Example:

>>> from collections import deque

>>> d = deque('ghi') # make a new deque with three items >>> for elem in d: # iterate over the deque's elements

... print(elem.upper())

G

H





I


>>> d.append('j') # add a new entry to the right side >>> d.appendleft('f') # add a new entry to the left side >>> d # show the representation of the deque

deque(['f', 'g', 'h', 'i', 'j'])

>>> d.pop() # return and remove the rightmost item

'j'

>>> d.popleft() # return and remove the leftmost item 'f'

>>> list(d) # list the contents of the deque

['g', 'h', 'i']

>>> d[0] # peek at leftmost item

'g'

>>> d[-1] # peek at rightmost item

'i'

>>> list(reversed(d)) # list the contents of a deque in reverse

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

['i', 'h', 'g']

>>> 'h' in d # search the deque

True

>>> d.extend('jkl') # add multiple elements at once

>>> d

deque(['g', 'h', 'i', 'j', 'k', 'l'])

>>> d.rotate(1) # right rotation

>>> d

deque(['l', 'g', 'h', 'i', 'j', 'k'])

>>> d.rotate(-1) # left rotation

>>> d

deque(['g', 'h', 'i', 'j', 'k', 'l'])

>>> deque(reversed(d)) # make a new deque in reverse order deque(['l', 'k', 'j', 'i', 'h', 'g'])

>>> d.clear() # empty the deque

>>> d.pop() # cannot pop from an empty deque

Traceback (most recent call last):

File "", line 1, in-toplevel-

d.pop()

IndexError: pop from an empty deque

>>> d.extendleft('abc') # extendleft() reverses the input order >>> d

deque(['c', 'b', 'a'])



deque Recipes

This section shows various approaches to working with deques.

Bounded length deques provide functionality similar to the tail filter in Unix:

def tail(filename, n=10):

'Return the last n lines of a file'

with open(filename) as f:

return deque(f, n)



Another approach to using deques is to maintain a sequence of recently added elements by appending to the right and popping to the left:

def moving_average(iterable, n=3):

# moving_average([40, 30, 50, 46, 39, 44]) --> 40.0 42.0 45.0 43.0

# https://en.wikipedia.org/wiki/Moving_average

it = iter(iterable)

d = deque(itertools.islice(it, n-1))

d.appendleft(0)

s = sum(d)

for elem in it:

s += elem-d.popleft()

d.append(elem)

yield s / n



A round-robin scheduler can be implemented with input iterators stored in a deque. Values are yielded from the

active iterator in position zero. If that iterator is exhausted, it can be removed with popleft(); otherwise, it can be

cycled back to the end with the rotate() method:



The Python Library Reference, Release 3.13.2



def roundrobin(*iterables):

"roundrobin('ABC', 'D', 'EF') --> A D E B F C"

iterators = deque(map(iter, iterables))

while iterators:

try:

while True:

yield next(iterators[0])

iterators.rotate(-1)

except StopIteration:

# Remove an exhausted iterator.

iterators.popleft()



The rotate() method provides a way to implement deque slicing and deletion. For example, a pure Python implementation of del d[n] relies on the rotate() method to position elements to be popped:

def delete_nth(d, n):

d.rotate(-n)

d.popleft()

d.rotate(n)



To implement deque slicing, use a similar approach applying rotate() to bring a target element to the left side

of the deque. Remove old entries with popleft(), add new entries with extend(), and then reverse the rotation. With minor variations on that approach, it is easy to implement Forth style stack manipulations such as dup, drop, swap, over, pick, rot, and roll.



8.4.4 defaultdict objects

class collections.defaultdict(default_factory=None, / [, ... ])

Return a new dictionary-like object. defaultdict is a subclass of the built-in dict class. It overrides one

method and adds one writable instance variable. The remaining functionality is the same as for the dict class

and is not documented here.

The first argument provides the initial value for the default_factory attribute; it defaults to None. All

remaining arguments are treated the same as if they were passed to the dict constructor, including keyword

arguments.

defaultdict objects support the following method in addition to the standard dict operations:

__missing__(key)

If the default_factory attribute is None, this raises a KeyError exception with the key as argument.

If default_factory is not None, it is called without arguments to provide a default value for the given key, this value is inserted in the dictionary for the key, and returned.

If calling default_factory raises an exception this exception is propagated unchanged.

This method is called by the __getitem__() method of the dict class when the requested key is not found; whatever it returns or raises is then returned or raised by __getitem__().

Note that __missing__() is not called for any operations besides __getitem__(). This means that

get() will, like normal dictionaries, return None as a default rather than using default_factory.

defaultdict objects support the following instance variable:

default_factory

This attribute is used by the __missing__() method; it is initialized from the first argument to the constructor, if present, or to None, if absent.

Changed in version 3.9: Added merge (|) and update (|=) operators, specified in PEP 584.



The Python Library Reference, Release 3.13.2



defaultdict Examples

Using list as the default_factory, it is easy to group a sequence of key-value pairs into a dictionary of lists:

>>> s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)] >>> d = defaultdict(list)

>>> for k, v in s:

... d[k].append(v)

...

>>> sorted(d.items())

[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]



When each key is encountered for the first time, it is not already in the mapping; so an entry is automatically created

using the default_factory function which returns an empty list. The list.append() operation then attaches the value to the new list. When keys are encountered again, the look-up proceeds normally (returning the list for that key) and the list.append() operation adds another value to the list. This technique is simpler and faster than an

equivalent technique using dict.setdefault():

>>> d = {}

>>> for k, v in s:

... d.setdefault(k, []).append(v)

...

>>> sorted(d.items())

[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]



Setting the default_factory to int makes the defaultdict useful for counting (like a bag or multiset in other languages):

>>> s = 'mississippi'

>>> d = defaultdict(int)

>>> for k in s:

... d[k] += 1

...

>>> sorted(d.items())

[('i', 4), ('m', 1), ('p', 2), ('s', 4)]



When a letter is first encountered, it is missing from the mapping, so the default_factory function calls int() to supply a default count of zero. The increment operation then builds up the count for each letter.

The function int() which always returns zero is just a special case of constant functions. A faster and more flexible way to create constant functions is to use a lambda function which can supply any constant value (not just zero):

>>> def constant_factory(value):

... return lambda: value

...

>>> d = defaultdict(constant_factory(''))

>>> d.update(name='John', action='ran')

>>> '%(name)s %(action)s to %(object)s' % d

'John ran to '



Setting the default_factory to set makes the defaultdict useful for building a dictionary of sets:

>>> s = [('red', 1), ('blue', 2), ('red', 3), ('blue', 4), ('red', 1), ('blue', 4)] >>> d = defaultdict(set)

>>> for k, v in s:

... d[k].add(v)

...

>>> sorted(d.items())

[('blue', {2, 4}), ('red', {1, 3})]

The Python Library Reference, Release 3.13.2



8.4.5 namedtuple() Factory Function for Tuples with Named Fields

Named tuples assign meaning to each position in a tuple and allow for more readable, self-documenting code. They can be used wherever regular tuples are used, and they add the ability to access fields by name instead of position index.

collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)

Returns a new tuple subclass named typename. The new subclass is used to create tuple-like objects that have

fields accessible by attribute lookup as well as being indexable and iterable. Instances of the subclass also have

a helpful docstring (with typename and field_names) and a helpful __repr__() method which lists the tuple

contents in a name=value format.

The field_names are a sequence of strings such as ['x', 'y']. Alternatively, field_names can be a single

string with each fieldname separated by whitespace and/or commas, for example 'x y' or 'x, y'.

Any valid Python identifier may be used for a fieldname except for names starting with an underscore. Valid

identifiers consist of letters, digits, and underscores but do not start with a digit or underscore and cannot be a

keyword such as class, for, return, global, pass, or raise.

If rename is true, invalid fieldnames are automatically replaced with positional names. For example, ['abc',

'def', 'ghi', 'abc'] is converted to ['abc', '_1', 'ghi', '_3'], eliminating the keyword def

and the duplicate fieldname abc.

defaults can be None or an iterable of default values. Since fields with a default value must come after any

fields without a default, the defaults are applied to the rightmost parameters. For example, if the fieldnames

are ['x', 'y', 'z'] and the defaults are (1, 2), then x will be a required argument, y will default to 1,

and z will default to 2.

If module is defined, the __module__ attribute of the named tuple is set to that value.

Named tuple instances do not have per-instance dictionaries, so they are lightweight and require no more

memory than regular tuples.

To support pickling, the named tuple class should be assigned to a variable that matches typename.

Changed in version 3.1: Added support for rename.

Changed in version 3.6: The verbose and rename parameters became keyword-only arguments.

Changed in version 3.6: Added the module parameter.

Changed in version 3.7: Removed the verbose parameter and the _source attribute.

Changed in version 3.7: Added the defaults parameter and the _field_defaults attribute.

>>> # Basic example

>>> Point = namedtuple('Point', ['x', 'y'])

>>> p = Point(11, y=22) # instantiate with positional or keyword arguments >>> p[0] + p[1] # indexable like the plain tuple (11, 22) 33

>>> x, y = p # unpack like a regular tuple

>>> x, y

(11, 22)

>>> p.x + p.y # fields also accessible by name

33

>>> p # readable __repr__ with a name=value style

Point(x=11, y=22)



Named tuples are especially useful for assigning field names to result tuples returned by the csv or sqlite3 modules:

EmployeeRecord = namedtuple('EmployeeRecord', 'name, age, title, department,␣

, →paygrade')

import csv

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

for emp in map(EmployeeRecord._make, csv.reader(open("employees.csv", "rb"))):

print(emp.name, emp.title)

import sqlite3

conn = sqlite3.connect('/companydata')

cursor = conn.cursor()

cursor.execute('SELECT name, age, title, department, paygrade FROM employees') for emp in map(EmployeeRecord._make, cursor.fetchall()):

print(emp.name, emp.title)



In addition to the methods inherited from tuples, named tuples support three additional methods and two attributes. To prevent conflicts with field names, the method and attribute names start with an underscore.

classmethod somenamedtuple._make(iterable)

Class method that makes a new instance from an existing sequence or iterable.

>>> t = [11, 22]

>>> Point._make(t)

Point(x=11, y=22)



somenamedtuple._asdict()

Return a new dict which maps field names to their corresponding values:

>>> p = Point(x=11, y=22)

>>> p._asdict()

{'x': 11, 'y': 22}



Changed in version 3.1: Returns an OrderedDict instead of a regular dict.

Changed in version 3.8: Returns a regular dict instead of an OrderedDict. As of Python 3.7, regular dicts

are guaranteed to be ordered. If the extra features of OrderedDict are required, the suggested remediation

is to cast the result to the desired type: OrderedDict(nt._asdict()).

somenamedtuple._replace(**kwargs)

Return a new instance of the named tuple replacing specified fields with new values:

>>> p = Point(x=11, y=22)

>>> p._replace(x=33)

Point(x=33, y=22)

>>> for partnum, record in inventory.items():

... inventory[partnum] = record._replace(price=newprices[partnum],␣

, →timestamp=time.now())



Named tuples are also supported by generic function copy.replace().

Changed in version 3.13: Raise TypeError instead of ValueError for invalid keyword arguments.

somenamedtuple._fields

Tuple of strings listing the field names. Useful for introspection and for creating new named tuple types from

existing named tuples.

>>> p._fields # view the field names

('x', 'y')

>>> Color = namedtuple('Color', 'red green blue')

>>> Pixel = namedtuple('Pixel', Point._fields + Color._fields)

>>> Pixel(11, 22, 128, 255, 0)

Pixel(x=11, y=22, red=128, green=255, blue=0)

The Python Library Reference, Release 3.13.2



somenamedtuple._field_defaults

Dictionary mapping field names to default values.

>>> Account = namedtuple('Account', ['type', 'balance'], defaults=[0])

>>> Account._field_defaults

{'balance': 0}

>>> Account('premium')

Account(type='premium', balance=0)



To retrieve a field whose name is stored in a string, use the getattr() function:

>>> getattr(p, 'x')

11



To convert a dictionary to a named tuple, use the double-star-operator (as described in tut-unpacking-arguments):

>>> d = {'x': 11, 'y': 22}

>>> Point(**d)

Point(x=11, y=22)



Since a named tuple is a regular Python class, it is easy to add or change functionality with a subclass. Here is how to add a calculated field and a fixed-width print format:

>>> class Point(namedtuple('Point', ['x', 'y'])):

... __slots__ = ()

... @property

... def hypot(self):

... return (self.x ** 2 + self.y ** 2) ** 0.5

... def __str__(self):

... return 'Point: x=%6.3f y=%6.3f hypot=%6.3f' % (self.x, self.y, self.

, →hypot)

>>> for p in Point(3, 4), Point(14, 5/7):

... print(p)

Point: x= 3.000 y= 4.000 hypot= 5.000

Point: x=14.000 y= 0.714 hypot=14.018



The subclass shown above sets __slots__ to an empty tuple. This helps keep memory requirements low by pre-venting the creation of instance dictionaries.

Subclassing is not useful for adding new, stored fields. Instead, simply create a new named tuple type from the

_fields attribute:

>>> Point3D = namedtuple('Point3D', Point._fields + ('z',))



Docstrings can be customized by making direct assignments to the __doc__ fields:

>>> Book = namedtuple('Book', ['id', 'title', 'authors']) >>> Book.__doc__ += ': Hardcover book in active collection' >>> Book.id.__doc__ = '13-digit ISBN'

>>> Book.title.__doc__ = 'Title of first printing'

>>> Book.authors.__doc__ = 'List of authors sorted by last name'



Changed in version 3.5: Property docstrings became writeable.



µ See also

• See typing.NamedTuple for a way to add type hints for named tuples. It also provides an elegant notation

using the class keyword:

The Python Library Reference, Release 3.13.2



class Component(NamedTuple):

part_number: int

weight: float

description: Optional[str] = None

• See types.SimpleNamespace() for a mutable namespace based on an underlying dictionary instead of

a tuple.

• The dataclasses module provides a decorator and functions for automatically adding generated special

methods to user-defined classes.



8.4.6 OrderedDict objects

Ordered dictionaries are just like regular dictionaries but have some extra capabilities relating to ordering operations.

They have become less important now that the built-in dict class gained the ability to remember insertion order (this new behavior became guaranteed in Python 3.7).

Some differences from dict still remain:

• The regular dict was designed to be very good at mapping operations. Tracking insertion order was secondary.

• The OrderedDict was designed to be good at reordering operations. Space efficiency, iteration speed, and

the performance of update operations were secondary.

• The OrderedDict algorithm can handle frequent reordering operations better than dict. As shown in the

recipes below, this makes it suitable for implementing various kinds of LRU caches.

• The equality operation for OrderedDict checks for matching order.

A regular dict can emulate the order sensitive equality test with p == q and all(k1 == k2 for k1,

k2 in zip(p, q)).

• The popitem() method of OrderedDict has a different signature. It accepts an optional argument to specify

which item is popped.

A regular dict can emulate OrderedDict’s od.popitem(last=True) with d.popitem() which is guar-

anteed to pop the rightmost (last) item.

A regular dict can emulate OrderedDict’s od.popitem(last=False) with (k := next(iter(d)),

d.pop(k)) which will return and remove the leftmost (first) item if it exists.

• OrderedDict has a move_to_end() method to efficiently reposition an element to an endpoint.

A regular dict can emulate OrderedDict’s od.move_to_end(k, last=True) with d[k] = d.pop(k)

which will move the key and its associated value to the rightmost (last) position.

A regular dict does not have an efficient equivalent for OrderedDict’s od.move_to_end(k, last=False)

which moves the key and its associated value to the leftmost (first) position.

• Until Python 3.8, dict lacked a __reversed__() method.

class collections.OrderedDict( items [ ])

Return an instance of a dict subclass that has methods specialized for rearranging dictionary order.

Added in version 3.1.

popitem(last=True)

The popitem() method for ordered dictionaries returns and removes a (key, value) pair. The pairs are returned in LIFO order if last is true or FIFO (first-in, first-out) order if false.

move_to_end(key, last=True)

Move an existing key to either end of an ordered dictionary. The item is moved to the right end if last is

true (the default) or to the beginning if last is false. Raises KeyError if the key does not exist:



The Python Library Reference, Release 3.13.2



>>> d = OrderedDict.fromkeys('abcde')

>>> d.move_to_end('b')

>>> ''.join(d)

'acdeb'

>>> d.move_to_end('b', last=False)

>>> ''.join(d)

'bacde'



Added in version 3.2.

In addition to the usual mapping methods, ordered dictionaries also support reverse iteration using reversed().

Equality tests between OrderedDict objects are order-sensitive and are roughly equivalent to list(od1. items())==list(od2.items()).

Equality tests between OrderedDict objects and other Mapping objects are order-insensitive like regular dictio-

naries. This allows OrderedDict objects to be substituted anywhere a regular dictionary is used.

Changed in version 3.5: The items, keys, and values views of OrderedDict now support reverse iteration using

reversed().

Changed in version 3.6: With the acceptance of PEP 468, order is retained for keyword arguments passed to the

OrderedDict constructor and its update() method.

Changed in version 3.9: Added merge (|) and update (|=) operators, specified in PEP 584.



OrderedDict Examples and Recipes

It is straightforward to create an ordered dictionary variant that remembers the order the keys were last inserted. If a new entry overwrites an existing entry, the original insertion position is changed and moved to the end:

class LastUpdatedOrderedDict(OrderedDict):

'Store items in the order the keys were last added'

def __setitem__(self, key, value):

super().__setitem__(key, value)

self.move_to_end(key)



An OrderedDict would also be useful for implementing variants of functools.lru_cache():

from collections import OrderedDict

from time import time

class TimeBoundedLRU:

"LRU Cache that invalidates and refreshes old entries."

def __init__(self, func, maxsize=128, maxage=30):

self.cache = OrderedDict() # { args : (timestamp, result)} self.func = func

self.maxsize = maxsize

self.maxage = maxage

def __call__(self, *args):

if args in self.cache:

self.cache.move_to_end(args)

timestamp, result = self.cache[args]

if time()-timestamp <= self.maxage:

return result

result = self.func(*args)

self.cache[args] = time(), result

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

if len(self.cache) > self.maxsize:

self.cache.popitem(last=False)

return result



class MultiHitLRUCache:

""" LRU cache that defers caching a result until

it has been requested multiple times.

To avoid flushing the LRU cache with one-time requests, we don't cache until a request has been made more than once.

"""

def __init__(self, func, maxsize=128, maxrequests=4096, cache_after=1):

self.requests = OrderedDict() # { uncached_key : request_count } self.cache = OrderedDict() # { cached_key : function_result } self.func = func

self.maxrequests = maxrequests # max number of uncached requests self.maxsize = maxsize # max number of stored return values self.cache_after = cache_after

def __call__(self, *args):

if args in self.cache:

self.cache.move_to_end(args)

return self.cache[args]

result = self.func(*args)

self.requests[args] = self.requests.get(args, 0) + 1

if self.requests[args] <= self.cache_after:

self.requests.move_to_end(args)

if len(self.requests) > self.maxrequests:

self.requests.popitem(last=False)

else:

self.requests.pop(args, None)

self.cache[args] = result

if len(self.cache) > self.maxsize:

self.cache.popitem(last=False)

return result



8.4.7 UserDict objects

The class, UserDict acts as a wrapper around dictionary objects. The need for this class has been partially supplanted

by the ability to subclass directly from dict; however, this class can be easier to work with because the underlying dictionary is accessible as an attribute.

class collections.UserDict( initialdata [ ])

Class that simulates a dictionary. The instance’s contents are kept in a regular dictionary, which is accessible

via the data attribute of UserDict instances. If initialdata is provided, data is initialized with its contents;

note that a reference to initialdata will not be kept, allowing it to be used for other purposes.

In addition to supporting the methods and operations of mappings, UserDict instances provide the following

attribute:

data

A real dictionary used to store the contents of the UserDict class.



The Python Library Reference, Release 3.13.2



8.4.8 UserList objects

This class acts as a wrapper around list objects. It is a useful base class for your own list-like classes which can inherit from them and override existing methods or add new ones. In this way, one can add new behaviors to lists.

The need for this class has been partially supplanted by the ability to subclass directly from list; however, this class can be easier to work with because the underlying list is accessible as an attribute.

class collections.UserList( list [ ])

Class that simulates a list. The instance’s contents are kept in a regular list, which is accessible via the data

attribute of UserList instances. The instance’s contents are initially set to a copy of list, defaulting to the

empty list []. list can be any iterable, for example a real Python list or a UserList object.

In addition to supporting the methods and operations of mutable sequences, UserList instances provide the

following attribute:

data

A real list object used to store the contents of the UserList class.

Subclassing requirements: Subclasses of UserList are expected to offer a constructor which can be called with either no arguments or one argument. List operations which return a new sequence attempt to create an instance of the actual implementation class. To do so, it assumes that the constructor can be called with a single parameter, which is a sequence object used as a data source.

If a derived class does not wish to comply with this requirement, all of the special methods supported by this class will need to be overridden; please consult the sources for information about the methods which need to be provided in that case.



8.4.9 UserString objects

The class, UserString acts as a wrapper around string objects. The need for this class has been partially supplanted

by the ability to subclass directly from str; however, this class can be easier to work with because the underlying string is accessible as an attribute.

class collections.UserString(seq)

Class that simulates a string object. The instance’s content is kept in a regular string object, which is accessible

via the data attribute of UserString instances. The instance’s contents are initially set to a copy of seq. The

seq argument can be any object which can be converted into a string using the built-in str() function.

In addition to supporting the methods and operations of strings, UserString instances provide the following

attribute:

data

A real str object used to store the contents of the UserString class.

Changed in version 3.5: New methods __getnewargs__, __rmod__, casefold, format_map,

isprintable, and maketrans.



8.5 collections.abc — Abstract Base Classes for Containers

Added in version 3.3: Formerly, this module was part of the collections module.

Source code: Lib/_collections_abc.py



This module provides abstract base classes that can be used to test whether a class provides a particular interface; for

example, whether it is hashable or whether it is a mapping.

An issubclass() or isinstance() test for an interface works in one of three ways.

1) A newly written class can inherit directly from one of the abstract base classes. The class must supply the required abstract methods. The remaining mixin methods come from inheritance and can be overridden if desired. Other methods may be added as needed:

The Python Library Reference, Release 3.13.2



class C(Sequence): # Direct inheritance

def __init__(self): ... # Extra method not required by the ABC

def __getitem__(self, index): ... # Required abstract method

def __len__(self): ... # Required abstract method

def count(self, value): ... # Optionally override a mixin method



>>> issubclass(C, Sequence)

True

>>> isinstance(C(), Sequence)

True



2) Existing classes and built-in classes can be registered as “virtual subclasses” of the ABCs. Those classes should define the full API including all of the abstract methods and all of the mixin methods. This lets users rely on

issubclass() or isinstance() tests to determine whether the full interface is supported. The exception to this rule is for methods that are automatically inferred from the rest of the API:

class D: # No inheritance

def __init__(self): ... # Extra method not required by the ABC

def __getitem__(self, index): ... # Abstract method

def __len__(self): ... # Abstract method

def count(self, value): ... # Mixin method

def index(self, value): ... # Mixin method

Sequence.register(D) # Register instead of inherit



>>> issubclass(D, Sequence)

True

>>> isinstance(D(), Sequence)

True



In this example, class D does not need to define __contains__, __iter__, and __reversed__ because the

in-operator, the iteration logic, and the reversed() function automatically fall back to using __getitem__ and __len__.

3) Some simple interfaces are directly recognizable by the presence of the required methods (unless those methods

have been set to None):

class E:

def __iter__(self): ...

def __next__(self): ...



>>> issubclass(E, Iterable)

True

>>> isinstance(E(), Iterable)

True



Complex interfaces do not support this last technique because an interface is more than just the presence of method names. Interfaces specify semantics and relationships between methods that cannot be inferred solely from the pres-ence of specific method names. For example, knowing that a class supplies __getitem__, __len__, and __iter__

is insufficient for distinguishing a Sequence from a Mapping.

Added in version 3.9: These abstract classes now support []. See Generic Alias Type and PEP 585.



The Python Library Reference, Release 3.13.2



8.5.1 Collections Abstract Base Classes

The collections module offers the following ABCs:



ABC Inherits Abstract Methods Mixin Methods

from

Container1 __contains__

Hashable 1 __hash__

Iterable 12 __iter__

Iterator1 Iterable __next__ __iter__

Reversible1 Iterable __reversed__

Generator1 Iterator send, throw close, __iter__, __next__

Sized 1 __len__

Callable 1 __call__

Collection1 Sized , __contains__,

Iterable, __iter__, __len__

Container

Sequence Reversible, __getitem__, __contains__, __iter__, __reversed__,

Collection __len__ index , and count

MutableSequence Sequence __getitem__, Inherited Sequence methods and append,

__setitem__, clear, reverse, extend, pop, remove, and

__delitem__, __iadd__

__len__ , insert

ByteString Sequence __getitem__, Inherited Sequence methods

__len__

Set Collection __contains__, __le__, __lt__, __eq__, __ne__, __gt__,

__iter__, __len__ __ge__, __and__, __or__, __sub__,

__rsub__, __xor__, __rxor__ and

isdisjoint

MutableSet Set __contains__, Inherited Set methods and clear, pop,

__iter__, __len__, remove, __ior__, __iand__, __ixor__,

add , discard and __isub__

Mapping Collection __getitem__, __contains__, keys, items, values, get,

__iter__, __len__ __eq__, and __ne__

MutableMapping Mapping __getitem__, Inherited Mapping methods and pop,

__setitem__, popitem, clear, update, and setdefault

__delitem__,

__iter__, __len__

MappingView Sized __init__, __len__ and __repr__

ItemsView MappingView , __contains__, __iter__

Set

KeysView MappingView , __contains__, __iter__

Set

ValuesView MappingView , __contains__, __iter__

Collection

Awaitable 1 __await__

Coroutine 1 Awaitable send , throw close

AsyncIterable1 __aiter__

AsyncIterator1 AsyncIterable __anext__ __aiter__

AsyncGenerator1 AsyncIterator asend , athrow aclose, __aiter__, __anext__

Buffer 1 __buffer__



1 These ABCs override __subclasshook__() to support testing an interface by verifying the required methods are present and have not

been set to None. This only works for simple interfaces. More complex interfaces require registration or direct subclassing.

2 Checking isinstance(obj, Iterable) detects classes that are registered as Iterable or that have an __iter__() method, but it

does not detect classes that iterate with the __getitem__() method. The only reliable way to determine whether an object is iterable is to call iter(obj).

The Python Library Reference, Release 3.13.2



8.5.2 Collections Abstract Base Classes – Detailed Descriptions

class collections.abc.Container

ABC for classes that provide the __contains__() method.

class collections.abc.Hashable

ABC for classes that provide the __hash__() method.

class collections.abc.Sized

ABC for classes that provide the __len__() method.

class collections.abc.Callable

ABC for classes that provide the __call__() method.

See Annotating callable objects for details on how to use Callable in type annotations.

class collections.abc.Iterable

ABC for classes that provide the __iter__() method.

Checking isinstance(obj, Iterable) detects classes that are registered as Iterable or that have an

__iter__() method, but it does not detect classes that iterate with the __getitem__() method. The only

reliable way to determine whether an object is iterable is to call iter(obj).

class collections.abc.Collection

ABC for sized iterable container classes.

Added in version 3.6.

class collections.abc.Iterator

ABC for classes that provide the __iter__() and __next__() methods. See also the definition of iterator.

class collections.abc.Reversible

ABC for iterable classes that also provide the __reversed__() method.

Added in version 3.6.

class collections.abc.Generator

ABC for generator classes that implement the protocol defined in PEP 342 that extends iterators with the

send() , throw() and close() methods.

See Annotating generators and coroutines for details on using Generator in type annotations.

Added in version 3.5.

class collections.abc.Sequence

class collections.abc.MutableSequence

class collections.abc.ByteString

ABCs for read-only and mutable sequences.

Implementation note: Some of the mixin methods, such as __iter__(), __reversed__() and index(),

make repeated calls to the underlying __getitem__() method. Consequently, if __getitem__() is imple-

mented with constant access speed, the mixin methods will have linear performance; however, if the underlying

method is linear (as it would be with a linked list), the mixins will have quadratic performance and will likely

need to be overridden.

Changed in version 3.5: The index() method added support for stop and start arguments.

Deprecated since version 3.12, will be removed in version 3.14: The ByteString ABC has been deprecated.

For use in typing, prefer a union, like bytes | bytearray, or collections.abc.Buffer. For use as

an ABC, prefer Sequence or collections.abc.Buffer.

class collections.abc.Set



The Python Library Reference, Release 3.13.2



class collections.abc.MutableSet

ABCs for read-only and mutable sets.

class collections.abc.Mapping

class collections.abc.MutableMapping

ABCs for read-only and mutable mappings.

class collections.abc.MappingView

class collections.abc.ItemsView

class collections.abc.KeysView

class collections.abc.ValuesView

ABCs for mapping, items, keys, and values views.

class collections.abc.Awaitable

ABC for awaitable objects, which can be used in await expressions. Custom implementations must provide

the __await__() method.

Coroutine objects and instances of the Coroutine ABC are all instances of this ABC.



® Note

In CPython, generator-based coroutines (generators decorated with @types.coroutine) are awaitables, even though they do not have an __await__() method. Using isinstance(gencoro, Awaitable)

for them will return False. Use inspect.isawaitable() to detect them.



Added in version 3.5.

class collections.abc.Coroutine

ABC for coroutine compatible classes. These implement the following methods, defined in coroutine-objects:

send() , throw(), and close(). Custom implementations must also implement __await__(). All

Coroutine instances are also instances of Awaitable.



® Note

In CPython, generator-based coroutines (generators decorated with @types.coroutine) are awaitables, even though they do not have an __await__() method. Using isinstance(gencoro, Coroutine)

for them will return False. Use inspect.isawaitable() to detect them.



See Annotating generators and coroutines for details on using Coroutine in type annotations. The variance

and order of type parameters correspond to those of Generator.

Added in version 3.5.

class collections.abc.AsyncIterable

ABC for classes that provide an __aiter__ method. See also the definition of asynchronous iterable.

Added in version 3.5.

class collections.abc.AsyncIterator

ABC for classes that provide __aiter__ and __anext__ methods. See also the definition of asynchronous

iterator.

Added in version 3.5.

class collections.abc.AsyncGenerator

ABC for asynchronous generator classes that implement the protocol defined in PEP 525 and PEP 492.

See Annotating generators and coroutines for details on using AsyncGenerator in type annotations.

Added in version 3.6.

The Python Library Reference, Release 3.13.2



class collections.abc.Buffer

ABC for classes that provide the __buffer__() method, implementing the buffer protocol. See PEP 688.

Added in version 3.12.



8.5.3 Examples and Recipes

ABCs allow us to ask classes or instances if they provide particular functionality, for example:

size = None

if isinstance(myvar, collections.abc.Sized):

size = len(myvar)



Several of the ABCs are also useful as mixins that make it easier to develop classes supporting container APIs. For

example, to write a class supporting the full Set API, it is only necessary to supply the three underlying abstract

methods: __contains__(), __iter__(), and __len__(). The ABC supplies the remaining methods such as

__and__() and isdisjoint():

class ListBasedSet(collections.abc.Set):

''' Alternate set implementation favoring space over speed

and not requiring the set elements to be hashable. '''

def __init__(self, iterable):

self.elements = lst = []

for value in iterable:

if value not in lst:

lst.append(value)

def __iter__(self):

return iter(self.elements)

def __contains__(self, value):

return value in self.elements

def __len__(self):

return len(self.elements)

s1 = ListBasedSet('abcdef')

s2 = ListBasedSet('defghi')

overlap = s1 & s2 # The __and__() method is supported automatically



Notes on using Set and MutableSet as a mixin:

(1) Since some set operations create new sets, the default mixin methods need a way to create new instances

from an iterable. The class constructor is assumed to have a signature in the form ClassName(iterable).

That assumption is factored-out to an internal classmethod called _from_iterable() which calls

cls(iterable) to produce a new set. If the Set mixin is being used in a class with a different construc-

tor signature, you will need to override _from_iterable() with a classmethod or regular method that can

construct new instances from an iterable argument.

(2) To override the comparisons (presumably for speed, as the semantics are fixed), redefine __le__() and

__ge__(), then the other operations will automatically follow suit.

(3) The Set mixin provides a _hash() method to compute a hash value for the set; however, __hash__() is not

defined because not all sets are hashable or immutable. To add set hashability using mixins, inherit from both

Set() and Hashable(), then define __hash__ = Set._hash.



µ See also

• OrderedSet recipe for an example built on MutableSet.

The Python Library Reference, Release 3.13.2



• For more about ABCs, see the abc module and PEP 3119.



8.6 heapq — Heap queue algorithm

Source code: Lib/heapq.py



This module provides an implementation of the heap queue algorithm, also known as the priority queue algorithm.

Heaps are binary trees for which every parent node has a value less than or equal to any of its children. We refer to this condition as the heap invariant.

This implementation uses arrays for which heap[k] <= heap[2*k+1] and heap[k] <= heap[2*k+2] for all k, counting elements from zero. For the sake of comparison, non-existing elements are considered to be infinite. The interesting property of a heap is that its smallest element is always the root, heap[0].

The API below differs from textbook heap algorithms in two aspects: (a) We use zero-based indexing. This makes the relationship between the index for a node and the indexes for its children slightly less obvious, but is more suitable since Python uses zero-based indexing. (b) Our pop method returns the smallest item, not the largest (called a “min heap” in textbooks; a “max heap” is more common in texts because of its suitability for in-place sorting).

These two make it possible to view the heap as a regular Python list without surprises: heap[0] is the smallest item, and heap.sort() maintains the heap invariant!

To create a heap, use a list initialized to [], or you can transform a populated list into a heap via function heapify().

The following functions are provided:

heapq.heappush(heap, item)

Push the value item onto the heap, maintaining the heap invariant.

heapq.heappop(heap)

Pop and return the smallest item from the heap, maintaining the heap invariant. If the heap is empty,

IndexError is raised. To access the smallest item without popping it, use heap[0].

heapq.heappushpop(heap, item)

Push item on the heap, then pop and return the smallest item from the heap. The combined action runs more

efficiently than heappush() followed by a separate call to heappop().

heapq.heapify(x)

Transform list x into a heap, in-place, in linear time.

heapq.heapreplace(heap, item)

Pop and return the smallest item from the heap, and also push the new item. The heap size doesn’t change. If

the heap is empty, IndexError is raised.

This one step operation is more efficient than a heappop() followed by heappush() and can be more ap-

propriate when using a fixed-size heap. The pop/push combination always returns an element from the heap

and replaces it with item.

The value returned may be larger than the item added. If that isn’t desired, consider using heappushpop()

instead. Its push/pop combination returns the smaller of the two values, leaving the larger value on the heap.

The module also offers three general purpose functions based on heaps.

heapq.merge(*iterables, key=None, reverse=False)

Merge multiple sorted inputs into a single sorted output (for example, merge timestamped entries from multiple

log files). Returns an iterator over the sorted values.

Similar to sorted(itertools.chain(*iterables)) but returns an iterable, does not pull the data into

memory all at once, and assumes that each of the input streams is already sorted (smallest to largest).

Has two optional arguments which must be specified as keyword arguments.

The Python Library Reference, Release 3.13.2



key specifies a key function of one argument that is used to extract a comparison key from each input element.

The default value is None (compare the elements directly).

reverse is a boolean value. If set to True, then the input elements are merged as if each comparison were

reversed. To achieve behavior similar to sorted(itertools.chain(*iterables), reverse=True),

all iterables must be sorted from largest to smallest.

Changed in version 3.5: Added the optional key and reverse parameters.

heapq.nlargest(n, iterable, key=None)

Return a list with the n largest elements from the dataset defined by iterable. key, if provided, specifies a

function of one argument that is used to extract a comparison key from each element in iterable (for example,

key=str.lower). Equivalent to: sorted(iterable, key=key, reverse=True)[:n].

heapq.nsmallest(n, iterable, key=None)

Return a list with the n smallest elements from the dataset defined by iterable. key, if provided, specifies a

function of one argument that is used to extract a comparison key from each element in iterable (for example,

key=str.lower). Equivalent to: sorted(iterable, key=key)[:n].

The latter two functions perform best for smaller values of n. For larger values, it is more efficient to use the sorted()

function. Also, when n==1, it is more efficient to use the built-in min() and max() functions. If repeated usage of these functions is required, consider turning the iterable into an actual heap.



8.6.1 Basic Examples

A heapsort can be implemented by pushing all values onto a heap and then popping off the smallest values one at a time:

>>> def heapsort(iterable):

... h = []

... for value in iterable:

... heappush(h, value)

... return [heappop(h) for i in range(len(h))]

...

>>> heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0])

[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]



This is similar to sorted(iterable), but unlike sorted(), this implementation is not stable.

Heap elements can be tuples. This is useful for assigning comparison values (such as task priorities) alongside the main record being tracked:

>>> h = []

>>> heappush(h, (5, 'write code'))

>>> heappush(h, (7, 'release product'))

>>> heappush(h, (1, 'write spec'))

>>> heappush(h, (3, 'create tests'))

>>> heappop(h)

(1, 'write spec')



8.6.2 Priority Queue Implementation Notes

A priority queue is common use for a heap, and it presents several implementation challenges:

• Sort stability: how do you get two tasks with equal priorities to be returned in the order they were originally

added?

• Tuple comparison breaks for (priority, task) pairs if the priorities are equal and the tasks do not have a default

comparison order.

• If the priority of a task changes, how do you move it to a new position in the heap?

• Or if a pending task needs to be deleted, how do you find it and remove it from the queue?

The Python Library Reference, Release 3.13.2



A solution to the first two challenges is to store entries as 3-element list including the priority, an entry count, and the task. The entry count serves as a tie-breaker so that two tasks with the same priority are returned in the order they were added. And since no two entry counts are the same, the tuple comparison will never attempt to directly compare two tasks.

Another solution to the problem of non-comparable tasks is to create a wrapper class that ignores the task item and only compares the priority field:

from dataclasses import dataclass, field

from typing import Any

@dataclass(order=True)

class PrioritizedItem:

priority: int

item: Any=field(compare=False)



The remaining challenges revolve around finding a pending task and making changes to its priority or removing it entirely. Finding a task can be done with a dictionary pointing to an entry in the queue.

Removing the entry or changing its priority is more difficult because it would break the heap structure invariants. So, a possible solution is to mark the entry as removed and add a new entry with the revised priority:

pq = [] # list of entries arranged in a heap

entry_finder = {} # mapping of tasks to entries

REMOVED = '' # placeholder for a removed task counter = itertools.count() # unique sequence count

def add_task(task, priority=0):

'Add a new task or update the priority of an existing task'

if task in entry_finder:

remove_task(task)

count = next(counter)

entry = [priority, count, task]

entry_finder[task] = entry

heappush(pq, entry)

def remove_task(task):

'Mark an existing task as REMOVED. Raise KeyError if not found.'

entry = entry_finder.pop(task)

entry[-1] = REMOVED

def pop_task():

'Remove and return the lowest priority task. Raise KeyError if empty.'

while pq:

priority, count, task = heappop(pq)

if task is not REMOVED:

del entry_finder[task]

return task

raise KeyError('pop from an empty priority queue')



8.6.3 Theory

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for all k, counting elements from 0. For the sake of comparison, non-existing elements are considered to be infinite. The interesting property of a heap is that a[0] is always its smallest element.

The strange invariant above is meant to be an efficient memory representation for a tournament. The numbers below are k, not a[k]:

The Python Library Reference, Release 3.13.2



0

1 2

3 4 5 6

7 8 9 10 11 12 13 14

15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30



In the tree above, each cell k is topping 2*k+1 and 2*k+2. In a usual binary tournament we see in sports, each cell is the winner over the two cells it tops, and we can trace the winner down the tree to see all opponents s/he had. However, in many computer applications of such tournaments, we do not need to trace the history of a winner. To be more memory efficient, when a winner is promoted, we try to replace it by something else at a lower level, and the rule becomes that a cell and the two cells it tops contain three different items, but the top cell “wins” over the two topped cells.

If this heap invariant is protected at all time, index 0 is clearly the overall winner. The simplest algorithmic way to remove it and find the “next” winner is to move some loser (let’s say cell 30 in the diagram above) into the 0 position, and then percolate this new 0 down the tree, exchanging values, until the invariant is re-established. This is clearly logarithmic on the total number of items in the tree. By iterating over all items, you get an O(n log n) sort.

A nice feature of this sort is that you can efficiently insert new items while the sort is going on, provided that the inserted items are not “better” than the last 0’th element you extracted. This is especially useful in simulation contexts, where the tree holds all incoming events, and the “win” condition means the smallest scheduled time. When an event schedules other events for execution, they are scheduled into the future, so they can easily go into the heap. So, a heap is a good structure for implementing schedulers (this is what I used for my MIDI sequencer :-).

Various structures for implementing schedulers have been extensively studied, and heaps are good for this, as they are reasonably speedy, the speed is almost constant, and the worst case is not much different than the average case. However, there are other representations which are more efficient overall, yet the worst cases might be terrible.

Heaps are also very useful in big disk sorts. You most probably all know that a big sort implies producing “runs” (which are pre-sorted sequences, whose size is usually related to the amount of CPU memory), followed by a merging

passes for these runs, which merging is often very cleverly organised1. It is very important that the initial sort produces the longest runs possible. Tournaments are a good way to achieve that. If, using all the memory available to hold a tournament, you replace and percolate items that happen to fit the current run, you’ll produce runs which are twice the size of the memory for random input, and much better for input fuzzily ordered.

Moreover, if you output the 0’th item on disk and get an input which may not fit in the current tournament (because the value “wins” over the last output value), it cannot fit in the heap, so the size of the heap decreases. The freed memory could be cleverly reused immediately for progressively building a second heap, which grows at exactly the same rate the first heap is melting. When the first heap completely vanishes, you switch heaps and start a new run. Clever and quite effective!

In a word, heaps are useful memory structures to know. I use them in a few applications, and I think it is good to keep a ‘heap’ module around. :-)



8.7 bisect — Array bisection algorithm

Source code: Lib/bisect.py



This module provides support for maintaining a list in sorted order without having to sort the list after each insertion. For long lists of items with expensive comparison operations, this can be an improvement over linear searches or frequent resorting.

1 The disk balancing algorithms which are current, nowadays, are more annoying than clever, and this is a consequence of the seeking capa-

bilities of the disks. On devices which cannot seek, like big tape drives, the story was quite different, and one had to be very clever to ensure (far in advance) that each tape movement will be the most effective possible (that is, will best participate at “progressing” the merge). Some tapes were even able to read backwards, and this was also used to avoid the rewinding time. Believe me, real good tape sorts were quite spectacular to watch! From all times, sorting has always been a Great Art! :-)

The Python Library Reference, Release 3.13.2



The module is called bisect because it uses a basic bisection algorithm to do its work. Unlike other bisection tools that search for a specific value, the functions in this module are designed to locate an insertion point. Accordingly, the functions never call an __eq__() method to determine whether a value has been found. Instead, the functions only call the __lt__() method and will return an insertion point between values in an array.

The following functions are provided:

bisect.bisect_left(a, x, lo=0, hi=len(a), *, key=None)

Locate the insertion point for x in a to maintain sorted order. The parameters lo and hi may be used to specify

a subset of the list which should be considered; by default the entire list is used. If x is already present in a,

the insertion point will be before (to the left of) any existing entries. The return value is suitable for use as the

first parameter to list.insert() assuming that a is already sorted.

The returned insertion point ip partitions the array a into two slices such that all(elem < x for elem in

a[lo : ip]) is true for the left slice and all(elem >= x for elem in a[ip : hi]) is true for the

right slice.

key specifies a key function of one argument that is used to extract a comparison key from each element in the

array. To support searching complex records, the key function is not applied to the x value.

If key is None, the elements are compared directly and no key function is called.

Changed in version 3.10: Added the key parameter.

bisect.bisect_right(a, x, lo=0, hi=len(a), *, key=None)

bisect.bisect(a, x, lo=0, hi=len(a), *, key=None)

Similar to bisect_left(), but returns an insertion point which comes after (to the right of) any existing

entries of x in a.

The returned insertion point ip partitions the array a into two slices such that all(elem <= x for elem

in a[lo : ip]) is true for the left slice and all(elem > x for elem in a[ip : hi]) is true for

the right slice.

Changed in version 3.10: Added the key parameter.

bisect.insort_left(a, x, lo=0, hi=len(a), *, key=None)

Insert x in a in sorted order.

This function first runs bisect_left() to locate an insertion point. Next, it runs the insert() method on

a to insert x at the appropriate position to maintain sort order.

To support inserting records in a table, the key function (if any) is applied to x for the search step but not for

the insertion step.

Keep in mind that the O(log n) search is dominated by the slow O(n) insertion step.

Changed in version 3.10: Added the key parameter.

bisect.insort_right(a, x, lo=0, hi=len(a), *, key=None)

bisect.insort(a, x, lo=0, hi=len(a), *, key=None)

Similar to insort_left(), but inserting x in a after any existing entries of x.

This function first runs bisect_right() to locate an insertion point. Next, it runs the insert() method

on a to insert x at the appropriate position to maintain sort order.

To support inserting records in a table, the key function (if any) is applied to x for the search step but not for

the insertion step.

Keep in mind that the O(log n) search is dominated by the slow O(n) insertion step.

Changed in version 3.10: Added the key parameter.



The Python Library Reference, Release 3.13.2



8.7.1 Performance Notes

When writing time sensitive code using bisect() and insort(), keep these thoughts in mind:

• Bisection is effective for searching ranges of values. For locating specific values, dictionaries are more perfor-

mant.

• The insort() functions are O(n) because the logarithmic search step is dominated by the linear time insertion

step.

• The search functions are stateless and discard key function results after they are used. Consequently, if the

search functions are used in a loop, the key function may be called again and again on the same array elements.

If the key function isn’t fast, consider wrapping it with functools.cache() to avoid duplicate computations.

Alternatively, consider searching an array of precomputed keys to locate the insertion point (as shown in the

examples section below).



µ See also

• Sorted Collections is a high performance module that uses bisect to managed sorted collections of data.

• The SortedCollection recipe uses bisect to build a full-featured collection class with straight-forward search

methods and support for a key-function. The keys are precomputed to save unnecessary calls to the key function during searches.



8.7.2 Searching Sorted Lists

The above bisect functions are useful for finding insertion points but can be tricky or awkward to use for common searching tasks. The following five functions show how to transform them into the standard lookups for sorted lists:

def index(a, x):

'Locate the leftmost value exactly equal to x'

i = bisect_left(a, x)

if i != len(a) and a[i] == x:

return i

raise ValueError

def find_lt(a, x):

'Find rightmost value less than x'

i = bisect_left(a, x)

if i:

return a[i-1]

raise ValueError

def find_le(a, x):

'Find rightmost value less than or equal to x'

i = bisect_right(a, x)

if i:

return a[i-1]

raise ValueError

def find_gt(a, x):

'Find leftmost value greater than x'

i = bisect_right(a, x)

if i != len(a):

return a[i]

raise ValueError

def find_ge(a, x):

'Find leftmost item greater than or equal to x'

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

i = bisect_left(a, x)

if i != len(a):

return a[i]

raise ValueError



8.7.3 Examples

The bisect() function can be useful for numeric table lookups. This example uses bisect() to look up a letter grade for an exam score (say) based on a set of ordered numeric breakpoints: 90 and up is an ‘A’, 80 to 89 is a ‘B’, and so on:

>>> def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'): ... i = bisect(breakpoints, score)

... return grades[i]

...

>>> [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]]

['F', 'A', 'C', 'C', 'B', 'A', 'A']



The bisect() and insort() functions also work with lists of tuples. The key argument can serve to extract the field used for ordering records in a table:

>>> from collections import namedtuple

>>> from operator import attrgetter

>>> from bisect import bisect, insort

>>> from pprint import pprint

>>> Movie = namedtuple('Movie', ('name', 'released', 'director'))

>>> movies = [

... Movie('Jaws', 1975, 'Spielberg'),

... Movie('Titanic', 1997, 'Cameron'),

... Movie('The Birds', 1963, 'Hitchcock'),

... Movie('Aliens', 1986, 'Cameron')

... ]

>>> # Find the first movie released after 1960

>>> by_year = attrgetter('released')

>>> movies.sort(key=by_year)

>>> movies[bisect(movies, 1960, key=by_year)]

Movie(name='The Birds', released=1963, director='Hitchcock')

>>> # Insert a movie while maintaining sort order

>>> romance = Movie('Love Story', 1970, 'Hiller')

>>> insort(movies, romance, key=by_year)

>>> pprint(movies)

[Movie(name='The Birds', released=1963, director='Hitchcock'),

Movie(name='Love Story', released=1970, director='Hiller'), Movie(name='Jaws', released=1975, director='Spielberg'), Movie(name='Aliens', released=1986, director='Cameron'), Movie(name='Titanic', released=1997, director='Cameron')]



If the key function is expensive, it is possible to avoid repeated function calls by searching a list of precomputed keys to find the index of a record:

>>> data = [('red', 5), ('blue', 1), ('yellow', 8), ('black', 0)] >>> data.sort(key=lambda r: r[1]) # Or use operator.itemgetter(1).

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> keys = [r[1] for r in data] # Precompute a list of keys. >>> data[bisect_left(keys, 0)]

('black', 0)

>>> data[bisect_left(keys, 1)]

('blue', 1)

>>> data[bisect_left(keys, 5)]

('red', 5)

>>> data[bisect_left(keys, 8)]

('yellow', 8)



8.8 array — Efficient arrays of numeric values



This module defines an object type which can compactly represent an array of basic values: characters, integers, floating-point numbers. Arrays are sequence types and behave very much like lists, except that the type of objects stored in them is constrained. The type is specified at object creation time by using a type code, which is a single character. The following type codes are defined:



Type code C Type Python Type Minimum size in bytes Notes

'b' signed char int 1

'B' unsigned char int 1

'u' wchar_t Unicode character 2 (1)

'w' Py_UCS4 Unicode character 4

'h' signed short int 2

'H' unsigned short int 2

'i' signed int int 2

'I' unsigned int int 2

'l' signed long int 4

'L' unsigned long int 4

'q' signed long long int 8

'Q' unsigned long long int 8

'f' float float 4

'd' double float 8



Notes:

(1) It can be 16 bits or 32 bits depending on the platform.

Changed in version 3.9: array('u') now uses wchar_t as C type instead of deprecated Py_UNICODE. This

change doesn’t affect its behavior because Py_UNICODE is alias of wchar_t since Python 3.3.

Deprecated since version 3.3, will be removed in version 3.16: Please migrate to 'w' typecode.

The actual representation of values is determined by the machine architecture (strictly speaking, by the C implemen-

tation). The actual size can be accessed through the array.itemsize attribute.

The module defines the following item:

array.typecodes

A string with all available type codes.

The module defines the following type:

class array.array(typecode [, initializer ])

A new array whose items are restricted by typecode, and initialized from the optional initializer value, which

must be a bytes or bytearray object, a Unicode string, or iterable over elements of the appropriate type.

The Python Library Reference, Release 3.13.2



If given a bytes or bytearray object, the initializer is passed to the new array’s frombytes() method;

if given a Unicode string, the initializer is passed to the fromunicode() method; otherwise, the initializer’s

iterator is passed to the extend() method to add initial items to the array.

Array objects support the ordinary sequence operations of indexing, slicing, concatenation, and multiplication.

When using slice assignment, the assigned value must be an array object with the same type code; in all other

cases, TypeError is raised. Array objects also implement the buffer interface, and may be used wherever

bytes-like objects are supported.

Raises an auditing event array.__new__ with arguments typecode, initializer.

typecode

The typecode character used to create the array.

itemsize

The length in bytes of one array item in the internal representation.

append(x)

Append a new item with value x to the end of the array.

buffer_info()

Return a tuple (address, length) giving the current memory address and the length in elements of the buffer used to hold array’s contents. The size of the memory buffer in bytes can be computed as array.buffer_info()[1] * array.itemsize. This is occasionally useful when working with low-level (and inherently unsafe) I/O interfaces that require memory addresses, such as certain ioctl() operations. The returned numbers are valid as long as the array exists and no length-changing operations are applied to it.



® Note

When using array objects from code written in C or C++ (the only way to effectively make use of this information), it makes more sense to use the buffer interface supported by array objects. This method is maintained for backward compatibility and should be avoided in new code. The buffer interface is documented in bufferobjects.



byteswap()

“Byteswap” all items of the array. This is only supported for values which are 1, 2, 4, or 8 bytes in size;

for other types of values, RuntimeError is raised. It is useful when reading data from a file written on a machine with a different byte order.

count(x)

Return the number of occurrences of x in the array.

extend(iterable)

Append items from iterable to the end of the array. If iterable is another array, it must have exactly the

same type code; if not, TypeError will be raised. If iterable is not an array, it must be iterable and its elements must be the right type to be appended to the array.

frombytes(buffer)

Appends items from the bytes-like object, interpreting its content as an array of machine values (as if it

had been read from a file using the fromfile() method).

Added in version 3.2: fromstring() is renamed to frombytes() for clarity.

fromfile(f, n)

Read n items (as machine values) from the file object f and append them to the end of the array. If less

than n items are available, EOFError is raised, but the items that were available are still inserted into the array.



The Python Library Reference, Release 3.13.2



fromlist(list)

Append items from the list. This is equivalent to for x in list: a.append(x) except that if there is a type error, the array is unchanged.

fromunicode(s)

Extends this array with data from the given Unicode string. The array must have type code 'u' or 'w';

otherwise a ValueError is raised. Use array.frombytes(unicodestring.encode(enc)) to append Unicode data to an array of some other type.

index(x [, start[, stop ]])

Return the smallest i such that i is the index of the first occurrence of x in the array. The optional argu-

ments start and stop can be specified to search for x within a subsection of the array. Raise ValueError if x is not found.

Changed in version 3.10: Added optional start and stop parameters.

insert(i, x)

Insert a new item with value x in the array before position i. Negative values are treated as being relative to the end of the array.

pop( i [ ])

Removes the item with the index i from the array and returns it. The optional argument defaults to-1, so that by default the last item is removed and returned.

remove(x)

Remove the first occurrence of x from the array.

clear()

Remove all elements from the array.

Added in version 3.13.

reverse()

Reverse the order of the items in the array.

tobytes()

Convert the array to an array of machine values and return the bytes representation (the same sequence

of bytes that would be written to a file by the tofile() method.)

Added in version 3.2: tostring() is renamed to tobytes() for clarity.

tofile(f)

Write all items (as machine values) to the file object f.

tolist()

Convert the array to an ordinary list with the same items.

tounicode()

Convert the array to a Unicode string. The array must have a type 'u' or 'w'; otherwise a ValueError is raised. Use array.tobytes().decode(enc) to obtain a Unicode string from an array of some other type.

The string representation of array objects has the form array(typecode, initializer). The initializer is omitted if the array is empty, otherwise it is a Unicode string if the typecode is 'u' or 'w', otherwise it is a list of numbers. The string representation is guaranteed to be able to be converted back to an array with the same type and

value using eval(), so long as the array class has been imported using from array import array. Variables inf and nan must also be defined if it contains corresponding floating-point values. Examples:

array('l')

array('w', 'hello \u2641')

array('l', [1, 2, 3, 4, 5])

array('d', [1.0, 2.0, 3.14,-inf, nan])

The Python Library Reference, Release 3.13.2



µ See also

Module struct

Packing and unpacking of heterogeneous binary data.

NumPy

The NumPy package defines another array type.



8.9 weakref — Weak references

Source code: Lib/weakref.py



The weakref module allows the Python programmer to create weak references to objects.

In the following, the term referent means the object which is referred to by a weak reference.

A weak reference to an object is not enough to keep the object alive: when the only remaining references to a

referent are weak references, garbage collection is free to destroy the referent and reuse its memory for something else. However, until the object is actually destroyed the weak reference may return the object even if there are no strong references to it.

A primary use for weak references is to implement caches or mappings holding large objects, where it’s desired that a large object not be kept alive solely because it appears in a cache or mapping.

For example, if you have a number of large binary image objects, you may wish to associate a name with each. If you used a Python dictionary to map names to images, or images to names, the image objects would remain alive just be-

cause they appeared as values or keys in the dictionaries. The WeakKeyDictionary and WeakValueDictionary

classes supplied by the weakref module are an alternative, using weak references to construct mappings that don’t keep objects alive solely because they appear in the mapping objects. If, for example, an image object is a value in

a WeakValueDictionary, then when the last remaining references to that image object are the weak references held by weak mappings, garbage collection can reclaim the object, and its corresponding entries in weak mappings are simply deleted.

WeakKeyDictionary and WeakValueDictionary use weak references in their implementation, setting up call-back functions on the weak references that notify the weak dictionaries when a key or value has been reclaimed by

garbage collection. WeakSet implements the set interface, but keeps weak references to its elements, just like a

WeakKeyDictionary does.

finalize provides a straight forward way to register a cleanup function to be called when an object is garbage collected. This is simpler to use than setting up a callback function on a raw weak reference, since the module automatically ensures that the finalizer remains alive until the object is collected.

Most programs should find that using one of these weak container types or finalize is all they need – it’s not usually

necessary to create your own weak references directly. The low-level machinery is exposed by the weakref module for the benefit of advanced uses.

Not all objects can be weakly referenced. Objects which support weak references include class instances, functions

written in Python (but not in C), instance methods, sets, frozensets, some file objects, generators, type objects, sockets, arrays, deques, regular expression pattern objects, and code objects.

Changed in version 3.2: Added support for thread.lock, threading.Lock, and code objects.

Several built-in types such as list and dict do not directly support weak references but can add support through subclassing:

class Dict(dict):

pass

obj = Dict(red=1, green=2, blue=3) # this object is weak referenceable

The Python Library Reference, Release 3.13.2



CPython implementation detail: Other built-in types such as tuple and int do not support weak references even when subclassed.

Extension types can easily be made to support weak references; see weakref-support.

When __slots__ are defined for a given type, weak reference support is disabled unless a '__weakref__' string is also present in the sequence of strings in the __slots__ declaration. See __slots__ documentation for details.

class weakref.ref(object [, callback ])

Return a weak reference to object. The original object can be retrieved by calling the reference object if the

referent is still alive; if the referent is no longer alive, calling the reference object will cause None to be returned.

If callback is provided and not None, and the returned weakref object is still alive, the callback will be called

when the object is about to be finalized; the weak reference object will be passed as the only parameter to the

callback; the referent will no longer be available.

It is allowable for many weak references to be constructed for the same object. Callbacks registered for each

weak reference will be called from the most recently registered callback to the oldest registered callback.

Exceptions raised by the callback will be noted on the standard error output, but cannot be propagated; they

are handled in exactly the same way as exceptions raised from an object’s __del__() method.

Weak references are hashable if the object is hashable. They will maintain their hash value even after the object

was deleted. If hash() is called the first time only after the object was deleted, the call will raise TypeError.

Weak references support tests for equality, but not ordering. If the referents are still alive, two references have

the same equality relationship as their referents (regardless of the callback). If either referent has been deleted,

the references are equal only if the reference objects are the same object.

This is a subclassable type rather than a factory function.

__callback__

This read-only attribute returns the callback currently associated to the weakref. If there is no callback or if the referent of the weakref is no longer alive then this attribute will have value None.

Changed in version 3.4: Added the __callback__ attribute.

weakref.proxy(object [, callback ])

Return a proxy to object which uses a weak reference. This supports use of the proxy in most contexts instead of

requiring the explicit dereferencing used with weak reference objects. The returned object will have a type of

either ProxyType or CallableProxyType, depending on whether object is callable. Proxy objects are not

hashable regardless of the referent; this avoids a number of problems related to their fundamentally mutable

nature, and prevents their use as dictionary keys. callback is the same as the parameter of the same name to

the ref() function.

Accessing an attribute of the proxy object after the referent is garbage collected raises ReferenceError.

Changed in version 3.8: Extended the operator support on proxy objects to include the matrix multiplication

operators @ and @=.

weakref.getweakrefcount(object)

Return the number of weak references and proxies which refer to object.

weakref.getweakrefs(object)

Return a list of all weak reference and proxy objects which refer to object.

class weakref.WeakKeyDictionary( dict [ ])

Mapping class that references keys weakly. Entries in the dictionary will be discarded when there is no longer

a strong reference to the key. This can be used to associate additional data with an object owned by other parts

of an application without adding attributes to those objects. This can be especially useful with objects that

override attribute accesses.

Note that when a key with equal value to an existing key (but not equal identity) is inserted into the dictionary,

it replaces the value but does not replace the existing key. Due to this, when the reference to the original key

is deleted, it also deletes the entry in the dictionary:

The Python Library Reference, Release 3.13.2



>>> class T(str): pass

...

>>> k1, k2 = T(), T()

>>> d = weakref.WeakKeyDictionary()

>>> d[k1] = 1 # d = {k1: 1}

>>> d[k2] = 2 # d = {k1: 2}

>>> del k1 # d = {}



A workaround would be to remove the key prior to reassignment:

>>> class T(str): pass

...

>>> k1, k2 = T(), T()

>>> d = weakref.WeakKeyDictionary()

>>> d[k1] = 1 # d = {k1: 1}

>>> del d[k1]

>>> d[k2] = 2 # d = {k2: 2}

>>> del k1 # d = {k2: 2}



Changed in version 3.9: Added support for | and |= operators, as specified in PEP 584.

WeakKeyDictionary objects have an additional method that exposes the internal references directly. The refer-ences are not guaranteed to be “live” at the time they are used, so the result of calling the references needs to be checked before being used. This can be used to avoid creating references that will cause the garbage collector to keep the keys around longer than needed.

WeakKeyDictionary.keyrefs()

Return an iterable of the weak references to the keys.

class weakref.WeakValueDictionary( dict [ ])

Mapping class that references values weakly. Entries in the dictionary will be discarded when no strong ref-

erence to the value exists any more.

Changed in version 3.9: Added support for | and |= operators, as specified in PEP 584.

WeakValueDictionary objects have an additional method that has the same issues as the WeakKeyDictionary.

keyrefs() method.

WeakValueDictionary.valuerefs()

Return an iterable of the weak references to the values.

class weakref.WeakSet( elements [ ])

Set class that keeps weak references to its elements. An element will be discarded when no strong reference to

it exists any more.

class weakref.WeakMethod(method [, callback ])

A custom ref subclass which simulates a weak reference to a bound method (i.e., a method defined on a class

and looked up on an instance). Since a bound method is ephemeral, a standard weak reference cannot keep

hold of it. WeakMethod has special code to recreate the bound method until either the object or the original

function dies:

>>> class C:

... def method(self):

... print("method called!")

...

>>> c = C()

>>> r = weakref.ref(c.method)

>>> r()

>>> r = weakref.WeakMethod(c.method)

>>> r()

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>

>>> r()()

method called!

>>> del c

>>> gc.collect()

0

>>> r()

>>>



callback is the same as the parameter of the same name to the ref() function.

Added in version 3.4.

class weakref.finalize(obj, func, / , *args, **kwargs)

Return a callable finalizer object which will be called when obj is garbage collected. Unlike an ordinary weak

reference, a finalizer will always survive until the reference object is collected, greatly simplifying lifecycle

management.

A finalizer is considered alive until it is called (either explicitly or at garbage collection), and after that it is

dead. Calling a live finalizer returns the result of evaluating func(*arg, **kwargs), whereas calling a

dead finalizer returns None.

Exceptions raised by finalizer callbacks during garbage collection will be shown on the standard error output,

but cannot be propagated. They are handled in the same way as exceptions raised from an object’s __del__()

method or a weak reference’s callback.

When the program exits, each remaining live finalizer is called unless its atexit attribute has been set to false.

They are called in reverse order of creation.

A finalizer will never invoke its callback during the later part of the interpreter shutdown when module globals

are liable to have been replaced by None.

__call__()

If self is alive then mark it as dead and return the result of calling func(*args, **kwargs). If self

is dead then return None.

detach()

If self is alive then mark it as dead and return the tuple (obj, func, args, kwargs). If self is dead

then return None.

peek()

If self is alive then return the tuple (obj, func, args, kwargs). If self is dead then return None.

alive

Property which is true if the finalizer is alive, false otherwise.

atexit

A writable boolean property which by default is true. When the program exits, it calls all remaining live

finalizers for which atexit is true. They are called in reverse order of creation.



® Note

It is important to ensure that func, args and kwargs do not own any references to obj, either directly or indirectly, since otherwise obj will never be garbage collected. In particular, func should not be a bound method of obj.



Added in version 3.4.

weakref.ReferenceType

The type object for weak references objects.

The Python Library Reference, Release 3.13.2



weakref.ProxyType

The type object for proxies of objects which are not callable.

weakref.CallableProxyType

The type object for proxies of callable objects.

weakref.ProxyTypes

Sequence containing all the type objects for proxies. This can make it simpler to test if an object is a proxy

without being dependent on naming both proxy types.



µ See also

PEP 205- Weak References

The proposal and rationale for this feature, including links to earlier implementations and information about similar features in other languages.



8.9.1 Weak Reference Objects

Weak reference objects have no methods and no attributes besides ref.__callback__. A weak reference object allows the referent to be obtained, if it still exists, by calling it:

>>> import weakref

>>> class Object:

... pass

...

>>> o = Object()

>>> r = weakref.ref(o)

>>> o2 = r()

>>> o is o2

True



If the referent no longer exists, calling the reference object returns None:

>>> del o, o2

>>> print(r())

None



Testing that a weak reference object is still live should be done using the expression ref() is not None. Nor-mally, application code that needs to use a reference object should follow this pattern:

# r is a weak reference object

o = r()

if o is None:

# referent has been garbage collected

print("Object has been deallocated; can't frobnicate.")

else:

print("Object is still live!")

o.do_something_useful()



Using a separate test for “liveness” creates race conditions in threaded applications; another thread can cause a weak reference to become invalidated before the weak reference is called; the idiom shown above is safe in threaded applications as well as single-threaded applications.

Specialized versions of ref objects can be created through subclassing. This is used in the implementation of the

WeakValueDictionary to reduce the memory overhead for each entry in the mapping. This may be most useful to associate additional information with a reference, but could also be used to insert additional processing on calls to retrieve the referent.

The Python Library Reference, Release 3.13.2



This example shows how a subclass of ref can be used to store additional information about an object and affect the value that’s returned when the referent is accessed:

import weakref

class ExtendedRef(weakref.ref):

def __init__(self, ob, callback=None, /, **annotations):

super().__init__(ob, callback)

self.__counter = 0

for k, v in annotations.items():

setattr(self, k, v)

def __call__(self):

"""Return a pair containing the referent and the number of times the reference has been called.

"""

ob = super().__call__()

if ob is not None:

self.__counter += 1

ob = (ob, self.__counter)

return ob



8.9.2 Example

This simple example shows how an application can use object IDs to retrieve objects that it has seen before. The IDs of the objects can then be used in other data structures without forcing the objects to remain alive, but the objects can still be retrieved by ID if they do.

import weakref

_id2obj_dict = weakref.WeakValueDictionary()

def remember(obj):

oid = id(obj)

_id2obj_dict[oid] = obj

return oid

def id2obj(oid):

return _id2obj_dict[oid]



8.9.3 Finalizer Objects

The main benefit of using finalize is that it makes it simple to register a callback without needing to preserve the returned finalizer object. For instance

>>> import weakref

>>> class Object:

... pass

...

>>> kenny = Object()

>>> weakref.finalize(kenny, print, "You killed Kenny!")

>>> del kenny

You killed Kenny!



The finalizer can be called directly as well. However the finalizer will invoke the callback at most once.

The Python Library Reference, Release 3.13.2



>>> def callback(x, y, z):

... print("CALLBACK")

... return x + y + z

...

>>> obj = Object()

>>> f = weakref.finalize(obj, callback, 1, 2, z=3)

>>> assert f.alive

>>> assert f() == 6

CALLBACK

>>> assert not f.alive

>>> f() # callback not called because finalizer dead >>> del obj # callback not called because finalizer dead



You can unregister a finalizer using its detach() method. This kills the finalizer and returns the arguments passed to the constructor when it was created.

>>> obj = Object()

>>> f = weakref.finalize(obj, callback, 1, 2, z=3)

>>> f.detach()

(<...Object object ...>, , (1, 2), {'z': 3}) >>> newobj, func, args, kwargs = _

>>> assert not f.alive

>>> assert newobj is obj

>>> assert func(*args, **kwargs) == 6

CALLBACK



Unless you set the atexit attribute to False, a finalizer will be called when the program exits if it is still alive. For instance

>>> obj = Object()

>>> weakref.finalize(obj, print, "obj dead or exiting")

>>> exit()

obj dead or exiting



8.9.4 Comparing finalizers with __del__() methods

Suppose we want to create a class whose instances represent temporary directories. The directories should be deleted with their contents when the first of the following events occurs:

• the object is garbage collected,

• the object’s remove() method is called, or

• the program exits.

We might try to implement the class using a __del__() method as follows:

class TempDir:

def __init__(self):

self.name = tempfile.mkdtemp()

def remove(self):

if self.name is not None:

shutil.rmtree(self.name)

self.name = None

@property

def removed(self):

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

return self.name is None

def __del__(self):

self.remove()



Starting with Python 3.4, __del__() methods no longer prevent reference cycles from being garbage collected, and

module globals are no longer forced to None during interpreter shutdown. So this code should work without any issues on CPython.

However, handling of __del__() methods is notoriously implementation specific, since it depends on internal details of the interpreter’s garbage collector implementation.

A more robust alternative can be to define a finalizer which only references the specific functions and objects that it needs, rather than having access to the full state of the object:

class TempDir:

def __init__(self):

self.name = tempfile.mkdtemp()

self._finalizer = weakref.finalize(self, shutil.rmtree, self.name)

def remove(self):

self._finalizer()

@property

def removed(self):

return not self._finalizer.alive



Defined like this, our finalizer only receives a reference to the details it needs to clean up the directory appropriately. If the object never gets garbage collected the finalizer will still be called at exit.

The other advantage of weakref based finalizers is that they can be used to register finalizers for classes where the definition is controlled by a third party, such as running code when a module is unloaded:

import weakref, sys

def unloading_module():

# implicit reference to the module globals from the function body

weakref.finalize(sys.modules[__name__], unloading_module)



® Note

If you create a finalizer object in a daemonic thread just as the program exits then there is the possibility that

the finalizer does not get called at exit. However, in a daemonic thread atexit.register(), try: ...

finally: ... and with: ... do not guarantee that cleanup occurs either.



8.10 types — Dynamic type creation and names for built-in types

Source code: Lib/types.py



This module defines utility functions to assist in dynamic creation of new types.

It also defines names for some object types that are used by the standard Python interpreter, but not exposed as

builtins like int or str are.

Finally, it provides some additional type-related utility classes and functions that are not fundamental enough to be builtins.

The Python Library Reference, Release 3.13.2



8.10.1 Dynamic Type Creation

types.new_class(name, bases=(), kwds=None, exec_body=None)

Creates a class object dynamically using the appropriate metaclass.

The first three arguments are the components that make up a class definition header: the class name, the base

classes (in order), the keyword arguments (such as metaclass).

The exec_body argument is a callback that is used to populate the freshly created class namespace. It should

accept the class namespace as its sole argument and update the namespace directly with the class contents. If

no callback is provided, it has the same effect as passing in lambda ns: None.

Added in version 3.3.

types.prepare_class(name, bases=(), kwds=None)

Calculates the appropriate metaclass and creates the class namespace.

The arguments are the components that make up a class definition header: the class name, the base classes (in

order) and the keyword arguments (such as metaclass).

The return value is a 3-tuple: metaclass, namespace, kwds

metaclass is the appropriate metaclass, namespace is the prepared class namespace and kwds is an updated

copy of the passed in kwds argument with any 'metaclass' entry removed. If no kwds argument is passed

in, this will be an empty dict.

Added in version 3.3.

Changed in version 3.6: The default value for the namespace element of the returned tuple has changed. Now

an insertion-order-preserving mapping is used when the metaclass does not have a __prepare__ method.



µ See also

metaclasses

Full details of the class creation process supported by these functions

PEP 3115- Metaclasses in Python 3000

Introduced the __prepare__ namespace hook



types.resolve_bases(bases)

Resolve MRO entries dynamically as specified by PEP 560.

This function looks for items in bases that are not instances of type, and returns a tuple where each such object

that has an __mro_entries__() method is replaced with an unpacked result of calling this method. If a

bases item is an instance of type, or it doesn’t have an __mro_entries__() method, then it is included in

the return tuple unchanged.

Added in version 3.7.

types.get_original_bases(cls, / )

Return the tuple of objects originally given as the bases of cls before the __mro_entries__() method has

been called on any bases (following the mechanisms laid out in PEP 560). This is useful for introspecting

Generics.

For classes that have an __orig_bases__ attribute, this function returns the value of cls.

__orig_bases__. For classes without the __orig_bases__ attribute, cls.__bases__ is returned.

Examples:

from typing import TypeVar, Generic, NamedTuple, TypedDict

T = TypeVar("T")

class Foo(Generic[T]): ...

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

class Bar(Foo[int], float): ...

class Baz(list[str]): ...

Eggs = NamedTuple("Eggs", [("a", int), ("b", str)])

Spam = TypedDict("Spam", {"a": int, "b": str})

assert Bar.__bases__ == (Foo, float)

assert get_original_bases(Bar) == (Foo[int], float)

assert Baz.__bases__ == (list,)

assert get_original_bases(Baz) == (list[str],)

assert Eggs.__bases__ == (tuple,)

assert get_original_bases(Eggs) == (NamedTuple,)

assert Spam.__bases__ == (dict,)

assert get_original_bases(Spam) == (TypedDict,)

assert int.__bases__ == (object,)

assert get_original_bases(int) == (object,)



Added in version 3.12.



µ See also

PEP 560- Core support for typing module and generic types



8.10.2 Standard Interpreter Types

This module provides names for many of the types that are required to implement a Python interpreter. It deliberately avoids including some of the types that arise only incidentally during processing such as the listiterator type.

Typical use of these names is for isinstance() or issubclass() checks.

If you instantiate any of these types, note that signatures may vary between Python versions.

Standard names are defined for the following types:

types.NoneType

The type of None.

Added in version 3.10.

types.FunctionType

types.LambdaType

The type of user-defined functions and functions created by lambda expressions.

Raises an auditing event function.__new__ with argument code.

The audit event only occurs for direct instantiation of function objects, and is not raised for normal compilation.

types.GeneratorType

The type of generator-iterator objects, created by generator functions.

types.CoroutineType

The type of coroutine objects, created by async def functions.

Added in version 3.5.



The Python Library Reference, Release 3.13.2



types.AsyncGeneratorType

The type of asynchronous generator-iterator objects, created by asynchronous generator functions.

Added in version 3.6.

class types.CodeType(**kwargs)

The type of code objects such as returned by compile().

Raises an auditing event code.__new__ with arguments code, filename, name, argcount,

posonlyargcount, kwonlyargcount, nlocals, stacksize, flags.

Note that the audited arguments may not match the names or positions required by the initializer. The audit

event only occurs for direct instantiation of code objects, and is not raised for normal compilation.

types.CellType

The type for cell objects: such objects are used as containers for a function’s closure variables.

Added in version 3.8.

types.MethodType

The type of methods of user-defined class instances.

types.BuiltinFunctionType

types.BuiltinMethodType

The type of built-in functions like len() or sys.exit(), and methods of built-in classes. (Here, the term

“built-in” means “written in C”.)

types.WrapperDescriptorType

The type of methods of some built-in data types and base classes such as object.__init__() or object.

__lt__().

Added in version 3.7.

types.MethodWrapperType

The type of bound methods of some built-in data types and base classes. For example it is the type of

object().__str__.

Added in version 3.7.

types.NotImplementedType

The type of NotImplemented.

Added in version 3.10.

types.MethodDescriptorType

The type of methods of some built-in data types such as str.join().

Added in version 3.7.

types.ClassMethodDescriptorType

The type of unbound class methods of some built-in data types such as dict.__dict__['fromkeys'].

Added in version 3.7.

class types.ModuleType(name, doc=None)

The type of modules. The constructor takes the name of the module to be created and optionally its docstring.



µ See also



Documentation on module objects

Provides details on the special attributes that can be found on instances of ModuleType.



The Python Library Reference, Release 3.13.2



importlib.util.module_from_spec()

Modules created using the ModuleType constructor are created with many of their special attributes unset or set to default values. module_from_spec() provides a more robust way of creating ModuleType instances which ensures the various attributes are set appropriately.



types.EllipsisType

The type of Ellipsis.

Added in version 3.10.

class types.GenericAlias(t_origin, t_args)

The type of parameterized generics such as list[int].

t_origin should be a non-parameterized generic class, such as list, tuple or dict. t_args should be a

tuple (possibly of length 1) of types which parameterize t_origin:

>>> from types import GenericAlias

>>> list[int] == GenericAlias(list, (int,))

True

>>> dict[str, int] == GenericAlias(dict, (str, int))

True



Added in version 3.9.

Changed in version 3.9.2: This type can now be subclassed.



µ See also



Generic Alias Types

In-depth documentation on instances of types.GenericAlias

PEP 585- Type Hinting Generics In Standard Collections

Introducing the types.GenericAlias class



class types.UnionType

The type of union type expressions.

Added in version 3.10.

class types.TracebackType(tb_next, tb_frame, tb_lasti, tb_lineno)

The type of traceback objects such as found in sys.exception().__traceback__.

See the language reference for details of the available attributes and operations, and guidance on creating

tracebacks dynamically.

types.FrameType

The type of frame objects such as found in tb.tb_frame if tb is a traceback object.

types.GetSetDescriptorType

The type of objects defined in extension modules with PyGetSetDef, such as FrameType.f_locals or

array.array.typecode . This type is used as descriptor for object attributes; it has the same purpose as

the property type, but for classes defined in extension modules.

types.MemberDescriptorType

The type of objects defined in extension modules with PyMemberDef, such as datetime.timedelta.days.

This type is used as descriptor for simple C data members which use standard conversion functions; it has the

same purpose as the property type, but for classes defined in extension modules.

The Python Library Reference, Release 3.13.2



In addition, when a class is defined with a __slots__ attribute, then for each slot, an instance of

MemberDescriptorType will be added as an attribute on the class. This allows the slot to appear in the

class’s __dict__.

CPython implementation detail: In other implementations of Python, this type may be identical to

GetSetDescriptorType .

class types.MappingProxyType(mapping)

Read-only proxy of a mapping. It provides a dynamic view on the mapping’s entries, which means that when

the mapping changes, the view reflects these changes.

Added in version 3.3.

Changed in version 3.9: Updated to support the new union (|) operator from PEP 584, which simply delegates

to the underlying mapping.

key in proxy

Return True if the underlying mapping has a key key, else False.

proxy[key]

Return the item of the underlying mapping with key key. Raises a KeyError if key is not in the underlying mapping.

iter(proxy)

Return an iterator over the keys of the underlying mapping. This is a shortcut for iter(proxy. keys()) .

len(proxy)

Return the number of items in the underlying mapping.

copy()

Return a shallow copy of the underlying mapping.

get(key[, default ])

Return the value for key if key is in the underlying mapping, else default. If default is not given, it defaults

to None, so that this method never raises a KeyError.

items()

Return a new view of the underlying mapping’s items ((key, value) pairs).

keys()

Return a new view of the underlying mapping’s keys.

values()

Return a new view of the underlying mapping’s values.

reversed(proxy)

Return a reverse iterator over the keys of the underlying mapping.

Added in version 3.9.

hash(proxy)

Return a hash of the underlying mapping.

Added in version 3.12.

class types.CapsuleType

The type of capsule objects.

Added in version 3.13.



The Python Library Reference, Release 3.13.2



8.10.3 Additional Utility Classes and Functions

class types.SimpleNamespace

A simple object subclass that provides attribute access to its namespace, as well as a meaningful repr.

Unlike object, with SimpleNamespace you can add and remove attributes.

SimpleNamespace objects may be initialized in the same way as dict: either with keyword arguments,

with a single positional argument, or with both. When initialized with keyword arguments, those are directly

added to the underlying namespace. Alternatively, when initialized with a positional argument, the underlying

namespace will be updated with key-value pairs from that argument (either a mapping object or an iterable

object producing key-value pairs). All such keys must be strings.

The type is roughly equivalent to the following code:

class SimpleNamespace:

def __init__(self, mapping_or_iterable=(), /, **kwargs):

self.__dict__.update(mapping_or_iterable)

self.__dict__.update(kwargs)

def __repr__(self):

items = (f"{k}={v!r}" for k, v in self.__dict__.items()) return "{}({})".format(type(self).__name__, ", ".join(items))

def __eq__(self, other):

if isinstance(self, SimpleNamespace) and isinstance(other,␣

, →SimpleNamespace):

return self.__dict__ == other.__dict__

return NotImplemented



SimpleNamespace may be useful as a replacement for class NS: pass. However, for a structured record

type use namedtuple() instead.

SimpleNamespace objects are supported by copy.replace().

Added in version 3.3.

Changed in version 3.9: Attribute order in the repr changed from alphabetical to insertion (like dict).

Changed in version 3.13: Added support for an optional positional argument.

types.DynamicClassAttribute(fget=None, fset=None, fdel=None, doc=None)

Route attribute access on a class to __getattr__.

This is a descriptor, used to define attributes that act differently when accessed through an instance and through

a class. Instance access remains normal, but access to an attribute through a class will be routed to the class’s

__getattr__ method; this is done by raising AttributeError.

This allows one to have properties active on an instance, and have virtual attributes on the class with the same

name (see enum.Enum for an example).

Added in version 3.4.



8.10.4 Coroutine Utility Functions

types.coroutine(gen_func)

This function transforms a generator function into a coroutine function which returns a generator-based corou-

tine. The generator-based coroutine is still a generator iterator, but is also considered to be a coroutine object

and is awaitable. However, it may not necessarily implement the __await__() method.

If gen_func is a generator function, it will be modified in-place.

If gen_func is not a generator function, it will be wrapped. If it returns an instance of collections.abc.

Generator, the instance will be wrapped in an awaitable proxy object. All other types of objects will be

returned as is.

The Python Library Reference, Release 3.13.2



Added in version 3.5.



8.11 copy — Shallow and deep copy operations

Source code: Lib/copy.py



Assignment statements in Python do not copy objects, they create bindings between a target and an object. For collections that are mutable or contain mutable items, a copy is sometimes needed so one can change one copy without changing the other. This module provides generic shallow and deep copy operations (explained below).

Interface summary:

copy.copy(obj)

Return a shallow copy of obj.

copy.deepcopy(obj[, memo ])

Return a deep copy of obj.

copy.replace(obj, / , **changes)

Creates a new object of the same type as obj, replacing fields with values from changes.

Added in version 3.13.

exception copy.Error

Raised for module specific errors.

The difference between shallow and deep copying is only relevant for compound objects (objects that contain other objects, like lists or class instances):

• A shallow copy constructs a new compound object and then (to the extent possible) inserts references into it to

the objects found in the original.

• A deep copy constructs a new compound object and then, recursively, inserts copies into it of the objects found

in the original.

Two problems often exist with deep copy operations that don’t exist with shallow copy operations:

• Recursive objects (compound objects that, directly or indirectly, contain a reference to themselves) may cause

a recursive loop.

• Because deep copy copies everything it may copy too much, such as data which is intended to be shared

between copies.

The deepcopy() function avoids these problems by:

• keeping a memo dictionary of objects already copied during the current copying pass; and

• letting user-defined classes override the copying operation or the set of components copied.

This module does not copy types like module, method, stack trace, stack frame, file, socket, window, or any similar types. It does “copy” functions and classes (shallow and deeply), by returning the original object unchanged; this is

compatible with the way these are treated by the pickle module.

Shallow copies of dictionaries can be made using dict.copy(), and of lists by assigning a slice of the entire list, for example, copied_list = original_list[:].

Classes can use the same interfaces to control copying that they use to control pickling. See the description of module

pickle for information on these methods. In fact, the copy module uses the registered pickle functions from the

copyreg module.

In order for a class to define its own copy implementation, it can define special methods __copy__() and

__deepcopy__().

object.__copy__(self)

Called to implement the shallow copy operation; no additional arguments are passed.

The Python Library Reference, Release 3.13.2



object.__deepcopy__(self, memo)

Called to implement the deep copy operation; it is passed one argument, the memo dictionary. If the

__deepcopy__ implementation needs to make a deep copy of a component, it should call the deepcopy()

function with the component as first argument and the memo dictionary as second argument. The memo dic-

tionary should be treated as an opaque object.

Function copy.replace() is more limited than copy() and deepcopy(), and only supports named tuples created

by namedtuple(), dataclasses, and other classes which define method __replace__().

object.__replace__(self, / , **changes)

This method should create a new object of the same type, replacing fields with values from changes.



µ See also

Module pickle

Discussion of the special methods used to support object state retrieval and restoration.



8.12 pprint — Data pretty printer

Source code: Lib/pprint.py



The pprint module provides a capability to “pretty-print” arbitrary Python data structures in a form which can be used as input to the interpreter. If the formatted structures include objects which are not fundamental Python types, the representation may not be loadable. This may be the case if objects such as files, sockets or classes are included, as well as many other objects which are not representable as Python literals.

The formatted representation keeps objects on a single line if it can, and breaks them onto multiple lines if they don’t fit within the allowed width, adjustable by the width parameter defaulting to 80 characters.

Dictionaries are sorted by key before the display is computed.

Changed in version 3.9: Added support for pretty-printing types.SimpleNamespace.

Changed in version 3.10: Added support for pretty-printing dataclasses.dataclass.



8.12.1 Functions

pprint.pp(object, stream=None, indent=1, width=80, depth=None, *, compact=False, sort_dicts=False,

underscore_numbers=False)

Prints the formatted representation of object, followed by a newline. This function may be used in the interactive

interpreter instead of the print() function for inspecting values. Tip: you can reassign print = pprint.

pp for use within a scope.

Parameters

• object – The object to be printed.

• stream (file-like object | None) – A file-like object to which the output will be written by

calling its write() method. If None (the default), sys.stdout is used.

• indent (int) – The amount of indentation added for each nesting level.

• width (int) – The desired maximum number of characters per line in the output. If a

structure cannot be formatted within the width constraint, a best effort will be made.

• depth (int | None) – The number of nesting levels which may be printed. If the data

structure being printed is too deep, the next contained level is replaced by .... If None (the default), there is no constraint on the depth of the objects being formatted.

The Python Library Reference, Release 3.13.2



• compact (bool) – Control the way long sequences are formatted. If False (the default),

each item of a sequence will be formatted on a separate line, otherwise as many items as will fit within the width will be formatted on each output line.

• sort_dicts (bool) – If True, dictionaries will be formatted with their keys sorted,

otherwise they will be displayed in insertion order (the default).

• underscore_numbers (bool) – If True, integers will be formatted with the _ character

for a thousands separator, otherwise underscores are not displayed (the default).

>>> import pprint

>>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']

>>> stuff.insert(0, stuff)

>>> pprint.pp(stuff)

[,

'spam',

'eggs',

'lumberjack',

'knights',

'ni']



Added in version 3.8.

pprint.pprint(object, stream=None, indent=1, width=80, depth=None, *, compact=False, sort_dicts=True,

underscore_numbers=False)

Alias for pp() with sort_dicts set to True by default, which would automatically sort the dictionaries’ keys,

you might want to use pp() instead where it is False by default.

pprint.pformat(object, indent=1, width=80, depth=None, *, compact=False, sort_dicts=True,

underscore_numbers=False)

Return the formatted representation of object as a string. indent, width, depth, compact, sort_dicts and under-

score_numbers are passed to the PrettyPrinter constructor as formatting parameters and their meanings

are as described in the documentation above.

pprint.isreadable(object)

Determine if the formatted representation of object is “readable”, or can be used to reconstruct the value using

eval() . This always returns False for recursive objects.

>>> pprint.isreadable(stuff)

False



pprint.isrecursive(object)

Determine if object requires a recursive representation. This function is subject to the same limitations as noted

in saferepr() below and may raise an RecursionError if it fails to detect a recursive object.

pprint.saferepr(object)

Return a string representation of object, protected against recursion in some common data structures, namely

instances of dict, list and tuple or subclasses whose __repr__ has not been overridden. If the repre-

sentation of object exposes a recursive entry, the recursive reference will be represented as

typename with id=number>. The representation is not otherwise formatted.

>>> pprint.saferepr(stuff)

"[, 'spam', 'eggs', 'lumberjack', 'knights', 'ni

, →']"



8.12.2 PrettyPrinter Objects

class pprint.PrettyPrinter(indent=1, width=80, depth=None, stream=None, *, compact=False,

sort_dicts=True, underscore_numbers=False)

The Python Library Reference, Release 3.13.2



Construct a PrettyPrinter instance.

Arguments have the same meaning as for pp(). Note that they are in a different order, and that sort_dicts

defaults to True.

>>> import pprint

>>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']

>>> stuff.insert(0, stuff[:])

>>> pp = pprint.PrettyPrinter(indent=4)

>>> pp.pprint(stuff)

[ ['spam', 'eggs', 'lumberjack', 'knights', 'ni'],

'spam',

'eggs',

'lumberjack',

'knights',

'ni']

>>> pp = pprint.PrettyPrinter(width=41, compact=True)

>>> pp.pprint(stuff)

[['spam', 'eggs', 'lumberjack',

'knights', 'ni'],

'spam', 'eggs', 'lumberjack', 'knights',

'ni']

>>> tup = ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead',

... ('parrot', ('fresh fruit',))))))))

>>> pp = pprint.PrettyPrinter(depth=6)

>>> pp.pprint(tup)

('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead', (...)))))))



Changed in version 3.4: Added the compact parameter.

Changed in version 3.8: Added the sort_dicts parameter.

Changed in version 3.10: Added the underscore_numbers parameter.

Changed in version 3.11: No longer attempts to write to sys.stdout if it is None.

PrettyPrinter instances have the following methods:

PrettyPrinter.pformat( object)

Return the formatted representation of object. This takes into account the options passed to the

PrettyPrinter constructor.

PrettyPrinter.pprint(object)

Print the formatted representation of object on the configured stream, followed by a newline.

The following methods provide the implementations for the corresponding functions of the same names. Using these

methods on an instance is slightly more efficient since new PrettyPrinter objects don’t need to be created.

PrettyPrinter.isreadable(object)

Determine if the formatted representation of the object is “readable,” or can be used to reconstruct the

value using eval(). Note that this returns False for recursive objects. If the depth parameter of the

PrettyPrinter is set and the object is deeper than allowed, this returns False.

PrettyPrinter.isrecursive(object)

Determine if the object requires a recursive representation.

This method is provided as a hook to allow subclasses to modify the way objects are converted to strings. The default

implementation uses the internals of the saferepr() implementation.

PrettyPrinter.format(object, context, maxlevels, level)

Returns three values: the formatted version of object as a string, a flag indicating whether the result is readable,

and a flag indicating whether recursion was detected. The first argument is the object to be presented. The The Python Library Reference, Release 3.13.2



second is a dictionary which contains the id() of objects that are part of the current presentation context

(direct and indirect containers for object that are affecting the presentation) as the keys; if an object needs to

be presented which is already represented in context, the third return value should be True. Recursive calls

to the format() method should add additional entries for containers to this dictionary. The third argument,

maxlevels, gives the requested limit to recursion; this will be 0 if there is no requested limit. This argument

should be passed unmodified to recursive calls. The fourth argument, level, gives the current level; recursive

calls should be passed a value less than that of the current call.



8.12.3 Example

To demonstrate several uses of the pp() function and its parameters, let’s fetch information about a project from

PyPI:

>>> import json

>>> import pprint

>>> from urllib.request import urlopen

>>> with urlopen('https://pypi.org/pypi/sampleproject/1.2.0/json') as resp: ... project_info = json.load(resp)['info']



In its basic form, pp() shows the whole object:

>>> pprint.pp(project_info)

{'author': 'The Python Packaging Authority',

'author_email': 'pypa-dev@googlegroups.com',

'bugtrack_url': None,

'classifiers': ['Development Status :: 3 - Alpha',

'Intended Audience :: Developers',

'License :: OSI Approved :: MIT License',

'Programming Language :: Python :: 2',

'Programming Language :: Python :: 2.6',

'Programming Language :: Python :: 2.7',

'Programming Language :: Python :: 3',

'Programming Language :: Python :: 3.2',

'Programming Language :: Python :: 3.3',

'Programming Language :: Python :: 3.4',

'Topic :: Software Development :: Build Tools'],

'description': 'A sample Python project\n'

'=======================\n'

'\n'

'This is the description file for the project.\n'

'\n'

'The file should use UTF-8 encoding and be written using ' 'ReStructured Text. It\n'

'will be used to generate the project webpage on PyPI, and ' 'should be written for\n'

'that purpose.\n'

'\n'

'Typical contents for this file would include an overview of ' 'the project, basic\n'

'usage examples, etc. Generally, including the project ' 'changelog in here is not\n'

'a good idea, although a simple "What\'s New" section for the ' 'most recent version\n'

'may be appropriate.',

'description_content_type': None,

'docs_url': None,

'download_url': 'UNKNOWN',

'downloads': {'last_day': -1, 'last_month': -1, 'last_week': -1},

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

'home_page': 'https://github.com/pypa/sampleproject', 'keywords': 'sample setuptools development',

'license': 'MIT',

'maintainer': None,

'maintainer_email': None,

'name': 'sampleproject',

'package_url': 'https://pypi.org/project/sampleproject/', 'platform': 'UNKNOWN',

'project_url': 'https://pypi.org/project/sampleproject/', 'project_urls': {'Download': 'UNKNOWN',

'Homepage': 'https://github.com/pypa/sampleproject'},

'release_url': 'https://pypi.org/project/sampleproject/1.2.0/', 'requires_dist': None,

'requires_python': None,

'summary': 'A sample Python project',

'version': '1.2.0'}



The result can be limited to a certain depth (ellipsis is used for deeper contents):

>>> pprint.pp(project_info, depth=1)

{'author': 'The Python Packaging Authority',

'author_email': 'pypa-dev@googlegroups.com',

'bugtrack_url': None,

'classifiers': [...],

'description': 'A sample Python project\n'

'=======================\n'

'\n'

'This is the description file for the project.\n'

'\n'

'The file should use UTF-8 encoding and be written using ' 'ReStructured Text. It\n'

'will be used to generate the project webpage on PyPI, and ' 'should be written for\n'

'that purpose.\n'

'\n'

'Typical contents for this file would include an overview of ' 'the project, basic\n'

'usage examples, etc. Generally, including the project ' 'changelog in here is not\n'

'a good idea, although a simple "What\'s New" section for the ' 'most recent version\n'

'may be appropriate.',

'description_content_type': None,

'docs_url': None,

'download_url': 'UNKNOWN',

'downloads': {...},

'home_page': 'https://github.com/pypa/sampleproject', 'keywords': 'sample setuptools development',

'license': 'MIT',

'maintainer': None,

'maintainer_email': None,

'name': 'sampleproject',

'package_url': 'https://pypi.org/project/sampleproject/', 'platform': 'UNKNOWN',

'project_url': 'https://pypi.org/project/sampleproject/', 'project_urls': {...},

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

'release_url': 'https://pypi.org/project/sampleproject/1.2.0/', 'requires_dist': None,

'requires_python': None,

'summary': 'A sample Python project',

'version': '1.2.0'}



Additionally, maximum character width can be suggested. If a long object cannot be split, the specified width will be exceeded:

>>> pprint.pp(project_info, depth=1, width=60)

{'author': 'The Python Packaging Authority',

'author_email': 'pypa-dev@googlegroups.com',

'bugtrack_url': None,

'classifiers': [...],

'description': 'A sample Python project\n'

'=======================\n'

'\n'

'This is the description file for the '

'project.\n'

'\n'

'The file should use UTF-8 encoding and be '

'written using ReStructured Text. It\n'

'will be used to generate the project '

'webpage on PyPI, and should be written '

'for\n'

'that purpose.\n'

'\n'

'Typical contents for this file would '

'include an overview of the project, '

'basic\n'

'usage examples, etc. Generally, including '

'the project changelog in here is not\n'

'a good idea, although a simple "What\'s '

'New" section for the most recent version\n'

'may be appropriate.',

'description_content_type': None,

'docs_url': None,

'download_url': 'UNKNOWN',

'downloads': {...},

'home_page': 'https://github.com/pypa/sampleproject', 'keywords': 'sample setuptools development',

'license': 'MIT',

'maintainer': None,

'maintainer_email': None,

'name': 'sampleproject',

'package_url': 'https://pypi.org/project/sampleproject/', 'platform': 'UNKNOWN',

'project_url': 'https://pypi.org/project/sampleproject/', 'project_urls': {...},

'release_url': 'https://pypi.org/project/sampleproject/1.2.0/', 'requires_dist': None,

'requires_python': None,

'summary': 'A sample Python project',

'version': '1.2.0'}



The Python Library Reference, Release 3.13.2



8.13 reprlib — Alternate repr() implementation

Source code: Lib/reprlib.py



The reprlib module provides a means for producing object representations with limits on the size of the resulting strings. This is used in the Python debugger and may be useful in other contexts as well.

This module provides a class, an instance, and a function:

class reprlib.Repr(*, maxlevel=6, maxtuple=6, maxlist=6, maxarray=5, maxdict=4, maxset=6,

maxfrozenset=6, maxdeque=6, maxstring=30, maxlong=40, maxother=30, fillvalue=’...’, indent=None)

Class which provides formatting services useful in implementing functions similar to the built-in repr(); size

limits for different object types are added to avoid the generation of representations which are excessively long.

The keyword arguments of the constructor can be used as a shortcut to set the attributes of the Repr instance.

Which means that the following initialization:

aRepr = reprlib.Repr(maxlevel=3)



Is equivalent to:

aRepr = reprlib.Repr()

aRepr.maxlevel = 3



See section Repr Objects for more information about Repr attributes.

Changed in version 3.12: Allow attributes to be set via keyword arguments.

reprlib.aRepr

This is an instance of Repr which is used to provide the repr() function described below. Changing the

attributes of this object will affect the size limits used by repr() and the Python debugger.

reprlib.repr(obj)

This is the repr() method of aRepr. It returns a string similar to that returned by the built-in function of the

same name, but with limits on most sizes.

In addition to size-limiting tools, the module also provides a decorator for detecting recursive calls to __repr__() and substituting a placeholder string instead.

@reprlib.recursive_repr(fillvalue=’...’)

Decorator for __repr__() methods to detect recursive calls within the same thread. If a recursive call is

made, the fillvalue is returned, otherwise, the usual __repr__() call is made. For example:

>>> from reprlib import recursive_repr

>>> class MyList(list):

... @recursive_repr()

... def __repr__(self):

... return '<' + '|'.join(map(repr, self)) + '>'

...

>>> m = MyList('abc')

>>> m.append(m)

>>> m.append('x')

>>> print(m)

<'a'|'b'|'c'|...|'x'>



Added in version 3.2.



The Python Library Reference, Release 3.13.2



8.13.1 Repr Objects

Repr instances provide several attributes which can be used to provide size limits for the representations of different object types, and methods which format specific object types.

Repr.fillvalue

This string is displayed for recursive references. It defaults to ....

Added in version 3.11.

Repr.maxlevel

Depth limit on the creation of recursive representations. The default is 6.

Repr.maxdict

Repr.maxlist

Repr.maxtuple

Repr.maxset

Repr.maxfrozenset

Repr.maxdeque

Repr.maxarray

Limits on the number of entries represented for the named object type. The default is 4 for maxdict, 5 for

maxarray, and 6 for the others.

Repr.maxlong

Maximum number of characters in the representation for an integer. Digits are dropped from the middle. The

default is 40.

Repr.maxstring

Limit on the number of characters in the representation of the string. Note that the “normal” representation

of the string is used as the character source: if escape sequences are needed in the representation, these may

be mangled when the representation is shortened. The default is 30.

Repr.maxother

This limit is used to control the size of object types for which no specific formatting method is available on the

Repr object. It is applied in a similar manner as maxstring. The default is 20.

Repr.indent

If this attribute is set to None (the default), the output is formatted with no line breaks or indentation, like the

standard repr(). For example:

>>> example = [

... 1, 'spam', {'a': 2, 'b': 'spam eggs', 'c': {3: 4.5, 6: []}}, 'ham']

>>> import reprlib

>>> aRepr = reprlib.Repr()

>>> print(aRepr.repr(example))

[1, 'spam', {'a': 2, 'b': 'spam eggs', 'c': {3: 4.5, 6: []}}, 'ham']



If indent is set to a string, each recursion level is placed on its own line, indented by that string:

>>> aRepr.indent = '-->'

>>> print(aRepr.repr(example))

[

-->1,

-->'spam',

-->{

-->-->'a': 2,

-->-->'b': 'spam eggs',

-->-->'c': {

-->-->-->3: 4.5,

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

-->-->-->6: [],

-->-->},

-->},

-->'ham',

]



Setting indent to a positive integer value behaves as if it was set to a string with that number of spaces:

>>> aRepr.indent = 4

>>> print(aRepr.repr(example))

[

1,

'spam',

{

'a': 2,

'b': 'spam eggs',

'c': {

3: 4.5,

6: [],

},

},

'ham',

]



Added in version 3.12.

Repr.repr(obj)

The equivalent to the built-in repr() that uses the formatting imposed by the instance.

Repr.repr1(obj, level)

Recursive implementation used by repr(). This uses the type of obj to determine which formatting method to

call, passing it obj and level. The type-specific methods should call repr1() to perform recursive formatting,

with level - 1 for the value of level in the recursive call.

Repr.repr_TYPE(obj, level)

Formatting methods for specific types are implemented as methods with a name based on the type name. In

the method name, TYPE is replaced by '_'.join(type(obj).__name__.split()). Dispatch to these

methods is handled by repr1(). Type-specific methods which need to recursively format a value should call

self.repr1(subobj, level - 1).



8.13.2 Subclassing Repr Objects

The use of dynamic dispatching by Repr.repr1() allows subclasses of Repr to add support for additional built-in object types or to modify the handling of types already supported. This example shows how special support for file objects could be added:

import reprlib

import sys

class MyRepr(reprlib.Repr):

def repr_TextIOWrapper(self, obj, level):

if obj.name in {'', '', ''}:

return obj.name

return repr(obj)

aRepr = MyRepr()

print(aRepr.repr(sys.stdin)) # prints '<stdin>'

The Python Library Reference, Release 3.13.2





8.14 enum — Support for enumerations

Added in version 3.4.

Source code: Lib/enum.py



Important

This page contains the API reference information. For tutorial information and discussion of more advanced

topics, see

• Basic Tutorial

• Advanced Tutorial

• Enum Cookbook



An enumeration:

• is a set of symbolic names (members) bound to unique values

• can be iterated over to return its canonical (i.e. non-alias) members in definition order

• uses call syntax to return members by value

• uses index syntax to return members by name

Enumerations are created either by using class syntax, or by using function-call syntax:

>>> from enum import Enum

>>> # class syntax

>>> class Color(Enum):

... RED = 1

... GREEN = 2

... BLUE = 3

>>> # functional syntax

>>> Color = Enum('Color', [('RED', 1), ('GREEN', 2), ('BLUE', 3)])



Even though we can use class syntax to create Enums, Enums are not normal Python classes. See How are Enums different? for more details.



® Note

Nomenclature

• The class Color is an enumeration (or enum)

• The attributes Color.RED, Color.GREEN, etc., are enumeration members (or members) and are function-

ally constants.

• The enum members have names and values (the name of Color.RED is RED, the value of Color.BLUE

is 3, etc.)



The Python Library Reference, Release 3.13.2



8.14.1 Module Contents

EnumType

The type for Enum and its subclasses.

Enum

Base class for creating enumerated constants.

IntEnum

Base class for creating enumerated constants that are also subclasses of int. (Notes)

StrEnum

Base class for creating enumerated constants that are also subclasses of str. (Notes)

Flag

Base class for creating enumerated constants that can be combined using the bitwise opera-

tions without losing their Flag membership.

IntFlag

Base class for creating enumerated constants that can be combined using the bitwise operators

without losing their IntFlag membership. IntFlag members are also subclasses of int.

(Notes)

ReprEnum

Used by IntEnum, StrEnum, and IntFlag to keep the str() of the mixed-in type.

EnumCheck

An enumeration with the values CONTINUOUS, NAMED_FLAGS, and UNIQUE, for use with

verify() to ensure various constraints are met by a given enumeration.

FlagBoundary

An enumeration with the values STRICT, CONFORM, EJECT, and KEEP which allows for more fine-grained control over how invalid values are dealt with in an enumeration.

EnumDict

A subclass of dict for use when subclassing EnumType.

auto

Instances are replaced with an appropriate value for Enum members. StrEnum defaults to the lower-cased version of the member name, while other Enums default to 1 and increase from there.

property()

Allows Enum members to have attributes without conflicting with member names. The value and name attributes are implemented this way.

unique()

Enum class decorator that ensures only one name is bound to any one value.

verify()

Enum class decorator that checks user-selectable constraints on an enumeration.

member()

Make obj a member. Can be used as a decorator.

nonmember()

Do not make obj a member. Can be used as a decorator.

The Python Library Reference, Release 3.13.2



global_enum()

Modify the str() and repr() of an enum to show its members as belonging to the module instead of its class, and export the enum members to the global namespace.

show_flag_values()

Return a list of all power-of-two integers contained in a flag.

Added in version 3.6: Flag, IntFlag, auto

Added in version 3.11: StrEnum, EnumCheck, ReprEnum, FlagBoundary, property, member, nonmember, global_enum, show_flag_values

Added in version 3.13: EnumDict



8.14.2 Data Types

class enum.EnumType

EnumType is the metaclass for enum enumerations. It is possible to subclass EnumType – see Subclassing

EnumType for details.

EnumType is responsible for setting the correct __repr__(), __str__(), __format__(), and

__reduce__() methods on the final enum, as well as creating the enum members, properly handling du-

plicates, providing iteration over the enum class, etc.

__call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1,

boundary=None)

This method is called in two different ways:

• to look up an existing member:

cls

The enum class being called.

value

The value to lookup.

• to use the cls enum to create a new enum (only if the existing enum does not have any members):

cls

The enum class being called.

value

The name of the new Enum to create.

names

The names/values of the members for the new Enum.

module

The name of the module the new Enum is created in.

qualname

The actual location in the module where this Enum can be found.

type

A mix-in type for the new Enum.

start

The first integer value for the Enum (used by auto).

boundary

How to handle out-of-range values from bit operations (Flag only).



The Python Library Reference, Release 3.13.2



__contains__(cls, member)

Returns True if member belongs to the cls:

>>> some_var = Color.RED

>>> some_var in Color

True

>>> Color.RED.value in Color

True



Changed in version 3.12: Before Python 3.12, a TypeError is raised if a non-Enum-member is used in a

containment check.

__dir__(cls)

Returns ['__class__', '__doc__', '__members__', '__module__'] and the names of the members in cls:

>>> dir(Color)

['BLUE', 'GREEN', 'RED', '__class__', '__contains__', '__doc__', '__

, →getitem__', '__init_subclass__', '__iter__', '__len__', '__members__', '_ , →_module__', '__name__', '__qualname__']



__getitem__(cls, name)

Returns the Enum member in cls matching name, or raises a KeyError:

>>> Color['BLUE']





__iter__(cls)

Returns each member in cls in definition order:

>>> list(Color)

[, , ]



__len__(cls)

Returns the number of member in cls:

>>> len(Color)

3



__members__

Returns a mapping of every enum name to its member, including aliases

__reversed__(cls)

Returns each member in cls in reverse definition order:

>>> list(reversed(Color))

[, , ]



_add_alias_()

Adds a new name as an alias to an existing member. Raises a NameError if the name is already assigned to a different member.

_add_value_alias_()

Adds a new value as an alias to an existing member. Raises a ValueError if the value is already linked with a different member.

Added in version 3.11: Before 3.11 EnumType was called EnumMeta, which is still available as an alias.

The Python Library Reference, Release 3.13.2



class enum.Enum

Enum is the base class for all enum enumerations.

name

The name used to define the Enum member:

>>> Color.BLUE.name

'BLUE'



value

The value given to the Enum member:

>>> Color.RED.value

1



Value of the member, can be set in __new__().



® Note

Enum member values

Member values can be anything: int, str, etc. If the exact value is unimportant you may use auto

instances and an appropriate value will be chosen for you. See auto for the details.

While mutable/unhashable values, such as dict, list or a mutable dataclass, can be used, they will have a quadratic performance impact during creation relative to the total number of muta-ble/unhashable values in the enum.



_name_

Name of the member.

_value_

Value of the member, can be set in __new__().

_order_

No longer used, kept for backward compatibility. (class attribute, removed during class creation).

_ignore_

_ignore_ is only used during creation and is removed from the enumeration once creation is complete.

_ignore_ is a list of names that will not become members, and whose names will also be removed from the completed enumeration. See TimePeriod for an example.

__dir__(self)

Returns ['__class__', '__doc__', '__module__', 'name', 'value'] and any public methods defined on self.__class__:

>>> from datetime import date

>>> class Weekday(Enum):

... MONDAY = 1

... TUESDAY = 2

... WEDNESDAY = 3

... THURSDAY = 4

... FRIDAY = 5

... SATURDAY = 6

... SUNDAY = 7

... @classmethod

... def today(cls):

... print('today is %s' % cls(date.today().isoweekday()).name)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

...

>>> dir(Weekday.SATURDAY)

['__class__', '__doc__', '__eq__', '__hash__', '__module__', 'name', 'today

, →', 'value']



_generate_next_value_(name, start, count, last_values)

name

The name of the member being defined (e.g. ‘RED’).

start

The start value for the Enum; the default is 1.

count

The number of members currently defined, not including this one.

last_values

A list of the previous values.

A staticmethod that is used to determine the next value returned by auto:

>>> from enum import auto

>>> class PowersOfThree(Enum):

... @staticmethod

... def _generate_next_value_(name, start, count, last_values): ... return 3 ** (count + 1)

... FIRST = auto()

... SECOND = auto()

...

>>> PowersOfThree.SECOND.value

9



__init__(self, *args, **kwds)

By default, does nothing. If multiple values are given in the member assignment, those values become separate arguments to __init__; e.g.

>>> from enum import Enum

>>> class Weekday(Enum):

... MONDAY = 1, 'Mon'



Weekday.__init__() would be called as Weekday.__init__(self, 1, 'Mon')

__init_subclass__(cls, **kwds)

A classmethod that is used to further configure subsequent subclasses. By default, does nothing.

_missing_(cls, value)

A classmethod for looking up values not found in cls. By default it does nothing, but can be overridden to implement custom search behavior:

>>> from enum import StrEnum

>>> class Build(StrEnum):

... DEBUG = auto()

... OPTIMIZED = auto()

... @classmethod

... def _missing_(cls, value):

... value = value.lower()

... for member in cls:

... if member.value == value:

... return member

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... return None

...

>>> Build.DEBUG.value

'debug'

>>> Build('deBUG')





__new__(cls, *args, **kwds)

By default, doesn’t exist. If specified, either in the enum class definition or in a mixin class (such as int), all values given in the member assignment will be passed; e.g.

>>> from enum import Enum

>>> class MyIntEnum(int, Enum):

... TWENTYSIX = '1a', 16



results in the call int('1a', 16) and a value of 26 for the member.



® Note

When writing a custom __new__, do not use super().__new__ – call the appropriate __new__ instead.



__repr__(self)

Returns the string used for repr() calls. By default, returns the Enum name, member name, and value, but can be overridden:

>>> class OtherStyle(Enum):

... ALTERNATE = auto()

... OTHER = auto()

... SOMETHING_ELSE = auto()

... def __repr__(self):

... cls_name = self.__class__.__name__

... return f'{cls_name}.{self.name}'

...

>>> OtherStyle.ALTERNATE, str(OtherStyle.ALTERNATE), f"{OtherStyle.

, →ALTERNATE}"

(OtherStyle.ALTERNATE, 'OtherStyle.ALTERNATE', 'OtherStyle.ALTERNATE')



__str__(self)

Returns the string used for str() calls. By default, returns the Enum name and member name, but can be overridden:

>>> class OtherStyle(Enum):

... ALTERNATE = auto()

... OTHER = auto()

... SOMETHING_ELSE = auto()

... def __str__(self):

... return f'{self.name}'

...

>>> OtherStyle.ALTERNATE, str(OtherStyle.ALTERNATE), f"{OtherStyle.

, →ALTERNATE}"

(, 'ALTERNATE', 'ALTERNATE')



__format__(self)

Returns the string used for format() and f-string calls. By default, returns __str__() return value, but can be overridden:

The Python Library Reference, Release 3.13.2



>>> class OtherStyle(Enum):

... ALTERNATE = auto()

... OTHER = auto()

... SOMETHING_ELSE = auto()

... def __format__(self, spec):

... return f'{self.name}'

...

>>> OtherStyle.ALTERNATE, str(OtherStyle.ALTERNATE), f"{OtherStyle.

, →ALTERNATE}"

(, 'OtherStyle.ALTERNATE', 'ALTERNATE')



® Note

Using auto with Enum results in integers of increasing value, starting with 1.



Changed in version 3.12: Added enum-dataclass-support

class enum.IntEnum

IntEnum is the same as Enum, but its members are also integers and can be used anywhere that an integer can be

used. If any integer operation is performed with an IntEnum member, the resulting value loses its enumeration

status.

>>> from enum import IntEnum

>>> class Number(IntEnum):

... ONE = 1

... TWO = 2

... THREE = 3

...

>>> Number.THREE



>>> Number.ONE + Number.TWO

3

>>> Number.THREE + 5

8

>>> Number.THREE == 3

True



® Note

Using auto with IntEnum results in integers of increasing value, starting with 1.



Changed in version 3.11: __str__() is now int.__str__() to better support the replacement of existing

constants use-case. __format__() was already int.__format__() for that same reason.

class enum.StrEnum

StrEnum is the same as Enum, but its members are also strings and can be used in most of the same places

that a string can be used. The result of any string operation performed on or with a StrEnum member is not

part of the enumeration.



® Note

There are places in the stdlib that check for an exact str instead of a str subclass (i.e. type(unknown) == str instead of isinstance(unknown, str)), and in those locations you will need to use str(StrEnum.member).

The Python Library Reference, Release 3.13.2



® Note

Using auto with StrEnum results in the lower-cased member name as the value.



® Note

__str__() is str.__str__() to better support the replacement of existing constants use-case. __format__() is likewise str.__format__() for that same reason.



Added in version 3.11.

class enum.Flag

Flag is the same as Enum, but its members support the bitwise operators & (AND), | (OR), ^ (XOR), and ~

(INVERT); the results of those operations are (aliases of) members of the enumeration.

__contains__(self, value)

Returns True if value is in self:

>>> from enum import Flag, auto

>>> class Color(Flag):

... RED = auto()

... GREEN = auto()

... BLUE = auto()

...

>>> purple = Color.RED | Color.BLUE

>>> white = Color.RED | Color.GREEN | Color.BLUE

>>> Color.GREEN in purple

False

>>> Color.GREEN in white

True

>>> purple in white

True

>>> white in purple

False



__iter__(self):

Returns all contained non-alias members:

>>> list(Color.RED)

[]

>>> list(purple)

[, ]



Added in version 3.11.

__len__(self):

Returns number of members in flag:

>>> len(Color.GREEN)

1

>>> len(white)

3



Added in version 3.11.

__bool__(self):

Returns True if any members in flag, False otherwise:

The Python Library Reference, Release 3.13.2



>>> bool(Color.GREEN)

True

>>> bool(white)

True

>>> black = Color(0)

>>> bool(black)

False



__or__(self, other)

Returns current flag binary or’ed with other:

>>> Color.RED | Color.GREEN





__and__(self, other)

Returns current flag binary and’ed with other:

>>> purple & white



>>> purple & Color.GREEN





__xor__(self, other)

Returns current flag binary xor’ed with other:

>>> purple ^ white



>>> purple ^ Color.GREEN





__invert__(self):

Returns all the flags in type(self) that are not in self:

>>> ~white



>>> ~purple



>>> ~Color.RED





_numeric_repr_()

Function used to format any remaining unnamed numeric values. Default is the value’s repr; common

choices are hex() and oct().



® Note

Using auto with Flag results in integers that are powers of two, starting with 1.



Changed in version 3.11: The repr() of zero-valued flags has changed. It is now::

>>> Color(0)





class enum.IntFlag

IntFlag is the same as Flag, but its members are also integers and can be used anywhere that an integer can

be used.

The Python Library Reference, Release 3.13.2



>>> from enum import IntFlag, auto

>>> class Color(IntFlag):

... RED = auto()

... GREEN = auto()

... BLUE = auto()

...

>>> Color.RED & 2



>>> Color.RED | 2





If any integer operation is performed with an IntFlag member, the result is not an IntFlag:

>>> Color.RED + 2

3



If a Flag operation is performed with an IntFlag member and:

• the result is a valid IntFlag: an IntFlag is returned

• the result is not a valid IntFlag: the result depends on the FlagBoundary setting

The repr() of unnamed zero-valued flags has changed. It is now:

>>> Color(0)





® Note

Using auto with IntFlag results in integers that are powers of two, starting with 1.



Changed in version 3.11: __str__() is now int.__str__() to better support the replacement of existing

constants use-case. __format__() was already int.__format__() for that same reason.

Inversion of an IntFlag now returns a positive value that is the union of all flags not in the given flag, rather

than a negative value. This matches the existing Flag behavior.

class enum.ReprEnum

ReprEnum uses the repr() of Enum, but the str() of the mixed-in data type:

• int.__str__() for IntEnum and IntFlag

• str.__str__() for StrEnum

Inherit from ReprEnum to keep the str() / format() of the mixed-in data type instead of using the Enum-

default str().

Added in version 3.11.

class enum.EnumCheck

EnumCheck contains the options used by the verify() decorator to ensure various constraints; failed con-

straints result in a ValueError.

UNIQUE

Ensure that each value has only one name:

>>> from enum import Enum, verify, UNIQUE

>>> @verify(UNIQUE)

... class Color(Enum):

... RED = 1

... GREEN = 2

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... BLUE = 3

... CRIMSON = 1

Traceback (most recent call last):

...

ValueError: aliases found in : CRIMSON -> RED



CONTINUOUS

Ensure that there are no missing values between the lowest-valued member and the highest-valued mem-ber:

>>> from enum import Enum, verify, CONTINUOUS

>>> @verify(CONTINUOUS)

... class Color(Enum):

... RED = 1

... GREEN = 2

... BLUE = 5

Traceback (most recent call last):

...

ValueError: invalid enum 'Color': missing values 3, 4



NAMED_FLAGS

Ensure that any flag groups/masks contain only named flags – useful when values are specified instead of

being generated by auto():

>>> from enum import Flag, verify, NAMED_FLAGS

>>> @verify(NAMED_FLAGS)

... class Color(Flag):

... RED = 1

... GREEN = 2

... BLUE = 4

... WHITE = 15

... NEON = 31

Traceback (most recent call last):

...

ValueError: invalid Flag 'Color': aliases WHITE and NEON are missing␣

, →combined values of 0x18 [use enum.show_flag_values(value) for details]



® Note

CONTINUOUS and NAMED_FLAGS are designed to work with integer-valued members.



Added in version 3.11.

class enum.FlagBoundary

FlagBoundary controls how out-of-range values are handled in Flag and its subclasses.

STRICT

Out-of-range values cause a ValueError to be raised. This is the default for Flag:

>>> from enum import Flag, STRICT, auto

>>> class StrictFlag(Flag, boundary=STRICT):

... RED = auto()

... GREEN = auto()

... BLUE = auto()

...

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> StrictFlag(2**2 + 2**4)

Traceback (most recent call last):

...

ValueError: invalid value 20

given 0b0 10100

allowed 0b0 00111



CONFORM

Out-of-range values have invalid values removed, leaving a valid Flag value:

>>> from enum import Flag, CONFORM, auto

>>> class ConformFlag(Flag, boundary=CONFORM):

... RED = auto()

... GREEN = auto()

... BLUE = auto()

...

>>> ConformFlag(2**2 + 2**4)





EJECT

Out-of-range values lose their Flag membership and revert to int.

>>> from enum import Flag, EJECT, auto

>>> class EjectFlag(Flag, boundary=EJECT):

... RED = auto()

... GREEN = auto()

... BLUE = auto()

...

>>> EjectFlag(2**2 + 2**4)

20



KEEP

Out-of-range values are kept, and the Flag membership is kept. This is the default for IntFlag:

>>> from enum import Flag, KEEP, auto

>>> class KeepFlag(Flag, boundary=KEEP):

... RED = auto()

... GREEN = auto()

... BLUE = auto()

...

>>> KeepFlag(2**2 + 2**4)





Added in version 3.11.

class enum.EnumDict

EnumDict is a subclass of dict that is used as the namespace for defining enum classes (see prepare). It is

exposed to allow subclasses of EnumType with advanced behavior like having multiple values per member. It

should be called with the name of the enum class being created, otherwise private names and internal classes

will not be handled correctly.

Note that only the MutableMapping interface (__setitem__() and update()) is overridden. It may be

possible to bypass the checks using other dict operations like |=.

member_names

A list of member names.

Added in version 3.13.

The Python Library Reference, Release 3.13.2



Supported __dunder__ names

__members__ is a read-only ordered mapping of member_name:member items. It is only available on the class.

__new__(), if specified, must create and return the enum members; it is also a very good idea to set the member’s _value_ appropriately. Once all the members are created it is no longer used.



Supported _sunder_ names

• _add_alias_() – adds a new name as an alias to an existing member.

• _add_value_alias_() – adds a new value as an alias to an existing member.

• _name_ – name of the member

• _value_ – value of the member; can be set in __new__

• _missing_() – a lookup function used when a value is not found; may be overridden

• _ignore_ – a list of names, either as a list or a str, that will not be transformed into members, and will

be removed from the final class

• _order_ – no longer used, kept for backward compatibility (class attribute, removed during class creation)

• _generate_next_value_() – used to get an appropriate value for an enum member; may be overridden



® Note

For standard Enum classes the next value chosen is the highest value seen incremented by one.

For Flag classes the next value chosen will be the next highest power-of-two.



• While _sunder_ names are generally reserved for the further development of the Enum class and can not be

used, some are explicitly allowed:

– _repr_* (e.g. _repr_html_), as used in IPython’s rich display

Added in version 3.6: _missing_, _order_, _generate_next_value_

Added in version 3.7: _ignore_

Added in version 3.13: _add_alias_, _add_value_alias_, _repr_*



8.14.3 Utilities and Decorators

class enum.auto

auto can be used in place of a value. If used, the Enum machinery will call an Enum’s

_generate_next_value_() to get an appropriate value. For Enum and IntEnum that appropriate value

will be the last value plus one; for Flag and IntFlag it will be the first power-of-two greater than the highest

value; for StrEnum it will be the lower-cased version of the member’s name. Care must be taken if mixing

auto() with manually specified values.

auto instances are only resolved when at the top level of an assignment:

• FIRST = auto() will work (auto() is replaced with 1);

• SECOND = auto(), -2 will work (auto is replaced with 2, so 2, -2 is used to create the SECOND

enum member;

• THREE = [auto(), -3] will not work (, -3 is used to create the THREE enum

member)

The Python Library Reference, Release 3.13.2



Changed in version 3.11.1: In prior versions, auto() had to be the only thing on the assignment line to work

properly.

_generate_next_value_ can be overridden to customize the values used by auto.



® Note

in 3.13 the default _generate_next_value_ will always return the highest member value incremented by 1, and will fail if any member is an incompatible type.



@enum.property

A decorator similar to the built-in property, but specifically for enumerations. It allows member attributes to

have the same names as members themselves.



® Note

the property and the member must be defined in separate classes; for example, the value and name attributes are defined in the Enum class, and Enum subclasses can define members with the names value and name.



Added in version 3.11.

@enum.unique

A class decorator specifically for enumerations. It searches an enumeration’s __members__, gathering any

aliases it finds; if any are found ValueError is raised with the details:

>>> from enum import Enum, unique

>>> @unique

... class Mistake(Enum):

... ONE = 1

... TWO = 2

... THREE = 3

... FOUR = 3

...

Traceback (most recent call last):

...

ValueError: duplicate values found in : FOUR -> THREE



@enum.verify

A class decorator specifically for enumerations. Members from EnumCheck are used to specify which

constraints should be checked on the decorated enumeration.

Added in version 3.11.

@enum.member

A decorator for use in enums: its target will become a member.

Added in version 3.11.

@enum.nonmember

A decorator for use in enums: its target will not become a member.

Added in version 3.11.

@enum.global_enum

A decorator to change the str() and repr() of an enum to show its members as belonging to the module

instead of its class. Should only be used when the enum members are exported to the module global namespace

(see re.RegexFlag for an example).

Added in version 3.11.

The Python Library Reference, Release 3.13.2



enum.show_flag_values( value)

Return a list of all power-of-two integers contained in a flag value.

Added in version 3.11.



8.14.4 Notes

IntEnum , StrEnum, and IntFlag

These three enum types are designed to be drop-in replacements for existing integer- and string-based

values; as such, they have extra limitations:

• __str__ uses the value and not the name of the enum member

• __format__, because it uses __str__, will also use the value of the enum member instead of

its name

If you do not need/want those limitations, you can either create your own base class by mixing in the

int or str type yourself:

>>> from enum import Enum

>>> class MyIntEnum(int, Enum):

... pass



or you can reassign the appropriate str(), etc., in your enum:

>>> from enum import Enum, IntEnum

>>> class MyIntEnum(IntEnum):

... __str__ = Enum.__str__



8.15 graphlib — Functionality to operate with graph-like structures

Source code: Lib/graphlib.py



class graphlib.TopologicalSorter(graph=None)

Provides functionality to topologically sort a graph of hashable nodes.

A topological order is a linear ordering of the vertices in a graph such that for every directed edge u -> v from

vertex u to vertex v, vertex u comes before vertex v in the ordering. For instance, the vertices of the graph

may represent tasks to be performed, and the edges may represent constraints that one task must be performed

before another; in this example, a topological ordering is just a valid sequence for the tasks. A complete

topological ordering is possible if and only if the graph has no directed cycles, that is, if it is a directed acyclic

graph.

If the optional graph argument is provided it must be a dictionary representing a directed acyclic graph where

the keys are nodes and the values are iterables of all predecessors of that node in the graph (the nodes that have

edges that point to the value in the key). Additional nodes can be added to the graph using the add() method.

In the general case, the steps required to perform the sorting of a given graph are as follows:

• Create an instance of the TopologicalSorter with an optional initial graph.

• Add additional nodes to the graph.

• Call prepare() on the graph.

• While is_active() is True, iterate over the nodes returned by get_ready() and process them. Call

done() on each node as it finishes processing.

In case just an immediate sorting of the nodes in the graph is required and no parallelism is involved, the

convenience method TopologicalSorter.static_order() can be used directly:

The Python Library Reference, Release 3.13.2



>>> graph = {"D": {"B", "C"}, "C": {"A"}, "B": {"A"}}

>>> ts = TopologicalSorter(graph)

>>> tuple(ts.static_order())

('A', 'C', 'B', 'D')



The class is designed to easily support parallel processing of the nodes as they become ready. For instance:

topological_sorter = TopologicalSorter()

# Add nodes to 'topological_sorter'...

topological_sorter.prepare()

while topological_sorter.is_active():

for node in topological_sorter.get_ready():

# Worker threads or processes take nodes to work on off the # 'task_queue' queue.

task_queue.put(node)

# When the work for a node is done, workers put the node in # 'finalized_tasks_queue' so we can get more nodes to work on. # The definition of 'is_active()' guarantees that, at this point, at # least one node has been placed on 'task_queue' that hasn't yet # been passed to 'done()', so this blocking 'get()' must (eventually) # succeed. After calling 'done()', we loop back to call 'get_ready()' # again, so put newly freed nodes on 'task_queue' as soon as # logically possible.

node = finalized_tasks_queue.get()

topological_sorter.done(node)



add(node, *predecessors)

Add a new node and its predecessors to the graph. Both the node and all elements in predecessors must

be hashable.

If called multiple times with the same node argument, the set of dependencies will be the union of all dependencies passed in.

It is possible to add a node with no dependencies (predecessors is not provided) or to provide a dependency twice. If a node that has not been provided before is included among predecessors it will be automatically added to the graph with no predecessors of its own.

Raises ValueError if called after prepare().

prepare()

Mark the graph as finished and check for cycles in the graph. If any cycle is detected, CycleError will

be raised, but get_ready() can still be used to obtain as many nodes as possible until cycles block more progress. After a call to this function, the graph cannot be modified, and therefore no more nodes

can be added using add().

is_active()

Returns True if more progress can be made and False otherwise. Progress can be made if cy-cles do not block the resolution and either there are still nodes ready that haven’t yet been returned

by TopologicalSorter.get_ready() or the number of nodes marked TopologicalSorter.

done() is less than the number that have been returned by TopologicalSorter.get_ready().

The __bool__() method of this class defers to this function, so instead of:

if ts.is_active():

...



it is possible to simply do:

The Python Library Reference, Release 3.13.2



if ts:

...



Raises ValueError if called without calling prepare() previously.

done(*nodes)

Marks a set of nodes returned by TopologicalSorter.get_ready() as processed, unblocking any

successor of each node in nodes for being returned in the future by a call to TopologicalSorter.

get_ready().

Raises ValueError if any node in nodes has already been marked as processed by a previous call to

this method or if a node was not added to the graph by using TopologicalSorter.add(), if called

without calling prepare() or if node has not yet been returned by get_ready().

get_ready()

Returns a tuple with all the nodes that are ready. Initially it returns all nodes with no predecessors, and

once those are marked as processed by calling TopologicalSorter.done(), further calls will return all new nodes that have all their predecessors already processed. Once no more progress can be made, empty tuples are returned.

Raises ValueError if called without calling prepare() previously.

static_order()

Returns an iterator object which will iterate over nodes in a topological order. When using this method,

prepare() and done() should not be called. This method is equivalent to:

def static_order(self):

self.prepare()

while self.is_active():

node_group = self.get_ready()

yield from node_group

self.done(*node_group)



The particular order that is returned may depend on the specific order in which the items were inserted in the graph. For example:

>>> ts = TopologicalSorter()

>>> ts.add(3, 2, 1)

>>> ts.add(1, 0)

>>> print([*ts.static_order()])

[2, 0, 1, 3]

>>> ts2 = TopologicalSorter()

>>> ts2.add(1, 0)

>>> ts2.add(3, 2, 1)

>>> print([*ts2.static_order()])

[0, 2, 1, 3]



This is due to the fact that “0” and “2” are in the same level in the graph (they would have been returned

in the same call to get_ready()) and the order between them is determined by the order of insertion.

If any cycle is detected, CycleError will be raised.

Added in version 3.9.



8.15.1 Exceptions

The graphlib module defines the following exception classes:



The Python Library Reference, Release 3.13.2



exception graphlib.CycleError

Subclass of ValueError raised by TopologicalSorter.prepare() if cycles exist in the working graph.

If multiple cycles exist, only one undefined choice among them will be reported and included in the exception.

The detected cycle can be accessed via the second element in the args attribute of the exception instance and

consists in a list of nodes, such that each node is, in the graph, an immediate predecessor of the next node in

the list. In the reported list, the first and the last node will be the same, to make it clear that it is cyclic.





CHAPTER




NINE



NUMERIC AND MATHEMATICAL MODULES



The modules described in this chapter provide numeric and math-related functions and data types. The numbers

module defines an abstract hierarchy of numeric types. The math and cmath modules contain various mathematical

functions for floating-point and complex numbers. The decimal module supports exact representations of decimal numbers, using arbitrary precision arithmetic.

The following modules are documented in this chapter:



9.1 numbers — Numeric abstract base classes

Source code: Lib/numbers.py



The numbers module (PEP 3141) defines a hierarchy of numeric abstract base classes which progressively define more operations. None of the types defined in this module are intended to be instantiated.

class numbers.Number

The root of the numeric hierarchy. If you just want to check if an argument x is a number, without caring what

kind, use isinstance(x, Number).



9.1.1 The numeric tower

class numbers.Complex

Subclasses of this type describe complex numbers and include the operations that work on the built-in complex

type. These are: conversions to complex and bool, real, imag, +,-, *, /, **, abs(), conjugate(), ==,

and !=. All except-and != are abstract.

real

Abstract. Retrieves the real component of this number.

imag

Abstract. Retrieves the imaginary component of this number.

abstractmethod conjugate()

Abstract. Returns the complex conjugate. For example, (1+3j).conjugate() == (1-3j).

class numbers.Real

To Complex, Real adds the operations that work on real numbers.

In short, those are: a conversion to float, math.trunc(), round(), math.floor(), math.ceil(),

divmod(), //, %, <, <=, >, and >=.

Real also provides defaults for complex(), real, imag, and conjugate().

class numbers.Rational

Subtypes Real and adds numerator and denominator properties. It also provides a default for float().

The numerator and denominator values should be instances of Integral and should be in lowest terms

with denominator positive.

The Python Library Reference, Release 3.13.2



numerator

Abstract.

denominator

Abstract.

class numbers.Integral

Subtypes Rational and adds a conversion to int. Provides defaults for float(), numerator, and

denominator. Adds abstract methods for pow() with modulus and bit-string operations: <<, >>, &, ^,

|, ~.



9.1.2 Notes for type implementers

Implementers should be careful to make equal numbers equal and hash them to the same values. This may be subtle

if there are two different extensions of the real numbers. For example, fractions.Fraction implements hash() as follows:

def __hash__(self):

if self.denominator == 1:

# Get integers right.

return hash(self.numerator)

# Expensive check, but definitely correct.

if self == float(self):

return hash(float(self))

else:

# Use tuple's hash to avoid a high collision rate on # simple fractions.

return hash((self.numerator, self.denominator))



Adding More Numeric ABCs

There are, of course, more possible ABCs for numbers, and this would be a poor hierarchy if it precluded the

possibility of adding those. You can add MyFoo between Complex and Real with:

class MyFoo(Complex): ...

MyFoo.register(Real)



Implementing the arithmetic operations

We want to implement the arithmetic operations so that mixed-mode operations either call an implementation whose author knew about the types of both arguments, or convert both to the nearest built in type and do the operation there.

For subtypes of Integral, this means that __add__() and __radd__() should be defined as:

class MyIntegral(Integral):

def __add__(self, other):

if isinstance(other, MyIntegral):

return do_my_adding_stuff(self, other)

elif isinstance(other, OtherTypeIKnowAbout):

return do_my_other_adding_stuff(self, other)

else:

return NotImplemented

def __radd__(self, other):

if isinstance(other, MyIntegral):

return do_my_adding_stuff(other, self)

elif isinstance(other, OtherTypeIKnowAbout):

return do_my_other_adding_stuff(other, self)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

elif isinstance(other, Integral):

return int(other) + int(self)

elif isinstance(other, Real):

return float(other) + float(self)

elif isinstance(other, Complex):

return complex(other) + complex(self)

else:

return NotImplemented



There are 5 different cases for a mixed-type operation on subclasses of Complex. I’ll refer to all of the above code that doesn’t refer to MyIntegral and OtherTypeIKnowAbout as “boilerplate”. a will be an instance of A, which

is a subtype of Complex (a : A <: Complex), and b : B <: Complex. I’ll consider a + b:

1. If A defines an __add__() which accepts b, all is well.

2. If A falls back to the boilerplate code, and it were to return a value from __add__(), we’d miss the possibil-

ity that B defines a more intelligent __radd__(), so the boilerplate should return NotImplemented from

__add__(). (Or A may not implement __add__() at all.)

3. Then B’s __radd__() gets a chance. If it accepts a, all is well.

4. If it falls back to the boilerplate, there are no more possible methods to try, so this is where the default imple-

mentation should live.

5. If B <: A, Python tries B.__radd__ before A.__add__. This is ok, because it was implemented with

knowledge of A, so it can handle those instances before delegating to Complex.

If A <: Complex and B <: Real without sharing any other knowledge, then the appropriate shared operation is

the one involving the built in complex, and both __radd__() s land there, so a+b == b+a.

Because most of the operations on any given type will be very similar, it can be useful to define a helper function

which generates the forward and reverse instances of any given operator. For example, fractions.Fraction uses:

def _operator_fallbacks(monomorphic_operator, fallback_operator):

def forward(a, b):

if isinstance(b, (int, Fraction)):

return monomorphic_operator(a, b)

elif isinstance(b, float):

return fallback_operator(float(a), b)

elif isinstance(b, complex):

return fallback_operator(complex(a), b)

else:

return NotImplemented

forward.__name__ = '__' + fallback_operator.__name__ + '__'

forward.__doc__ = monomorphic_operator.__doc__

def reverse(b, a):

if isinstance(a, Rational):

# Includes ints.

return monomorphic_operator(a, b)

elif isinstance(a, Real):

return fallback_operator(float(a), float(b))

elif isinstance(a, Complex):

return fallback_operator(complex(a), complex(b))

else:

return NotImplemented

reverse.__name__ = '__r' + fallback_operator.__name__ + '__'

reverse.__doc__ = monomorphic_operator.__doc__

return forward, reverse

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)



def _add(a, b):

"""a + b"""

return Fraction(a.numerator * b.denominator +

b.numerator * a.denominator,

a.denominator * b.denominator)

__add__, __radd__ = _operator_fallbacks(_add, operator.add)

# ...



9.2 math — Mathematical functions



This module provides access to the mathematical functions defined by the C standard.

These functions cannot be used with complex numbers; use the functions of the same name from the cmath module if you require support for complex numbers. The distinction between functions which support complex numbers and those which don’t is made since most users do not want to learn quite as much mathematics as required to understand complex numbers. Receiving an exception instead of a complex result allows earlier detection of the unexpected complex number used as a parameter, so that the programmer can determine how and why it was generated in the first place.

The following functions are provided by this module. Except when explicitly noted otherwise, all return values are floats.



Number-theoretic functions

comb(n, k) Number of ways to choose k items from n items without repetition and without order

factorial(n) n factorial

gcd(*integers) Greatest common divisor of the integer arguments

isqrt(n) Integer square root of a nonnegative integer n

lcm(*integers) Least common multiple of the integer arguments

perm(n, k) Number of ways to choose k items from n items without repetition and with order

Floating point arithmetic

ceil(x) Ceiling of x, the smallest integer greater than or equal to x

fabs(x) Absolute value of x

floor(x) Floor of x, the largest integer less than or equal to x

fma(x, y, z) Fused multiply-add operation: (x * y) + z

fmod(x, y) Remainder of division x / y

modf(x) Fractional and integer parts of x

remainder(x, y) Remainder of x with respect to y

trunc(x) Integer part of x

Floating point manipulation functions

copysign(x, y) Magnitude (absolute value) of x with the sign of y

frexp(x) Mantissa and exponent of x

isclose(a, b, rel_tol, abs_tol) Check if the values a and b are close to each other

isfinite(x) Check if x is neither an infinity nor a NaN

isinf(x) Check if x is a positive or negative infinity

isnan(x) Check if x is a NaN (not a number)

ldexp(x, i) x * (2**i), inverse of function frexp()

nextafter(x, y, steps) Floating-point value steps steps after x towards y

ulp(x) Value of the least significant bit of x

Power, exponential and logarithmic functions

cbrt(x) Cube root of x

continues on next page

The Python Library Reference, Release 3.13.2



Table 1 – continued from previous page

exp(x) e raised to the power x

exp2(x) 2 raised to the power x

expm1(x) e raised to the power x, minus 1

log(x, base) Logarithm of x to the given base (e by default)

log1p(x) Natural logarithm of 1+x (base e)

log2(x) Base-2 logarithm of x

log10(x) Base-10 logarithm of x

pow(x, y) x raised to the power y

sqrt(x) Square root of x

Summation and product functions

dist(p, q) Euclidean distance between two points p and q given as an iterable of coordinates

fsum(iterable) Sum of values in the input iterable

hypot(*coordinates) Euclidean norm of an iterable of coordinates

prod(iterable, start) Product of elements in the input iterable with a start value

sumprod(p, q) Sum of products from two iterables p and q

Angular conversion

degrees(x) Convert angle x from radians to degrees

radians(x) Convert angle x from degrees to radians

Trigonometric functions

acos(x) Arc cosine of x

asin(x) Arc sine of x

atan(x) Arc tangent of x

atan2(y, x) atan(y / x)

cos(x) Cosine of x

sin(x) Sine of x

tan(x) Tangent of x

Hyperbolic functions

acosh(x) Inverse hyperbolic cosine of x

asinh(x) Inverse hyperbolic sine of x

atanh(x) Inverse hyperbolic tangent of x

cosh(x) Hyperbolic cosine of x

sinh(x) Hyperbolic sine of x

tanh(x) Hyperbolic tangent of x

Special functions

erf(x) Error function at x

erfc(x) Complementary error function at x

gamma(x) Gamma function at x

lgamma(x) Natural logarithm of the absolute value of the Gamma function at x

Constants

pi π = 3.141592…

e e = 2.718281…

tau τ = 2π = 6.283185…

inf Positive infinity

nan “Not a number” (NaN)



9.2.1 Number-theoretic functions

math.comb(n, k)

Return the number of ways to choose k items from n items without repetition and without order.

Evaluates to n! / (k! * (n - k)!) when k <= n and evaluates to zero when k > n.

Also called the binomial coefficient because it is equivalent to the coefficient of k-th term in polynomial ex-

pansion of (1 + x)ⁿ.

Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments

are negative.

The Python Library Reference, Release 3.13.2



Added in version 3.8.

math.factorial(n)

Return n factorial as an integer. Raises ValueError if n is not integral or is negative.

Changed in version 3.10: Floats with integral values (like 5.0) are no longer accepted.

math.gcd(*integers)

Return the greatest common divisor of the specified integer arguments. If any of the arguments is nonzero,

then the returned value is the largest positive integer that is a divisor of all arguments. If all arguments are

zero, then the returned value is 0. gcd() without arguments returns 0.

Added in version 3.5.

Changed in version 3.9: Added support for an arbitrary number of arguments. Formerly, only two arguments

were supported.

math.isqrt(n)

Return the integer square root of the nonnegative integer n. This is the floor of the exact square root of n, or

equivalently the greatest integer a such that a² ≤ n.

For some applications, it may be more convenient to have the least integer a such that n ≤ a², or in other words

the ceiling of the exact square root of n. For positive n, this can be computed using a = 1 + isqrt(n -

1).

Added in version 3.8.

math.lcm(*integers)

Return the least common multiple of the specified integer arguments. If all arguments are nonzero, then the

returned value is the smallest positive integer that is a multiple of all arguments. If any of the arguments is

zero, then the returned value is 0. lcm() without arguments returns 1.

Added in version 3.9.

math.perm(n, k=None)

Return the number of ways to choose k items from n items without repetition and with order.

Evaluates to n! / (n - k)! when k <= n and evaluates to zero when k > n.

If k is not specified or is None, then k defaults to n and the function returns n!.

Raises TypeError if either of the arguments are not integers. Raises ValueError if either of the arguments

are negative.

Added in version 3.8.



9.2.2 Floating point arithmetic

math.ceil(x)

Return the ceiling of x, the smallest integer greater than or equal to x. If x is not a float, delegates to x.

__ceil__, which should return an Integral value.

math.fabs(x)

Return the absolute value of x.

math.floor(x)

Return the floor of x, the largest integer less than or equal to x. If x is not a float, delegates to x.__floor__,

which should return an Integral value.

math.fma(x, y, z)

Fused multiply-add operation. Return (x * y) + z, computed as though with infinite precision and range

followed by a single round to the float format. This operation often provides better accuracy than the direct

expression (x * y) + z.

The Python Library Reference, Release 3.13.2



This function follows the specification of the fusedMultiplyAdd operation described in the IEEE 754 stan-

dard. The standard leaves one case implementation-defined, namely the result of fma(0, inf, nan) and

fma(inf, 0, nan). In these cases, math.fma returns a NaN, and does not raise any exception.

Added in version 3.13.

math.fmod(x, y)

Return the floating-point remainder of x / y, as defined by the platform C library function fmod(x, y).

Note that the Python expression x % y may not return the same result. The intent of the C standard is that

fmod(x, y) be exactly (mathematically; to infinite precision) equal to x - n*y for some integer n such that

the result has the same sign as x and magnitude less than abs(y). Python’s x % y returns a result with the sign

of y instead, and may not be exactly computable for float arguments. For example, fmod(-1e-100, 1e100)

is-1e-100, but the result of Python’s-1e-100 % 1e100 is 1e100-1e-100, which cannot be represented

exactly as a float, and rounds to the surprising 1e100. For this reason, function fmod() is generally preferred

when working with floats, while Python’s x % y is preferred when working with integers.

math.modf(x)

Return the fractional and integer parts of x. Both results carry the sign of x and are floats.

Note that modf() has a different call/return pattern than its C equivalents: it takes a single argument and return

a pair of values, rather than returning its second return value through an ‘output parameter’ (there is no such

thing in Python).

math.remainder(x, y)

Return the IEEE 754-style remainder of x with respect to y. For finite x and finite nonzero y, this is the

difference x - n*y, where n is the closest integer to the exact value of the quotient x / y. If x / y is

exactly halfway between two consecutive integers, the nearest even integer is used for n. The remainder r =

remainder(x, y) thus always satisfies abs(r) <= 0.5 * abs(y).

Special cases follow IEEE 754: in particular, remainder(x, math.inf) is x for any finite x, and

remainder(x, 0) and remainder(math.inf, x) raise ValueError for any non-NaN x. If the result

of the remainder operation is zero, that zero will have the same sign as x.

On platforms using IEEE 754 binary floating point, the result of this operation is always exactly representable:

no rounding error is introduced.

Added in version 3.7.

math.trunc(x)

Return x with the fractional part removed, leaving the integer part. This rounds toward 0: trunc() is equiv-

alent to floor() for positive x, and equivalent to ceil() for negative x. If x is not a float, delegates to

x.__trunc__, which should return an Integral value.

For the ceil(), floor(), and modf() functions, note that all floating-point numbers of sufficiently large magnitude are exact integers. Python floats typically carry no more than 53 bits of precision (the same as the platform C double type), in which case any float x with abs(x) >= 2**52 necessarily has no fractional bits.



9.2.3 Floating point manipulation functions

math.copysign(x, y)

Return a float with the magnitude (absolute value) of x but the sign of y. On platforms that support signed

zeros, copysign(1.0, -0.0) returns-1.0.

math.frexp(x)

Return the mantissa and exponent of x as the pair (m, e). m is a float and e is an integer such that x == m *

2**e exactly. If x is zero, returns (0.0, 0), otherwise 0.5 <= abs(m) < 1. This is used to “pick apart”

the internal representation of a float in a portable way.

Note that frexp() has a different call/return pattern than its C equivalents: it takes a single argument and

return a pair of values, rather than returning its second return value through an ‘output parameter’ (there is no

such thing in Python).

The Python Library Reference, Release 3.13.2



math.isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)

Return True if the values a and b are close to each other and False otherwise.

Whether or not two values are considered close is determined according to given absolute and relative toler-

ances. If no errors occur, the result will be: abs(a-b) <= max(rel_tol * max(abs(a), abs(b)),

abs_tol).

rel_tol is the relative tolerance – it is the maximum allowed difference between a and b, relative to the larger

absolute value of a or b. For example, to set a tolerance of 5%, pass rel_tol=0.05. The default tolerance

is 1e-09, which assures that the two values are the same within about 9 decimal digits. rel_tol must be

nonnegative and less than 1.0.

abs_tol is the absolute tolerance; it defaults to 0.0 and it must be nonnegative. When comparing x to 0.0,

isclose(x, 0) is computed as abs(x) <= rel_tol * abs(x), which is False for any x and rel_tol

less than 1.0. So add an appropriate positive abs_tol argument to the call.

The IEEE 754 special values of NaN, inf, and-inf will be handled according to IEEE rules. Specifically,

NaN is not considered close to any other value, including NaN. inf and-inf are only considered close to

themselves.

Added in version 3.5.



µ See also

PEP 485 – A function for testing approximate equality



math.isfinite(x)

Return True if x is neither an infinity nor a NaN, and False otherwise. (Note that 0.0 is considered finite.)

Added in version 3.2.

math.isinf(x)

Return True if x is a positive or negative infinity, and False otherwise.

math.isnan(x)

Return True if x is a NaN (not a number), and False otherwise.

math.ldexp(x, i)

Return x * (2**i). This is essentially the inverse of function frexp().

math.nextafter(x, y, steps=1)

Return the floating-point value steps steps after x towards y.

If x is equal to y, return y, unless steps is zero.

Examples:

• math.nextafter(x, math.inf) goes up: towards positive infinity.

• math.nextafter(x, -math.inf) goes down: towards minus infinity.

• math.nextafter(x, 0.0) goes towards zero.

• math.nextafter(x, math.copysign(math.inf, x)) goes away from zero.

See also math.ulp().

Added in version 3.9.

Changed in version 3.12: Added the steps argument.

math.ulp(x)

Return the value of the least significant bit of the float x:

• If x is a NaN (not a number), return x.

The Python Library Reference, Release 3.13.2



• If x is negative, return ulp(-x).

• If x is a positive infinity, return x.

• If x is equal to zero, return the smallest positive denormalized representable float (smaller than the min-

imum positive normalized float, sys.float_info.min).

• If x is equal to the largest positive representable float, return the value of the least significant bit of x,

such that the first float smaller than x is x - ulp(x).

• Otherwise (x is a positive finite number), return the value of the least significant bit of x, such that the

first float bigger than x is x + ulp(x).

ULP stands for “Unit in the Last Place”.

See also math.nextafter() and sys.float_info.epsilon.

Added in version 3.9.



9.2.4 Power, exponential and logarithmic functions

math.cbrt(x)

Return the cube root of x.

Added in version 3.11.

math.exp(x)

Return e raised to the power x, where e = 2.718281… is the base of natural logarithms. This is usually more

accurate than math.e ** x or pow(math.e, x).

math.exp2(x)

Return 2 raised to the power x.

Added in version 3.11.

math.expm1(x)

Return e raised to the power x, minus 1. Here e is the base of natural logarithms. For small floats x, the

subtraction in exp(x) - 1 can result in a significant loss of precision; the expm1() function provides a way

to compute this quantity to full precision:

>>> from math import exp, expm1

>>> exp(1e-5)-1 # gives result accurate to 11 places

1.0000050000069649e-05

>>> expm1(1e-5) # result accurate to full precision

1.0000050000166668e-05



Added in version 3.2.

math.log(x [, base ])

With one argument, return the natural logarithm of x (to base e).

With two arguments, return the logarithm of x to the given base, calculated as log(x)/log(base).

math.log1p(x)

Return the natural logarithm of 1+x (base e). The result is calculated in a way which is accurate for x near

zero.

math.log2(x)

Return the base-2 logarithm of x. This is usually more accurate than log(x, 2).

Added in version 3.3.



The Python Library Reference, Release 3.13.2



µ See also

int.bit_length() returns the number of bits necessary to represent an integer in binary, excluding the sign and leading zeros.



math.log10(x)

Return the base-10 logarithm of x. This is usually more accurate than log(x, 10).

math.pow(x, y)

Return x raised to the power y. Exceptional cases follow the IEEE 754 standard as far as possible. In particular,

pow(1.0, x) and pow(x, 0.0) always return 1.0, even when x is a zero or a NaN. If both x and y are

finite, x is negative, and y is not an integer then pow(x, y) is undefined, and raises ValueError.

Unlike the built-in ** operator, math.pow() converts both its arguments to type float. Use ** or the

built-in pow() function for computing exact integer powers.

Changed in version 3.11: The special cases pow(0.0, -inf) and pow(-0.0, -inf) were changed to

return inf instead of raising ValueError, for consistency with IEEE 754.

math.sqrt(x)

Return the square root of x.



9.2.5 Summation and product functions

math.dist(p, q)

Return the Euclidean distance between two points p and q, each given as a sequence (or iterable) of coordinates.

The two points must have the same dimension.

Roughly equivalent to:

sqrt(sum((px-qx) ** 2.0 for px, qx in zip(p, q)))



Added in version 3.8.

math.fsum(iterable)

Return an accurate floating-point sum of values in the iterable. Avoids loss of precision by tracking multiple

intermediate partial sums.

The algorithm’s accuracy depends on IEEE-754 arithmetic guarantees and the typical case where the rounding

mode is half-even. On some non-Windows builds, the underlying C library uses extended precision addition

and may occasionally double-round an intermediate sum causing it to be off in its least significant bit.

For further discussion and two alternative approaches, see the ASPN cookbook recipes for accurate floating-

point summation.

math.hypot(*coordinates)

Return the Euclidean norm, sqrt(sum(x**2 for x in coordinates)). This is the length of the vector

from the origin to the point given by the coordinates.

For a two dimensional point (x, y), this is equivalent to computing the hypotenuse of a right triangle using

the Pythagorean theorem, sqrt(x*x + y*y).

Changed in version 3.8: Added support for n-dimensional points. Formerly, only the two dimensional case was

supported.

Changed in version 3.10: Improved the algorithm’s accuracy so that the maximum error is under 1 ulp (unit in

the last place). More typically, the result is almost always correctly rounded to within 1/2 ulp.

math.prod(iterable, *, start=1)

Calculate the product of all the elements in the input iterable. The default start value for the product is 1.

The Python Library Reference, Release 3.13.2



When the iterable is empty, return the start value. This function is intended specifically for use with numeric

values and may reject non-numeric types.

Added in version 3.8.

math.sumprod(p, q)

Return the sum of products of values from two iterables p and q.

Raises ValueError if the inputs do not have the same length.

Roughly equivalent to:

sum(itertools.starmap(operator.mul, zip(p, q, strict=True)))



For float and mixed int/float inputs, the intermediate products and sums are computed with extended precision.

Added in version 3.12.



9.2.6 Angular conversion

math.degrees(x)

Convert angle x from radians to degrees.

math.radians(x)

Convert angle x from degrees to radians.



9.2.7 Trigonometric functions

math.acos(x)

Return the arc cosine of x, in radians. The result is between 0 and pi.

math.asin(x)

Return the arc sine of x, in radians. The result is between-pi/2 and pi/2.

math.atan(x)

Return the arc tangent of x, in radians. The result is between-pi/2 and pi/2.

math.atan2(y, x)

Return atan(y / x), in radians. The result is between-pi and pi. The vector in the plane from the origin to

point (x, y) makes this angle with the positive X axis. The point of atan2() is that the signs of both inputs

are known to it, so it can compute the correct quadrant for the angle. For example, atan(1) and atan2(1,

1) are both pi/4, but atan2(-1, -1) is-3*pi/4.

math.cos(x)

Return the cosine of x radians.

math.sin(x)

Return the sine of x radians.

math.tan(x)

Return the tangent of x radians.



9.2.8 Hyperbolic functions

Hyperbolic functions are analogs of trigonometric functions that are based on hyperbolas instead of circles.

math.acosh(x)

Return the inverse hyperbolic cosine of x.

math.asinh(x)

Return the inverse hyperbolic sine of x.

The Python Library Reference, Release 3.13.2



math.atanh(x)

Return the inverse hyperbolic tangent of x.

math.cosh(x)

Return the hyperbolic cosine of x.

math.sinh(x)

Return the hyperbolic sine of x.

math.tanh(x)

Return the hyperbolic tangent of x.



9.2.9 Special functions

math.erf(x)

Return the error function at x.

The erf() function can be used to compute traditional statistical functions such as the cumulative standard

normal distribution:

def phi(x):

'Cumulative distribution function for the standard normal distribution' return (1.0 + erf(x / sqrt(2.0))) / 2.0



Added in version 3.2.

math.erfc(x)

Return the complementary error function at x. The complementary error function is defined as 1.0 -

erf(x) . It is used for large values of x where a subtraction from one would cause a loss of significance.

Added in version 3.2.

math.gamma(x)

Return the Gamma function at x.

Added in version 3.2.

math.lgamma(x)

Return the natural logarithm of the absolute value of the Gamma function at x.

Added in version 3.2.



9.2.10 Constants

math.pi

The mathematical constant π = 3.141592…, to available precision.

math.e

The mathematical constant e = 2.718281…, to available precision.

math.tau

The mathematical constant τ = 6.283185…, to available precision. Tau is a circle constant equal to 2π, the

ratio of a circle’s circumference to its radius. To learn more about Tau, check out Vi Hart’s video Pi is (still)

Wrong, and start celebrating Tau day by eating twice as much pie!

Added in version 3.6.

math.inf

A floating-point positive infinity. (For negative infinity, use-math.inf.) Equivalent to the output of

float('inf').

Added in version 3.5.

The Python Library Reference, Release 3.13.2



math.nan

A floating-point “not a number” (NaN) value. Equivalent to the output of float('nan'). Due to the re-

quirements of the IEEE-754 standard, math.nan and float('nan') are not considered to equal to any

other numeric value, including themselves. To check whether a number is a NaN, use the isnan() function

to test for NaNs instead of is or ==. Example:

>>> import math

>>> math.nan == math.nan

False

>>> float('nan') == float('nan')

False

>>> math.isnan(math.nan)

True

>>> math.isnan(float('nan'))

True



Added in version 3.5.

Changed in version 3.11: It is now always available.

CPython implementation detail: The math module consists mostly of thin wrappers around the platform C math library functions. Behavior in exceptional cases follows Annex F of the C99 standard where appropriate. The current

implementation will raise ValueError for invalid operations like sqrt(-1.0) or log(0.0) (where C99 Annex

F recommends signaling invalid operation or divide-by-zero), and OverflowError for results that overflow (for example, exp(1000.0)). A NaN will not be returned from any of the functions above unless one or more of the input arguments was a NaN; in that case, most functions will return a NaN, but (again following C99 Annex F) there are some exceptions to this rule, for example pow(float('nan'), 0.0) or hypot(float('nan'), float('inf')).

Note that Python makes no effort to distinguish signaling NaNs from quiet NaNs, and behavior for signaling NaNs remains unspecified. Typical behavior is to treat all NaNs as though they were quiet.



µ See also

Module cmath

Complex number versions of many of these functions.



9.3 cmath — Mathematical functions for complex numbers



This module provides access to mathematical functions for complex numbers. The functions in this module accept integers, floating-point numbers or complex numbers as arguments. They will also accept any Python object that has either a __complex__() or a __float__() method: these methods are used to convert the object to a complex or floating-point number, respectively, and the function is then applied to the result of the conversion.



® Note

For functions involving branch cuts, we have the problem of deciding how to define those functions on the cut

itself. Following Kahan’s “Branch cuts for complex elementary functions” paper, as well as Annex G of C99 and

later C standards, we use the sign of zero to distinguish one side of the branch cut from the other: for a branch

cut along (a portion of) the real axis we look at the sign of the imaginary part, while for a branch cut along the

imaginary axis we look at the sign of the real part.

For example, the cmath.sqrt() function has a branch cut along the negative real axis. An argument of

complex(-2.0, -0.0) is treated as though it lies below the branch cut, and so gives a result on the nega-

tive imaginary axis:

The Python Library Reference, Release 3.13.2



>>> cmath.sqrt(complex(-2.0,-0.0))

-1.4142135623730951j

But an argument of complex(-2.0, 0.0) is treated as though it lies above the branch cut:

>>> cmath.sqrt(complex(-2.0, 0.0))

1.4142135623730951j



9.3.1 Conversions to and from polar coordinates

A Python complex number z is stored internally using rectangular or Cartesian coordinates. It is completely deter-mined by its real part z.real and its imaginary part z.imag.

Polar coordinates give an alternative way to represent a complex number. In polar coordinates, a complex number z is defined by the modulus r and the phase angle phi. The modulus r is the distance from z to the origin, while the phase phi is the counterclockwise angle, measured in radians, from the positive x-axis to the line segment that joins the origin to z.

The following functions can be used to convert from the native rectangular coordinates to polar coordinates and back.



cmath.phase(x)

Return the phase of x (also known as the argument of x), as a float. phase(x) is equivalent to math.atan2(x.

imag, x.real). The result lies in the range [-π, π], and the branch cut for this operation lies along the

negative real axis. The sign of the result is the same as the sign of x.imag, even when x.imag is zero:

>>> phase(complex(-1.0, 0.0))

3.141592653589793

>>> phase(complex(-1.0,-0.0))

-3.141592653589793



® Note

The modulus (absolute value) of a complex number x can be computed using the built-in abs() function. There

is no separate cmath module function for this operation.



cmath.polar(x)

Return the representation of x in polar coordinates. Returns a pair (r, phi) where r is the modulus of x and

phi is the phase of x. polar(x) is equivalent to (abs(x), phase(x)).

cmath.rect(r, phi)

Return the complex number x with polar coordinates r and phi. Equivalent to complex(r * math.

cos(phi), r * math.sin(phi)).



9.3.2 Power and logarithmic functions

cmath.exp(x)

Return e raised to the power x, where e is the base of natural logarithms.

cmath.log(x [, base ])

Returns the logarithm of x to the given base. If the base is not specified, returns the natural logarithm of x.

There is one branch cut, from 0 along the negative real axis to -∞.

cmath.log10(x)

Return the base-10 logarithm of x. This has the same branch cut as log().

cmath.sqrt(x)

Return the square root of x. This has the same branch cut as log().

The Python Library Reference, Release 3.13.2



9.3.3 Trigonometric functions

cmath.acos(x)

Return the arc cosine of x. There are two branch cuts: One extends right from 1 along the real axis to ∞. The

other extends left from -1 along the real axis to -∞.

cmath.asin(x)

Return the arc sine of x. This has the same branch cuts as acos().

cmath.atan(x)

Return the arc tangent of x. There are two branch cuts: One extends from 1j along the imaginary axis to ∞j.

The other extends from-1j along the imaginary axis to-∞j.

cmath.cos(x)

Return the cosine of x.

cmath.sin(x)

Return the sine of x.

cmath.tan(x)

Return the tangent of x.



9.3.4 Hyperbolic functions

cmath.acosh(x)

Return the inverse hyperbolic cosine of x. There is one branch cut, extending left from 1 along the real axis to

-∞.

cmath.asinh(x)

Return the inverse hyperbolic sine of x. There are two branch cuts: One extends from 1j along the imaginary

axis to ∞j. The other extends from-1j along the imaginary axis to-∞j.

cmath.atanh(x)

Return the inverse hyperbolic tangent of x. There are two branch cuts: One extends from 1 along the real axis

to ∞. The other extends from-1 along the real axis to-∞.

cmath.cosh(x)

Return the hyperbolic cosine of x.

cmath.sinh(x)

Return the hyperbolic sine of x.

cmath.tanh(x)

Return the hyperbolic tangent of x.



9.3.5 Classification functions

cmath.isfinite(x)

Return True if both the real and imaginary parts of x are finite, and False otherwise.

Added in version 3.2.

cmath.isinf(x)

Return True if either the real or the imaginary part of x is an infinity, and False otherwise.

cmath.isnan(x)

Return True if either the real or the imaginary part of x is a NaN, and False otherwise.



The Python Library Reference, Release 3.13.2



cmath.isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)

Return True if the values a and b are close to each other and False otherwise.

Whether or not two values are considered close is determined according to given absolute and relative toler-

ances. If no errors occur, the result will be: abs(a-b) <= max(rel_tol * max(abs(a), abs(b)),

abs_tol).

rel_tol is the relative tolerance – it is the maximum allowed difference between a and b, relative to the larger

absolute value of a or b. For example, to set a tolerance of 5%, pass rel_tol=0.05. The default tolerance

is 1e-09, which assures that the two values are the same within about 9 decimal digits. rel_tol must be

nonnegative and less than 1.0.

abs_tol is the absolute tolerance; it defaults to 0.0 and it must be nonnegative. When comparing x to 0.0,

isclose(x, 0) is computed as abs(x) <= rel_tol * abs(x), which is False for any x and rel_tol

less than 1.0. So add an appropriate positive abs_tol argument to the call.

The IEEE 754 special values of NaN, inf, and-inf will be handled according to IEEE rules. Specifically,

NaN is not considered close to any other value, including NaN. inf and-inf are only considered close to

themselves.

Added in version 3.5.



µ See also

PEP 485 – A function for testing approximate equality



9.3.6 Constants

cmath.pi

The mathematical constant π, as a float.

cmath.e

The mathematical constant e, as a float.

cmath.tau

The mathematical constant τ, as a float.

Added in version 3.6.

cmath.inf

Floating-point positive infinity. Equivalent to float('inf').

Added in version 3.6.

cmath.infj

Complex number with zero real part and positive infinity imaginary part. Equivalent to complex(0.0,

float('inf')).

Added in version 3.6.

cmath.nan

A floating-point “not a number” (NaN) value. Equivalent to float('nan').

Added in version 3.6.

cmath.nanj

Complex number with zero real part and NaN imaginary part. Equivalent to complex(0.0,

float('nan')).

Added in version 3.6.

Note that the selection of functions is similar, but not identical, to that in module math. The reason for having two modules is that some users aren’t interested in complex numbers, and perhaps don’t even know what they are. They would rather have math.sqrt(-1) raise an exception than return a complex number. Also note that the functions

The Python Library Reference, Release 3.13.2



defined in cmath always return a complex number, even if the answer can be expressed as a real number (in which case the complex number has an imaginary part of zero).

A note on branch cuts: They are curves along which the given function fails to be continuous. They are a necessary feature of many complex functions. It is assumed that if you need to compute with complex functions, you will understand about branch cuts. Consult almost any (not too elementary) book on complex variables for enlightenment. For information of the proper choice of branch cuts for numerical purposes, a good reference should be the following:



µ See also

Kahan, W: Branch cuts for complex elementary functions; or, Much ado about nothing’s sign bit. In Iserles, A.,

and Powell, M. (eds.), The state of the art in numerical analysis. Clarendon Press (1987) pp165–211.



9.4 decimal — Decimal fixed-point and floating-point arithmetic

Source code: Lib/decimal.py



The decimal module provides support for fast correctly rounded decimal floating-point arithmetic. It offers several

advantages over the float datatype:

• Decimal “is based on a floating-point model which was designed with people in mind, and necessarily has

a paramount guiding principle – computers must provide an arithmetic that works in the same way as the

arithmetic that people learn at school.” – excerpt from the decimal arithmetic specification.

• Decimal numbers can be represented exactly. In contrast, numbers like 1.1 and 2.2 do not have exact

representations in binary floating point. End users typically would not expect 1.1 + 2.2 to display as 3.

3000000000000003 as it does with binary floating point.

• The exactness carries over into arithmetic. In decimal floating point, 0.1 + 0.1 + 0.1 - 0.3 is exactly

equal to zero. In binary floating point, the result is 5.5511151231257827e-017. While near to zero, the dif-

ferences prevent reliable equality testing and differences can accumulate. For this reason, decimal is preferred

in accounting applications which have strict equality invariants.

• The decimal module incorporates a notion of significant places so that 1.30 + 1.20 is 2.50. The trailing

zero is kept to indicate significance. This is the customary presentation for monetary applications. For multi-

plication, the “schoolbook” approach uses all the figures in the multiplicands. For instance, 1.3 * 1.2 gives

1.56 while 1.30 * 1.20 gives 1.5600.

• Unlike hardware based binary floating point, the decimal module has a user alterable precision (defaulting to

28 places) which can be as large as needed for a given problem:

>>> from decimal import *

>>> getcontext().prec = 6

>>> Decimal(1) / Decimal(7)

Decimal('0.142857')

>>> getcontext().prec = 28

>>> Decimal(1) / Decimal(7)

Decimal('0.1428571428571428571428571429')



• Both binary and decimal floating point are implemented in terms of published standards. While the built-in

float type exposes only a modest portion of its capabilities, the decimal module exposes all required parts of

the standard. When needed, the programmer has full control over rounding and signal handling. This includes

an option to enforce exact arithmetic by using exceptions to block any inexact operations.

• The decimal module was designed to support “without prejudice, both exact unrounded decimal arithmetic

(sometimes called fixed-point arithmetic) and rounded floating-point arithmetic.” – excerpt from the decimal

arithmetic specification.

The Python Library Reference, Release 3.13.2



The module design is centered around three concepts: the decimal number, the context for arithmetic, and signals.

A decimal number is immutable. It has a sign, coefficient digits, and an exponent. To preserve significance, the coefficient digits do not truncate trailing zeros. Decimals also include special values such as Infinity,-Infinity, and NaN. The standard also differentiates-0 from +0.

The context for arithmetic is an environment specifying precision, rounding rules, limits on exponents, flags indicat-ing the results of operations, and trap enablers which determine whether signals are treated as exceptions. Round-

ing options include ROUND_CEILING, ROUND_DOWN, ROUND_FLOOR, ROUND_HALF_DOWN, ROUND_HALF_EVEN,

ROUND_HALF_UP, ROUND_UP, and ROUND_05UP.

Signals are groups of exceptional conditions arising during the course of computation. Depending on the needs of the application, signals may be ignored, considered as informational, or treated as exceptions. The signals in the decimal

module are: Clamped, InvalidOperation, DivisionByZero, Inexact, Rounded, Subnormal, Overflow,

Underflow and FloatOperation.

For each signal there is a flag and a trap enabler. When a signal is encountered, its flag is set to one, then, if the trap enabler is set to one, an exception is raised. Flags are sticky, so the user needs to reset them before monitoring a calculation.



µ See also

• IBM’s General Decimal Arithmetic Specification, The General Decimal Arithmetic Specification.



9.4.1 Quick-start Tutorial

The usual start to using decimals is importing the module, viewing the current context with getcontext() and, if necessary, setting new values for precision, rounding, or enabled traps:

>>> from decimal import *

>>> getcontext()

Context(prec=28, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999,

capitals=1, clamp=0, flags=[], traps=[Overflow, DivisionByZero, InvalidOperation])

>>> getcontext().prec = 7 # Set a new precision



Decimal instances can be constructed from integers, strings, floats, or tuples. Construction from an integer or a float performs an exact conversion of the value of that integer or float. Decimal numbers include special values such as NaN which stands for “Not a number”, positive and negative Infinity, and-0:

>>> getcontext().prec = 28

>>> Decimal(10)

Decimal('10')

>>> Decimal('3.14')

Decimal('3.14')

>>> Decimal(3.14)

Decimal('3.140000000000000124344978758017532527446746826171875') >>> Decimal((0, (3, 1, 4),-2))

Decimal('3.14')

>>> Decimal(str(2.0 ** 0.5))

Decimal('1.4142135623730951')

>>> Decimal(2) ** Decimal('0.5')

Decimal('1.414213562373095048801688724')

>>> Decimal('NaN')

Decimal('NaN')

>>> Decimal('-Infinity')

Decimal('-Infinity')

The Python Library Reference, Release 3.13.2



If the FloatOperation signal is trapped, accidental mixing of decimals and floats in constructors or ordering comparisons raises an exception:

>>> c = getcontext()

>>> c.traps[FloatOperation] = True

>>> Decimal(3.14)

Traceback (most recent call last):

File "", line 1, in

decimal.FloatOperation: [] >>> Decimal('3.5') < 3.7

Traceback (most recent call last):

File "", line 1, in

decimal.FloatOperation: [] >>> Decimal('3.5') == 3.5

True



Added in version 3.3.

The significance of a new Decimal is determined solely by the number of digits input. Context precision and rounding only come into play during arithmetic operations.

>>> getcontext().prec = 6

>>> Decimal('3.0')

Decimal('3.0')

>>> Decimal('3.1415926535')

Decimal('3.1415926535')

>>> Decimal('3.1415926535') + Decimal('2.7182818285') Decimal('5.85987')

>>> getcontext().rounding = ROUND_UP

>>> Decimal('3.1415926535') + Decimal('2.7182818285') Decimal('5.85988')



If the internal limits of the C version are exceeded, constructing a decimal raises InvalidOperation:

>>> Decimal("1e9999999999999999999")

Traceback (most recent call last):

File "", line 1, in

decimal.InvalidOperation: []



Changed in version 3.3.

Decimals interact well with much of the rest of Python. Here is a small decimal floating-point flying circus:

>>> data = list(map(Decimal, '1.34 1.87 3.45 2.35 1.00 0.03 9.25'.split())) >>> max(data)

Decimal('9.25')

>>> min(data)

Decimal('0.03')

>>> sorted(data)

[Decimal('0.03'), Decimal('1.00'), Decimal('1.34'), Decimal('1.87'),

Decimal('2.35'), Decimal('3.45'), Decimal('9.25')]

>>> sum(data)

Decimal('19.29')

>>> a,b,c = data[:3]

>>> str(a)

'1.34'

>>> float(a)

1.34

>>> round(a, 1)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

Decimal('1.3')

>>> int(a)

1

>>> a * 5

Decimal('6.70')

>>> a * b

Decimal('2.5058')

>>> c % a

Decimal('0.77')



And some mathematical functions are also available to Decimal:

>>> getcontext().prec = 28

>>> Decimal(2).sqrt()

Decimal('1.414213562373095048801688724')

>>> Decimal(1).exp()

Decimal('2.718281828459045235360287471')

>>> Decimal('10').ln()

Decimal('2.302585092994045684017991455')

>>> Decimal('10').log10()

Decimal('1')



The quantize() method rounds a number to a fixed exponent. This method is useful for monetary applications that often round results to a fixed number of places:

>>> Decimal('7.325').quantize(Decimal('.01'), rounding=ROUND_DOWN) Decimal('7.32')

>>> Decimal('7.325').quantize(Decimal('1.'), rounding=ROUND_UP) Decimal('8')



As shown above, the getcontext() function accesses the current context and allows the settings to be changed. This approach meets the needs of most applications.

For more advanced work, it may be useful to create alternate contexts using the Context() constructor. To make an

alternate active, use the setcontext() function.

In accordance with the standard, the decimal module provides two ready to use standard contexts, BasicContext

and ExtendedContext. The former is especially useful for debugging because many of the traps are enabled:

>>> myothercontext = Context(prec=60, rounding=ROUND_HALF_DOWN) >>> setcontext(myothercontext)

>>> Decimal(1) / Decimal(7)

Decimal('0.142857142857142857142857142857142857142857142857142857142857')

>>> ExtendedContext

Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999,

capitals=1, clamp=0, flags=[], traps=[])

>>> setcontext(ExtendedContext)

>>> Decimal(1) / Decimal(7)

Decimal('0.142857143')

>>> Decimal(42) / Decimal(0)

Decimal('Infinity')

>>> setcontext(BasicContext)

>>> Decimal(42) / Decimal(0)

Traceback (most recent call last):

File "", line 1, in -toplevel-

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

Decimal(42) / Decimal(0)

DivisionByZero: x / 0



Contexts also have signal flags for monitoring exceptional conditions encountered during computations. The flags remain set until explicitly cleared, so it is best to clear the flags before each set of monitored computations by using

the clear_flags() method.

>>> setcontext(ExtendedContext)

>>> getcontext().clear_flags()

>>> Decimal(355) / Decimal(113)

Decimal('3.14159292')

>>> getcontext()

Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999,

capitals=1, clamp=0, flags=[Inexact, Rounded], traps=[])



The flags entry shows that the rational approximation to pi was rounded (digits beyond the context precision were thrown away) and that the result is inexact (some of the discarded digits were non-zero).

Individual traps are set using the dictionary in the traps attribute of a context:

>>> setcontext(ExtendedContext)

>>> Decimal(1) / Decimal(0)

Decimal('Infinity')

>>> getcontext().traps[DivisionByZero] = 1

>>> Decimal(1) / Decimal(0)

Traceback (most recent call last):

File "", line 1, in -toplevel-

Decimal(1) / Decimal(0)

DivisionByZero: x / 0



Most programs adjust the current context only once, at the beginning of the program. And, in many applications,

data is converted to Decimal with a single cast inside a loop. With context set and decimals created, the bulk of the program manipulates the data no differently than with other Python numeric types.



9.4.2 Decimal objects

class decimal.Decimal( value=’0’, context=None)

Construct a new Decimal object based from value.

value can be an integer, string, tuple, float, or another Decimal object. If no value is given, returns

Decimal('0'). If value is a string, it should conform to the decimal numeric string syntax after leading

and trailing whitespace characters, as well as underscores throughout, are removed:

sign ::= '+' | '-'

digit ::= '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'

indicator ::= 'e' | 'E'

digits ::= digit [digit]...

decimal-part ::= digits '.' [digits] | ['.'] digits

exponent-part ::= indicator [sign] digits

infinity ::= 'Infinity' | 'Inf'

nan ::= 'NaN' [digits] | 'sNaN' [digits]

numeric-value ::= decimal-part [exponent-part] | infinity

numeric-string ::= [sign] numeric-value | [sign] nan



Other Unicode decimal digits are also permitted where digit appears above. These include decimal digits

from various other alphabets (for example, Arabic-Indic and Devanāgarī digits) along with the fullwidth digits

'\uff10' through '\uff19'.

The Python Library Reference, Release 3.13.2



If value is a tuple, it should have three components, a sign (0 for positive or 1 for negative), a tuple of

digits, and an integer exponent. For example, Decimal((0, (1, 4, 1, 4), -3)) returns Decimal('1.

414') .

If value is a float, the binary floating-point value is losslessly converted to its exact decimal equivalent.

This conversion can often require 53 or more digits of precision. For example, Decimal(float('1.1'))

converts to Decimal('1.100000000000000088817841970012523233890533447265625').

The context precision does not affect how many digits are stored. That is determined exclusively by the number

of digits in value. For example, Decimal('3.00000') records all five zeros even if the context precision is

only three.

The purpose of the context argument is determining what to do if value is a malformed string. If the context

traps InvalidOperation, an exception is raised; otherwise, the constructor returns a new Decimal with the

value of NaN.

Once constructed, Decimal objects are immutable.

Changed in version 3.2: The argument to the constructor is now permitted to be a float instance.

Changed in version 3.3: float arguments raise an exception if the FloatOperation trap is set. By default

the trap is off.

Changed in version 3.6: Underscores are allowed for grouping, as with integral and floating-point literals in

code.

Decimal floating-point objects share many properties with the other built-in numeric types such as float and

int . All of the usual math operations and special methods apply. Likewise, decimal objects can be copied,

pickled, printed, used as dictionary keys, used as set elements, compared, sorted, and coerced to another type

(such as float or int).

There are some small differences between arithmetic on Decimal objects and arithmetic on integers and floats.

When the remainder operator % is applied to Decimal objects, the sign of the result is the sign of the dividend

rather than the sign of the divisor:

>>> (-7) % 4

1

>>> Decimal(-7) % Decimal(4)

Decimal('-3')



The integer division operator // behaves analogously, returning the integer part of the true quotient (truncating

towards zero) rather than its floor, so as to preserve the usual identity x == (x // y) * y + x % y:

>>>-7 // 4

-2

>>> Decimal(-7) // Decimal(4)

Decimal('-1')



The % and // operators implement the remainder and divide-integer operations (respectively) as de-

scribed in the specification.

Decimal objects cannot generally be combined with floats or instances of fractions.Fraction in arithmetic

operations: an attempt to add a Decimal to a float, for example, will raise a TypeError. However, it is

possible to use Python’s comparison operators to compare a Decimal instance x with another number y. This

avoids confusing results when doing equality comparisons between numbers of different types.

Changed in version 3.2: Mixed-type comparisons between Decimal instances and other numeric types are

now fully supported.

In addition to the standard numeric properties, decimal floating-point objects also have a number of specialized

methods:

adjusted()

Return the adjusted exponent after shifting out the coefficient’s rightmost digits until only the lead digit

The Python Library Reference, Release 3.13.2



remains: Decimal('321e+5').adjusted() returns seven. Used for determining the position of the most significant digit with respect to the decimal point.

as_integer_ratio()

Return a pair (n, d) of integers that represent the given Decimal instance as a fraction, in lowest terms and with a positive denominator:

>>> Decimal('-3.14').as_integer_ratio()

(-157, 50)



The conversion is exact. Raise OverflowError on infinities and ValueError on NaNs.

Added in version 3.6.

as_tuple()

Return a named tuple representation of the number: DecimalTuple(sign, digits, exponent).

canonical()

Return the canonical encoding of the argument. Currently, the encoding of a Decimal instance is always canonical, so this operation returns its argument unchanged.

compare(other, context=None)

Compare the values of two Decimal instances. compare() returns a Decimal instance, and if either operand is a NaN then the result is a NaN:

a or b is a NaN ==> Decimal('NaN')

a < b ==> Decimal('-1')

a == b ==> Decimal('0')

a > b ==> Decimal('1')



compare_signal(other, context=None)

This operation is identical to the compare() method, except that all NaNs signal. That is, if neither operand is a signaling NaN then any quiet NaN operand is treated as though it were a signaling NaN.

compare_total(other, context=None)

Compare two operands using their abstract representation rather than their numerical value. Similar to

the compare() method, but the result gives a total ordering on Decimal instances. Two Decimal instances with the same numeric value but different representations compare unequal in this ordering:

>>> Decimal('12.0').compare_total(Decimal('12'))

Decimal('-1')



Quiet and signaling NaNs are also included in the total ordering. The result of this function is Decimal('0') if both operands have the same representation, Decimal('-1') if the first operand is lower in the total order than the second, and Decimal('1') if the first operand is higher in the total order than the second operand. See the specification for details of the total order.

This operation is unaffected by context and is quiet: no flags are changed and no rounding is performed. As an exception, the C version may raise InvalidOperation if the second operand cannot be converted exactly.

compare_total_mag(other, context=None)

Compare two operands using their abstract representation rather than their value as in

compare_total(), but ignoring the sign of each operand. x.compare_total_mag(y) is

equivalent to x.copy_abs().compare_total(y.copy_abs()).

This operation is unaffected by context and is quiet: no flags are changed and no rounding is performed. As an exception, the C version may raise InvalidOperation if the second operand cannot be converted exactly.

conjugate()

Just returns self, this method is only to comply with the Decimal Specification.

The Python Library Reference, Release 3.13.2



copy_abs()

Return the absolute value of the argument. This operation is unaffected by the context and is quiet: no flags are changed and no rounding is performed.

copy_negate()

Return the negation of the argument. This operation is unaffected by the context and is quiet: no flags are changed and no rounding is performed.

copy_sign(other, context=None)

Return a copy of the first operand with the sign set to be the same as the sign of the second operand. For example:

>>> Decimal('2.3').copy_sign(Decimal('-1.5'))

Decimal('-2.3')



This operation is unaffected by context and is quiet: no flags are changed and no rounding is performed. As an exception, the C version may raise InvalidOperation if the second operand cannot be converted exactly.

exp(context=None)

Return the value of the (natural) exponential function e**x at the given number. The result is correctly

rounded using the ROUND_HALF_EVEN rounding mode.

>>> Decimal(1).exp()

Decimal('2.718281828459045235360287471')

>>> Decimal(321).exp()

Decimal('2.561702493119680037517373933E+139')



classmethod from_float(f)

Alternative constructor that only accepts instances of float or int.

Note Decimal.from_float(0.1) is not the same as Decimal('0.1'). Since 0.1 is

not exactly representable in binary floating point, the value is stored as the nearest repre-sentable value which is 0x1.999999999999ap-4. That equivalent value in decimal is 0.

1000000000000000055511151231257827021181583404541015625.



® Note

From Python 3.2 onwards, a Decimal instance can also be constructed directly from a float.



>>> Decimal.from_float(0.1)

Decimal('0.1000000000000000055511151231257827021181583404541015625') >>> Decimal.from_float(float('nan'))

Decimal('NaN')

>>> Decimal.from_float(float('inf'))

Decimal('Infinity')

>>> Decimal.from_float(float('-inf'))

Decimal('-Infinity')



Added in version 3.1.

fma(other, third, context=None)

Fused multiply-add. Return self*other+third with no rounding of the intermediate product self*other.

>>> Decimal(2).fma(3, 5)

Decimal('11')



The Python Library Reference, Release 3.13.2



is_canonical()

Return True if the argument is canonical and False otherwise. Currently, a Decimal instance is always

canonical, so this operation always returns True.

is_finite()

Return True if the argument is a finite number, and False if the argument is an infinity or a NaN.

is_infinite()

Return True if the argument is either positive or negative infinity and False otherwise.

is_nan()

Return True if the argument is a (quiet or signaling) NaN and False otherwise.

is_normal(context=None)

Return True if the argument is a normal finite number. Return False if the argument is zero, subnormal, infinite or a NaN.

is_qnan()

Return True if the argument is a quiet NaN, and False otherwise.

is_signed()

Return True if the argument has a negative sign and False otherwise. Note that zeros and NaNs can both carry signs.

is_snan()

Return True if the argument is a signaling NaN and False otherwise.

is_subnormal(context=None)

Return True if the argument is subnormal, and False otherwise.

is_zero()

Return True if the argument is a (positive or negative) zero and False otherwise.

ln( context=None)

Return the natural (base e) logarithm of the operand. The result is correctly rounded using the

ROUND_HALF_EVEN rounding mode.

log10(context=None)

Return the base ten logarithm of the operand. The result is correctly rounded using the

ROUND_HALF_EVEN rounding mode.

logb(context=None)

For a nonzero number, return the adjusted exponent of its operand as a Decimal instance. If the operand

is a zero then Decimal('-Infinity') is returned and the DivisionByZero flag is raised. If the operand is an infinity then Decimal('Infinity') is returned.

logical_and(other, context=None)

logical_and() is a logical operation which takes two logical operands (see Logical operands). The result is the digit-wise and of the two operands.

logical_invert(context=None)

logical_invert() is a logical operation. The result is the digit-wise inversion of the operand.

logical_or(other, context=None)

logical_or() is a logical operation which takes two logical operands (see Logical operands). The result is the digit-wise or of the two operands.

logical_xor(other, context=None)

logical_xor() is a logical operation which takes two logical operands (see Logical operands). The result is the digit-wise exclusive or of the two operands.

The Python Library Reference, Release 3.13.2



max(other, context=None)

Like max(self, other) except that the context rounding rule is applied before returning and that NaN values are either signaled or ignored (depending on the context and whether they are signaling or quiet).

max_mag(other, context=None)

Similar to the max() method, but the comparison is done using the absolute values of the operands.

min(other, context=None)

Like min(self, other) except that the context rounding rule is applied before returning and that NaN values are either signaled or ignored (depending on the context and whether they are signaling or quiet).

min_mag(other, context=None)

Similar to the min() method, but the comparison is done using the absolute values of the operands.

next_minus(context=None)

Return the largest number representable in the given context (or in the current thread’s context if no context is given) that is smaller than the given operand.

next_plus(context=None)

Return the smallest number representable in the given context (or in the current thread’s context if no context is given) that is larger than the given operand.

next_toward(other, context=None)

If the two operands are unequal, return the number closest to the first operand in the direction of the second operand. If both operands are numerically equal, return a copy of the first operand with the sign set to be the same as the sign of the second operand.

normalize(context=None)

Used for producing canonical values of an equivalence class within either the current context or the specified context.

This has the same semantics as the unary plus operation, except that if the final result is finite it is reduced to its simplest form, with all trailing zeros removed and its sign preserved. That is, while the coefficient is non-zero and a multiple of ten the coefficient is divided by ten and the exponent is incremented by 1. Otherwise (the coefficient is zero) the exponent is set to 0. In all cases the sign is unchanged.

For example, Decimal('32.100') and Decimal('0.321000e+2') both normalize to the equivalent value Decimal('32.1').

Note that rounding is applied before reducing to simplest form.

In the latest versions of the specification, this operation is also known as reduce.

number_class(context=None)

Return a string describing the class of the operand. The returned value is one of the following ten strings.

• "-Infinity", indicating that the operand is negative infinity.

• "-Normal", indicating that the operand is a negative normal number.

• "-Subnormal", indicating that the operand is negative and subnormal.

• "-Zero", indicating that the operand is a negative zero.

• "+Zero", indicating that the operand is a positive zero.

• "+Subnormal", indicating that the operand is positive and subnormal.

• "+Normal", indicating that the operand is a positive normal number.

• "+Infinity", indicating that the operand is positive infinity.

• "NaN", indicating that the operand is a quiet NaN (Not a Number).

• "sNaN", indicating that the operand is a signaling NaN.

The Python Library Reference, Release 3.13.2



quantize(exp, rounding=None, context=None)

Return a value equal to the first operand after rounding and having the exponent of the second operand.

>>> Decimal('1.41421356').quantize(Decimal('1.000')) Decimal('1.414')



Unlike other operations, if the length of the coefficient after the quantize operation would be greater

than precision, then an InvalidOperation is signaled. This guarantees that, unless there is an error condition, the quantized exponent is always equal to that of the right-hand operand.

Also unlike other operations, quantize never signals Underflow, even if the result is subnormal and inexact.

If the exponent of the second operand is larger than that of the first then rounding may be necessary. In this case, the rounding mode is determined by the rounding argument if given, else by the given context argument; if neither argument is given the rounding mode of the current thread’s context is used.

An error is returned whenever the resulting exponent is greater than Emax or less than Etiny().

radix()

Return Decimal(10), the radix (base) in which the Decimal class does all its arithmetic. Included for compatibility with the specification.

remainder_near(other, context=None)

Return the remainder from dividing self by other. This differs from self % other in that the sign of the remainder is chosen so as to minimize its absolute value. More precisely, the return value is self -n * other where n is the integer nearest to the exact value of self / other, and if two integers are equally near then the even one is chosen.

If the result is zero then its sign will be the sign of self.

>>> Decimal(18).remainder_near(Decimal(10))

Decimal('-2')

>>> Decimal(25).remainder_near(Decimal(10))

Decimal('5')

>>> Decimal(35).remainder_near(Decimal(10))

Decimal('-5')



rotate(other, context=None)

Return the result of rotating the digits of the first operand by an amount specified by the second operand. The second operand must be an integer in the range -precision through precision. The absolute value of the second operand gives the number of places to rotate. If the second operand is positive then rotation is to the left; otherwise rotation is to the right. The coefficient of the first operand is padded on the left with zeros to length precision if necessary. The sign and exponent of the first operand are unchanged.

same_quantum(other, context=None)

Test whether self and other have the same exponent or whether both are NaN.

This operation is unaffected by context and is quiet: no flags are changed and no rounding is performed. As an exception, the C version may raise InvalidOperation if the second operand cannot be converted exactly.

scaleb(other, context=None)

Return the first operand with exponent adjusted by the second. Equivalently, return the first operand multiplied by 10**other. The second operand must be an integer.

shift(other, context=None)

Return the result of shifting the digits of the first operand by an amount specified by the second operand. The second operand must be an integer in the range -precision through precision. The absolute value of the second operand gives the number of places to shift. If the second operand is positive then the shift is to the left; otherwise the shift is to the right. Digits shifted into the coefficient are zeros. The sign and exponent of the first operand are unchanged.

The Python Library Reference, Release 3.13.2



sqrt(context=None)

Return the square root of the argument to full precision.

to_eng_string(context=None)

Convert to a string, using engineering notation if an exponent is needed.

Engineering notation has an exponent which is a multiple of 3. This can leave up to 3 digits to the left of the decimal place and may require the addition of either one or two trailing zeros.

For example, this converts Decimal('123E+1') to Decimal('1.23E+3').

to_integral(rounding=None, context=None)

Identical to the to_integral_value() method. The to_integral name has been kept for compat-ibility with older versions.

to_integral_exact(rounding=None, context=None)

Round to the nearest integer, signaling Inexact or Rounded as appropriate if rounding occurs. The rounding mode is determined by the rounding parameter if given, else by the given context. If neither parameter is given then the rounding mode of the current context is used.

to_integral_value(rounding=None, context=None)

Round to the nearest integer without signaling Inexact or Rounded. If given, applies rounding; other-wise, uses the rounding method in either the supplied context or the current context.

Decimal numbers can be rounded using the round() function:

round(number)

round(number, ndigits)

If ndigits is not given or None, returns the nearest int to number, rounding ties to even, and ignor-

ing the rounding mode of the Decimal context. Raises OverflowError if number is an infinity or

ValueError if it is a (quiet or signaling) NaN.

If ndigits is an int, the context’s rounding mode is respected and a Decimal representing num-ber rounded to the nearest multiple of Decimal('1E-ndigits') is returned; in this case, round(number, ndigits) is equivalent to self.quantize(Decimal('1E-ndigits')). Re-

turns Decimal('NaN') if number is a quiet NaN. Raises InvalidOperation if number is an infinity, a signaling NaN, or if the length of the coefficient after the quantize operation would be greater than the current context’s precision. In other words, for the non-corner cases:

• if ndigits is positive, return number rounded to ndigits decimal places;

• if ndigits is zero, return number rounded to the nearest integer;

• if ndigits is negative, return number rounded to the nearest multiple of 10**abs(ndigits).

For example:

>>> from decimal import Decimal, getcontext, ROUND_DOWN >>> getcontext().rounding = ROUND_DOWN

>>> round(Decimal('3.75')) # context rounding ignored 4

>>> round(Decimal('3.5')) # round-ties-to-even

4

>>> round(Decimal('3.75'), 0) # uses the context rounding Decimal('3')

>>> round(Decimal('3.75'), 1)

Decimal('3.7')

>>> round(Decimal('3.75'),-1)

Decimal('0E+1')



The Python Library Reference, Release 3.13.2



Logical operands

The logical_and(), logical_invert(), logical_or(), and logical_xor() methods expect their argu-

ments to be logical operands. A logical operand is a Decimal instance whose exponent and sign are both zero, and whose digits are all either 0 or 1.



9.4.3 Context objects

Contexts are environments for arithmetic operations. They govern precision, set rules for rounding, determine which signals are treated as exceptions, and limit the range for exponents.

Each thread has its own current context which is accessed or changed using the getcontext() and setcontext() functions:

decimal.getcontext()

Return the current context for the active thread.

decimal.setcontext(c)

Set the current context for the active thread to c.

You can also use the with statement and the localcontext() function to temporarily change the active context.

decimal.localcontext(ctx=None, **kwargs)

Return a context manager that will set the current context for the active thread to a copy of ctx on entry to the

with-statement and restore the previous context when exiting the with-statement. If no context is specified, a

copy of the current context is used. The kwargs argument is used to set the attributes of the new context.

For example, the following code sets the current decimal precision to 42 places, performs a calculation, and

then automatically restores the previous context:

from decimal import localcontext

with localcontext() as ctx:

ctx.prec = 42 # Perform a high precision calculation

s = calculate_something()

s = +s # Round the final result back to the default precision



Using keyword arguments, the code would be the following:

from decimal import localcontext

with localcontext(prec=42) as ctx:

s = calculate_something()

s = +s



Raises TypeError if kwargs supplies an attribute that Context doesn’t support. Raises either TypeError

or ValueError if kwargs supplies an invalid value for an attribute.

Changed in version 3.11: localcontext() now supports setting context attributes through the use of key-

word arguments.

New contexts can also be created using the Context constructor described below. In addition, the module provides three pre-made contexts:

decimal.BasicContext

This is a standard context defined by the General Decimal Arithmetic Specification. Precision is set to nine.

Rounding is set to ROUND_HALF_UP. All flags are cleared. All traps are enabled (treated as exceptions) except

Inexact , Rounded, and Subnormal.

Because many of the traps are enabled, this context is useful for debugging.



The Python Library Reference, Release 3.13.2



decimal.ExtendedContext

This is a standard context defined by the General Decimal Arithmetic Specification. Precision is set to nine.

Rounding is set to ROUND_HALF_EVEN. All flags are cleared. No traps are enabled (so that exceptions are not

raised during computations).

Because the traps are disabled, this context is useful for applications that prefer to have result value of NaN

or Infinity instead of raising exceptions. This allows an application to complete a run in the presence of

conditions that would otherwise halt the program.

decimal.DefaultContext

This context is used by the Context constructor as a prototype for new contexts. Changing a field (such a

precision) has the effect of changing the default for new contexts created by the Context constructor.

This context is most useful in multi-threaded environments. Changing one of the fields before threads are

started has the effect of setting system-wide defaults. Changing the fields after threads have started is not

recommended as it would require thread synchronization to prevent race conditions.

In single threaded environments, it is preferable to not use this context at all. Instead, simply create contexts

explicitly as described below.

The default values are Context.prec=28, Context.rounding=ROUND_HALF_EVEN, and enabled traps

for Overflow, InvalidOperation, and DivisionByZero.

In addition to the three supplied contexts, new contexts can be created with the Context constructor.

class decimal.Context( prec=None, rounding=None, Emin=None, Emax=None, capitals=None, clamp=None,

flags=None, traps=None)

Creates a new context. If a field is not specified or is None, the default values are copied from the

DefaultContext. If the flags field is not specified or is None, all flags are cleared.

prec is an integer in the range [1, MAX_PREC] that sets the precision for arithmetic operations in the context.

The rounding option is one of the constants listed in the section Rounding Modes.

The traps and flags fields list any signals to be set. Generally, new contexts should only set traps and leave the

flags clear.

The Emin and Emax fields are integers specifying the outer limits allowable for exponents. Emin must be in

the range [MIN_EMIN, 0], Emax in the range [0, MAX_EMAX].

The capitals field is either 0 or 1 (the default). If set to 1, exponents are printed with a capital E; otherwise, a

lowercase e is used: Decimal('6.02e+23').

The clamp field is either 0 (the default) or 1. If set to 1, the exponent e of a Decimal instance representable in

this context is strictly limited to the range Emin - prec + 1 <= e <= Emax - prec + 1. If clamp is 0

then a weaker condition holds: the adjusted exponent of the Decimal instance is at most Emax. When clamp

is 1, a large normal number will, where possible, have its exponent reduced and a corresponding number of

zeros added to its coefficient, in order to fit the exponent constraints; this preserves the value of the number

but loses information about significant trailing zeros. For example:

>>> Context(prec=6, Emax=999, clamp=1).create_decimal('1.23e999')

Decimal('1.23000E+999')



A clamp value of 1 allows compatibility with the fixed-width decimal interchange formats specified in IEEE

754.

The Context class defines several general purpose methods as well as a large number of methods for doing

arithmetic directly in a given context. In addition, for each of the Decimal methods described above (with the

exception of the adjusted() and as_tuple() methods) there is a corresponding Context method. For

example, for a Context instance C and Decimal instance x, C.exp(x) is equivalent to x.exp(context=C).

Each Context method accepts a Python integer (an instance of int) anywhere that a Decimal instance is

accepted.



The Python Library Reference, Release 3.13.2



clear_flags()

Resets all of the flags to 0.

clear_traps()

Resets all of the traps to 0.

Added in version 3.3.

copy()

Return a duplicate of the context.

copy_decimal(num)

Return a copy of the Decimal instance num.

create_decimal(num)

Creates a new Decimal instance from num but using self as context. Unlike the Decimal constructor, the context precision, rounding method, flags, and traps are applied to the conversion.

This is useful because constants are often given to a greater precision than is needed by the application. Another benefit is that rounding immediately eliminates unintended effects from digits beyond the current precision. In the following example, using unrounded inputs means that adding zero to a sum can change the result:

>>> getcontext().prec = 3

>>> Decimal('3.4445') + Decimal('1.0023')

Decimal('4.45')

>>> Decimal('3.4445') + Decimal(0) + Decimal('1.0023')

Decimal('4.44')



This method implements the to-number operation of the IBM specification. If the argument is a string, no leading or trailing whitespace or underscores are permitted.

create_decimal_from_float(f )

Creates a new Decimal instance from a float f but rounding using self as the context. Unlike the

Decimal.from_float() class method, the context precision, rounding method, flags, and traps are applied to the conversion.

>>> context = Context(prec=5, rounding=ROUND_DOWN)

>>> context.create_decimal_from_float(math.pi)

Decimal('3.1415')

>>> context = Context(prec=5, traps=[Inexact])

>>> context.create_decimal_from_float(math.pi)

Traceback (most recent call last):

...

decimal.Inexact: None



Added in version 3.1.

Etiny()

Returns a value equal to Emin - prec + 1 which is the minimum exponent value for subnormal results.

When underflow occurs, the exponent is set to Etiny.

Etop()

Returns a value equal to Emax - prec + 1.

The usual approach to working with decimals is to create Decimal instances and then apply arithmetic op-

erations which take place within the current context for the active thread. An alternative approach is to use

context methods for calculating within a specific context. The methods are similar to those for the Decimal

class and are only briefly recounted here.

abs(x)

Returns the absolute value of x.

The Python Library Reference, Release 3.13.2



add(x, y)

Return the sum of x and y.

canonical(x)

Returns the same Decimal object x.

compare(x, y)

Compares x and y numerically.

compare_signal(x, y)

Compares the values of the two operands numerically.

compare_total(x, y)

Compares two operands using their abstract representation.

compare_total_mag(x, y)

Compares two operands using their abstract representation, ignoring sign.

copy_abs(x)

Returns a copy of x with the sign set to 0.

copy_negate(x)

Returns a copy of x with the sign inverted.

copy_sign(x, y)

Copies the sign from y to x.

divide(x, y)

Return x divided by y.

divide_int(x, y)

Return x divided by y, truncated to an integer.

divmod(x, y)

Divides two numbers and returns the integer part of the result.

exp(x)

Returns e ** x.

fma(x, y, z)

Returns x multiplied by y, plus z.

is_canonical(x)

Returns True if x is canonical; otherwise returns False.

is_finite(x)

Returns True if x is finite; otherwise returns False.

is_infinite(x)

Returns True if x is infinite; otherwise returns False.

is_nan(x)

Returns True if x is a qNaN or sNaN; otherwise returns False.

is_normal(x)

Returns True if x is a normal number; otherwise returns False.

is_qnan(x)

Returns True if x is a quiet NaN; otherwise returns False.

is_signed(x)

Returns True if x is negative; otherwise returns False.

The Python Library Reference, Release 3.13.2



is_snan(x)

Returns True if x is a signaling NaN; otherwise returns False.

is_subnormal(x)

Returns True if x is subnormal; otherwise returns False.

is_zero(x)

Returns True if x is a zero; otherwise returns False.

ln( x)

Returns the natural (base e) logarithm of x.

log10(x)

Returns the base 10 logarithm of x.

logb(x)

Returns the exponent of the magnitude of the operand’s MSD.

logical_and(x, y)

Applies the logical operation and between each operand’s digits.

logical_invert(x)

Invert all the digits in x.

logical_or(x, y)

Applies the logical operation or between each operand’s digits.

logical_xor(x, y)

Applies the logical operation xor between each operand’s digits.

max(x, y)

Compares two values numerically and returns the maximum.

max_mag(x, y)

Compares the values numerically with their sign ignored.

min(x, y)

Compares two values numerically and returns the minimum.

min_mag(x, y)

Compares the values numerically with their sign ignored.

minus(x)

Minus corresponds to the unary prefix minus operator in Python.

multiply(x, y)

Return the product of x and y.

next_minus(x)

Returns the largest representable number smaller than x.

next_plus(x)

Returns the smallest representable number larger than x.

next_toward(x, y)

Returns the number closest to x, in direction towards y.

normalize(x)

Reduces x to its simplest form.

number_class(x)

Returns an indication of the class of x.

The Python Library Reference, Release 3.13.2



plus(x)

Plus corresponds to the unary prefix plus operator in Python. This operation applies the context precision and rounding, so it is not an identity operation.

power(x, y, modulo=None)

Return x to the power of y, reduced modulo modulo if given.

With two arguments, compute x**y. If x is negative then y must be integral. The result will be inexact unless y is integral and the result is finite and can be expressed exactly in ‘precision’ digits. The rounding mode of the context is used. Results are always correctly rounded in the Python version.

Decimal(0) ** Decimal(0) results in InvalidOperation, and if InvalidOperation is not trapped, then results in Decimal('NaN').

Changed in version 3.3: The C module computes power() in terms of the correctly rounded exp() and

ln() functions. The result is well-defined but only “almost always correctly rounded”.

With three arguments, compute (x**y) % modulo. For the three argument form, the following re-strictions on the arguments hold:

• all three arguments must be integral

• y must be nonnegative

• at least one of x or y must be nonzero

• modulo must be nonzero and have at most ‘precision’ digits

The value resulting from Context.power(x, y, modulo) is equal to the value that would be ob-tained by computing (x**y) % modulo with unbounded precision, but is computed more efficiently. The exponent of the result is zero, regardless of the exponents of x, y and modulo. The result is always exact.

quantize(x, y)

Returns a value equal to x (rounded), having the exponent of y.

radix()

Just returns 10, as this is Decimal, :)

remainder(x, y)

Returns the remainder from integer division.

The sign of the result, if non-zero, is the same as that of the original dividend.

remainder_near(x, y)

Returns x - y * n, where n is the integer nearest the exact value of x / y (if the result is 0 then its sign will be the sign of x).

rotate(x, y)

Returns a rotated copy of x, y times.

same_quantum(x, y)

Returns True if the two operands have the same exponent.

scaleb(x, y)

Returns the first operand after adding the second value its exp.

shift(x, y)

Returns a shifted copy of x, y times.

sqrt(x)

Square root of a non-negative number to context precision.

subtract(x, y)

Return the difference between x and y.

The Python Library Reference, Release 3.13.2



to_eng_string(x)

Convert to a string, using engineering notation if an exponent is needed.

Engineering notation has an exponent which is a multiple of 3. This can leave up to 3 digits to the left of the decimal place and may require the addition of either one or two trailing zeros.

to_integral_exact(x)

Rounds to an integer.

to_sci_string(x)

Converts a number to a string using scientific notation.



9.4.4 Constants

The constants in this section are only relevant for the C module. They are also included in the pure Python version for compatibility.



32-bit 64-bit

425000000 999999999999999999

decimal.MAX_PREC



425000000 999999999999999999

decimal.MAX_EMAX



-425000000 -999999999999999999

decimal.MIN_EMIN



-849999999 -1999999999999999997

decimal.MIN_ETINY



decimal.HAVE_THREADS

The value is True. Deprecated, because Python now always has threads.

Deprecated since version 3.9.

decimal.HAVE_CONTEXTVAR

The default value is True. If Python is configured using the --without-decimal-contextvar

option , the C version uses a thread-local rather than a coroutine-local context and the value is False. This

is slightly faster in some nested context scenarios.

Added in version 3.8.3.



9.4.5 Rounding modes

decimal.ROUND_CEILING

Round towards Infinity.

decimal.ROUND_DOWN

Round towards zero.

decimal.ROUND_FLOOR

Round towards-Infinity.

decimal.ROUND_HALF_DOWN

Round to nearest with ties going towards zero.

decimal.ROUND_HALF_EVEN

Round to nearest with ties going to nearest even integer.

The Python Library Reference, Release 3.13.2



decimal.ROUND_HALF_UP

Round to nearest with ties going away from zero.

decimal.ROUND_UP

Round away from zero.

decimal.ROUND_05UP

Round away from zero if last digit after rounding towards zero would have been 0 or 5; otherwise round towards

zero.



9.4.6 Signals

Signals represent conditions that arise during computation. Each corresponds to one context flag and one context trap enabler.

The context flag is set whenever the condition is encountered. After the computation, flags may be checked for informational purposes (for instance, to determine whether a computation was exact). After checking the flags, be sure to clear all flags before starting the next computation.

If the context’s trap enabler is set for the signal, then the condition causes a Python exception to be raised. For

example, if the DivisionByZero trap is set, then a DivisionByZero exception is raised upon encountering the condition.

class decimal.Clamped

Altered an exponent to fit representation constraints.

Typically, clamping occurs when an exponent falls outside the context’s Emin and Emax limits. If possible, the

exponent is reduced to fit by adding zeros to the coefficient.

class decimal.DecimalException

Base class for other signals and a subclass of ArithmeticError.

class decimal.DivisionByZero

Signals the division of a non-infinite number by zero.

Can occur with division, modulo division, or when raising a number to a negative power. If this signal is not

trapped, returns Infinity or-Infinity with the sign determined by the inputs to the calculation.

class decimal.Inexact

Indicates that rounding occurred and the result is not exact.

Signals when non-zero digits were discarded during rounding. The rounded result is returned. The signal flag

or trap is used to detect when results are inexact.

class decimal.InvalidOperation

An invalid operation was performed.

Indicates that an operation was requested that does not make sense. If not trapped, returns NaN. Possible causes

include:

Infinity-Infinity

0 * Infinity

Infinity / Infinity

x % 0

Infinity % x

sqrt(-x) and x > 0

0 ** 0

x ** (non-integer)

x ** Infinity



The Python Library Reference, Release 3.13.2



class decimal.Overflow

Numerical overflow.

Indicates the exponent is larger than Context.Emax after rounding has occurred. If not trapped, the result

depends on the rounding mode, either pulling inward to the largest representable finite number or rounding

outward to Infinity. In either case, Inexact and Rounded are also signaled.

class decimal.Rounded

Rounding occurred though possibly no information was lost.

Signaled whenever rounding discards digits; even if those digits are zero (such as rounding 5.00 to 5.0). If

not trapped, returns the result unchanged. This signal is used to detect loss of significant digits.

class decimal.Subnormal

Exponent was lower than Emin prior to rounding.

Occurs when an operation result is subnormal (the exponent is too small). If not trapped, returns the result

unchanged.

class decimal.Underflow

Numerical underflow with result rounded to zero.

Occurs when a subnormal result is pushed to zero by rounding. Inexact and Subnormal are also signaled.

class decimal.FloatOperation

Enable stricter semantics for mixing floats and Decimals.

If the signal is not trapped (default), mixing floats and Decimals is permitted in the Decimal constructor,

create_decimal() and all comparison operators. Both conversion and comparisons are exact. Any oc-

currence of a mixed operation is silently recorded by setting FloatOperation in the context flags. Explicit

conversions with from_float() or create_decimal_from_float() do not set the flag.

Otherwise (the signal is trapped), only equality comparisons and explicit conversions are silent. All other

mixed operations raise FloatOperation.

The following table summarizes the hierarchy of signals:

exceptions.ArithmeticError(exceptions.Exception)

DecimalException

Clamped

DivisionByZero(DecimalException, exceptions.ZeroDivisionError) Inexact

Overflow(Inexact, Rounded)

Underflow(Inexact, Rounded, Subnormal)

InvalidOperation

Rounded

Subnormal

FloatOperation(DecimalException, exceptions.TypeError)



9.4.7 Floating-Point Notes

Mitigating round-off error with increased precision

The use of decimal floating point eliminates decimal representation error (making it possible to represent 0.1 ex-actly); however, some operations can still incur round-off error when non-zero digits exceed the fixed precision.

The effects of round-off error can be amplified by the addition or subtraction of nearly offsetting quantities result-ing in loss of significance. Knuth provides two instructive examples where rounded floating-point arithmetic with insufficient precision causes the breakdown of the associative and distributive properties of addition:

# Examples from Seminumerical Algorithms, Section 4.2.2. >>> from decimal import Decimal, getcontext

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> getcontext().prec = 8

>>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111') >>> (u + v) + w

Decimal('9.5111111')

>>> u + (v + w)

Decimal('10')

>>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003') >>> (u*v) + (u*w)

Decimal('0.01')

>>> u * (v+w)

Decimal('0.0060000')



The decimal module makes it possible to restore the identities by expanding the precision sufficiently to avoid loss of significance:

>>> getcontext().prec = 20

>>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111') >>> (u + v) + w

Decimal('9.51111111')

>>> u + (v + w)

Decimal('9.51111111')

>>>

>>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003') >>> (u*v) + (u*w)

Decimal('0.0060000')

>>> u * (v+w)

Decimal('0.0060000')



Special values

The number system for the decimal module provides special values including NaN, sNaN,-Infinity, Infinity, and two zeros, +0 and-0.

Infinities can be constructed directly with: Decimal('Infinity'). Also, they can arise from dividing by zero

when the DivisionByZero signal is not trapped. Likewise, when the Overflow signal is not trapped, infinity can result from rounding beyond the limits of the largest representable number.

The infinities are signed (affine) and can be used in arithmetic operations where they get treated as very large, inde-terminate numbers. For instance, adding a constant to infinity gives another infinite result.

Some operations are indeterminate and return NaN, or if the InvalidOperation signal is trapped, raise an excep-tion. For example, 0/0 returns NaN which means “not a number”. This variety of NaN is quiet and, once created, will flow through other computations always resulting in another NaN. This behavior can be useful for a series of computations that occasionally have missing inputs — it allows the calculation to proceed while flagging specific results as invalid.

A variant is sNaN which signals rather than remaining quiet after every operation. This is a useful return value when an invalid result needs to interrupt a calculation for special handling.

The behavior of Python’s comparison operators can be a little surprising where a NaN is involved. A test

for equality where one of the operands is a quiet or signaling NaN always returns False (even when doing

Decimal('NaN')==Decimal('NaN')), while a test for inequality always returns True. An attempt to compare

two Decimals using any of the <, <=, > or >= operators will raise the InvalidOperation signal if either operand

is a NaN, and return False if this signal is not trapped. Note that the General Decimal Arithmetic specification does not specify the behavior of direct comparisons; these rules for comparisons involving a NaN were taken from

the IEEE 854 standard (see Table 3 in section 5.7). To ensure strict standards-compliance, use the compare() and

compare_signal() methods instead.

The Python Library Reference, Release 3.13.2



The signed zeros can result from calculations that underflow. They keep the sign that would have resulted if the calculation had been carried out to greater precision. Since their magnitude is zero, both positive and negative zeros are treated as equal and their sign is informational.

In addition to the two signed zeros which are distinct yet equal, there are various representations of zero with differing precisions yet equivalent in value. This takes a bit of getting used to. For an eye accustomed to normalized floating-point representations, it is not immediately obvious that the following calculation returns a value equal to zero:

>>> 1 / Decimal('Infinity')

Decimal('0E-1000026')



9.4.8 Working with threads

The getcontext() function accesses a different Context object for each thread. Having separate thread contexts means that threads may make changes (such as getcontext().prec=10) without interfering with other threads.

Likewise, the setcontext() function automatically assigns its target to the current thread.

If setcontext() has not been called before getcontext(), then getcontext() will automatically create a new context for use in the current thread.

The new context is copied from a prototype context called DefaultContext. To control the defaults so that each thread will use the same values throughout the application, directly modify the DefaultContext object. This should be done

before any threads are started so that there won’t be a race condition between threads calling getcontext(). For example:

# Set applicationwide defaults for all threads about to be launched DefaultContext.prec = 12

DefaultContext.rounding = ROUND_DOWN

DefaultContext.traps = ExtendedContext.traps.copy()

DefaultContext.traps[InvalidOperation] = 1

setcontext(DefaultContext)

# Afterwards, the threads can be started

t1.start()

t2.start()

t3.start()

. . .



9.4.9 Recipes

Here are a few recipes that serve as utility functions and that demonstrate ways to work with the Decimal class:

def moneyfmt(value, places=2, curr='', sep=',', dp='.',

pos='', neg='-', trailneg=''):

"""Convert Decimal to a money formatted string.

places: required number of places after the decimal point

curr: optional currency symbol before the sign (may be blank)

sep: optional grouping separator (comma, period, space, or blank)

dp: decimal point indicator (comma or period)

only specify as blank when places is zero

pos: optional sign for positive numbers: '+', space or blank

neg: optional sign for negative numbers: '-', '(', space or blank

trailneg:optional trailing minus indicator: '-', ')', space or blank

>>> d = Decimal('-1234567.8901')

>>> moneyfmt(d, curr='$')

'-$1,234,567.89'

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> moneyfmt(d, places=0, sep='.', dp='', neg='', trailneg='-')

'1.234.568-'

>>> moneyfmt(d, curr='$', neg='(', trailneg=')')

'($1,234,567.89)'

>>> moneyfmt(Decimal(123456789), sep=' ')

'123 456 789.00'

>>> moneyfmt(Decimal('-0.02'), neg='<', trailneg='>')

'<0.02>'

"""

q = Decimal(10) ** -places # 2 places --> '0.01'

sign, digits, exp = value.quantize(q).as_tuple()

result = []

digits = list(map(str, digits))

build, next = result.append, digits.pop

if sign:

build(trailneg)

for i in range(places):

build(next() if digits else '0')

if places:

build(dp)

if not digits:

build('0')

i = 0

while digits:

build(next())

i += 1

if i == 3 and digits:

i = 0

build(sep)

build(curr)

build(neg if sign else pos)

return ''.join(reversed(result))

def pi():

"""Compute Pi to the current precision.

>>> print(pi())

3.141592653589793238462643383

"""

getcontext().prec += 2 # extra digits for intermediate steps

three = Decimal(3) # substitute "three=3.0" for regular floats

lasts, t, s, n, na, d, da = 0, three, 3, 1, 0, 0, 24

while s != lasts:

lasts = s

n, na = n+na, na+8

d, da = d+da, da+32

t = (t * n) / d

s += t

getcontext().prec-= 2

return +s # unary plus applies the new precision

def exp(x):

"""Return e raised to the power of x. Result type matches input type.



(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> print(exp(Decimal(1)))

2.718281828459045235360287471

>>> print(exp(Decimal(2)))

7.389056098930650227230427461

>>> print(exp(2.0))

7.38905609893

>>> print(exp(2+0j))

(7.38905609893+0j)

"""

getcontext().prec += 2

i, lasts, s, fact, num = 0, 0, 1, 1, 1

while s != lasts:

lasts = s

i += 1

fact *= i

num *= x

s += num / fact

getcontext().prec-= 2

return +s

def cos(x):

"""Return the cosine of x as measured in radians.

The Taylor series approximation works best for a small value of x.

For larger values, first compute x = x % (2 * pi).

>>> print(cos(Decimal('0.5')))

0.8775825618903727161162815826

>>> print(cos(0.5))

0.87758256189

>>> print(cos(0.5+0j))

(0.87758256189+0j)

"""

getcontext().prec += 2

i, lasts, s, fact, num, sign = 0, 0, 1, 1, 1, 1

while s != lasts:

lasts = s

i += 2

fact *= i * (i-1)

num *= x * x

sign *= -1

s += num / fact * sign

getcontext().prec-= 2

return +s

def sin(x):

"""Return the sine of x as measured in radians.

The Taylor series approximation works best for a small value of x.

For larger values, first compute x = x % (2 * pi).

>>> print(sin(Decimal('0.5')))

0.4794255386042030002732879352

>>> print(sin(0.5))

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

0.479425538604

>>> print(sin(0.5+0j))

(0.479425538604+0j)

"""

getcontext().prec += 2

i, lasts, s, fact, num, sign = 1, 0, x, 1, x, 1

while s != lasts:

lasts = s

i += 2

fact *= i * (i-1)

num *= x * x

sign *= -1

s += num / fact * sign

getcontext().prec-= 2

return +s



9.4.10 Decimal FAQ

Q. It is cumbersome to type decimal.Decimal('1234.5'). Is there a way to minimize typing when using the interactive interpreter?

A. Some users abbreviate the constructor to just a single letter:

>>> D = decimal.Decimal

>>> D('1.23') + D('3.45')

Decimal('4.68')



Q. In a fixed-point application with two decimal places, some inputs have many places and need to be rounded. Others are not supposed to have excess digits and need to be validated. What methods should be used?

A. The quantize() method rounds to a fixed number of decimal places. If the Inexact trap is set, it is also useful for validation:

>>> TWOPLACES = Decimal(10) ** -2 # same as Decimal('0.01')



>>> # Round to two places

>>> Decimal('3.214').quantize(TWOPLACES)

Decimal('3.21')



>>> # Validate that a number does not exceed two places >>> Decimal('3.21').quantize(TWOPLACES, context=Context(traps=[Inexact])) Decimal('3.21')



>>> Decimal('3.214').quantize(TWOPLACES, context=Context(traps=[Inexact])) Traceback (most recent call last):

...

Inexact: None



Q. Once I have valid two place inputs, how do I maintain that invariant throughout an application?

A. Some operations like addition, subtraction, and multiplication by an integer will automatically preserve fixed point. Others operations, like division and non-integer multiplication, will change the number of decimal places and need

to be followed-up with a quantize() step:

>>> a = Decimal('102.72') # Initial fixed-point values >>> b = Decimal('3.17')

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> a + b # Addition preserves fixed-point

Decimal('105.89')

>>> a-b

Decimal('99.55')

>>> a * 42 # So does integer multiplication

Decimal('4314.24')

>>> (a * b).quantize(TWOPLACES) # Must quantize non-integer multiplication Decimal('325.62')

>>> (b / a).quantize(TWOPLACES) # And quantize division Decimal('0.03')



In developing fixed-point applications, it is convenient to define functions to handle the quantize() step:

>>> def mul(x, y, fp=TWOPLACES):

... return (x * y).quantize(fp)

...

>>> def div(x, y, fp=TWOPLACES):

... return (x / y).quantize(fp)



>>> mul(a, b) # Automatically preserve fixed-point

Decimal('325.62')

>>> div(b, a)

Decimal('0.03')



Q. There are many ways to express the same value. The numbers 200, 200.000, 2E2, and .02E+4 all have the same value at various precisions. Is there a way to transform them to a single recognizable canonical value?

A. The normalize() method maps all equivalent values to a single representative:

>>> values = map(Decimal, '200 200.000 2E2 .02E+4'.split()) >>> [v.normalize() for v in values]

[Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2')]



Q. When does rounding occur in a computation?

A. It occurs after the computation. The philosophy of the decimal specification is that numbers are considered exact and are created independent of the current context. They can even have greater precision than current context. Computations process with those exact inputs and then rounding (or other context operations) is applied to the result of the computation:

>>> getcontext().prec = 5

>>> pi = Decimal('3.1415926535') # More than 5 digits

>>> pi # All digits are retained

Decimal('3.1415926535')

>>> pi + 0 # Rounded after an addition

Decimal('3.1416')

>>> pi-Decimal('0.00005') # Subtract unrounded numbers, then round Decimal('3.1415')

>>> pi + 0-Decimal('0.00005'). # Intermediate values are rounded Decimal('3.1416')



Q. Some decimal values always print with exponential notation. Is there a way to get a non-exponential representation?

A. For some values, exponential notation is the only way to express the number of significant places in the coeffi-cient. For example, expressing 5.0E+3 as 5000 keeps the value constant but cannot show the original’s two-place significance.

If an application does not care about tracking significance, it is easy to remove the exponent and trailing zeroes, losing significance, but keeping the value unchanged:

The Python Library Reference, Release 3.13.2



>>> def remove_exponent(d):

... return d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize()



>>> remove_exponent(Decimal('5E+3'))

Decimal('5000')



Q. Is there a way to convert a regular float to a Decimal?

A. Yes, any binary floating-point number can be exactly expressed as a Decimal though an exact conversion may take more precision than intuition would suggest:

>>> Decimal(math.pi)

Decimal('3.141592653589793115997963468544185161590576171875')



Q. Within a complex calculation, how can I make sure that I haven’t gotten a spurious result because of insufficient precision or rounding anomalies.

A. The decimal module makes it easy to test results. A best practice is to re-run calculations using greater precision and with various rounding modes. Widely differing results indicate insufficient precision, rounding mode issues, ill-conditioned inputs, or a numerically unstable algorithm.

Q. I noticed that context precision is applied to the results of operations but not to the inputs. Is there anything to watch out for when mixing values of different precisions?

A. Yes. The principle is that all values are considered to be exact and so is the arithmetic on those values. Only the results are rounded. The advantage for inputs is that “what you type is what you get”. A disadvantage is that the results can look odd if you forget that the inputs haven’t been rounded:

>>> getcontext().prec = 3

>>> Decimal('3.104') + Decimal('2.104')

Decimal('5.21')

>>> Decimal('3.104') + Decimal('0.000') + Decimal('2.104') Decimal('5.20')



The solution is either to increase precision or to force rounding of inputs using the unary plus operation:

>>> getcontext().prec = 3

>>> +Decimal('1.23456789') # unary plus triggers rounding Decimal('1.23')



Alternatively, inputs can be rounded upon creation using the Context.create_decimal() method:

>>> Context(prec=5, rounding=ROUND_DOWN).create_decimal('1.2345678') Decimal('1.2345')



Q. Is the CPython implementation fast for large numbers?

A. Yes. In the CPython and PyPy3 implementations, the C/CFFI versions of the decimal module integrate the high

speed 1 libmpdec library for arbitrary precision correctly rounded decimal floating-point arithmetic. libmpdec uses

Karatsuba multiplication for medium-sized numbers and the Number Theoretic Transform for very large numbers.

The context must be adapted for exact arbitrary precision arithmetic. Emin and Emax should always be set to the maximum values, clamp should always be 0 (the default). Setting prec requires some care.

The easiest approach for trying out bignum arithmetic is to use the maximum value for 2 prec as well:

1

Added in version 3.3.

2

Changed in version 3.9: This approach now works for all exact results except for non-integer powers.

The Python Library Reference, Release 3.13.2



>>> setcontext(Context(prec=MAX_PREC, Emax=MAX_EMAX, Emin=MIN_EMIN)) >>> x = Decimal(2) ** 256

>>> x / 128

Decimal(

, →'904625697166532776746648320380374280103671755200316906558262375061821325312')



For inexact results, MAX_PREC is far too large on 64-bit platforms and the available memory will be insufficient:

>>> Decimal(1) / 3

Traceback (most recent call last):

File "", line 1, in

MemoryError



On systems with overallocation (e.g. Linux), a more sophisticated approach is to adjust prec to the amount of available RAM. Suppose that you have 8GB of RAM and expect 10 simultaneous operands using a maximum of 500MB each:

>>> import sys

>>>

>>> # Maximum number of digits for a single operand using 500MB in 8-byte words >>> # with 19 digits per word (4-byte and 9 digits for the 32-bit build): >>> maxdigits = 19 * ((500 * 1024**2) // 8)

>>>

>>> # Check that this works:

>>> c = Context(prec=maxdigits, Emax=MAX_EMAX, Emin=MIN_EMIN) >>> c.traps[Inexact] = True

>>> setcontext(c)

>>>

>>> # Fill the available precision with nines:

>>> x = Decimal(0).logical_invert() * 9

>>> sys.getsizeof(x)

524288112

>>> x + 2

Traceback (most recent call last):

File "", line 1, in

decimal.Inexact: []



In general (and especially on systems without overallocation), it is recommended to estimate even tighter bounds and

set the Inexact trap if all calculations are expected to be exact.



9.5 fractions — Rational numbers

Source code: Lib/fractions.py



The fractions module provides support for rational number arithmetic.

A Fraction instance can be constructed from a pair of integers, from another rational number, or from a string.

class fractions.Fraction(numerator=0, denominator=1)

class fractions.Fraction(other_fraction)

class fractions.Fraction(float)

class fractions.Fraction(decimal)

class fractions.Fraction(string)

The first version requires that numerator and denominator are instances of numbers.Rational and re-

turns a new Fraction instance with value numerator/denominator. If denominator is 0, it raises The Python Library Reference, Release 3.13.2



a ZeroDivisionError. The second version requires that other_fraction is an instance of numbers.

Rational and returns a Fraction instance with the same value. The next two versions accept either a

float or a decimal.Decimal instance, and return a Fraction instance with exactly the same value. Note

that due to the usual issues with binary floating point (see tut-fp-issues), the argument to Fraction(1.1)

is not exactly equal to 11/10, and so Fraction(1.1) does not return Fraction(11, 10) as one might

expect. (But see the documentation for the limit_denominator() method below.) The last version of the

constructor expects a string or unicode instance. The usual form for this instance is:

[sign] numerator ['/' denominator]



where the optional sign may be either ‘+’ or ‘-’ and numerator and denominator (if present) are strings

of decimal digits (underscores may be used to delimit digits as with integral literals in code). In addition, any

string that represents a finite value and is accepted by the float constructor is also accepted by the Fraction

constructor. In either form the input string may also have leading and/or trailing whitespace. Here are some

examples:

>>> from fractions import Fraction

>>> Fraction(16,-10)

Fraction(-8, 5)

>>> Fraction(123)

Fraction(123, 1)

>>> Fraction()

Fraction(0, 1)

>>> Fraction('3/7')

Fraction(3, 7)

>>> Fraction(' -3/7 ')

Fraction(-3, 7)

>>> Fraction('1.414213 \t\n')

Fraction(1414213, 1000000)

>>> Fraction('-.125')

Fraction(-1, 8)

>>> Fraction('7e-6')

Fraction(7, 1000000)

>>> Fraction(2.25)

Fraction(9, 4)

>>> Fraction(1.1)

Fraction(2476979795053773, 2251799813685248)

>>> from decimal import Decimal

>>> Fraction(Decimal('1.1'))

Fraction(11, 10)



The Fraction class inherits from the abstract base class numbers.Rational, and implements all of the

methods and operations from that class. Fraction instances are hashable, and should be treated as immutable.

In addition, Fraction has the following properties and methods:

Changed in version 3.2: The Fraction constructor now accepts float and decimal.Decimal instances.

Changed in version 3.9: The math.gcd() function is now used to normalize the numerator and denominator.

math.gcd() always returns an int type. Previously, the GCD type depended on numerator and denominator.

Changed in version 3.11: Underscores are now permitted when creating a Fraction instance from a string,

following PEP 515 rules.

Changed in version 3.11: Fraction implements __int__ now to satisfy typing.SupportsInt instance

checks.

Changed in version 3.12: Space is allowed around the slash for string inputs: Fraction('2 / 3').

Changed in version 3.12: Fraction instances now support float-style formatting, with presentation types "e",

"E" , "f", "F", "g", "G" and "%"".

The Python Library Reference, Release 3.13.2



Changed in version 3.13: Formatting of Fraction instances without a presentation type now supports fill,

alignment, sign handling, minimum width and grouping.

numerator

Numerator of the Fraction in lowest term.

denominator

Denominator of the Fraction in lowest term.

as_integer_ratio()

Return a tuple of two integers, whose ratio is equal to the original Fraction. The ratio is in lowest terms and has a positive denominator.

Added in version 3.8.

is_integer()

Return True if the Fraction is an integer.

Added in version 3.12.

classmethod from_float(flt)

Alternative constructor which only accepts instances of float or numbers.Integral. Beware that Fraction.from_float(0.3) is not the same value as Fraction(3, 10).



® Note

From Python 3.2 onwards, you can also construct a Fraction instance directly from a float.



classmethod from_decimal(dec)

Alternative constructor which only accepts instances of decimal.Decimal or numbers.Integral.



® Note

From Python 3.2 onwards, you can also construct a Fraction instance directly from a decimal.

Decimal instance.



limit_denominator(max_denominator=1000000)

Finds and returns the closest Fraction to self that has denominator at most max_denominator. This method is useful for finding rational approximations to a given floating-point number:

>>> from fractions import Fraction

>>> Fraction('3.1415926535897932').limit_denominator(1000) Fraction(355, 113)



or for recovering a rational number that’s represented as a float:

>>> from math import pi, cos

>>> Fraction(cos(pi/3))

Fraction(4503599627370497, 9007199254740992)

>>> Fraction(cos(pi/3)).limit_denominator()

Fraction(1, 2)

>>> Fraction(1.1).limit_denominator()

Fraction(11, 10)



__floor__()

Returns the greatest int <= self. This method can also be accessed through the math.floor() function:

The Python Library Reference, Release 3.13.2



>>> from math import floor

>>> floor(Fraction(355, 113))

3



__ceil__()

Returns the least int >= self. This method can also be accessed through the math.ceil() function.

__round__()

__round__(ndigits)

The first version returns the nearest int to self, rounding half to even. The second version rounds self to the nearest multiple of Fraction(1, 10**ndigits) (logically, if ndigits is negative),

again rounding half toward even. This method can also be accessed through the round() function.

__format__(format_spec, / )

Provides support for formatting of Fraction instances via the str.format() method, the format() built-in function, or Formatted string literals.

If the format_spec format specification string does not end with one of the presentation types 'e', 'E', 'f', 'F', 'g', 'G' or '%' then formatting follows the general rules for fill, alignment, sign handling,

minimum width, and grouping as described in the format specification mini-language. The “alternate form” flag '#' is supported: if present, it forces the output string to always include an explicit denomi-nator, even when the value being formatted is an exact integer. The zero-fill flag '0' is not supported.

If the format_spec format specification string ends with one of the presentation types 'e', 'E', 'f',

'F', 'g', 'G' or '%' then formatting follows the rules outlined for the float type in the Format

Specification Mini-Language section.

Here are some examples:

>>> from fractions import Fraction

>>> format(Fraction(103993, 33102), '_')

'103_993/33_102'

>>> format(Fraction(1, 7), '.^+10')

'...+1/7...'

>>> format(Fraction(3, 1), '')

'3'

>>> format(Fraction(3, 1), '#')

'3/1'

>>> format(Fraction(1, 7), '.40g')

'0.1428571428571428571428571428571428571429'

>>> format(Fraction('1234567.855'), '_.2f')

'1_234_567.86'

>>> f"{Fraction(355, 113):*>20.6e}"

'********3.141593e+00'

>>> old_price, new_price = 499, 672

>>> "{:.2%} price increase".format(Fraction(new_price, old_price)-1) '34.67% price increase'



µ See also

Module numbers

The abstract base classes making up the numeric tower.



The Python Library Reference, Release 3.13.2



9.6 random — Generate pseudo-random numbers

Source code: Lib/random.py



This module implements pseudo-random number generators for various distributions.

For integers, there is uniform selection from a range. For sequences, there is uniform selection of a random element, a function to generate a random permutation of a list in-place, and a function for random sampling without replacement.

On the real line, there are functions to compute uniform, normal (Gaussian), lognormal, negative exponential, gamma, and beta distributions. For generating distributions of angles, the von Mises distribution is available.

Almost all module functions depend on the basic function random(), which generates a random float uniformly in the half-open range 0.0 <= X < 1.0. Python uses the Mersenne Twister as the core generator. It produces 53-bit precision floats and has a period of 2**19937-1. The underlying implementation in C is both fast and threadsafe. The Mersenne Twister is one of the most extensively tested random number generators in existence. However, being completely deterministic, it is not suitable for all purposes, and is completely unsuitable for cryptographic purposes.

The functions supplied by this module are actually bound methods of a hidden instance of the random.Random

class. You can instantiate your own instances of Random to get generators that don’t share state.

Class Random can also be subclassed if you want to use a different basic generator of your own devising: see the documentation on that class for more details.

The random module also provides the SystemRandom class which uses the system function os.urandom() to generate random numbers from sources provided by the operating system.



Á Warning

The pseudo-random generators of this module should not be used for security purposes. For security or crypto-

graphic uses, see the secrets module.



µ See also

M. Matsumoto and T. Nishimura, “Mersenne Twister: A 623-dimensionally equidistributed uniform pseudo-

random number generator”, ACM Transactions on Modeling and Computer Simulation Vol. 8, No. 1, January

pp.3–30 1998.

Complementary-Multiply-with-Carry recipe for a compatible alternative random number generator with a long

period and comparatively simple update operations.



® Note

The global random number generator and instances of Random are thread-safe. However, in the free-threaded

build, concurrent calls to the global generator or to the same instance of Random may encounter contention and

poor performance. Consider using separate instances of Random per thread instead.



9.6.1 Bookkeeping functions

random.seed(a=None, version=2)

Initialize the random number generator.

If a is omitted or None, the current system time is used. If randomness sources are provided by the operating

system, they are used instead of the system time (see the os.urandom() function for details on availability).

If a is an int, it is used directly.

The Python Library Reference, Release 3.13.2



With version 2 (the default), a str, bytes, or bytearray object gets converted to an int and all of its bits

are used.

With version 1 (provided for reproducing random sequences from older versions of Python), the algorithm for

str and bytes generates a narrower range of seeds.

Changed in version 3.2: Moved to the version 2 scheme which uses all of the bits in a string seed.

Changed in version 3.11: The seed must be one of the following types: None, int, float, str, bytes, or

bytearray.

random.getstate()

Return an object capturing the current internal state of the generator. This object can be passed to setstate()

to restore the state.

random.setstate(state)

state should have been obtained from a previous call to getstate(), and setstate() restores the internal

state of the generator to what it was at the time getstate() was called.



9.6.2 Functions for bytes

random.randbytes(n)

Generate n random bytes.

This method should not be used for generating security tokens. Use secrets.token_bytes() instead.

Added in version 3.9.



9.6.3 Functions for integers

random.randrange(stop)

random.randrange(start, stop[, step ])

Return a randomly selected element from range(start, stop, step).

This is roughly equivalent to choice(range(start, stop, step)) but supports arbitrarily large ranges

and is optimized for common cases.

The positional argument pattern matches the range() function.

Keyword arguments should not be used because they can be interpreted in unexpected ways. For example

randrange(start=100) is interpreted as randrange(0, 100, 1).

Changed in version 3.2: randrange() is more sophisticated about producing equally distributed values.

Formerly it used a style like int(random()*n) which could produce slightly uneven distributions.

Changed in version 3.12: Automatic conversion of non-integer types is no longer supported. Calls such as

randrange(10.0) and randrange(Fraction(10, 1)) now raise a TypeError.

random.randint(a, b)

Return a random integer N such that a <= N <= b. Alias for randrange(a, b+1).

random.getrandbits(k)

Returns a non-negative Python integer with k random bits. This method is supplied with the Mersenne Twister

generator and some other generators may also provide it as an optional part of the API. When available,

getrandbits() enables randrange() to handle arbitrarily large ranges.

Changed in version 3.9: This method now accepts zero for k.



9.6.4 Functions for sequences

random.choice(seq)

Return a random element from the non-empty sequence seq. If seq is empty, raises IndexError.

The Python Library Reference, Release 3.13.2



random.choices(population, weights=None, *, cum_weights=None, k=1)

Return a k sized list of elements chosen from the population with replacement. If the population is empty,

raises IndexError.

If a weights sequence is specified, selections are made according to the relative weights. Alternatively, if a

cum_weights sequence is given, the selections are made according to the cumulative weights (perhaps computed

using itertools.accumulate()). For example, the relative weights [10, 5, 30, 5] are equivalent to

the cumulative weights [10, 15, 45, 50]. Internally, the relative weights are converted to cumulative

weights before making selections, so supplying the cumulative weights saves work.

If neither weights nor cum_weights are specified, selections are made with equal probability. If a weights

sequence is supplied, it must be the same length as the population sequence. It is a TypeError to specify both

weights and cum_weights.

The weights or cum_weights can use any numeric type that interoperates with the float values returned by

random() (that includes integers, floats, and fractions but excludes decimals). Weights are assumed to be

non-negative and finite. A ValueError is raised if all weights are zero.

For a given seed, the choices() function with equal weighting typically produces a different sequence than

repeated calls to choice(). The algorithm used by choices() uses floating-point arithmetic for internal

consistency and speed. The algorithm used by choice() defaults to integer arithmetic with repeated selections

to avoid small biases from round-off error.

Added in version 3.6.

Changed in version 3.9: Raises a ValueError if all weights are zero.

random.shuffle(x)

Shuffle the sequence x in place.

To shuffle an immutable sequence and return a new shuffled list, use sample(x, k=len(x)) instead.

Note that even for small len(x), the total number of permutations of x can quickly grow larger than the

period of most random number generators. This implies that most permutations of a long sequence can never

be generated. For example, a sequence of length 2080 is the largest that can fit within the period of the

Mersenne Twister random number generator.

Changed in version 3.11: Removed the optional parameter random.

random.sample(population, k, *, counts=None)

Return a k length list of unique elements chosen from the population sequence. Used for random sampling

without replacement.

Returns a new list containing elements from the population while leaving the original population unchanged.

The resulting list is in selection order so that all sub-slices will also be valid random samples. This allows raffle

winners (the sample) to be partitioned into grand prize and second place winners (the subslices).

Members of the population need not be hashable or unique. If the population contains repeats, then each

occurrence is a possible selection in the sample.

Repeated elements can be specified one at a time or with the optional keyword-only counts parameter.

For example, sample(['red', 'blue'], counts=[4, 2], k=5) is equivalent to sample(['red',

'red', 'red', 'red', 'blue', 'blue'], k=5).

To choose a sample from a range of integers, use a range() object as an argument. This is especially fast and

space efficient for sampling from a large population: sample(range(10000000), k=60).

If the sample size is larger than the population size, a ValueError is raised.

Changed in version 3.9: Added the counts parameter.

Changed in version 3.11: The population must be a sequence. Automatic conversion of sets to lists is no longer

supported.



The Python Library Reference, Release 3.13.2



9.6.5 Discrete distributions

The following function generates a discrete distribution.

random.binomialvariate(n=1, p=0.5)

Binomial distribution. Return the number of successes for n independent trials with the probability of success

in each trial being p:

Mathematically equivalent to:

sum(random() < p for i in range(n))



The number of trials n should be a non-negative integer. The probability of success p should be between 0.0

<= p <= 1.0. The result is an integer in the range 0 <= X <= n.

Added in version 3.12.



9.6.6 Real-valued distributions

The following functions generate specific real-valued distributions. Function parameters are named after the corre-sponding variables in the distribution’s equation, as used in common mathematical practice; most of these equations can be found in any statistics text.

random.random()

Return the next random floating-point number in the range 0.0 <= X < 1.0

random.uniform(a, b)

Return a random floating-point number N such that a <= N <= b for a <= b and b <= N <= a for b <

a.

The end-point value b may or may not be included in the range depending on floating-point rounding in the

expression a + (b-a) * random().

random.triangular(low, high, mode)

Return a random floating-point number N such that low <= N <= high and with the specified mode between

those bounds. The low and high bounds default to zero and one. The mode argument defaults to the midpoint

between the bounds, giving a symmetric distribution.

random.betavariate(alpha, beta)

Beta distribution. Conditions on the parameters are alpha > 0 and beta > 0. Returned values range

between 0 and 1.

random.expovariate(lambd=1.0)

Exponential distribution. lambd is 1.0 divided by the desired mean. It should be nonzero. (The parameter

would be called “lambda”, but that is a reserved word in Python.) Returned values range from 0 to positive

infinity if lambd is positive, and from negative infinity to 0 if lambd is negative.

Changed in version 3.12: Added the default value for lambd.

random.gammavariate(alpha, beta)

Gamma distribution. (Not the gamma function!) The shape and scale parameters, alpha and beta, must have

positive values. (Calling conventions vary and some sources define ‘beta’ as the inverse of the scale).

The probability distribution function is:

x ** (alpha-1) * math.exp(-x / beta)

pdf(x) =--------------------------------------

math.gamma(alpha) * beta ** alpha



random.gauss(mu=0.0, sigma=1.0)

Normal distribution, also called the Gaussian distribution. mu is the mean, and sigma is the standard deviation.

This is slightly faster than the normalvariate() function defined below.

The Python Library Reference, Release 3.13.2



Multithreading note: When two threads call this function simultaneously, it is possible that they will receive

the same return value. This can be avoided in three ways. 1) Have each thread use a different instance of the

random number generator. 2) Put locks around all calls. 3) Use the slower, but thread-safe normalvariate()

function instead.

Changed in version 3.11: mu and sigma now have default arguments.

random.lognormvariate( mu, sigma)

Log normal distribution. If you take the natural logarithm of this distribution, you’ll get a normal distribution

with mean mu and standard deviation sigma. mu can have any value, and sigma must be greater than zero.

random.normalvariate(mu=0.0, sigma=1.0)

Normal distribution. mu is the mean, and sigma is the standard deviation.

Changed in version 3.11: mu and sigma now have default arguments.

random.vonmisesvariate(mu, kappa)

mu is the mean angle, expressed in radians between 0 and 2*pi, and kappa is the concentration parameter,

which must be greater than or equal to zero. If kappa is equal to zero, this distribution reduces to a uniform

random angle over the range 0 to 2*pi.

random.paretovariate(alpha)

Pareto distribution. alpha is the shape parameter.

random.weibullvariate( alpha, beta)

Weibull distribution. alpha is the scale parameter and beta is the shape parameter.



9.6.7 Alternative Generator

class random.Random( seed [ ])

Class that implements the default pseudo-random number generator used by the random module.

Changed in version 3.11: Formerly the seed could be any hashable object. Now it is limited to: None, int,

float , str, bytes, or bytearray.

Subclasses of Random should override the following methods if they wish to make use of a different basic

generator:

seed(a=None, version=2)

Override this method in subclasses to customise the seed() behaviour of Random instances.

getstate()

Override this method in subclasses to customise the getstate() behaviour of Random instances.

setstate(state)

Override this method in subclasses to customise the setstate() behaviour of Random instances.

random()

Override this method in subclasses to customise the random() behaviour of Random instances.

Optionally, a custom generator subclass can also supply the following method:

getrandbits(k)

Override this method in subclasses to customise the getrandbits() behaviour of Random instances.

class random.SystemRandom( seed [ ])

Class that uses the os.urandom() function for generating random numbers from sources provided by the

operating system. Not available on all systems. Does not rely on software state, and sequences are not repro-

ducible. Accordingly, the seed() method has no effect and is ignored. The getstate() and setstate()

methods raise NotImplementedError if called.



The Python Library Reference, Release 3.13.2



9.6.8 Notes on Reproducibility

Sometimes it is useful to be able to reproduce the sequences given by a pseudo-random number generator. By reusing a seed value, the same sequence should be reproducible from run to run as long as multiple threads are not running.

Most of the random module’s algorithms and seeding functions are subject to change across Python versions, but two aspects are guaranteed not to change:

• If a new seeding method is added, then a backward compatible seeder will be offered.

• The generator’s random() method will continue to produce the same sequence when the compatible seeder

is given the same seed.



9.6.9 Examples

Basic examples:

>>> random() # Random float: 0.0 <= x < 1.0

0.37444887175646646

>>> uniform(2.5, 10.0) # Random float: 2.5 <= x <= 10.0 3.1800146073117523

>>> expovariate(1 / 5) # Interval between arrivals averaging 5␣

, →seconds

5.148957571865031

>>> randrange(10) # Integer from 0 to 9 inclusive

7

>>> randrange(0, 101, 2) # Even integer from 0 to 100 inclusive 26

>>> choice(['win', 'lose', 'draw']) # Single random element from a sequence 'draw'

>>> deck = 'ace two three four'.split()

>>> shuffle(deck) # Shuffle a list

>>> deck

['four', 'two', 'ace', 'three']

>>> sample([10, 20, 30, 40, 50], k=4) # Four samples without replacement [40, 10, 50, 30]



Simulations:

>>> # Six roulette wheel spins (weighted sampling with replacement) >>> choices(['red', 'black', 'green'], [18, 18, 2], k=6) ['red', 'green', 'black', 'black', 'red', 'black']

>>> # Deal 20 cards without replacement from a deck >>> # of 52 playing cards, and determine the proportion of cards >>> # with a ten-value: ten, jack, queen, or king.

>>> deal = sample(['tens', 'low cards'], counts=[16, 36], k=20) >>> deal.count('tens') / 20

0.15

>>> # Estimate the probability of getting 5 or more heads from 7 spins >>> # of a biased coin that settles on heads 60% of the time. >>> sum(binomialvariate(n=7, p=0.6) >= 5 for i in range(10_000)) / 10_000

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

0.4169

>>> # Probability of the median of 5 samples being in middle two quartiles >>> def trial():

... return 2_500 <= sorted(choices(range(10_000), k=5))[2] < 7_500 ...

>>> sum(trial() for i in range(10_000)) / 10_000

0.7958



Example of statistical bootstrapping using resampling with replacement to estimate a confidence interval for the mean of a sample:

# https://www.thoughtco.com/example-of-bootstrapping-3126155 from statistics import fmean as mean

from random import choices

data = [41, 50, 29, 37, 81, 30, 73, 63, 20, 35, 68, 22, 60, 31, 95] means = sorted(mean(choices(data, k=len(data))) for i in range(100)) print(f'The sample mean of {mean(data):.1f} has a 90% confidence '

f'interval from {means[5]:.1f} to {means[94]:.1f}')



Example of a resampling permutation test to determine the statistical significance or p-value of an observed difference between the effects of a drug versus a placebo:

# Example from "Statistics is Easy" by Dennis Shasha and Manda Wilson from statistics import fmean as mean

from random import shuffle

drug = [54, 73, 53, 70, 73, 68, 52, 65, 65]

placebo = [54, 51, 58, 44, 55, 52, 42, 47, 58, 46]

observed_diff = mean(drug)-mean(placebo)

n = 10_000

count = 0

combined = drug + placebo

for i in range(n):

shuffle(combined)

new_diff = mean(combined[:len(drug)])-mean(combined[len(drug):])

count += (new_diff >= observed_diff)

print(f'{n} label reshufflings produced only {count} instances with a difference') print(f'at least as extreme as the observed difference of {observed_diff:.1f}.') print(f'The one-sided p-value of {count / n:.4f} leads us to reject the null') print(f'hypothesis that there is no difference between the drug and the placebo.')



Simulation of arrival times and service deliveries for a multiserver queue:

from heapq import heapify, heapreplace

from random import expovariate, gauss

from statistics import mean, quantiles

average_arrival_interval = 5.6

average_service_time = 15.0

stdev_service_time = 3.5

num_servers = 3

waits = []

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

arrival_time = 0.0

servers = [0.0] * num_servers # time when each server becomes available heapify(servers)

for i in range(1_000_000):

arrival_time += expovariate(1.0 / average_arrival_interval)

next_server_available = servers[0]

wait = max(0.0, next_server_available-arrival_time)

waits.append(wait)

service_duration = max(0.0, gauss(average_service_time, stdev_service_time))

service_completed = arrival_time + wait + service_duration

heapreplace(servers, service_completed)

print(f'Mean wait: {mean(waits):.1f} Max wait: {max(waits):.1f}') print('Quartiles:', [round(q, 1) for q in quantiles(waits)])



µ See also

Statistics for Hackers a video tutorial by Jake Vanderplas on statistical analysis using just a few fundamental

concepts including simulation, sampling, shuffling, and cross-validation.

Economics Simulation a simulation of a marketplace by Peter Norvig that shows effective use of many of the tools

and distributions provided by this module (gauss, uniform, sample, betavariate, choice, triangular, and randrange).

A Concrete Introduction to Probability (using Python) a tutorial by Peter Norvig covering the basics of probability

theory, how to write simulations, and how to perform data analysis using Python.



9.6.10 Recipes

These recipes show how to efficiently make random selections from the combinatoric iterators in the itertools module:

def random_product(*args, repeat=1):

"Random selection from itertools.product(*args, **kwds)"

pools = [tuple(pool) for pool in args] * repeat

return tuple(map(random.choice, pools))

def random_permutation(iterable, r=None):

"Random selection from itertools.permutations(iterable, r)"

pool = tuple(iterable)

r = len(pool) if r is None else r

return tuple(random.sample(pool, r))

def random_combination(iterable, r):

"Random selection from itertools.combinations(iterable, r)"

pool = tuple(iterable)

n = len(pool)

indices = sorted(random.sample(range(n), r))

return tuple(pool[i] for i in indices)

def random_combination_with_replacement(iterable, r):

"Choose r elements with replacement. Order the result to match the iterable."

# Result will be in set(itertools.combinations_with_replacement(iterable, r)).

pool = tuple(iterable)

n = len(pool)

indices = sorted(random.choices(range(n), k=r))

return tuple(pool[i] for i in indices)

The Python Library Reference, Release 3.13.2



The default random() returns multiples of 2⁻⁵³ in the range 0.0 ≤ x < 1.0. All such numbers are evenly spaced and are exactly representable as Python floats. However, many other representable floats in that interval are not possible selections. For example, 0.05954861408025609 isn’t an integer multiple of 2⁻⁵³.

The following recipe takes a different approach. All floats in the interval are possible selections. The mantissa comes from a uniform distribution of integers in the range 2⁵² ≤ mantissa < 2⁵³. The exponent comes from a geometric distribution where exponents smaller than-53 occur half as often as the next larger exponent.

from random import Random

from math import ldexp

class FullRandom(Random):

def random(self):

mantissa = 0x10_0000_0000_0000 | self.getrandbits(52)

exponent = -53

x = 0

while not x:

x = self.getrandbits(32)

exponent += x.bit_length()-32

return ldexp(mantissa, exponent)



All real valued distributions in the class will use the new method:

>>> fr = FullRandom()

>>> fr.random()

0.05954861408025609

>>> fr.expovariate(0.25)

8.87925541791544



The recipe is conceptually equivalent to an algorithm that chooses from all the multiples of 2⁻¹⁰⁷⁴ in the range 0.0 ≤ x < 1.0. All such numbers are evenly spaced, but most have to be rounded down to the nearest representable Python float. (The value 2⁻¹⁰⁷⁴ is the smallest positive unnormalized float and is equal to math.ulp(0.0).)



µ See also

Generating Pseudo-random Floating-Point Values a paper by Allen B. Downey describing ways to generate more

fine-grained floats than normally generated by random().



9.6.11 Command-line usage

Added in version 3.13.

The random module can be executed from the command line.

python -m random [-h] [-c CHOICE [CHOICE ...] | -i N | -f N] [input ...]



The following options are accepted:

-h,--help

Show the help message and exit.

-c CHOICE [CHOICE ...]

--choice CHOICE [CHOICE ...]

Print a random choice, using choice().

-i

--integer

Print a random integer between 1 and N inclusive, using randint().

The Python Library Reference, Release 3.13.2



-f

--float

Print a random floating-point number between 0 and N inclusive, using uniform().

If no options are given, the output depends on the input:

• String or multiple: same as--choice.

• Integer: same as--integer.

• Float: same as--float.



9.6.12 Command-line example

Here are some examples of the random command-line interface:

$ # Choose one at random

$ python -m random egg bacon sausage spam "Lobster Thermidor aux crevettes with a␣

, →Mornay sauce"

Lobster Thermidor aux crevettes with a Mornay sauce

$ # Random integer

$ python -m random 6

6

$ # Random floating-point number

$ python -m random 1.8

1.7080016272295635

$ # With explicit arguments

$ python -m random --choice egg bacon sausage spam "Lobster Thermidor aux␣

, →crevettes with a Mornay sauce"

egg

$ python -m random --integer 6

3

$ python -m random --float 1.8

1.5666339105010318

$ python -m random --integer 6

5

$ python -m random --float 6

3.1942323316565915



9.7 statistics — Mathematical statistics functions

Added in version 3.4.

Source code: Lib/statistics.py



This module provides functions for calculating mathematical statistics of numeric (Real-valued) data.

The module is not intended to be a competitor to third-party libraries such as NumPy, SciPy, or proprietary full-featured statistics packages aimed at professional statisticians such as Minitab, SAS and Matlab. It is aimed at the level of graphing and scientific calculators.

The Python Library Reference, Release 3.13.2



Unless explicitly noted, these functions support int, float, Decimal and Fraction. Behaviour with other types (whether in the numeric tower or not) is currently unsupported. Collections with a mix of types are also undefined

and implementation-dependent. If your input data consists of mixed types, you may be able to use map() to ensure a consistent result, for example: map(float, input_data).

Some datasets use NaN (not a number) values to represent missing data. Since NaNs have unusual comparison semantics, they cause surprising or undefined behaviors in the statistics functions that sort data or that count occur-rences. The functions affected are median(), median_low(), median_high(), median_grouped(), mode(), multimode(), and quantiles(). The NaN values should be stripped before calling these functions:

>>> from statistics import median

>>> from math import isnan

>>> from itertools import filterfalse

>>> data = [20.7, float('NaN'),19.2, 18.3, float('NaN'), 14.4] >>> sorted(data) # This has surprising behavior

[20.7, nan, 14.4, 18.3, 19.2, nan]

>>> median(data) # This result is unexpected

16.35

>>> sum(map(isnan, data)) # Number of missing values 2

>>> clean = list(filterfalse(isnan, data)) # Strip NaN values >>> clean

[20.7, 19.2, 18.3, 14.4]

>>> sorted(clean) # Sorting now works as expected

[14.4, 18.3, 19.2, 20.7]

>>> median(clean) # This result is now well defined

18.75



9.7.1 Averages and measures of central location

These functions calculate an average or typical value from a population or sample.



mean() Arithmetic mean (“average”) of data.

fmean() Fast, floating-point arithmetic mean, with optional weighting.

geometric_mean() Geometric mean of data.

harmonic_mean() Harmonic mean of data.

kde() Estimate the probability density distribution of the data.

kde_random() Random sampling from the PDF generated by kde().

median() Median (middle value) of data.

median_low() Low median of data.

median_high() High median of data.

median_grouped() Median (50th percentile) of grouped data.

mode() Single mode (most common value) of discrete or nominal data.

multimode() List of modes (most common values) of discrete or nominal data.

quantiles() Divide data into intervals with equal probability.



9.7.2 Measures of spread

These functions calculate a measure of how much the population or sample tends to deviate from the typical or average values.



pstdev() Population standard deviation of data.

pvariance() Population variance of data.

stdev() Sample standard deviation of data.

variance() Sample variance of data.

The Python Library Reference, Release 3.13.2



9.7.3 Statistics for relations between two inputs

These functions calculate statistics regarding relations between two inputs.



covariance() Sample covariance for two variables.

correlation() Pearson and Spearman’s correlation coefficients.

linear_regression() Slope and intercept for simple linear regression.



9.7.4 Function details

Note: The functions do not require the data given to them to be sorted. However, for reading convenience, most of the examples show sorted sequences.

statistics.mean(data)

Return the sample arithmetic mean of data which can be a sequence or iterable.

The arithmetic mean is the sum of the data divided by the number of data points. It is commonly called “the

average”, although it is only one of many different mathematical averages. It is a measure of the central location

of the data.

If data is empty, StatisticsError will be raised.

Some examples of use:

>>> mean([1, 2, 3, 4, 4])

2.8

>>> mean([-1.0, 2.5, 3.25, 5.75])

2.625

>>> from fractions import Fraction as F

>>> mean([F(3, 7), F(1, 21), F(5, 3), F(1, 3)])

Fraction(13, 21)

>>> from decimal import Decimal as D

>>> mean([D("0.5"), D("0.75"), D("0.625"), D("0.375")])

Decimal('0.5625')



® Note

The mean is strongly affected by outliers and is not necessarily a typical example of the data points. For a

more robust, although less efficient, measure of central tendency, see median().

The sample mean gives an unbiased estimate of the true population mean, so that when taken on average over all the possible samples, mean(sample) converges on the true mean of the entire population. If data represents the entire population rather than a sample, then mean(data) is equivalent to calculating the true population mean μ.



statistics.fmean(data, weights=None)

Convert data to floats and compute the arithmetic mean.

This runs faster than the mean() function and it always returns a float. The data may be a sequence or

iterable. If the input dataset is empty, raises a StatisticsError.

>>> fmean([3.5, 4.0, 5.25])

4.25



Optional weighting is supported. For example, a professor assigns a grade for a course by weighting quizzes at

20%, homework at 20%, a midterm exam at 30%, and a final exam at 30%:

The Python Library Reference, Release 3.13.2



>>> grades = [85, 92, 83, 91]

>>> weights = [0.20, 0.20, 0.30, 0.30]

>>> fmean(grades, weights)

87.6



If weights is supplied, it must be the same length as the data or a ValueError will be raised.

Added in version 3.8.

Changed in version 3.11: Added support for weights.

statistics.geometric_mean(data)

Convert data to floats and compute the geometric mean.

The geometric mean indicates the central tendency or typical value of the data using the product of the values

(as opposed to the arithmetic mean which uses their sum).

Raises a StatisticsError if the input dataset is empty, if it contains a zero, or if it contains a negative

value. The data may be a sequence or iterable.

No special efforts are made to achieve exact results. (However, this may change in the future.)

>>> round(geometric_mean([54, 24, 36]), 1)

36.0



Added in version 3.8.

statistics.harmonic_mean(data, weights=None)

Return the harmonic mean of data, a sequence or iterable of real-valued numbers. If weights is omitted or

None , then equal weighting is assumed.

The harmonic mean is the reciprocal of the arithmetic mean() of the reciprocals of the data. For example,

the harmonic mean of three values a, b and c will be equivalent to 3/(1/a + 1/b + 1/c). If one of the

values is zero, the result will be zero.

The harmonic mean is a type of average, a measure of the central location of the data. It is often appropriate

when averaging ratios or rates, for example speeds.

Suppose a car travels 10 km at 40 km/hr, then another 10 km at 60 km/hr. What is the average speed?

>>> harmonic_mean([40, 60])

48.0



Suppose a car travels 40 km/hr for 5 km, and when traffic clears, speeds-up to 60 km/hr for the remaining 30

km of the journey. What is the average speed?

>>> harmonic_mean([40, 60], weights=[5, 30])

56.0



StatisticsError is raised if data is empty, any element is less than zero, or if the weighted sum isn’t

positive.

The current algorithm has an early-out when it encounters a zero in the input. This means that the subsequent

inputs are not tested for validity. (This behavior may change in the future.)

Added in version 3.6.

Changed in version 3.10: Added support for weights.

statistics.kde(data, h, kernel=’normal’, *, cumulative=False)

Kernel Density Estimation (KDE): Create a continuous probability density function or cumulative distribution

function from discrete samples.

The basic idea is to smooth the data using a kernel function. to help draw inferences about a population from

a sample.

The Python Library Reference, Release 3.13.2



The degree of smoothing is controlled by the scaling parameter h which is called the bandwidth. Smaller values

emphasize local features while larger values give smoother results.

The kernel determines the relative weights of the sample data points. Generally, the choice of kernel shape

does not matter as much as the more influential bandwidth smoothing parameter.

Kernels that give some weight to every sample point include normal (gauss), logistic, and sigmoid.

Kernels that only give weight to sample points within the bandwidth include rectangular (uniform), triangular,

parabolic (epanechnikov), quartic (biweight), triweight, and cosine.

If cumulative is true, will return a cumulative distribution function.

A StatisticsError will be raised if the data sequence is empty.

Wikipedia has an example where we can use kde() to generate and plot a probability density function esti-

mated from a small sample:

>>> sample = [-2.1,-1.3,-0.4, 1.9, 5.1, 6.2]

>>> f_hat = kde(sample, h=1.5)

>>> xarr = [i/100 for i in range(-750, 1100)]

>>> yarr = [f_hat(x) for x in xarr]



The points in xarr and yarr can be used to make a PDF plot:





Added in version 3.13.

statistics.kde_random( data, h, kernel=’normal’, *, seed=None)

Return a function that makes a random selection from the estimated probability density function produced by

kde(data, h, kernel) .

Providing a seed allows reproducible selections. In the future, the values may change slightly as more accurate

kernel inverse CDF estimates are implemented. The seed may be an integer, float, str, or bytes.

A StatisticsError will be raised if the data sequence is empty.

Continuing the example for kde(), we can use kde_random() to generate new random selections from an

estimated probability density function:

The Python Library Reference, Release 3.13.2



>>> data = [-2.1,-1.3,-0.4, 1.9, 5.1, 6.2]

>>> rand = kde_random(data, h=1.5, seed=8675309)

>>> new_selections = [rand() for i in range(10)]

>>> [round(x, 1) for x in new_selections]

[0.7, 6.2, 1.2, 6.9, 7.0, 1.8, 2.5, -0.5, -1.8, 5.6]



Added in version 3.13.

statistics.median(data)

Return the median (middle value) of numeric data, using the common “mean of middle two” method. If data

is empty, StatisticsError is raised. data can be a sequence or iterable.

The median is a robust measure of central location and is less affected by the presence of outliers. When the

number of data points is odd, the middle data point is returned:

>>> median([1, 3, 5])

3



When the number of data points is even, the median is interpolated by taking the average of the two middle

values:

>>> median([1, 3, 5, 7])

4.0



This is suited for when your data is discrete, and you don’t mind that the median may not be an actual data

point.

If the data is ordinal (supports order operations) but not numeric (doesn’t support addition), consider using

median_low() or median_high() instead.

statistics.median_low( data)

Return the low median of numeric data. If data is empty, StatisticsError is raised. data can be a sequence

or iterable.

The low median is always a member of the data set. When the number of data points is odd, the middle value

is returned. When it is even, the smaller of the two middle values is returned.

>>> median_low([1, 3, 5])

3

>>> median_low([1, 3, 5, 7])

3



Use the low median when your data are discrete and you prefer the median to be an actual data point rather

than interpolated.

statistics.median_high(data)

Return the high median of data. If data is empty, StatisticsError is raised. data can be a sequence or

iterable.

The high median is always a member of the data set. When the number of data points is odd, the middle value

is returned. When it is even, the larger of the two middle values is returned.

>>> median_high([1, 3, 5])

3

>>> median_high([1, 3, 5, 7])

5



Use the high median when your data are discrete and you prefer the median to be an actual data point rather

than interpolated.

The Python Library Reference, Release 3.13.2



statistics.median_grouped(data, interval=1.0)

Estimates the median for numeric data that has been grouped or binned around the midpoints of consecutive,

fixed-width intervals.

The data can be any iterable of numeric data with each value being exactly the midpoint of a bin. At least one

value must be present.

The interval is the width of each bin.

For example, demographic information may have been summarized into consecutive ten-year age groups with

each group being represented by the 5-year midpoints of the intervals:

>>> from collections import Counter

>>> demographics = Counter({

... 25: 172, # 20 to 30 years old

... 35: 484, # 30 to 40 years old

... 45: 387, # 40 to 50 years old

... 55: 22, # 50 to 60 years old

... 65: 6, # 60 to 70 years old

... })

...



The 50th percentile (median) is the 536th person out of the 1071 member cohort. That person is in the 30 to

40 year old age group.

The regular median() function would assume that everyone in the tricenarian age group was exactly 35 years

old. A more tenable assumption is that the 484 members of that age group are evenly distributed between 30

and 40. For that, we use median_grouped():

>>> data = list(demographics.elements())

>>> median(data)

35

>>> round(median_grouped(data, interval=10), 1)

37.5



The caller is responsible for making sure the data points are separated by exact multiples of interval. This is

essential for getting a correct result. The function does not check this precondition.

Inputs may be any numeric type that can be coerced to a float during the interpolation step.

statistics.mode(data)

Return the single most common data point from discrete or nominal data. The mode (when it exists) is the

most typical value and serves as a measure of central location.

If there are multiple modes with the same frequency, returns the first one encountered in the data. If the

smallest or largest of those is desired instead, use min(multimode(data)) or max(multimode(data)).

If the input data is empty, StatisticsError is raised.

mode assumes discrete data and returns a single value. This is the standard treatment of the mode as commonly

taught in schools:

>>> mode([1, 1, 2, 3, 3, 3, 3, 4])

3



The mode is unique in that it is the only statistic in this package that also applies to nominal (non-numeric)

data:

>>> mode(["red", "blue", "blue", "red", "green", "red", "red"])

'red'



Only hashable inputs are supported. To handle type set, consider casting to frozenset. To handle type

list , consider casting to tuple. For mixed or nested inputs, consider using this slower quadratic algorithm

that only depends on equality tests: max(data, key=data.count).

The Python Library Reference, Release 3.13.2



Changed in version 3.8: Now handles multimodal datasets by returning the first mode encountered. Formerly,

it raised StatisticsError when more than one mode was found.

statistics.multimode(data)

Return a list of the most frequently occurring values in the order they were first encountered in the data. Will

return more than one result if there are multiple modes or an empty list if the data is empty:

>>> multimode('aabbbbccddddeeffffgg')

['b', 'd', 'f']

>>> multimode('')

[]



Added in version 3.8.

statistics.pstdev(data, mu=None)

Return the population standard deviation (the square root of the population variance). See pvariance() for

arguments and other details.

>>> pstdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])

0.986893273527251



statistics.pvariance(data, mu=None)

Return the population variance of data, a non-empty sequence or iterable of real-valued numbers. Variance, or

second moment about the mean, is a measure of the variability (spread or dispersion) of data. A large variance

indicates that the data is spread out; a small variance indicates it is clustered closely around the mean.

If the optional second argument mu is given, it should be the population mean of the data. It can also be used

to compute the second moment around a point that is not the mean. If it is missing or None (the default), the

arithmetic mean is automatically calculated.

Use this function to calculate the variance from the entire population. To estimate the variance from a sample,

the variance() function is usually a better choice.

Raises StatisticsError if data is empty.

Examples:

>>> data = [0.0, 0.25, 0.25, 1.25, 1.5, 1.75, 2.75, 3.25]

>>> pvariance(data)

1.25



If you have already calculated the mean of your data, you can pass it as the optional second argument mu to

avoid recalculation:

>>> mu = mean(data)

>>> pvariance(data, mu)

1.25



Decimals and Fractions are supported:

>>> from decimal import Decimal as D

>>> pvariance([D("27.5"), D("30.25"), D("30.25"), D("34.5"), D("41.75")])

Decimal('24.815')

>>> from fractions import Fraction as F

>>> pvariance([F(1, 4), F(5, 4), F(1, 2)])

Fraction(13, 72)



The Python Library Reference, Release 3.13.2



® Note

When called with the entire population, this gives the population variance σ². When called on a sample instead, this is the biased sample variance s², also known as variance with N degrees of freedom.

If you somehow know the true population mean μ, you may use this function to calculate the variance of a sample, giving the known population mean as the second argument. Provided the data points are a random sample of the population, the result will be an unbiased estimate of the population variance.



statistics.stdev(data, xbar=None)

Return the sample standard deviation (the square root of the sample variance). See variance() for arguments

and other details.

>>> stdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])

1.0810874155219827



statistics.variance(data, xbar=None)

Return the sample variance of data, an iterable of at least two real-valued numbers. Variance, or second

moment about the mean, is a measure of the variability (spread or dispersion) of data. A large variance

indicates that the data is spread out; a small variance indicates it is clustered closely around the mean.

If the optional second argument xbar is given, it should be the sample mean of data. If it is missing or None

(the default), the mean is automatically calculated.

Use this function when your data is a sample from a population. To calculate the variance from the entire

population, see pvariance().

Raises StatisticsError if data has fewer than two values.

Examples:

>>> data = [2.75, 1.75, 1.25, 0.25, 0.5, 1.25, 3.5]

>>> variance(data)

1.3720238095238095



If you have already calculated the sample mean of your data, you can pass it as the optional second argument

xbar to avoid recalculation:

>>> m = mean(data)

>>> variance(data, m)

1.3720238095238095



This function does not attempt to verify that you have passed the actual mean as xbar. Using arbitrary values

for xbar can lead to invalid or impossible results.

Decimal and Fraction values are supported:

>>> from decimal import Decimal as D

>>> variance([D("27.5"), D("30.25"), D("30.25"), D("34.5"), D("41.75")])

Decimal('31.01875')

>>> from fractions import Fraction as F

>>> variance([F(1, 6), F(1, 2), F(5, 3)])

Fraction(67, 108)



® Note

This is the sample variance s² with Bessel’s correction, also known as variance with N-1 degrees of freedom.

The Python Library Reference, Release 3.13.2



Provided that the data points are representative (e.g. independent and identically distributed), the result should be an unbiased estimate of the true population variance.

If you somehow know the actual population mean μ you should pass it to the pvariance() function as the mu parameter to get the variance of a sample.



statistics.quantiles(data, *, n=4, method=’exclusive’)

Divide data into n continuous intervals with equal probability. Returns a list of n - 1 cut points separating

the intervals.

Set n to 4 for quartiles (the default). Set n to 10 for deciles. Set n to 100 for percentiles which gives the 99

cuts points that separate data into 100 equal sized groups. Raises StatisticsError if n is not least 1.

The data can be any iterable containing sample data. For meaningful results, the number of data points in data

should be larger than n. Raises StatisticsError if there is not at least one data point.

The cut points are linearly interpolated from the two nearest data points. For example, if a cut point falls

one-third of the distance between two sample values, 100 and 112, the cut-point will evaluate to 104.

The method for computing quantiles can be varied depending on whether the data includes or excludes the

lowest and highest possible values from the population.

The default method is “exclusive” and is used for data sampled from a population that can have more extreme

values than found in the samples. The portion of the population falling below the i-th of m sorted data points

is computed as i / (m + 1). Given nine sample values, the method sorts them and assigns the following

percentiles: 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%.

Setting the method to “inclusive” is used for describing population data or for samples that are known to include

the most extreme values from the population. The minimum value in data is treated as the 0th percentile and

the maximum value is treated as the 100th percentile. The portion of the population falling below the i-th of

m sorted data points is computed as (i - 1) / (m - 1). Given 11 sample values, the method sorts them

and assigns the following percentiles: 0%, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%.

# Decile cut points for empirically sampled data

>>> data = [105, 129, 87, 86, 111, 111, 89, 81, 108, 92, 110,

... 100, 75, 105, 103, 109, 76, 119, 99, 91, 103, 129,

... 106, 101, 84, 111, 74, 87, 86, 103, 103, 106, 86,

... 111, 75, 87, 102, 121, 111, 88, 89, 101, 106, 95,

... 103, 107, 101, 81, 109, 104]

>>> [round(q, 1) for q in quantiles(data, n=10)]

[81.0, 86.2, 89.0, 99.4, 102.5, 103.6, 106.0, 109.8, 111.0]



Added in version 3.8.

Changed in version 3.13: No longer raises an exception for an input with only a single data point. This allows

quantile estimates to be built up one sample point at a time becoming gradually more refined with each new

data point.

statistics.covariance( x, y, / )

Return the sample covariance of two inputs x and y. Covariance is a measure of the joint variability of two

inputs.

Both inputs must be of the same length (no less than two), otherwise StatisticsError is raised.

Examples:

>>> x = [1, 2, 3, 4, 5, 6, 7, 8, 9]

>>> y = [1, 2, 3, 1, 2, 3, 1, 2, 3]

>>> covariance(x, y)

0.75

>>> z = [9, 8, 7, 6, 5, 4, 3, 2, 1]

>>> covariance(x, z)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

-7.5

>>> covariance(z, x)

-7.5



Added in version 3.10.

statistics.correlation(x, y, / , *, method=’linear’)

Return the Pearson’s correlation coefficient for two inputs. Pearson’s correlation coefficient r takes values

between -1 and +1. It measures the strength and direction of a linear relationship.

If method is “ranked”, computes Spearman’s rank correlation coefficient for two inputs. The data is replaced

by ranks. Ties are averaged so that equal values receive the same rank. The resulting coefficient measures the

strength of a monotonic relationship.

Spearman’s correlation coefficient is appropriate for ordinal data or for continuous data that doesn’t meet the

linear proportion requirement for Pearson’s correlation coefficient.

Both inputs must be of the same length (no less than two), and need not to be constant, otherwise

StatisticsError is raised.

Example with Kepler’s laws of planetary motion:

>>> # Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune

>>> orbital_period = [88, 225, 365, 687, 4331, 10_756, 30_687, 60_190] #␣

, →days

>>> dist_from_sun = [58, 108, 150, 228, 778, 1_400, 2_900, 4_500] # million km

>>> # Show that a perfect monotonic relationship exists

>>> correlation(orbital_period, dist_from_sun, method='ranked')

1.0

>>> # Observe that a linear relationship is imperfect

>>> round(correlation(orbital_period, dist_from_sun), 4)

0.9882

>>> # Demonstrate Kepler's third law: There is a linear correlation

>>> # between the square of the orbital period and the cube of the

>>> # distance from the sun.

>>> period_squared = [p * p for p in orbital_period]

>>> dist_cubed = [d * d * d for d in dist_from_sun]

>>> round(correlation(period_squared, dist_cubed), 4)

1.0



Added in version 3.10.

Changed in version 3.12: Added support for Spearman’s rank correlation coefficient.

statistics.linear_regression(x, y, / , *, proportional=False)

Return the slope and intercept of simple linear regression parameters estimated using ordinary least squares.

Simple linear regression describes the relationship between an independent variable x and a dependent variable

y in terms of this linear function:

y = slope * x + intercept + noise

where slope and intercept are the regression parameters that are estimated, and noise represents the

variability of the data that was not explained by the linear regression (it is equal to the difference between

predicted and actual values of the dependent variable).

Both inputs must be of the same length (no less than two), and the independent variable x cannot be constant;

otherwise a StatisticsError is raised.

The Python Library Reference, Release 3.13.2



For example, we can use the release dates of the Monty Python films to predict the cumulative number of

Monty Python films that would have been produced by 2019 assuming that they had kept the pace.

>>> year = [1971, 1975, 1979, 1982, 1983]

>>> films_total = [1, 2, 3, 4, 5]

>>> slope, intercept = linear_regression(year, films_total)

>>> round(slope * 2019 + intercept)

16



If proportional is true, the independent variable x and the dependent variable y are assumed to be directly

proportional. The data is fit to a line passing through the origin. Since the intercept will always be 0.0, the

underlying linear function simplifies to:

y = slope * x + noise

Continuing the example from correlation(), we look to see how well a model based on major planets can

predict the orbital distances for dwarf planets:

>>> model = linear_regression(period_squared, dist_cubed, proportional=True)

>>> slope = model.slope

>>> # Dwarf planets: Pluto, Eris, Makemake, Haumea, Ceres

>>> orbital_periods = [90_560, 204_199, 111_845, 103_410, 1_680] # days

>>> predicted_dist = [math.cbrt(slope * (p * p)) for p in orbital_periods]

>>> list(map(round, predicted_dist))

[5912, 10166, 6806, 6459, 414]

>>> [5_906, 10_152, 6_796, 6_450, 414] # actual distance in million km

[5906, 10152, 6796, 6450, 414]



Added in version 3.10.

Changed in version 3.11: Added support for proportional.



9.7.5 Exceptions

A single exception is defined:

exception statistics.StatisticsError

Subclass of ValueError for statistics-related exceptions.



9.7.6 NormalDist objects

NormalDist is a tool for creating and manipulating normal distributions of a random variable. It is a class that treats the mean and standard deviation of data measurements as a single entity.

Normal distributions arise from the Central Limit Theorem and have a wide range of applications in statistics.

class statistics.NormalDist(mu=0.0, sigma=1.0)

Returns a new NormalDist object where mu represents the arithmetic mean and sigma represents the standard

deviation.

If sigma is negative, raises StatisticsError.

mean

A read-only property for the arithmetic mean of a normal distribution.

median

A read-only property for the median of a normal distribution.

mode

A read-only property for the mode of a normal distribution.

The Python Library Reference, Release 3.13.2



stdev

A read-only property for the standard deviation of a normal distribution.

variance

A read-only property for the variance of a normal distribution. Equal to the square of the standard deviation.

classmethod from_samples(data)

Makes a normal distribution instance with mu and sigma parameters estimated from the data using

fmean() and stdev().

The data can be any iterable and should consist of values that can be converted to type float. If data

does not contain at least two elements, raises StatisticsError because it takes at least one point to estimate a central value and at least two points to estimate dispersion.

samples(n, *, seed=None)

Generates n random samples for a given mean and standard deviation. Returns a list of float values.

If seed is given, creates a new instance of the underlying random number generator. This is useful for creating reproducible results, even in a multi-threading context.

Changed in version 3.13.

Switched to a faster algorithm. To reproduce samples from previous versions, use random.seed() and

random.gauss().

pdf(x)

Using a probability density function (pdf), compute the relative likelihood that a random variable X will be near the given value x. Mathematically, it is the limit of the ratio P(x <= X < x+dx) / dx as dx approaches zero.

The relative likelihood is computed as the probability of a sample occurring in a narrow range divided by the width of the range (hence the word “density”). Since the likelihood is relative to other points, its value can be greater than 1.0.

cdf(x)

Using a cumulative distribution function (cdf), compute the probability that a random variable X will be less than or equal to x. Mathematically, it is written P(X <= x).

inv_cdf(p)

Compute the inverse cumulative distribution function, also known as the quantile function or the percent-

point function. Mathematically, it is written x : P(X <= x) = p.

Finds the value x of the random variable X such that the probability of the variable being less than or equal to that value equals the given probability p.

overlap(other)

Measures the agreement between two normal probability distributions. Returns a value between 0.0 and

1.0 giving the overlapping area for the two probability density functions.

quantiles(n=4)

Divide the normal distribution into n continuous intervals with equal probability. Returns a list of (n - 1) cut points separating the intervals.

Set n to 4 for quartiles (the default). Set n to 10 for deciles. Set n to 100 for percentiles which gives the 99 cuts points that separate the normal distribution into 100 equal sized groups.

zscore(x)

Compute the Standard Score describing x in terms of the number of standard deviations above or below the mean of the normal distribution: (x - mean) / stdev.

Added in version 3.9.

Instances of NormalDist support addition, subtraction, multiplication and division by a constant. These

operations are used for translation and scaling. For example:

The Python Library Reference, Release 3.13.2



>>> temperature_february = NormalDist(5, 2.5) # Celsius

>>> temperature_february * (9/5) + 32 # Fahrenheit

NormalDist(mu=41.0, sigma=4.5)



Dividing a constant by an instance of NormalDist is not supported because the result wouldn’t be normally

distributed.

Since normal distributions arise from additive effects of independent variables, it is possible to add and sub-

tract two independent normally distributed random variables represented as instances of NormalDist. For

example:

>>> birth_weights = NormalDist.from_samples([2.5, 3.1, 2.1, 2.4, 2.7, 3.5])

>>> drug_effects = NormalDist(0.4, 0.15)

>>> combined = birth_weights + drug_effects

>>> round(combined.mean, 1)

3.1

>>> round(combined.stdev, 1)

0.5



Added in version 3.8.



9.7.7 Examples and Recipes

Classic probability problems

NormalDist readily solves classic probability problems.

For example, given historical data for SAT exams showing that scores are normally distributed with a mean of 1060 and a standard deviation of 195, determine the percentage of students with test scores between 1100 and 1200, after rounding to the nearest whole number:

>>> sat = NormalDist(1060, 195)

>>> fraction = sat.cdf(1200 + 0.5)-sat.cdf(1100-0.5)

>>> round(fraction * 100.0, 1)

18.4



Find the quartiles and deciles for the SAT scores:

>>> list(map(round, sat.quantiles()))

[928, 1060, 1192]

>>> list(map(round, sat.quantiles(n=10)))

[810, 896, 958, 1011, 1060, 1109, 1162, 1224, 1310]



Monte Carlo inputs for simulations

To estimate the distribution for a model that isn’t easy to solve analytically, NormalDist can generate input samples

for a Monte Carlo simulation:

>>> def model(x, y, z):

... return (3*x + 7*x*y-5*y) / (11 * z)

...

>>> n = 100_000

>>> X = NormalDist(10, 2.5).samples(n, seed=3652260728) >>> Y = NormalDist(15, 1.75).samples(n, seed=4582495471) >>> Z = NormalDist(50, 1.25).samples(n, seed=6582483453) >>> quantiles(map(model, X, Y, Z))

[1.4591308524824727, 1.8035946855390597, 2.175091447274739]



The Python Library Reference, Release 3.13.2



Approximating binomial distributions

Normal distributions can be used to approximate Binomial distributions when the sample size is large and when the probability of a successful trial is near 50%.

For example, an open source conference has 750 attendees and two rooms with a 500 person capacity. There is a talk about Python and another about Ruby. In previous conferences, 65% of the attendees preferred to listen to Python talks. Assuming the population preferences haven’t changed, what is the probability that the Python room will stay within its capacity limits?

>>> n = 750 # Sample size

>>> p = 0.65 # Preference for Python

>>> q = 1.0-p # Preference for Ruby

>>> k = 500 # Room capacity

>>> # Approximation using the cumulative normal distribution >>> from math import sqrt

>>> round(NormalDist(mu=n*p, sigma=sqrt(n*p*q)).cdf(k + 0.5), 4) 0.8402

>>> # Exact solution using the cumulative binomial distribution >>> from math import comb, fsum

>>> round(fsum(comb(n, r) * p**r * q**(n-r) for r in range(k+1)), 4) 0.8402

>>> # Approximation using a simulation

>>> from random import seed, binomialvariate

>>> seed(8675309)

>>> mean(binomialvariate(n, p) <= k for i in range(10_000)) 0.8406



Naive bayesian classifier

Normal distributions commonly arise in machine learning problems.

Wikipedia has a nice example of a Naive Bayesian Classifier. The challenge is to predict a person’s gender from measurements of normally distributed features including height, weight, and foot size.

We’re given a training dataset with measurements for eight people. The measurements are assumed to be normally

distributed, so we summarize the data with NormalDist:

>>> height_male = NormalDist.from_samples([6, 5.92, 5.58, 5.92]) >>> height_female = NormalDist.from_samples([5, 5.5, 5.42, 5.75]) >>> weight_male = NormalDist.from_samples([180, 190, 170, 165]) >>> weight_female = NormalDist.from_samples([100, 150, 130, 150]) >>> foot_size_male = NormalDist.from_samples([12, 11, 12, 10]) >>> foot_size_female = NormalDist.from_samples([6, 8, 7, 9])



Next, we encounter a new person whose feature measurements are known but whose gender is unknown:

>>> ht = 6.0 # height

>>> wt = 130 # weight

>>> fs = 8 # foot size



Starting with a 50% prior probability of being male or female, we compute the posterior as the prior times the product of likelihoods for the feature measurements given the gender:

>>> prior_male = 0.5

>>> prior_female = 0.5

>>> posterior_male = (prior_male * height_male.pdf(ht) *

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... weight_male.pdf(wt) * foot_size_male.pdf(fs))

>>> posterior_female = (prior_female * height_female.pdf(ht) * ... weight_female.pdf(wt) * foot_size_female.pdf(fs))



The final prediction goes to the largest posterior. This is known as the maximum a posteriori or MAP:

>>> 'male' if posterior_male > posterior_female else 'female' 'female'



The Python Library Reference, Release 3.13.2





CHAPTER




TEN



FUNCTIONAL PROGRAMMING MODULES



The modules described in this chapter provide functions and classes that support a functional programming style, and general operations on callables.

The following modules are documented in this chapter:



10.1 itertools — Functions creating iterators for efficient looping



This module implements a number of iterator building blocks inspired by constructs from APL, Haskell, and SML. Each has been recast in a form suitable for Python.

The module standardizes a core set of fast, memory efficient tools that are useful by themselves or in combination. Together, they form an “iterator algebra” making it possible to construct specialized tools succinctly and efficiently in pure Python.

For instance, SML provides a tabulation tool: tabulate(f) which produces a sequence f(0), f(1), .... The

same effect can be achieved in Python by combining map() and count() to form map(f, count()).

Infinite iterators:



Iterator Argu- Results Example

ments

count() [start[, start, start+step, start+2*step, … count(10) → 10 11 12 13 14 ...

step]]

cycle() p p0, p1, … plast, p0, p1, … cycle('ABCD') → A B C D A B C

D ...

repeat() elem [,n] elem, elem, elem, … endlessly or up to n repeat(10, 3) → 10 10 10

times



Iterators terminating on the shortest input sequence:



The Python Library Reference, Release 3.13.2



Iterator Arguments Results Example

accumulate() p [,func] p0, p0+p1, p0+p1+p2, … accumulate([1,2,3,4,5]) → 1 3 6

10 15

batched() p, n (p0, p1, …, p_n-1), … batched('ABCDEFG', n=3) → ABC

DEF G

chain() p, q, … p0, p1, … plast, q0, q1, … chain('ABC', 'DEF') → A B C D E

F

chain. iterable p0, p1, … plast, q0, q1, … chain.from_iterable(['ABC',

from_iterable() 'DEF']) → A B C D E F

compress() data, selectors (d[0] if s[0]), (d[1] if s[1]), compress('ABCDEF', [1,0,1,0,1,

… 1]) → A C E F

dropwhile() predicate, seq seq[n], seq[n+1], starting dropwhile(lambda x: x<5, [1,4,6,

when predicate fails 3,8]) → 6 3 8

filterfalse() predicate, seq elements of seq where filterfalse(lambda x: x<5, [1,4,

predicate(elem) fails 6,3,8]) → 6 8

groupby() iterable[, key] sub-iterators grouped by groupby(['A','B','DEF'], len) →

value of key(v) (1, A B) (3, DEF)

islice() seq, [start,] elements from islice('ABCDEFG', 2, None) → C D

stop [, step] seq[start:stop:step] E F G

pairwise() iterable (p[0], p[1]), (p[1], p[2]) pairwise('ABCDEFG') → AB BC CD

DE EF FG

starmap() func, seq func(*seq[0]), starmap(pow, [(2,5), (3,2), (10,

func(*seq[1]), … 3)]) → 32 9 1000

takewhile() predicate, seq seq[0], seq[1], until predi- takewhile(lambda x: x<5, [1,4,6,

cate fails 3,8]) → 1 4

tee() it, n it1, it2, … itn splits one it-

erator into n

zip_longest() p, q, … (p[0], q[0]), (p[1], q[1]), … zip_longest('ABCD', 'xy',

fillvalue='-') → Ax By C- D-



Combinatoric iterators:



Iterator Arguments Results

product() p, q, … [re- cartesian product, equivalent to a nested for-loop

peat=1]

permutations() p[, r] r-length tuples, all possible orderings, no repeated el-

ements

combinations() p, r r-length tuples, in sorted order, no repeated elements

combinations_with_replacement() p, r r-length tuples, in sorted order, with repeated ele-

ments



Examples Results

product('ABCD', repeat=2) AA AB AC AD BA BB BC BD CA CB CC CD DA DB

DC DD

permutations('ABCD', 2) AB AC AD BA BC BD CA CB CD DA DB DC

combinations('ABCD', 2) AB AC AD BC BD CD

combinations_with_replacement('ABCD', AA AB AC AD BB BC BD CC CD DD

2)



The Python Library Reference, Release 3.13.2



10.1.1 Itertool Functions

The following functions all construct and return iterators. Some provide streams of infinite length, so they should only be accessed by functions or loops that truncate the stream.

itertools.accumulate(iterable[, function, *, initial=None ])

Make an iterator that returns accumulated sums or accumulated results from other binary functions.

The function defaults to addition. The function should accept two arguments, an accumulated total and a value

from the iterable.

If an initial value is provided, the accumulation will start with that value and the output will have one more

element than the input iterable.

Roughly equivalent to:

def accumulate(iterable, function=operator.add, *, initial=None):

'Return running totals'

# accumulate([1,2,3,4,5]) → 1 3 6 10 15

# accumulate([1,2,3,4,5], initial=100) → 100 101 103 106 110 115 # accumulate([1,2,3,4,5], operator.mul) → 1 2 6 24 120

iterator = iter(iterable)

total = initial

if initial is None:

try:

total = next(iterator)

except StopIteration:

return

yield total

for element in iterator:

total = function(total, element)

yield total



To compute a running minimum, set function to min(). For a running maximum, set function to max().

Or for a running product, set function to operator.mul(). To build an amortization table, accumulate the

interest and apply payments:

>>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8]

>>> list(accumulate(data, max)) # running maximum

[3, 4, 6, 6, 6, 9, 9, 9, 9, 9]

>>> list(accumulate(data, operator.mul)) # running product

[3, 12, 72, 144, 144, 1296, 0, 0, 0, 0]

# Amortize a 5% loan of 1000 with 10 annual payments of 90

>>> update = lambda balance, payment: round(balance * 1.05)-payment

>>> list(accumulate(repeat(90, 10), update, initial=1_000))

[1000, 960, 918, 874, 828, 779, 728, 674, 618, 559, 497]



See functools.reduce() for a similar function that returns only the final accumulated value.

Added in version 3.2.

Changed in version 3.3: Added the optional function parameter.

Changed in version 3.8: Added the optional initial parameter.

itertools.batched(iterable, n, *, strict=False)

Batch data from the iterable into tuples of length n. The last batch may be shorter than n.

If strict is true, will raise a ValueError if the final batch is shorter than n.

The Python Library Reference, Release 3.13.2



Loops over the input iterable and accumulates data into tuples up to size n. The input is consumed lazily, just

enough to fill a batch. The result is yielded as soon as the batch is full or when the input iterable is exhausted:

>>> flattened_data = ['roses', 'red', 'violets', 'blue', 'sugar', 'sweet']

>>> unflattened = list(batched(flattened_data, 2))

>>> unflattened

[('roses', 'red'), ('violets', 'blue'), ('sugar', 'sweet')]



Roughly equivalent to:

def batched(iterable, n, *, strict=False):

# batched('ABCDEFG', 3) → ABC DEF G

if n < 1:

raise ValueError('n must be at least one')

iterator = iter(iterable)

while batch := tuple(islice(iterator, n)):

if strict and len(batch) != n:

raise ValueError('batched(): incomplete batch')

yield batch



Added in version 3.12.

Changed in version 3.13: Added the strict option.

itertools.chain(*iterables)

Make an iterator that returns elements from the first iterable until it is exhausted, then proceeds to the next

iterable, until all of the iterables are exhausted. This combines multiple data sources into a single iterator.

Roughly equivalent to:

def chain(*iterables):

# chain('ABC', 'DEF') → A B C D E F

for iterable in iterables:

yield from iterable



classmethod chain.from_iterable(iterable)

Alternate constructor for chain(). Gets chained inputs from a single iterable argument that is evaluated lazily.

Roughly equivalent to:

def from_iterable(iterables):

# chain.from_iterable(['ABC', 'DEF']) → A B C D E F for iterable in iterables:

yield from iterable



itertools.combinations(iterable, r)

Return r length subsequences of elements from the input iterable.

The output is a subsequence of product() keeping only entries that are subsequences of the iterable. The

length of the output is given by math.comb() which computes n! / r! / (n - r)! when 0 ≤ r ≤ n

or zero when r > n.

The combination tuples are emitted in lexicographic order according to the order of the input iterable. If the

input iterable is sorted, the output tuples will be produced in sorted order.

Elements are treated as unique based on their position, not on their value. If the input elements are unique,

there will be no repeated values within each combination.

Roughly equivalent to:

def combinations(iterable, r):

# combinations('ABCD', 2) → AB AC AD BC BD CD

# combinations(range(4), 3) → 012 013 023 123

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)



pool = tuple(iterable)

n = len(pool)

if r > n:

return

indices = list(range(r))

yield tuple(pool[i] for i in indices)

while True:

for i in reversed(range(r)):

if indices[i] != i + n-r:

break

else:

return

indices[i] += 1

for j in range(i+1, r):

indices[j] = indices[j-1] + 1

yield tuple(pool[i] for i in indices)



itertools.combinations_with_replacement(iterable, r)

Return r length subsequences of elements from the input iterable allowing individual elements to be repeated

more than once.

The output is a subsequence of product() that keeps only entries that are subsequences (with possible re-

peated elements) of the iterable. The number of subsequence returned is (n + r - 1)! / r! / (n -

1)! when n > 0.

The combination tuples are emitted in lexicographic order according to the order of the input iterable. if the

input iterable is sorted, the output tuples will be produced in sorted order.

Elements are treated as unique based on their position, not on their value. If the input elements are unique, the

generated combinations will also be unique.

Roughly equivalent to:

def combinations_with_replacement(iterable, r):

# combinations_with_replacement('ABC', 2) → AA AB AC BB BC CC

pool = tuple(iterable)

n = len(pool)

if not n and r:

return

indices = [0] * r

yield tuple(pool[i] for i in indices)

while True:

for i in reversed(range(r)):

if indices[i] != n-1:

break

else:

return

indices[i:] = [indices[i] + 1] * (r-i)

yield tuple(pool[i] for i in indices)



Added in version 3.1.

itertools.compress(data, selectors)

Make an iterator that returns elements from data where the corresponding element in selectors is true. Stops

when either the data or selectors iterables have been exhausted. Roughly equivalent to:

The Python Library Reference, Release 3.13.2



def compress(data, selectors):

# compress('ABCDEF', [1,0,1,0,1,1]) → A C E F

return (datum for datum, selector in zip(data, selectors) if selector)



Added in version 3.1.

itertools.count(start=0, step=1)

Make an iterator that returns evenly spaced values beginning with start. Can be used with map() to generate

consecutive data points or with zip() to add sequence numbers. Roughly equivalent to:

def count(start=0, step=1):

# count(10) → 10 11 12 13 14 ...

# count(2.5, 0.5) → 2.5 3.0 3.5 ...

n = start

while True:

yield n

n += step



When counting with floating-point numbers, better accuracy can sometimes be achieved by substituting mul-

tiplicative code such as: (start + step * i for i in count()).

Changed in version 3.1: Added step argument and allowed non-integer arguments.

itertools.cycle(iterable)

Make an iterator returning elements from the iterable and saving a copy of each. When the iterable is exhausted,

return elements from the saved copy. Repeats indefinitely. Roughly equivalent to:

def cycle(iterable):

# cycle('ABCD') → A B C D A B C D A B C D ...

saved = []

for element in iterable:

yield element

saved.append(element)

while saved:

for element in saved:

yield element



This itertool may require significant auxiliary storage (depending on the length of the iterable).

itertools.dropwhile(predicate, iterable)

Make an iterator that drops elements from the iterable while the predicate is true and afterwards returns every

element. Roughly equivalent to:

def dropwhile(predicate, iterable):

# dropwhile(lambda x: x<5, [1,4,6,3,8]) → 6 3 8

iterator = iter(iterable)

for x in iterator:

if not predicate(x):

yield x

break

for x in iterator:

yield x



Note this does not produce any output until the predicate first becomes false, so this itertool may have a lengthy

start-up time.

The Python Library Reference, Release 3.13.2



itertools.filterfalse( predicate, iterable)

Make an iterator that filters elements from the iterable returning only those for which the predicate returns a

false value. If predicate is None, returns the items that are false. Roughly equivalent to:

def filterfalse(predicate, iterable):

# filterfalse(lambda x: x<5, [1,4,6,3,8]) → 6 8

if predicate is None:

predicate = bool

for x in iterable:

if not predicate(x):

yield x



itertools.groupby(iterable, key=None)

Make an iterator that returns consecutive keys and groups from the iterable. The key is a function computing

a key value for each element. If not specified or is None, key defaults to an identity function and returns the

element unchanged. Generally, the iterable needs to already be sorted on the same key function.

The operation of groupby() is similar to the uniq filter in Unix. It generates a break or new group every

time the value of the key function changes (which is why it is usually necessary to have sorted the data using

the same key function). That behavior differs from SQL’s GROUP BY which aggregates common elements

regardless of their input order.

The returned group is itself an iterator that shares the underlying iterable with groupby(). Because the source

is shared, when the groupby() object is advanced, the previous group is no longer visible. So, if that data is

needed later, it should be stored as a list:

groups = []

uniquekeys = []

data = sorted(data, key=keyfunc)

for k, g in groupby(data, keyfunc):

groups.append(list(g)) # Store group iterator as a list uniquekeys.append(k)



groupby() is roughly equivalent to:

def groupby(iterable, key=None):

# [k for k, g in groupby('AAAABBBCCDAABBB')] → A B C D A B # [list(g) for k, g in groupby('AAAABBBCCD')] → AAAA BBB CC D

keyfunc = (lambda x: x) if key is None else key

iterator = iter(iterable)

exhausted = False

def _grouper(target_key):

nonlocal curr_value, curr_key, exhausted

yield curr_value

for curr_value in iterator:

curr_key = keyfunc(curr_value)

if curr_key != target_key:

return

yield curr_value

exhausted = True

try:

curr_value = next(iterator)

except StopIteration:

return

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

curr_key = keyfunc(curr_value)

while not exhausted:

target_key = curr_key

curr_group = _grouper(target_key)

yield curr_key, curr_group

if curr_key == target_key:

for _ in curr_group:

pass



itertools.islice(iterable, stop)

itertools.islice(iterable, start, stop[, step ])

Make an iterator that returns selected elements from the iterable. Works like sequence slicing but does not

support negative values for start, stop, or step.

If start is zero or None, iteration starts at zero. Otherwise, elements from the iterable are skipped until start is

reached.

If stop is None, iteration continues until the input is exhausted, if at all. Otherwise, it stops at the specified

position.

If step is None, the step defaults to one. Elements are returned consecutively unless step is set higher than one

which results in items being skipped.

Roughly equivalent to:

def islice(iterable, *args):

# islice('ABCDEFG', 2) → A B

# islice('ABCDEFG', 2, 4) → C D

# islice('ABCDEFG', 2, None) → C D E F G

# islice('ABCDEFG', 0, None, 2) → A C E G

s = slice(*args)

start = 0 if s.start is None else s.start

stop = s.stop

step = 1 if s.step is None else s.step

if start < 0 or (stop is not None and stop < 0) or step <= 0:

raise ValueError

indices = count() if stop is None else range(max(start, stop)) next_i = start

for i, element in zip(indices, iterable):

if i == next_i:

yield element

next_i += step



If the input is an iterator, then fully consuming the islice advances the input iterator by max(start, stop)

steps regardless of the step value.

itertools.pairwise(iterable)

Return successive overlapping pairs taken from the input iterable.

The number of 2-tuples in the output iterator will be one fewer than the number of inputs. It will be empty if

the input iterable has fewer than two values.

Roughly equivalent to:

def pairwise(iterable):

# pairwise('ABCDEFG') → AB BC CD DE EF FG

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)



iterator = iter(iterable)

a = next(iterator, None)

for b in iterator:

yield a, b

a = b



Added in version 3.10.

itertools.permutations(iterable, r=None)

Return successive r length permutations of elements from the iterable.

If r is not specified or is None, then r defaults to the length of the iterable and all possible full-length permu-

tations are generated.

The output is a subsequence of product() where entries with repeated elements have been filtered out. The

length of the output is given by math.perm() which computes n! / (n - r)! when 0 ≤ r ≤ n or zero

when r > n.

The permutation tuples are emitted in lexicographic order according to the order of the input iterable. If the

input iterable is sorted, the output tuples will be produced in sorted order.

Elements are treated as unique based on their position, not on their value. If the input elements are unique,

there will be no repeated values within a permutation.

Roughly equivalent to:

def permutations(iterable, r=None):

# permutations('ABCD', 2) → AB AC AD BA BC BD CA CB CD DA DB DC # permutations(range(3)) → 012 021 102 120 201 210

pool = tuple(iterable)

n = len(pool)

r = n if r is None else r

if r > n:

return

indices = list(range(n))

cycles = list(range(n, n-r,-1))

yield tuple(pool[i] for i in indices[:r])

while n:

for i in reversed(range(r)):

cycles[i]-= 1

if cycles[i] == 0:

indices[i:] = indices[i+1:] + indices[i:i+1]

cycles[i] = n-i

else:

j = cycles[i]

indices[i], indices[-j] = indices[-j], indices[i]

yield tuple(pool[i] for i in indices[:r])

break

else:

return



itertools.product(*iterables, repeat=1)

Cartesian product of the input iterables.

The Python Library Reference, Release 3.13.2



Roughly equivalent to nested for-loops in a generator expression. For example, product(A, B) returns the

same as ((x,y) for x in A for y in B).

The nested loops cycle like an odometer with the rightmost element advancing on every iteration. This pattern

creates a lexicographic ordering so that if the input’s iterables are sorted, the product tuples are emitted in

sorted order.

To compute the product of an iterable with itself, specify the number of repetitions with the optional repeat

keyword argument. For example, product(A, repeat=4) means the same as product(A, A, A, A).

This function is roughly equivalent to the following code, except that the actual implementation does not build

up intermediate results in memory:

def product(*iterables, repeat=1):

# product('ABCD', 'xy') → Ax Ay Bx By Cx Cy Dx Dy

# product(range(2), repeat=3) → 000 001 010 011 100 101 110 111

if repeat < 0:

raise ValueError('repeat argument cannot be negative')

pools = [tuple(pool) for pool in iterables] * repeat

result = [[]]

for pool in pools:

result = [x+[y] for x in result for y in pool]

for prod in result:

yield tuple(prod)



Before product() runs, it completely consumes the input iterables, keeping pools of values in memory to

generate the products. Accordingly, it is only useful with finite inputs.

itertools.repeat(object [, times ])

Make an iterator that returns object over and over again. Runs indefinitely unless the times argument is specified.

Roughly equivalent to:

def repeat(object, times=None):

# repeat(10, 3) → 10 10 10

if times is None:

while True:

yield object

else:

for i in range(times):

yield object



A common use for repeat is to supply a stream of constant values to map or zip:

>>> list(map(pow, range(10), repeat(2)))

[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]



itertools.starmap(function, iterable)

Make an iterator that computes the function using arguments obtained from the iterable. Used instead of

map() when argument parameters have already been “pre-zipped” into tuples.

The difference between map() and starmap() parallels the distinction between function(a,b) and

function(*c). Roughly equivalent to:

def starmap(function, iterable):

# starmap(pow, [(2,5), (3,2), (10,3)]) → 32 9 1000 for args in iterable:

yield function(*args)

The Python Library Reference, Release 3.13.2



itertools.takewhile(predicate, iterable)

Make an iterator that returns elements from the iterable as long as the predicate is true. Roughly equivalent to:

def takewhile(predicate, iterable):

# takewhile(lambda x: x<5, [1,4,6,3,8]) → 1 4

for x in iterable:

if not predicate(x):

break

yield x



Note, the element that first fails the predicate condition is consumed from the input iterator and there is no way

to access it. This could be an issue if an application wants to further consume the input iterator after takewhile

has been run to exhaustion. To work around this problem, consider using more-itertools before_and_after()

instead.

itertools.tee(iterable, n=2)

Return n independent iterators from a single iterable.

Roughly equivalent to:

def tee(iterable, n=2):

if n < 0:

raise ValueError

if n == 0:

return ()

iterator = _tee(iterable)

result = [iterator]

for _ in range(n-1):

result.append(_tee(iterator))

return tuple(result)

class _tee:

def __init__(self, iterable):

it = iter(iterable)

if isinstance(it, _tee):

self.iterator = it.iterator

self.link = it.link

else:

self.iterator = it

self.link = [None, None]

def __iter__(self):

return self

def __next__(self):

link = self.link

if link[1] is None:

link[0] = next(self.iterator)

link[1] = [None, None]

value, self.link = link

return value



When the input iterable is already a tee iterator object, all members of the return tuple are constructed as if

they had been produced by the upstream tee() call. This “flattening step” allows nested tee() calls to share

the same underlying data chain and to have a single update step rather than a chain of calls.

The flattening property makes tee iterators efficiently peekable:

The Python Library Reference, Release 3.13.2



def lookahead(tee_iterator):

"Return the next value without moving the input forward" [forked_iterator] = tee(tee_iterator, 1)

return next(forked_iterator)



>>> iterator = iter('abcdef')

>>> [iterator] = tee(iterator, 1) # Make the input peekable

>>> next(iterator) # Move the iterator forward

'a'

>>> lookahead(iterator) # Check next value

'b'

>>> next(iterator) # Continue moving forward

'b'



tee iterators are not threadsafe. A RuntimeError may be raised when simultaneously using iterators returned

by the same tee() call, even if the original iterable is threadsafe.

This itertool may require significant auxiliary storage (depending on how much temporary data needs to be

stored). In general, if one iterator uses most or all of the data before another iterator starts, it is faster to use

list() instead of tee().

itertools.zip_longest( *iterables, fillvalue=None)

Make an iterator that aggregates elements from each of the iterables.

If the iterables are of uneven length, missing values are filled-in with fillvalue. If not specified, fillvalue defaults

to None.

Iteration continues until the longest iterable is exhausted.

Roughly equivalent to:

def zip_longest(*iterables, fillvalue=None):

# zip_longest('ABCD', 'xy', fillvalue='-') → Ax By C- D-

iterators = list(map(iter, iterables))

num_active = len(iterators)

if not num_active:

return

while True:

values = []

for i, iterator in enumerate(iterators):

try:

value = next(iterator)

except StopIteration:

num_active-= 1

if not num_active:

return

iterators[i] = repeat(fillvalue)

value = fillvalue

values.append(value)

yield tuple(values)



If one of the iterables is potentially infinite, then the zip_longest() function should be wrapped with some-

thing that limits the number of calls (for example islice() or takewhile()).



The Python Library Reference, Release 3.13.2



10.1.2 Itertools Recipes

This section shows recipes for creating an extended toolset using the existing itertools as building blocks.

The primary purpose of the itertools recipes is educational. The recipes show various ways of thinking about indi-vidual tools — for example, that chain.from_iterable is related to the concept of flattening. The recipes also give ideas about ways that the tools can be combined — for example, how starmap() and repeat() can work

together. The recipes also show patterns for using itertools with the operator and collections modules as well as with the built-in itertools such as map(), filter(), reversed(), and enumerate().

A secondary purpose of the recipes is to serve as an incubator. The accumulate(), compress(), and pairwise() itertools started out as recipes. Currently, the sliding_window(), iter_index(), and sieve() recipes are being tested to see whether they prove their worth.

Substantially all of these recipes and many, many others can be installed from the more-itertools project found on the Python Package Index:

python-m pip install more-itertools



Many of the recipes offer the same high performance as the underlying toolset. Superior memory performance is kept by processing elements one at a time rather than bringing the whole iterable into memory all at once. Code volume

is kept small by linking the tools together in a functional style. High speed is retained by preferring “vectorized”

building blocks over the use of for-loops and generators which incur interpreter overhead.

from collections import Counter, deque

from contextlib import suppress

from functools import reduce

from math import comb, prod, sumprod, isqrt

from operator import itemgetter, getitem, mul, neg

def take(n, iterable):

"Return first n items of the iterable as a list."

return list(islice(iterable, n))

def prepend(value, iterable):

"Prepend a single value in front of an iterable."

# prepend(1, [2, 3, 4]) → 1 2 3 4

return chain([value], iterable)

def tabulate(function, start=0):

"Return function(0), function(1), ..."

return map(function, count(start))

def repeatfunc(function, times=None, *args):

"Repeat calls to a function with specified arguments."

if times is None:

return starmap(function, repeat(args))

return starmap(function, repeat(args, times))

def flatten(list_of_lists):

"Flatten one level of nesting."

return chain.from_iterable(list_of_lists)

def ncycles(iterable, n):

"Returns the sequence elements n times."

return chain.from_iterable(repeat(tuple(iterable), n))

def loops(n):

"Loop n times. Like range(n) but without creating integers."

# for _ in loops(100): ...

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

return repeat(None, n)

def tail(n, iterable):

"Return an iterator over the last n items."

# tail(3, 'ABCDEFG') → E F G

return iter(deque(iterable, maxlen=n))

def consume(iterator, n=None):

"Advance the iterator n-steps ahead. If n is None, consume entirely."

# Use functions that consume iterators at C speed.

if n is None:

deque(iterator, maxlen=0)

else:

next(islice(iterator, n, n), None)

def nth(iterable, n, default=None):

"Returns the nth item or a default value."

return next(islice(iterable, n, None), default)

def quantify(iterable, predicate=bool):

"Given a predicate that returns True or False, count the True results."

return sum(map(predicate, iterable))

def first_true(iterable, default=False, predicate=None):

"Returns the first true value or the *default* if there is no true value."

# first_true([a,b,c], x) → a or b or c or x

# first_true([a,b], x, f) → a if f(a) else b if f(b) else x

return next(filter(predicate, iterable), default)

def all_equal(iterable, key=None):

"Returns True if all the elements are equal to each other."

# all_equal('4 ', key=int) → True

return len(take(2, groupby(iterable, key))) <= 1

def unique_justseen(iterable, key=None):

"Yield unique elements, preserving order. Remember only the element just seen."

# unique_justseen('AAAABBBCCDAABBB') → A B C D A B

# unique_justseen('ABBcCAD', str.casefold) → A B c A D

if key is None:

return map(itemgetter(0), groupby(iterable))

return map(next, map(itemgetter(1), groupby(iterable, key)))

def unique_everseen(iterable, key=None):

"Yield unique elements, preserving order. Remember all elements ever seen."

# unique_everseen('AAAABBBCCDAABBB') → A B C D

# unique_everseen('ABBcCAD', str.casefold) → A B c D

seen = set()

if key is None:

for element in filterfalse(seen.__contains__, iterable):

seen.add(element)

yield element

else:

for element in iterable:

k = key(element)

if k not in seen:

seen.add(k)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

yield element

def unique(iterable, key=None, reverse=False):

"Yield unique elements in sorted order. Supports unhashable inputs."

# unique([[1, 2], [3, 4], [1, 2]]) → [1, 2] [3, 4]

sequenced = sorted(iterable, key=key, reverse=reverse)

return unique_justseen(sequenced, key=key)

def sliding_window(iterable, n):

"Collect data into overlapping fixed-length chunks or blocks."

# sliding_window('ABCDEFG', 4) → ABCD BCDE CDEF DEFG

iterator = iter(iterable)

window = deque(islice(iterator, n-1), maxlen=n)

for x in iterator:

window.append(x)

yield tuple(window)

def grouper(iterable, n, *, incomplete='fill', fillvalue=None):

"Collect data into non-overlapping fixed-length chunks or blocks."

# grouper('ABCDEFG', 3, fillvalue='x') → ABC DEF Gxx

# grouper('ABCDEFG', 3, incomplete='strict') → ABC DEF ValueError

# grouper('ABCDEFG', 3, incomplete='ignore') → ABC DEF

iterators = [iter(iterable)] * n

match incomplete:

case 'fill':

return zip_longest(*iterators, fillvalue=fillvalue)

case 'strict':

return zip(*iterators, strict=True)

case 'ignore':

return zip(*iterators)

case _:

raise ValueError('Expected fill, strict, or ignore')

def roundrobin(*iterables):

"Visit input iterables in a cycle until each is exhausted."

# roundrobin('ABC', 'D', 'EF') → A D E B F C

# Algorithm credited to George Sakkis

iterators = map(iter, iterables)

for num_active in range(len(iterables), 0,-1):

iterators = cycle(islice(iterators, num_active))

yield from map(next, iterators)

def subslices(seq):

"Return all contiguous non-empty subslices of a sequence."

# subslices('ABCD') → A AB ABC ABCD B BC BCD C CD D

slices = starmap(slice, combinations(range(len(seq) + 1), 2))

return map(getitem, repeat(seq), slices)

def iter_index(iterable, value, start=0, stop=None):

"Return indices where a value occurs in a sequence or iterable."

# iter_index('AABCADEAF', 'A') → 0 1 4 7

seq_index = getattr(iterable, 'index', None)

if seq_index is None:

iterator = islice(iterable, start, stop)

for i, element in enumerate(iterator, start):

if element is value or element == value:

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

yield i

else:

stop = len(iterable) if stop is None else stop

i = start

with suppress(ValueError):

while True:

yield (i := seq_index(value, i, stop))

i += 1

def iter_except(function, exception, first=None):

"Convert a call-until-exception interface to an iterator interface."

# iter_except(d.popitem, KeyError) → non-blocking dictionary iterator

with suppress(exception):

if first is not None:

yield first()

while True:

yield function()



The following recipes have a more mathematical flavor:

def powerset(iterable):

"Subsequences of the iterable from shortest to longest."

# powerset([1,2,3]) → () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)

s = list(iterable)

return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))

def sum_of_squares(iterable):

"Add up the squares of the input values."

# sum_of_squares([10, 20, 30]) → 1400

return sumprod(*tee(iterable))

def reshape(matrix, columns):

"Reshape a 2-D matrix to have a given number of columns."

# reshape([(0, 1), (2, 3), (4, 5)], 3) → (0, 1, 2), (3, 4, 5)

return batched(chain.from_iterable(matrix), columns, strict=True)

def transpose(matrix):

"Swap the rows and columns of a 2-D matrix."

# transpose([(1, 2, 3), (11, 22, 33)]) → (1, 11) (2, 22) (3, 33)

return zip(*matrix, strict=True)

def matmul(m1, m2):

"Multiply two matrices."

# matmul([(7, 5), (3, 5)], [(2, 5), (7, 9)]) → (49, 80), (41, 60)

n = len(m2[0])

return batched(starmap(sumprod, product(m1, transpose(m2))), n)

def convolve(signal, kernel):

"""Discrete linear convolution of two iterables.

Equivalent to polynomial multiplication.

Convolutions are mathematically commutative; however, the inputs are

evaluated differently. The signal is consumed lazily and can be

infinite. The kernel is fully consumed before the calculations begin.

Article: https://betterexplained.com/articles/intuitive-convolution/

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

Video: https://www.youtube.com/watch?v=KuXjwB4LzSA

"""

# convolve([1, -1, -20], [1, -3]) → 1 -4 -17 60

# convolve(data, [0.25, 0.25, 0.25, 0.25]) → Moving average (blur)

# convolve(data, [1/2, 0, -1/2]) → 1st derivative estimate

# convolve(data, [1, -2, 1]) → 2nd derivative estimate

kernel = tuple(kernel)[::-1]

n = len(kernel)

padded_signal = chain(repeat(0, n-1), signal, repeat(0, n-1))

windowed_signal = sliding_window(padded_signal, n)

return map(sumprod, repeat(kernel), windowed_signal)

def polynomial_from_roots(roots):

"""Compute a polynomial's coefficients from its roots.

(x - 5) (x + 4) (x - 3) expands to: x³ -4x² -17x + 60

"""

# polynomial_from_roots([5, -4, 3]) → [1, -4, -17, 60]

factors = zip(repeat(1), map(neg, roots))

return list(reduce(convolve, factors, [1]))

def polynomial_eval(coefficients, x):

"""Evaluate a polynomial at a specific value.

Computes with better numeric stability than Horner's method.

"""

# Evaluate x³ -4x² -17x + 60 at x = 5

# polynomial_eval([1, -4, -17, 60], x=5) → 0

n = len(coefficients)

if not n:

return type(x)(0)

powers = map(pow, repeat(x), reversed(range(n)))

return sumprod(coefficients, powers)

def polynomial_derivative(coefficients):

"""Compute the first derivative of a polynomial.

f(x) = x³ -4x² -17x + 60

f'(x) = 3x² -8x -17

"""

# polynomial_derivative([1, -4, -17, 60]) → [3, -8, -17]

n = len(coefficients)

powers = reversed(range(1, n))

return list(map(mul, coefficients, powers))

def sieve(n):

"Primes less than n."

# sieve(30) → 2 3 5 7 11 13 17 19 23 29

if n > 2:

yield 2

data = bytearray((0, 1)) * (n // 2)

for p in iter_index(data, 1, start=3, stop=isqrt(n) + 1):

data[p*p : n : p+p] = bytes(len(range(p*p, n, p+p)))

yield from iter_index(data, 1, start=3)

def factor(n):

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

"Prime factors of n."

# factor(99) → 3 3 11

# factor(1_000_000_000_000_007) → 47 59 360620266859

# factor(1_000_000_000_000_403) → 1000000000000403

for prime in sieve(isqrt(n) + 1):

while not n % prime:

yield prime

n //= prime

if n == 1:

return

if n > 1:

yield n

def is_prime(n):

"Return True if n is prime."

# is_prime(1_000_000_000_000_403) → True

return n > 1 and next(factor(n)) == n

def totient(n):

"Count of natural numbers up to n that are coprime to n."

# https://mathworld.wolfram.com/TotientFunction.html

# totient(12) → 4 because len([1, 5, 7, 11]) == 4

for prime in set(factor(n)):

n-= n // prime

return n

def multinomial(*counts):

"Number of distinct arrangements of a multiset."

# Counter('abracadabra').values() -> 5 2 1 1 2

# multinomial(5, 2, 1, 1, 2) → 83160

return prod(map(comb, accumulate(counts), counts))



10.2 functools — Higher-order functions and operations on

callable objects

Source code: Lib/functools.py



The functools module is for higher-order functions: functions that act on or return other functions. In general, any callable object can be treated as a function for the purposes of this module.

The functools module defines the following functions:

@functools.cache(user_function)

Simple lightweight unbounded function cache. Sometimes called “memoize”.

Returns the same as lru_cache(maxsize=None), creating a thin wrapper around a dictionary lookup for

the function arguments. Because it never needs to evict old values, this is smaller and faster than lru_cache()

with a size limit.

For example:

@cache

def factorial(n):

return n * factorial(n-1) if n else 1

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> factorial(10) # no previously cached result, makes 11 recursive calls

3628800

>>> factorial(5) # just looks up cached value result

120

>>> factorial(12) # makes two new recursive calls, the other 10 are cached

479001600



The cache is threadsafe so that the wrapped function can be used in multiple threads. This means that the

underlying data structure will remain coherent during concurrent updates.

It is possible for the wrapped function to be called more than once if another thread makes an additional call

before the initial call has been completed and cached.

Added in version 3.9.

@functools.cached_property(func)

Transform a method of a class into a property whose value is computed once and then cached as a normal

attribute for the life of the instance. Similar to property(), with the addition of caching. Useful for expensive

computed properties of instances that are otherwise effectively immutable.

Example:

class DataSet:

def __init__(self, sequence_of_numbers):

self._data = tuple(sequence_of_numbers)

@cached_property

def stdev(self):

return statistics.stdev(self._data)



The mechanics of cached_property() are somewhat different from property(). A regular property

blocks attribute writes unless a setter is defined. In contrast, a cached_property allows writes.

The cached_property decorator only runs on lookups and only when an attribute of the same name doesn’t

exist. When it does run, the cached_property writes to the attribute with the same name. Subsequent attribute

reads and writes take precedence over the cached_property method and it works like a normal attribute.

The cached value can be cleared by deleting the attribute. This allows the cached_property method to run

again.

The cached_property does not prevent a possible race condition in multi-threaded usage. The getter function

could run more than once on the same instance, with the latest run setting the cached value. If the cached

property is idempotent or otherwise not harmful to run more than once on an instance, this is fine. If synchro-

nization is needed, implement the necessary locking inside the decorated getter function or around the cached

property access.

Note, this decorator interferes with the operation of PEP 412 key-sharing dictionaries. This means that in-

stance dictionaries can take more space than usual.

Also, this decorator requires that the __dict__ attribute on each instance be a mutable mapping. This means

it will not work with some types, such as metaclasses (since the __dict__ attributes on type instances are

read-only proxies for the class namespace), and those that specify __slots__ without including __dict__

as one of the defined slots (as such classes don’t provide a __dict__ attribute at all).

If a mutable mapping is not available or if space-efficient key sharing is desired, an effect similar to

cached_property() can also be achieved by stacking property() on top of lru_cache(). See faq-

cache-method-calls for more details on how this differs from cached_property().

Added in version 3.8.

Changed in version 3.12: Prior to Python 3.12, cached_property included an undocumented lock to ensure

that in multi-threaded usage the getter function was guaranteed to run only once per instance. However, the The Python Library Reference, Release 3.13.2



lock was per-property, not per-instance, which could result in unacceptably high lock contention. In Python

3.12+ this locking is removed.

functools.cmp_to_key(func)

Transform an old-style comparison function to a key function. Used with tools that accept key functions (such as

sorted(), min(), max(), heapq.nlargest(), heapq.nsmallest(), itertools.groupby()). This

function is primarily used as a transition tool for programs being converted from Python 2 which supported

the use of comparison functions.

A comparison function is any callable that accepts two arguments, compares them, and returns a negative

number for less-than, zero for equality, or a positive number for greater-than. A key function is a callable that

accepts one argument and returns another value to be used as the sort key.

Example:

sorted(iterable, key=cmp_to_key(locale.strcoll)) # locale-aware sort order



For sorting examples and a brief sorting tutorial, see sortinghowto.

Added in version 3.2.

@functools.lru_cache(user_function)

@functools.lru_cache(maxsize=128, typed=False)

Decorator to wrap a function with a memoizing callable that saves up to the maxsize most recent calls. It can

save time when an expensive or I/O bound function is periodically called with the same arguments.

The cache is threadsafe so that the wrapped function can be used in multiple threads. This means that the

underlying data structure will remain coherent during concurrent updates.

It is possible for the wrapped function to be called more than once if another thread makes an additional call

before the initial call has been completed and cached.

Since a dictionary is used to cache results, the positional and keyword arguments to the function must be

hashable.

Distinct argument patterns may be considered to be distinct calls with separate cache entries. For example,

f(a=1, b=2) and f(b=2, a=1) differ in their keyword argument order and may have two separate cache

entries.

If user_function is specified, it must be a callable. This allows the lru_cache decorator to be applied directly

to a user function, leaving the maxsize at its default value of 128:

@lru_cache

def count_vowels(sentence):

return sum(sentence.count(vowel) for vowel in 'AEIOUaeiou')



If maxsize is set to None, the LRU feature is disabled and the cache can grow without bound.

If typed is set to true, function arguments of different types will be cached separately. If typed is false, the

implementation will usually regard them as equivalent calls and only cache a single result. (Some types such

as str and int may be cached separately even when typed is false.)

Note, type specificity applies only to the function’s immediate arguments rather than their contents. The scalar

arguments, Decimal(42) and Fraction(42) are be treated as distinct calls with distinct results. In con-

trast, the tuple arguments ('answer', Decimal(42)) and ('answer', Fraction(42)) are treated as

equivalent.

The wrapped function is instrumented with a cache_parameters() function that returns a new dict show-

ing the values for maxsize and typed. This is for information purposes only. Mutating the values has no effect.

To help measure the effectiveness of the cache and tune the maxsize parameter, the wrapped function is instru-

mented with a cache_info() function that returns a named tuple showing hits, misses, maxsize and currsize.

The decorator also provides a cache_clear() function for clearing or invalidating the cache.

The Python Library Reference, Release 3.13.2



The original underlying function is accessible through the __wrapped__ attribute. This is useful for intro-

spection, for bypassing the cache, or for rewrapping the function with a different cache.

The cache keeps references to the arguments and return values until they age out of the cache or until the cache

is cleared.

If a method is cached, the self instance argument is included in the cache. See faq-cache-method-calls

An LRU (least recently used) cache works best when the most recent calls are the best predictors of upcoming

calls (for example, the most popular articles on a news server tend to change each day). The cache’s size limit

assures that the cache does not grow without bound on long-running processes such as web servers.

In general, the LRU cache should only be used when you want to reuse previously computed values. Accord-

ingly, it doesn’t make sense to cache functions with side-effects, functions that need to create distinct mutable

objects on each call (such as generators and async functions), or impure functions such as time() or random().

Example of an LRU cache for static web content:

@lru_cache(maxsize=32)

def get_pep(num):

'Retrieve text of a Python Enhancement Proposal'

resource = f'https://peps.python.org/pep-{num:04d}'

try:

with urllib.request.urlopen(resource) as s:

return s.read()

except urllib.error.HTTPError:

return 'Not Found'

>>> for n in 8, 290, 308, 320, 8, 218, 320, 279, 289, 320, 9991:

... pep = get_pep(n)

... print(n, len(pep))

>>> get_pep.cache_info()

CacheInfo(hits=3, misses=8, maxsize=32, currsize=8)



Example of efficiently computing Fibonacci numbers using a cache to implement a dynamic programming

technique:

@lru_cache(maxsize=None)

def fib(n):

if n < 2:

return n

return fib(n-1) + fib(n-2)

>>> [fib(n) for n in range(16)]

[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]

>>> fib.cache_info()

CacheInfo(hits=28, misses=16, maxsize=None, currsize=16)



Added in version 3.2.

Changed in version 3.3: Added the typed option.

Changed in version 3.8: Added the user_function option.

Changed in version 3.9: Added the function cache_parameters()

@functools.total_ordering

Given a class defining one or more rich comparison ordering methods, this class decorator supplies the rest.

This simplifies the effort involved in specifying all of the possible rich comparison operations:

The Python Library Reference, Release 3.13.2



The class must define one of __lt__(), __le__(), __gt__(), or __ge__(). In addition, the class should

supply an __eq__() method.

For example:

@total_ordering

class Student:

def _is_valid_operand(self, other):

return (hasattr(other, "lastname") and

hasattr(other, "firstname"))

def __eq__(self, other):

if not self._is_valid_operand(other):

return NotImplemented

return ((self.lastname.lower(), self.firstname.lower()) ==

(other.lastname.lower(), other.firstname.lower()))

def __lt__(self, other):

if not self._is_valid_operand(other):

return NotImplemented

return ((self.lastname.lower(), self.firstname.lower()) <

(other.lastname.lower(), other.firstname.lower()))



® Note

While this decorator makes it easy to create well behaved totally ordered types, it does come at the cost of slower execution and more complex stack traces for the derived comparison methods. If performance benchmarking indicates this is a bottleneck for a given application, implementing all six rich comparison methods instead is likely to provide an easy speed boost.



® Note

This decorator makes no attempt to override methods that have been declared in the class or its superclasses. Meaning that if a superclass defines a comparison operator, total_ordering will not implement it again, even if the original method is abstract.



Added in version 3.2.

Changed in version 3.4: Returning NotImplemented from the underlying comparison function for unrecog-

nised types is now supported.

functools.partial(func, / , *args, **keywords)

Return a new partial object which when called will behave like func called with the positional arguments args

and keyword arguments keywords. If more arguments are supplied to the call, they are appended to args. If

additional keyword arguments are supplied, they extend and override keywords. Roughly equivalent to:

def partial(func, /, *args, **keywords):

def newfunc(*fargs, **fkeywords):

newkeywords = {**keywords, **fkeywords}

return func(*args, *fargs, **newkeywords)

newfunc.func = func

newfunc.args = args

newfunc.keywords = keywords

return newfunc



The partial() is used for partial function application which “freezes” some portion of a function’s arguments

and/or keywords resulting in a new object with a simplified signature. For example, partial() can be used

to create a callable that behaves like the int() function where the base argument defaults to two:

The Python Library Reference, Release 3.13.2



>>> from functools import partial

>>> basetwo = partial(int, base=2)

>>> basetwo.__doc__ = 'Convert base 2 string to an int.'

>>> basetwo('10010')

18



class functools.partialmethod(func, / , *args, **keywords)

Return a new partialmethod descriptor which behaves like partial except that it is designed to be used

as a method definition rather than being directly callable.

func must be a descriptor or a callable (objects which are both, like normal functions, are handled as descrip-

tors).

When func is a descriptor (such as a normal Python function, classmethod(), staticmethod(),

abstractmethod() or another instance of partialmethod), calls to __get__ are delegated to the un-

derlying descriptor, and an appropriate partial object returned as the result.

When func is a non-descriptor callable, an appropriate bound method is created dynamically. This behaves

like a normal Python function when used as a method: the self argument will be inserted as the first positional

argument, even before the args and keywords supplied to the partialmethod constructor.

Example:

>>> class Cell:

... def __init__(self):

... self._alive = False

... @property

... def alive(self):

... return self._alive

... def set_state(self, state):

... self._alive = bool(state)

... set_alive = partialmethod(set_state, True)

... set_dead = partialmethod(set_state, False)

...

>>> c = Cell()

>>> c.alive

False

>>> c.set_alive()

>>> c.alive

True



Added in version 3.4.

functools.reduce(function, iterable, [initial, ]/ )

Apply function of two arguments cumulatively to the items of iterable, from left to right, so as to reduce the

iterable to a single value. For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates

((((1+2)+3)+4)+5) . The left argument, x, is the accumulated value and the right argument, y, is the

update value from the iterable. If the optional initial is present, it is placed before the items of the iterable in

the calculation, and serves as a default when the iterable is empty. If initial is not given and iterable contains

only one item, the first item is returned.

Roughly equivalent to:

initial_missing = object()

def reduce(function, iterable, initial=initial_missing, /):

it = iter(iterable)

if initial is initial_missing:

value = next(it)

else:

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

value = initial

for element in it:

value = function(value, element)

return value



See itertools.accumulate() for an iterator that yields all intermediate values.

@functools.singledispatch

Transform a function into a single-dispatch generic function.

To define a generic function, decorate it with the @singledispatch decorator. When defining a function

using @singledispatch, note that the dispatch happens on the type of the first argument:

>>> from functools import singledispatch

>>> @singledispatch

... def fun(arg, verbose=False):

... if verbose:

... print("Let me just say,", end=" ")

... print(arg)



To add overloaded implementations to the function, use the register() attribute of the generic function,

which can be used as a decorator. For functions annotated with types, the decorator will infer the type of the

first argument automatically:

>>> @fun.register

... def _(arg: int, verbose=False):

... if verbose:

... print("Strength in numbers, eh?", end=" ")

... print(arg)

...

>>> @fun.register

... def _(arg: list, verbose=False):

... if verbose:

... print("Enumerate this:")

... for i, elem in enumerate(arg):

... print(i, elem)



types.UnionType and typing.Union can also be used:

>>> @fun.register

... def _(arg: int | float, verbose=False):

... if verbose:

... print("Strength in numbers, eh?", end=" ")

... print(arg)

...

>>> from typing import Union

>>> @fun.register

... def _(arg: Union[list, set], verbose=False):

... if verbose:

... print("Enumerate this:")

... for i, elem in enumerate(arg):

... print(i, elem)

...



For code which doesn’t use type annotations, the appropriate type argument can be passed explicitly to the

decorator itself:



The Python Library Reference, Release 3.13.2



>>> @fun.register(complex)

... def _(arg, verbose=False):

... if verbose:

... print("Better than complicated.", end=" ")

... print(arg.real, arg.imag)

...



For code that dispatches on a collections type (e.g., list), but wants to typehint the items of the collection

(e.g., list[int]), the dispatch type should be passed explicitly to the decorator itself with the typehint going

into the function definition:

>>> @fun.register(list)

... def _(arg: list[int], verbose=False):

... if verbose:

... print("Enumerate this:")

... for i, elem in enumerate(arg):

... print(i, elem)



® Note

At runtime the function will dispatch on an instance of a list regardless of the type contained within the list i.e. [1,2,3] will be dispatched the same as ["foo", "bar", "baz"]. The annotation provided in this example is for static type checkers only and has no runtime impact.



To enable registering lambdas and pre-existing functions, the register() attribute can also be used in a

functional form:

>>> def nothing(arg, verbose=False):

... print("Nothing.")

...

>>> fun.register(type(None), nothing)



The register() attribute returns the undecorated function. This enables decorator stacking, pickling,

and the creation of unit tests for each variant independently:

>>> @fun.register(float)

... @fun.register(Decimal)

... def fun_num(arg, verbose=False):

... if verbose:

... print("Half of your number:", end=" ")

... print(arg / 2)

...

>>> fun_num is fun

False



When called, the generic function dispatches on the type of the first argument:

>>> fun("Hello, world.")

Hello, world.

>>> fun("test.", verbose=True)

Let me just say, test.

>>> fun(42, verbose=True)

Strength in numbers, eh? 42

>>> fun(['spam', 'spam', 'eggs', 'spam'], verbose=True)

Enumerate this:

0 spam

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

1 spam

2 eggs

3 spam

>>> fun(None)

Nothing.

>>> fun(1.23)

0.615



Where there is no registered implementation for a specific type, its method resolution order is used to find a

more generic implementation. The original function decorated with @singledispatch is registered for the

base object type, which means it is used if no better implementation is found.

If an implementation is registered to an abstract base class, virtual subclasses of the base class will be dispatched

to that implementation:

>>> from collections.abc import Mapping

>>> @fun.register

... def _(arg: Mapping, verbose=False):

... if verbose:

... print("Keys & Values")

... for key, value in arg.items():

... print(key, "=>", value)

...

>>> fun({"a": "b"})

a => b



To check which implementation the generic function will choose for a given type, use the dispatch() at-

tribute:

>>> fun.dispatch(float)



>>> fun.dispatch(dict) # note: default implementation





To access all registered implementations, use the read-only registry attribute:

>>> fun.registry.keys()

dict_keys([, , ,

, ,

])

>>> fun.registry[float]



>>> fun.registry[object]





Added in version 3.4.

Changed in version 3.7: The register() attribute now supports using type annotations.

Changed in version 3.11: The register() attribute now supports types.UnionType and typing.Union

as type annotations.

class functools.singledispatchmethod(func)

Transform a method into a single-dispatch generic function.

To define a generic method, decorate it with the @singledispatchmethod decorator. When defining a

function using @singledispatchmethod, note that the dispatch happens on the type of the first non-self or

non-cls argument:

The Python Library Reference, Release 3.13.2



class Negator:

@singledispatchmethod

def neg(self, arg):

raise NotImplementedError("Cannot negate a")

@neg.register

def _(self, arg: int):

return-arg

@neg.register

def _(self, arg: bool):

return not arg



@singledispatchmethod supports nesting with other decorators such as @classmethod. Note that to

allow for dispatcher.register, singledispatchmethod must be the outer most decorator. Here is the

Negator class with the neg methods bound to the class, rather than an instance of the class:

class Negator:

@singledispatchmethod

@classmethod

def neg(cls, arg):

raise NotImplementedError("Cannot negate a")

@neg.register

@classmethod

def _(cls, arg: int):

return-arg

@neg.register

@classmethod

def _(cls, arg: bool):

return not arg



The same pattern can be used for other similar decorators: @staticmethod, @abstractmethod, and others.

Added in version 3.8.

functools.update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS,

updated=WRAPPER_UPDATES)

Update a wrapper function to look like the wrapped function. The optional arguments are tuples to specify

which attributes of the original function are assigned directly to the matching attributes on the wrapper function

and which attributes of the wrapper function are updated with the corresponding attributes from the original

function. The default values for these arguments are the module level constants WRAPPER_ASSIGNMENTS

(which assigns to the wrapper function’s __module__, __name__, __qualname__, __annotations__,

__type_params__, and __doc__, the documentation string) and WRAPPER_UPDATES (which updates the

wrapper function’s __dict__, i.e. the instance dictionary).

To allow access to the original function for introspection and other purposes (e.g. bypassing a caching decorator

such as lru_cache()), this function automatically adds a __wrapped__ attribute to the wrapper that refers

to the function being wrapped.

The main intended use for this function is in decorator functions which wrap the decorated function and return

the wrapper. If the wrapper function is not updated, the metadata of the returned function will reflect the

wrapper definition rather than the original function definition, which is typically less than helpful.

update_wrapper() may be used with callables other than functions. Any attributes named in assigned or

updated that are missing from the object being wrapped are ignored (i.e. this function will not attempt to set

them on the wrapper function). AttributeError is still raised if the wrapper function itself is missing any

attributes named in updated.

The Python Library Reference, Release 3.13.2



Changed in version 3.2: The __wrapped__ attribute is now automatically added. The __annotations__

attribute is now copied by default. Missing attributes no longer trigger an AttributeError.

Changed in version 3.4: The __wrapped__ attribute now always refers to the wrapped function, even if that

function defined a __wrapped__ attribute. (see bpo-17482)

Changed in version 3.12: The __type_params__ attribute is now copied by default.

@functools.wraps(wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES)

This is a convenience function for invoking update_wrapper() as a function decorator when

defining a wrapper function. It is equivalent to partial(update_wrapper, wrapped=wrapped,

assigned=assigned, updated=updated) . For example:

>>> from functools import wraps

>>> def my_decorator(f):

... @wraps(f)

... def wrapper(*args, **kwds):

... print('Calling decorated function')

... return f(*args, **kwds)

... return wrapper

...

>>> @my_decorator

... def example():

... """Docstring"""

... print('Called example function')

...

>>> example()

Calling decorated function

Called example function

>>> example.__name__

'example'

>>> example.__doc__

'Docstring'



Without the use of this decorator factory, the name of the example function would have been 'wrapper',

and the docstring of the original example() would have been lost.



10.2.1 partial Objects

partial objects are callable objects created by partial(). They have three read-only attributes:

partial.func

A callable object or function. Calls to the partial object will be forwarded to func with new arguments and

keywords.

partial.args

The leftmost positional arguments that will be prepended to the positional arguments provided to a partial

object call.

partial.keywords

The keyword arguments that will be supplied when the partial object is called.

partial objects are like function objects in that they are callable, weak referenceable, and can have attributes. There are some important differences. For instance, the __name__ and function.__doc__ attributes are not created

automatically. Also, partial objects defined in classes behave like static methods and do not transform into bound methods during instance attribute look-up.



The Python Library Reference, Release 3.13.2



10.3 operator — Standard operators as functions

Source code: Lib/operator.py



The operator module exports a set of efficient functions corresponding to the intrinsic operators of Python. For example, operator.add(x, y) is equivalent to the expression x+y. Many function names are those used for special methods, without the double underscores. For backward compatibility, many of these have a variant with the double underscores kept. The variants without the double underscores are preferred for clarity.

The functions fall into categories that perform object comparisons, logical operations, mathematical operations and sequence operations.

The object comparison functions are useful for all objects, and are named after the rich comparison operators they support:

operator.lt(a, b)

operator.le(a, b)

operator.eq(a, b)

operator.ne(a, b)

operator.ge(a, b)

operator.gt(a, b)

operator.__lt__(a, b)

operator.__le__(a, b)

operator.__eq__(a, b)

operator.__ne__(a, b)

operator.__ge__(a, b)

operator.__gt__(a, b)

Perform “rich comparisons” between a and b. Specifically, lt(a, b) is equivalent to a < b, le(a, b) is

equivalent to a <= b, eq(a, b) is equivalent to a == b, ne(a, b) is equivalent to a != b, gt(a, b) is

equivalent to a > b and ge(a, b) is equivalent to a >= b. Note that these functions can return any value,

which may or may not be interpretable as a Boolean value. See comparisons for more information about rich

comparisons.

The logical operations are also generally applicable to all objects, and support truth tests, identity tests, and boolean operations:

operator.not_(obj)

operator.__not__(obj)

Return the outcome of not obj. (Note that there is no __not__() method for object instances; only the

interpreter core defines this operation. The result is affected by the __bool__() and __len__() methods.)

operator.truth(obj)

Return True if obj is true, and False otherwise. This is equivalent to using the bool constructor.

operator.is_(a, b)

Return a is b. Tests object identity.

operator.is_not(a, b)

Return a is not b. Tests object identity.

The mathematical and bitwise operations are the most numerous:

operator.abs(obj)

operator.__abs__(obj)

Return the absolute value of obj.

operator.add(a, b)

The Python Library Reference, Release 3.13.2



operator.__add__(a, b)

Return a + b, for a and b numbers.

operator.and_(a, b)

operator.__and__(a, b)

Return the bitwise and of a and b.

operator.floordiv(a, b)

operator.__floordiv__( a, b)

Return a // b.

operator.index(a)

operator.__index__(a)

Return a converted to an integer. Equivalent to a.__index__().

Changed in version 3.10: The result always has exact type int. Previously, the result could have been an

instance of a subclass of int.

operator.inv(obj)

operator.invert(obj)

operator.__inv__(obj)

operator.__invert__(obj)

Return the bitwise inverse of the number obj. This is equivalent to ~obj.

operator.lshift(a, b)

operator.__lshift__(a, b)

Return a shifted left by b.

operator.mod(a, b)

operator.__mod__(a, b)

Return a % b.

operator.mul(a, b)

operator.__mul__(a, b)

Return a * b, for a and b numbers.

operator.matmul(a, b)

operator.__matmul__(a, b)

Return a @ b.

Added in version 3.5.

operator.neg(obj)

operator.__neg__(obj)

Return obj negated (-obj).

operator.or_(a, b)

operator.__or__(a, b)

Return the bitwise or of a and b.

operator.pos(obj)

operator.__pos__(obj)

Return obj positive (+obj).

operator.pow(a, b)

operator.__pow__(a, b)

Return a ** b, for a and b numbers.

operator.rshift(a, b)

The Python Library Reference, Release 3.13.2



operator.__rshift__(a, b)

Return a shifted right by b.

operator.sub(a, b)

operator.__sub__(a, b)

Return a - b.

operator.truediv(a, b)

operator.__truediv__(a, b)

Return a / b where 2/3 is .66 rather than 0. This is also known as “true” division.

operator.xor(a, b)

operator.__xor__(a, b)

Return the bitwise exclusive or of a and b.

Operations which work with sequences (some of them with mappings too) include:

operator.concat(a, b)

operator.__concat__(a, b)

Return a + b for a and b sequences.

operator.contains(a, b)

operator.__contains__( a, b)

Return the outcome of the test b in a. Note the reversed operands.

operator.countOf(a, b)

Return the number of occurrences of b in a.

operator.delitem(a, b)

operator.__delitem__(a, b)

Remove the value of a at index b.

operator.getitem(a, b)

operator.__getitem__(a, b)

Return the value of a at index b.

operator.indexOf(a, b)

Return the index of the first of occurrence of b in a.

operator.setitem(a, b, c)

operator.__setitem__(a, b, c)

Set the value of a at index b to c.

operator.length_hint(obj, default=0)

Return an estimated length for the object obj. First try to return its actual length, then an estimate using

object.__length_hint__(), and finally return the default value.

Added in version 3.4.

The following operation works with callables:

operator.call(obj, / , *args, **kwargs)

operator.__call__(obj, / , *args, **kwargs)

Return obj(*args, **kwargs).

Added in version 3.11.

The operator module also defines tools for generalized attribute and item lookups. These are useful for making

fast field extractors as arguments for map(), sorted(), itertools.groupby(), or other functions that expect a function argument.

operator.attrgetter(attr)

The Python Library Reference, Release 3.13.2



operator.attrgetter(*attrs)

Return a callable object that fetches attr from its operand. If more than one attribute is requested, returns a

tuple of attributes. The attribute names can also contain dots. For example:

• After f = attrgetter('name'), the call f(b) returns b.name.

• After f = attrgetter('name', 'date'), the call f(b) returns (b.name, b.date).

• After f = attrgetter('name.first', 'name.last'), the call f(b) returns (b.name.first,

b.name.last).

Equivalent to:

def attrgetter(*items):

if any(not isinstance(item, str) for item in items):

raise TypeError('attribute name must be a string')

if len(items) == 1:

attr = items[0]

def g(obj):

return resolve_attr(obj, attr)

else:

def g(obj):

return tuple(resolve_attr(obj, attr) for attr in items)

return g

def resolve_attr(obj, attr):

for name in attr.split("."):

obj = getattr(obj, name)

return obj



operator.itemgetter(item)

operator.itemgetter(*items)

Return a callable object that fetches item from its operand using the operand’s __getitem__() method. If

multiple items are specified, returns a tuple of lookup values. For example:

• After f = itemgetter(2), the call f(r) returns r[2].

• After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3]).

Equivalent to:

def itemgetter(*items):

if len(items) == 1:

item = items[0]

def g(obj):

return obj[item]

else:

def g(obj):

return tuple(obj[item] for item in items)

return g



The items can be any type accepted by the operand’s __getitem__() method. Dictionaries accept any

hashable value. Lists, tuples, and strings accept an index or a slice:

>>> itemgetter(1)('ABCDEFG')

'B'

>>> itemgetter(1, 3, 5)('ABCDEFG')

('B', 'D', 'F')

>>> itemgetter(slice(2, None))('ABCDEFG')

'CDEFG'

>>> soldier = dict(rank='captain', name='dotterbart')

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> itemgetter('rank')(soldier)

'captain'



Example of using itemgetter() to retrieve specific fields from a tuple record:

>>> inventory = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]

>>> getcount = itemgetter(1)

>>> list(map(getcount, inventory))

[3, 2, 5, 1]

>>> sorted(inventory, key=getcount)

[('orange', 1), ('banana', 2), ('apple', 3), ('pear', 5)]



operator.methodcaller( name, / , *args, **kwargs)

Return a callable object that calls the method name on its operand. If additional arguments and/or keyword

arguments are given, they will be given to the method as well. For example:

• After f = methodcaller('name'), the call f(b) returns b.name().

• After f = methodcaller('name', 'foo', bar=1), the call f(b) returns b.name('foo',

bar=1) .

Equivalent to:

def methodcaller(name, /, *args, **kwargs):

def caller(obj):

return getattr(obj, name)(*args, **kwargs)

return caller



10.3.1 Mapping Operators to Functions

This table shows how abstract operations correspond to operator symbols in the Python syntax and the functions in

the operator module.



Operation Syntax Function

Addition a + b add(a, b)

Concatenation seq1 + seq2 concat(seq1, seq2)

Containment Test obj in seq contains(seq, obj)

Division a / b truediv(a, b)

Division a // b floordiv(a, b)

Bitwise And a & b and_(a, b)

Bitwise Exclusive Or a ^ b xor(a, b)

Bitwise Inversion ~ a invert(a)

Bitwise Or a | b or_(a, b)

Exponentiation a ** b pow(a, b)

Identity a is b is_(a, b)

Identity a is not b is_not(a, b)

Indexed Assignment obj[k] = v setitem(obj, k, v)

Indexed Deletion del obj[k] delitem(obj, k)

Indexing obj[k] getitem(obj, k)

Left Shift a << b lshift(a, b)

Modulo a % b mod(a, b)

Multiplication a * b mul(a, b)

Matrix Multiplication a @ b matmul(a, b)

Negation (Arithmetic) - a neg(a)

Negation (Logical) not a not_(a)

Positive + a pos(a)

continues on next page

The Python Library Reference, Release 3.13.2



Table 1 – continued from previous page

Operation Syntax Function

Right Shift a >> b rshift(a, b)

Slice Assignment seq[i:j] = values setitem(seq, slice(i, j), values) Slice Deletion del seq[i:j] delitem(seq, slice(i, j))

Slicing seq[i:j] getitem(seq, slice(i, j))

String Formatting s % obj mod(s, obj)

Subtraction a - b sub(a, b)

Truth Test obj truth(obj)

Ordering a < b lt(a, b)

Ordering a <= b le(a, b)

Equality a == b eq(a, b)

Difference a != b ne(a, b)

Ordering a >= b ge(a, b)

Ordering a > b gt(a, b)



10.3.2 In-place Operators

Many operations have an “in-place” version. Listed below are functions providing a more primitive access to in-place

operators than the usual syntax does; for example, the statement x += y is equivalent to x = operator.iadd(x, y). Another way to put it is to say that z = operator.iadd(x, y) is equivalent to the compound statement z = x; z += y.

In those examples, note that when an in-place method is called, the computation and assignment are performed in two separate steps. The in-place functions listed below only do the first step, calling the in-place method. The second step, assignment, is not handled.

For immutable targets such as strings, numbers, and tuples, the updated value is computed, but not assigned back to the input variable:

>>> a = 'hello'

>>> iadd(a, ' world')

'hello world'

>>> a

'hello'



For mutable targets such as lists and dictionaries, the in-place method will perform the update, so no subsequent assignment is necessary:

>>> s = ['h', 'e', 'l', 'l', 'o']

>>> iadd(s, [' ', 'w', 'o', 'r', 'l', 'd'])

['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd'] >>> s

['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd']



operator.iadd(a, b)

operator.__iadd__(a, b)

a = iadd(a, b) is equivalent to a += b.

operator.iand(a, b)

operator.__iand__(a, b)

a = iand(a, b) is equivalent to a &= b.

operator.iconcat(a, b)

operator.__iconcat__(a, b)

a = iconcat(a, b) is equivalent to a += b for a and b sequences.

operator.ifloordiv(a, b)

The Python Library Reference, Release 3.13.2



operator.__ifloordiv__(a, b)

a = ifloordiv(a, b) is equivalent to a //= b.

operator.ilshift(a, b)

operator.__ilshift__(a, b)

a = ilshift(a, b) is equivalent to a <<= b.

operator.imod(a, b)

operator.__imod__(a, b)

a = imod(a, b) is equivalent to a %= b.

operator.imul(a, b)

operator.__imul__(a, b)

a = imul(a, b) is equivalent to a *= b.

operator.imatmul(a, b)

operator.__imatmul__(a, b)

a = imatmul(a, b) is equivalent to a @= b.

Added in version 3.5.

operator.ior(a, b)

operator.__ior__(a, b)

a = ior(a, b) is equivalent to a |= b.

operator.ipow(a, b)

operator.__ipow__(a, b)

a = ipow(a, b) is equivalent to a **= b.

operator.irshift(a, b)

operator.__irshift__(a, b)

a = irshift(a, b) is equivalent to a >>= b.

operator.isub(a, b)

operator.__isub__(a, b)

a = isub(a, b) is equivalent to a -= b.

operator.itruediv(a, b)

operator.__itruediv__( a, b)

a = itruediv(a, b) is equivalent to a /= b.

operator.ixor(a, b)

operator.__ixor__(a, b)

a = ixor(a, b) is equivalent to a ^= b.



The Python Library Reference, Release 3.13.2





CHAPTER




ELEVEN



FILE AND DIRECTORY ACCESS



The modules described in this chapter deal with disk files and directories. For example, there are modules for reading the properties of files, manipulating paths in a portable way, and creating temporary files. The full list of modules in this chapter is:



11.1 pathlib — Object-oriented filesystem paths

Added in version 3.4.

Source code: Lib/pathlib/



This module offers classes representing filesystem paths with semantics appropriate for different operating systems.

Path classes are divided between pure paths, which provide purely computational operations without I/O, and concrete

paths, which inherit from pure paths but also provide I/O operations.





If you’ve never used this module before or just aren’t sure which class is right for your task, Path is most likely what

you need. It instantiates a concrete path for the platform the code is running on.

Pure paths are useful in some special cases; for example:

1. If you want to manipulate Windows paths on a Unix machine (or vice versa). You cannot instantiate a

WindowsPath when running on Unix, but you can instantiate PureWindowsPath.

The Python Library Reference, Release 3.13.2



2. You want to make sure that your code only manipulates paths without actually accessing the OS. In this case,

instantiating one of the pure classes may be useful since those simply don’t have any OS-accessing operations.



µ See also

PEP 428: The pathlib module – object-oriented filesystem paths.



µ See also

For low-level path manipulation on strings, you can also use the os.path module.



11.1.1 Basic use

Importing the main class:

>>> from pathlib import Path



Listing subdirectories:

>>> p = Path('.')

>>> [x for x in p.iterdir() if x.is_dir()]

[PosixPath('.hg'), PosixPath('docs'), PosixPath('dist'),

PosixPath('__pycache__'), PosixPath('build')]



Listing Python source files in this directory tree:

>>> list(p.glob('**/*.py'))

[PosixPath('test_pathlib.py'), PosixPath('setup.py'),

PosixPath('pathlib.py'), PosixPath('docs/conf.py'), PosixPath('build/lib/pathlib.py')]



Navigating inside a directory tree:

>>> p = Path('/etc')

>>> q = p / 'init.d' / 'reboot'

>>> q

PosixPath('/etc/init.d/reboot')

>>> q.resolve()

PosixPath('/etc/rc.d/init.d/halt')



Querying path properties:

>>> q.exists()

True

>>> q.is_dir()

False



Opening a file:

>>> with q.open() as f: f.readline()

...

'#!/bin/bash\n'



The Python Library Reference, Release 3.13.2



11.1.2 Exceptions

exception pathlib.UnsupportedOperation

An exception inheriting NotImplementedError that is raised when an unsupported operation is called on a

path object.

Added in version 3.13.



11.1.3 Pure paths

Pure path objects provide path-handling operations which don’t actually access a filesystem. There are three ways to access these classes, which we also call flavours:

class pathlib.PurePath(*pathsegments)

A generic class that represents the system’s path flavour (instantiating it creates either a PurePosixPath or a

PureWindowsPath):

>>> PurePath('setup.py') # Running on a Unix machine

PurePosixPath('setup.py')



Each element of pathsegments can be either a string representing a path segment, or an object implementing

the os.PathLike interface where the __fspath__() method returns a string, such as another path object:

>>> PurePath('foo', 'some/path', 'bar')

PurePosixPath('foo/some/path/bar')

>>> PurePath(Path('foo'), Path('bar'))

PurePosixPath('foo/bar')



When pathsegments is empty, the current directory is assumed:

>>> PurePath()

PurePosixPath('.')



If a segment is an absolute path, all previous segments are ignored (like os.path.join()):

>>> PurePath('/etc', '/usr', 'lib64')

PurePosixPath('/usr/lib64')

>>> PureWindowsPath('c:/Windows', 'd:bar')

PureWindowsPath('d:bar')



On Windows, the drive is not reset when a rooted relative path segment (e.g., r'\foo') is encountered:

>>> PureWindowsPath('c:/Windows', '/Program Files')

PureWindowsPath('c:/Program Files')



Spurious slashes and single dots are collapsed, but double dots ('..') and leading double slashes ('//') are

not, since this would change the meaning of a path for various reasons (e.g. symbolic links, UNC paths):

>>> PurePath('foo//bar')

PurePosixPath('foo/bar')

>>> PurePath('//foo/bar')

PurePosixPath('//foo/bar')

>>> PurePath('foo/./bar')

PurePosixPath('foo/bar')

>>> PurePath('foo/../bar')

PurePosixPath('foo/../bar')



(a naïve approach would make PurePosixPath('foo/../bar') equivalent to PurePosixPath('bar'),

which is wrong if foo is a symbolic link to another directory)

The Python Library Reference, Release 3.13.2



Pure path objects implement the os.PathLike interface, allowing them to be used anywhere the interface is

accepted.

Changed in version 3.6: Added support for the os.PathLike interface.

class pathlib.PurePosixPath(*pathsegments)

A subclass of PurePath, this path flavour represents non-Windows filesystem paths:

>>> PurePosixPath('/etc/hosts')

PurePosixPath('/etc/hosts')



pathsegments is specified similarly to PurePath.

class pathlib.PureWindowsPath(*pathsegments)

A subclass of PurePath, this path flavour represents Windows filesystem paths, including UNC paths:

>>> PureWindowsPath('c:/', 'Users', 'Ximénez')

PureWindowsPath('c:/Users/Ximénez')

>>> PureWindowsPath('//server/share/file')

PureWindowsPath('//server/share/file')



pathsegments is specified similarly to PurePath.

Regardless of the system you’re running on, you can instantiate all of these classes, since they don’t provide any operation that does system calls.



General properties

Paths are immutable and hashable. Paths of a same flavour are comparable and orderable. These properties respect the flavour’s case-folding semantics:

>>> PurePosixPath('foo') == PurePosixPath('FOO')

False

>>> PureWindowsPath('foo') == PureWindowsPath('FOO')

True

>>> PureWindowsPath('FOO') in { PureWindowsPath('foo') } True

>>> PureWindowsPath('C:') < PureWindowsPath('d:')

True



Paths of a different flavour compare unequal and cannot be ordered:

>>> PureWindowsPath('foo') == PurePosixPath('foo')

False

>>> PureWindowsPath('foo') < PurePosixPath('foo')

Traceback (most recent call last):

File "", line 1, in

TypeError: '<' not supported between instances of 'PureWindowsPath' and

, →'PurePosixPath'



Operators

The slash operator helps create child paths, like os.path.join(). If the argument is an absolute path, the previous path is ignored. On Windows, the drive is not reset when the argument is a rooted relative path (e.g., r'\foo'):

>>> p = PurePath('/etc')

>>> p

PurePosixPath('/etc')

>>> p / 'init.d' / 'apache2'

PurePosixPath('/etc/init.d/apache2')

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> q = PurePath('bin')

>>> '/usr' / q

PurePosixPath('/usr/bin')

>>> p / '/an_absolute_path'

PurePosixPath('/an_absolute_path')

>>> PureWindowsPath('c:/Windows', '/Program Files')

PureWindowsPath('c:/Program Files')



A path object can be used anywhere an object implementing os.PathLike is accepted:

>>> import os

>>> p = PurePath('/etc')

>>> os.fspath(p)

'/etc'



The string representation of a path is the raw filesystem path itself (in native form, e.g. with backslashes under Windows), which you can pass to any function taking a file path as a string:

>>> p = PurePath('/etc')

>>> str(p)

'/etc'

>>> p = PureWindowsPath('c:/Program Files')

>>> str(p)

'c:\\Program Files'



Similarly, calling bytes on a path gives the raw filesystem path as a bytes object, as encoded by os.fsencode():

>>> bytes(p)

b'/etc'



® Note

Calling bytes is only recommended under Unix. Under Windows, the unicode form is the canonical represen-

tation of filesystem paths.



Accessing individual parts

To access the individual “parts” (components) of a path, use the following property:

PurePath.parts

A tuple giving access to the path’s various components:

>>> p = PurePath('/usr/bin/python3')

>>> p.parts

('/', 'usr', 'bin', 'python3')

>>> p = PureWindowsPath('c:/Program Files/PSF')

>>> p.parts

('c:\\', 'Program Files', 'PSF')



(note how the drive and local root are regrouped in a single part)



The Python Library Reference, Release 3.13.2



Methods and properties

Pure paths provide the following methods and properties:

PurePath.parser

The implementation of the os.path module used for low-level path parsing and joining: either posixpath

or ntpath.

Added in version 3.13.

PurePath.drive

A string representing the drive letter or name, if any:

>>> PureWindowsPath('c:/Program Files/').drive

'c:'

>>> PureWindowsPath('/Program Files/').drive

''

>>> PurePosixPath('/etc').drive

''



UNC shares are also considered drives:

>>> PureWindowsPath('//host/share/foo.txt').drive

'\\\\host\\share'



PurePath.root

A string representing the (local or global) root, if any:

>>> PureWindowsPath('c:/Program Files/').root

'\\'

>>> PureWindowsPath('c:Program Files/').root

''

>>> PurePosixPath('/etc').root

'/'



UNC shares always have a root:

>>> PureWindowsPath('//host/share').root

'\\'



If the path starts with more than two successive slashes, PurePosixPath collapses them:

>>> PurePosixPath('//etc').root

'//'

>>> PurePosixPath('///etc').root

'/'

>>> PurePosixPath('////etc').root

'/'



® Note

This behavior conforms to The Open Group Base Specifications Issue 6, paragraph 4.11 Pathname Resolu-

tion:

“A pathname that begins with two successive slashes may be interpreted in an implementation-defined manner, although more than two leading slashes shall be treated as a single slash.”



PurePath.anchor

The concatenation of the drive and root:

The Python Library Reference, Release 3.13.2



>>> PureWindowsPath('c:/Program Files/').anchor

'c:\\'

>>> PureWindowsPath('c:Program Files/').anchor

'c:'

>>> PurePosixPath('/etc').anchor

'/'

>>> PureWindowsPath('//host/share').anchor

'\\\\host\\share\\'



PurePath.parents

An immutable sequence providing access to the logical ancestors of the path:

>>> p = PureWindowsPath('c:/foo/bar/setup.py')

>>> p.parents[0]

PureWindowsPath('c:/foo/bar')

>>> p.parents[1]

PureWindowsPath('c:/foo')

>>> p.parents[2]

PureWindowsPath('c:/')



Changed in version 3.10: The parents sequence now supports slices and negative index values.

PurePath.parent

The logical parent of the path:

>>> p = PurePosixPath('/a/b/c/d')

>>> p.parent

PurePosixPath('/a/b/c')



You cannot go past an anchor, or empty path:

>>> p = PurePosixPath('/')

>>> p.parent

PurePosixPath('/')

>>> p = PurePosixPath('.')

>>> p.parent

PurePosixPath('.')



® Note

This is a purely lexical operation, hence the following behaviour:

>>> p = PurePosixPath('foo/..')

>>> p.parent

PurePosixPath('foo')

If you want to walk an arbitrary filesystem path upwards, it is recommended to first call Path.resolve() so as to resolve symlinks and eliminate ".." components.



PurePath.name

A string representing the final path component, excluding the drive and root, if any:

>>> PurePosixPath('my/library/setup.py').name

'setup.py'



UNC drive names are not considered:

The Python Library Reference, Release 3.13.2



>>> PureWindowsPath('//some/share/setup.py').name

'setup.py'

>>> PureWindowsPath('//some/share').name

''



PurePath.suffix

The last dot-separated portion of the final component, if any:

>>> PurePosixPath('my/library/setup.py').suffix

'.py'

>>> PurePosixPath('my/library.tar.gz').suffix

'.gz'

>>> PurePosixPath('my/library').suffix

''



This is commonly called the file extension.

PurePath.suffixes

A list of the path’s suffixes, often called file extensions:

>>> PurePosixPath('my/library.tar.gar').suffixes

['.tar', '.gar']

>>> PurePosixPath('my/library.tar.gz').suffixes

['.tar', '.gz']

>>> PurePosixPath('my/library').suffixes

[]



PurePath.stem

The final path component, without its suffix:

>>> PurePosixPath('my/library.tar.gz').stem

'library.tar'

>>> PurePosixPath('my/library.tar').stem

'library'

>>> PurePosixPath('my/library').stem

'library'



PurePath.as_posix()

Return a string representation of the path with forward slashes (/):

>>> p = PureWindowsPath('c:\\windows')

>>> str(p)

'c:\\windows'

>>> p.as_posix()

'c:/windows'



PurePath.is_absolute()

Return whether the path is absolute or not. A path is considered absolute if it has both a root and (if the flavour

allows) a drive:

>>> PurePosixPath('/a/b').is_absolute()

True

>>> PurePosixPath('a/b').is_absolute()

False

>>> PureWindowsPath('c:/a/b').is_absolute()

True

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> PureWindowsPath('/a/b').is_absolute()

False

>>> PureWindowsPath('c:').is_absolute()

False

>>> PureWindowsPath('//some/share').is_absolute()

True



PurePath.is_relative_to(other)

Return whether or not this path is relative to the other path.

>>> p = PurePath('/etc/passwd')

>>> p.is_relative_to('/etc')

True

>>> p.is_relative_to('/usr')

False



This method is string-based; it neither accesses the filesystem nor treats “..” segments specially. The following

code is equivalent:

>>> u = PurePath('/usr')

>>> u == p or u in p.parents

False



Added in version 3.9.

Deprecated since version 3.12, will be removed in version 3.14: Passing additional arguments is deprecated;

if supplied, they are joined with other.

PurePath.is_reserved()

With PureWindowsPath, return True if the path is considered reserved under Windows, False otherwise.

With PurePosixPath, False is always returned.

Changed in version 3.13: Windows path names that contain a colon, or end with a dot or a space, are considered

reserved. UNC paths may be reserved.

Deprecated since version 3.13, will be removed in version 3.15: This method is deprecated; use os.path.

isreserved() to detect reserved paths on Windows.

PurePath.joinpath(*pathsegments)

Calling this method is equivalent to combining the path with each of the given pathsegments in turn:

>>> PurePosixPath('/etc').joinpath('passwd')

PurePosixPath('/etc/passwd')

>>> PurePosixPath('/etc').joinpath(PurePosixPath('passwd'))

PurePosixPath('/etc/passwd')

>>> PurePosixPath('/etc').joinpath('init.d', 'apache2')

PurePosixPath('/etc/init.d/apache2')

>>> PureWindowsPath('c:').joinpath('/Program Files')

PureWindowsPath('c:/Program Files')



PurePath.full_match(pattern, *, case_sensitive=None)

Match this path against the provided glob-style pattern. Return True if matching is successful, False other-

wise. For example:

>>> PurePath('a/b.py').full_match('a/*.py')

True

>>> PurePath('a/b.py').full_match('*.py')

False

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> PurePath('/a/b/c.py').full_match('/a/**')

True

>>> PurePath('/a/b/c.py').full_match('**/*.py')

True



µ See also

Pattern language documentation.



As with other methods, case-sensitivity follows platform defaults:

>>> PurePosixPath('b.py').full_match('*.PY')

False

>>> PureWindowsPath('b.py').full_match('*.PY')

True



Set case_sensitive to True or False to override this behaviour.

Added in version 3.13.

PurePath.match(pattern, *, case_sensitive=None)

Match this path against the provided non-recursive glob-style pattern. Return True if matching is successful,

False otherwise.

This method is similar to full_match(), but empty patterns aren’t allowed (ValueError is raised), the

recursive wildcard “**” isn’t supported (it acts like non-recursive “*”), and if a relative pattern is provided,

then matching is done from the right:

>>> PurePath('a/b.py').match('*.py')

True

>>> PurePath('/a/b/c.py').match('b/*.py')

True

>>> PurePath('/a/b/c.py').match('a/*.py')

False



Changed in version 3.12: The pattern parameter accepts a path-like object.

Changed in version 3.12: The case_sensitive parameter was added.

PurePath.relative_to(other, walk_up=False)

Compute a version of this path relative to the path represented by other. If it’s impossible, ValueError is

raised:

>>> p = PurePosixPath('/etc/passwd')

>>> p.relative_to('/')

PurePosixPath('etc/passwd')

>>> p.relative_to('/etc')

PurePosixPath('passwd')

>>> p.relative_to('/usr')

Traceback (most recent call last):

File "", line 1, in

File "pathlib.py", line 941, in relative_to

raise ValueError(error_message.format(str(self), str(formatted)))

ValueError: '/etc/passwd' is not in the subpath of '/usr' OR one path is␣

, →relative and the other is absolute.



When walk_up is false (the default), the path must start with other. When the argument is true, .. entries

may be added to form the relative path. In all other cases, such as the paths referencing different drives,

The Python Library Reference, Release 3.13.2



ValueError is raised.:

>>> p.relative_to('/usr', walk_up=True)

PurePosixPath('../etc/passwd')

>>> p.relative_to('foo', walk_up=True)

Traceback (most recent call last):

File "", line 1, in

File "pathlib.py", line 941, in relative_to

raise ValueError(error_message.format(str(self), str(formatted)))

ValueError: '/etc/passwd' is not on the same drive as 'foo' OR one path is␣

, →relative and the other is absolute.



Á Warning

This function is part of PurePath and works with strings. It does not check or access the underlying file structure. This can impact the walk_up option as it assumes that no symlinks are present in the path; call

resolve() first if necessary to resolve symlinks.



Changed in version 3.12: The walk_up parameter was added (old behavior is the same as walk_up=False).

Deprecated since version 3.12, will be removed in version 3.14: Passing additional positional arguments is

deprecated; if supplied, they are joined with other.

PurePath.with_name(name)

Return a new path with the name changed. If the original path doesn’t have a name, ValueError is raised:

>>> p = PureWindowsPath('c:/Downloads/pathlib.tar.gz')

>>> p.with_name('setup.py')

PureWindowsPath('c:/Downloads/setup.py')

>>> p = PureWindowsPath('c:/')

>>> p.with_name('setup.py')

Traceback (most recent call last):

File "", line 1, in

File "/home/antoine/cpython/default/Lib/pathlib.py", line 751, in with_name

raise ValueError("%r has an empty name" % (self,))

ValueError: PureWindowsPath('c:/') has an empty name



PurePath.with_stem(stem)

Return a new path with the stem changed. If the original path doesn’t have a name, ValueError is raised:

>>> p = PureWindowsPath('c:/Downloads/draft.txt')

>>> p.with_stem('final')

PureWindowsPath('c:/Downloads/final.txt')

>>> p = PureWindowsPath('c:/Downloads/pathlib.tar.gz')

>>> p.with_stem('lib')

PureWindowsPath('c:/Downloads/lib.gz')

>>> p = PureWindowsPath('c:/')

>>> p.with_stem('')

Traceback (most recent call last):

File "", line 1, in

File "/home/antoine/cpython/default/Lib/pathlib.py", line 861, in with_stem

return self.with_name(stem + self.suffix)

File "/home/antoine/cpython/default/Lib/pathlib.py", line 851, in with_name

raise ValueError("%r has an empty name" % (self,))

ValueError: PureWindowsPath('c:/') has an empty name



Added in version 3.9.

The Python Library Reference, Release 3.13.2



PurePath.with_suffix(suffix)

Return a new path with the suffix changed. If the original path doesn’t have a suffix, the new suffix is

appended instead. If the suffix is an empty string, the original suffix is removed:

>>> p = PureWindowsPath('c:/Downloads/pathlib.tar.gz')

>>> p.with_suffix('.bz2')

PureWindowsPath('c:/Downloads/pathlib.tar.bz2')

>>> p = PureWindowsPath('README')

>>> p.with_suffix('.txt')

PureWindowsPath('README.txt')

>>> p = PureWindowsPath('README.txt')

>>> p.with_suffix('')

PureWindowsPath('README')



PurePath.with_segments(*pathsegments)

Create a new path object of the same type by combining the given pathsegments. This method is called when-

ever a derivative path is created, such as from parent and relative_to(). Subclasses may override this

method to pass information to derivative paths, for example:

from pathlib import PurePosixPath

class MyPath(PurePosixPath):

def __init__(self, *pathsegments, session_id):

super().__init__(*pathsegments)

self.session_id = session_id

def with_segments(self, *pathsegments):

return type(self)(*pathsegments, session_id=self.session_id)

etc = MyPath('/etc', session_id=42)

hosts = etc / 'hosts'

print(hosts.session_id) # 42



Added in version 3.12.



11.1.4 Concrete paths

Concrete paths are subclasses of the pure path classes. In addition to operations provided by the latter, they also provide methods to do system calls on path objects. There are three ways to instantiate concrete paths:

class pathlib.Path(*pathsegments)

A subclass of PurePath, this class represents concrete paths of the system’s path flavour (instantiating it

creates either a PosixPath or a WindowsPath):

>>> Path('setup.py')

PosixPath('setup.py')



pathsegments is specified similarly to PurePath.

class pathlib.PosixPath(*pathsegments)

A subclass of Path and PurePosixPath, this class represents concrete non-Windows filesystem paths:

>>> PosixPath('/etc/hosts')

PosixPath('/etc/hosts')



pathsegments is specified similarly to PurePath.

Changed in version 3.13: Raises UnsupportedOperation on Windows. In previous versions,

NotImplementedError was raised instead.

The Python Library Reference, Release 3.13.2



class pathlib.WindowsPath(*pathsegments)

A subclass of Path and PureWindowsPath, this class represents concrete Windows filesystem paths:

>>> WindowsPath('c:/', 'Users', 'Ximénez')

WindowsPath('c:/Users/Ximénez')



pathsegments is specified similarly to PurePath.

Changed in version 3.13: Raises UnsupportedOperation on non-Windows platforms. In previous versions,

NotImplementedError was raised instead.

You can only instantiate the class flavour that corresponds to your system (allowing system calls on non-compatible path flavours could lead to bugs or failures in your application):

>>> import os

>>> os.name

'posix'

>>> Path('setup.py')

PosixPath('setup.py')

>>> PosixPath('setup.py')

PosixPath('setup.py')

>>> WindowsPath('setup.py')

Traceback (most recent call last):

File "", line 1, in

File "pathlib.py", line 798, in __new__

% (cls.__name__,))

UnsupportedOperation: cannot instantiate 'WindowsPath' on your system



Some concrete path methods can raise an OSError if a system call fails (for example because the path doesn’t exist).



Parsing and generating URIs

Concrete path objects can be created from, and represented as, ‘file’ URIs conforming to RFC 8089.



® Note

File URIs are not portable across machines with different filesystem encodings.



classmethod Path.from_uri(uri)

Return a new path object from parsing a ‘file’ URI. For example:

>>> p = Path.from_uri('file:///etc/hosts')

PosixPath('/etc/hosts')



On Windows, DOS device and UNC paths may be parsed from URIs:

>>> p = Path.from_uri('file:///c:/windows')

WindowsPath('c:/windows')

>>> p = Path.from_uri('file://server/share')

WindowsPath('//server/share')



Several variant forms are supported:

>>> p = Path.from_uri('file:////server/share')

WindowsPath('//server/share')

>>> p = Path.from_uri('file://///server/share')

WindowsPath('//server/share')

>>> p = Path.from_uri('file:c:/windows')

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

WindowsPath('c:/windows')

>>> p = Path.from_uri('file:/c|/windows')

WindowsPath('c:/windows')



ValueError is raised if the URI does not start with file:, or the parsed path isn’t absolute.

Added in version 3.13.

Path.as_uri()

Represent the path as a ‘file’ URI. ValueError is raised if the path isn’t absolute.

>>> p = PosixPath('/etc/passwd')

>>> p.as_uri()

'file:///etc/passwd'

>>> p = WindowsPath('c:/Windows')

>>> p.as_uri()

'file:///c:/Windows'



For historical reasons, this method is also available from PurePath objects. However, its use of os.

fsencode() makes it strictly impure.



Expanding and resolving paths

classmethod Path.home()

Return a new path object representing the user’s home directory (as returned by os.path.expanduser()

with ~ construct). If the home directory can’t be resolved, RuntimeError is raised.

>>> Path.home()

PosixPath('/home/antoine')



Added in version 3.5.

Path.expanduser()

Return a new path with expanded ~ and ~user constructs, as returned by os.path.expanduser(). If a

home directory can’t be resolved, RuntimeError is raised.

>>> p = PosixPath('~/films/Monty Python')

>>> p.expanduser()

PosixPath('/home/eric/films/Monty Python')



Added in version 3.5.

classmethod Path.cwd()

Return a new path object representing the current directory (as returned by os.getcwd()):

>>> Path.cwd()

PosixPath('/home/antoine/pathlib')



Path.absolute()

Make the path absolute, without normalization or resolving symlinks. Returns a new path object:

>>> p = Path('tests')

>>> p

PosixPath('tests')

>>> p.absolute()

PosixPath('/home/antoine/pathlib/tests')



The Python Library Reference, Release 3.13.2



Path.resolve(strict=False)

Make the path absolute, resolving any symlinks. A new path object is returned:

>>> p = Path()

>>> p

PosixPath('.')

>>> p.resolve()

PosixPath('/home/antoine/pathlib')



“..” components are also eliminated (this is the only method to do so):

>>> p = Path('docs/../setup.py')

>>> p.resolve()

PosixPath('/home/antoine/pathlib/setup.py')



If a path doesn’t exist or a symlink loop is encountered, and strict is True, OSError is raised. If strict is False,

the path is resolved as far as possible and any remainder is appended without checking whether it exists.

Changed in version 3.6: The strict parameter was added (pre-3.6 behavior is strict).

Changed in version 3.13: Symlink loops are treated like other errors: OSError is raised in strict mode, and

no exception is raised in non-strict mode. In previous versions, RuntimeError is raised no matter the value

of strict.

Path.readlink()

Return the path to which the symbolic link points (as returned by os.readlink()):

>>> p = Path('mylink')

>>> p.symlink_to('setup.py')

>>> p.readlink()

PosixPath('setup.py')



Added in version 3.9.

Changed in version 3.13: Raises UnsupportedOperation if os.readlink() is not available. In previous

versions, NotImplementedError was raised.



Querying file type and status

Changed in version 3.8: exists(), is_dir(), is_file(), is_mount(), is_symlink(),

is_block_device(), is_char_device(), is_fifo(), is_socket() now return False instead of raising an exception for paths that contain characters unrepresentable at the OS level.

Path.stat(*, follow_symlinks=True)

Return an os.stat_result object containing information about this path, like os.stat(). The result is

looked up at each call to this method.

This method normally follows symlinks; to stat a symlink add the argument follow_symlinks=False, or

use lstat().

>>> p = Path('setup.py')

>>> p.stat().st_size

956

>>> p.stat().st_mtime

1327883547.852554



Changed in version 3.10: The follow_symlinks parameter was added.

Path.lstat()

Like Path.stat() but, if the path points to a symbolic link, return the symbolic link’s information rather

than its target’s.

The Python Library Reference, Release 3.13.2



Path.exists(*, follow_symlinks=True)

Return True if the path points to an existing file or directory.

This method normally follows symlinks; to check if a symlink exists, add the argument

follow_symlinks=False .

>>> Path('.').exists()

True

>>> Path('setup.py').exists()

True

>>> Path('/etc').exists()

True

>>> Path('nonexistentfile').exists()

False



Changed in version 3.12: The follow_symlinks parameter was added.

Path.is_file(*, follow_symlinks=True)

Return True if the path points to a regular file, False if it points to another kind of file.

False is also returned if the path doesn’t exist or is a broken symlink; other errors (such as permission errors)

are propagated.

This method normally follows symlinks; to exclude symlinks, add the argument follow_symlinks=False.

Changed in version 3.13: The follow_symlinks parameter was added.

Path.is_dir(*, follow_symlinks=True)

Return True if the path points to a directory, False if it points to another kind of file.

False is also returned if the path doesn’t exist or is a broken symlink; other errors (such as permission errors)

are propagated.

This method normally follows symlinks; to exclude symlinks to directories, add the argument

follow_symlinks=False .

Changed in version 3.13: The follow_symlinks parameter was added.

Path.is_symlink()

Return True if the path points to a symbolic link, False otherwise.

False is also returned if the path doesn’t exist; other errors (such as permission errors) are propagated.

Path.is_junction()

Return True if the path points to a junction, and False for any other type of file. Currently only Windows

supports junctions.

Added in version 3.12.

Path.is_mount()

Return True if the path is a mount point: a point in a file system where a different file system has been mounted.

On POSIX, the function checks whether path’s parent, path/.., is on a different device than path, or whether

path/.. and path point to the same i-node on the same device — this should detect mount points for all Unix

and POSIX variants. On Windows, a mount point is considered to be a drive letter root (e.g. c:\), a UNC

share (e.g. \\server\share), or a mounted filesystem directory.

Added in version 3.7.

Changed in version 3.12: Windows support was added.

Path.is_socket()

Return True if the path points to a Unix socket (or a symbolic link pointing to a Unix socket), False if it

points to another kind of file.

False is also returned if the path doesn’t exist or is a broken symlink; other errors (such as permission errors)

are propagated.

The Python Library Reference, Release 3.13.2



Path.is_fifo()

Return True if the path points to a FIFO (or a symbolic link pointing to a FIFO), False if it points to another

kind of file.

False is also returned if the path doesn’t exist or is a broken symlink; other errors (such as permission errors)

are propagated.

Path.is_block_device()

Return True if the path points to a block device (or a symbolic link pointing to a block device), False if it

points to another kind of file.

False is also returned if the path doesn’t exist or is a broken symlink; other errors (such as permission errors)

are propagated.

Path.is_char_device()

Return True if the path points to a character device (or a symbolic link pointing to a character device), False

if it points to another kind of file.

False is also returned if the path doesn’t exist or is a broken symlink; other errors (such as permission errors)

are propagated.

Path.samefile(other_path)

Return whether this path points to the same file as other_path, which can be either a Path object, or a string.

The semantics are similar to os.path.samefile() and os.path.samestat().

An OSError can be raised if either file cannot be accessed for some reason.

>>> p = Path('spam')

>>> q = Path('eggs')

>>> p.samefile(q)

False

>>> p.samefile('spam')

True



Added in version 3.5.



Reading and writing files

Path.open(mode=’r’, buffering=-1, encoding=None, errors=None, newline=None)

Open the file pointed to by the path, like the built-in open() function does:

>>> p = Path('setup.py')

>>> with p.open() as f:

... f.readline()

...

'#!/usr/bin/env python3\n'



Path.read_text(encoding=None, errors=None, newline=None)

Return the decoded contents of the pointed-to file as a string:

>>> p = Path('my_text_file')

>>> p.write_text('Text file contents')

18

>>> p.read_text()

'Text file contents'



The file is opened and then closed. The optional parameters have the same meaning as in open().

Added in version 3.5.

Changed in version 3.13: The newline parameter was added.

The Python Library Reference, Release 3.13.2



Path.read_bytes()

Return the binary contents of the pointed-to file as a bytes object:

>>> p = Path('my_binary_file')

>>> p.write_bytes(b'Binary file contents')

20

>>> p.read_bytes()

b'Binary file contents'



Added in version 3.5.

Path.write_text(data, encoding=None, errors=None, newline=None)

Open the file pointed to in text mode, write data to it, and close the file:

>>> p = Path('my_text_file')

>>> p.write_text('Text file contents')

18

>>> p.read_text()

'Text file contents'



An existing file of the same name is overwritten. The optional parameters have the same meaning as in open().

Added in version 3.5.

Changed in version 3.10: The newline parameter was added.

Path.write_bytes(data)

Open the file pointed to in bytes mode, write data to it, and close the file:

>>> p = Path('my_binary_file')

>>> p.write_bytes(b'Binary file contents')

20

>>> p.read_bytes()

b'Binary file contents'



An existing file of the same name is overwritten.

Added in version 3.5.



Reading directories

Path.iterdir()

When the path points to a directory, yield path objects of the directory contents:

>>> p = Path('docs')

>>> for child in p.iterdir(): child

...

PosixPath('docs/conf.py')

PosixPath('docs/_templates')

PosixPath('docs/make.bat')

PosixPath('docs/index.rst')

PosixPath('docs/_build')

PosixPath('docs/_static')

PosixPath('docs/Makefile')



The children are yielded in arbitrary order, and the special entries '.' and '..' are not included. If a file is

removed from or added to the directory after creating the iterator, it is unspecified whether a path object for

that file is included.

If the path is not a directory or otherwise inaccessible, OSError is raised.

The Python Library Reference, Release 3.13.2



Path.glob(pattern, *, case_sensitive=None, recurse_symlinks=False)

Glob the given relative pattern in the directory represented by this path, yielding all matching files (of any

kind):

>>> sorted(Path('.').glob('*.py'))

[PosixPath('pathlib.py'), PosixPath('setup.py'), PosixPath('test_pathlib.py')]

>>> sorted(Path('.').glob('*/*.py'))

[PosixPath('docs/conf.py')]

>>> sorted(Path('.').glob('**/*.py'))

[PosixPath('build/lib/pathlib.py'),

PosixPath('docs/conf.py'),

PosixPath('pathlib.py'),

PosixPath('setup.py'),

PosixPath('test_pathlib.py')]



µ See also

Pattern language documentation.



By default, or when the case_sensitive keyword-only argument is set to None, this method matches paths us-

ing platform-specific casing rules: typically, case-sensitive on POSIX, and case-insensitive on Windows. Set

case_sensitive to True or False to override this behaviour.

By default, or when the recurse_symlinks keyword-only argument is set to False, this method follows symlinks

except when expanding “**” wildcards. Set recurse_symlinks to True to always follow symlinks.

Raises an auditing event pathlib.Path.glob with arguments self, pattern.

Changed in version 3.12: The case_sensitive parameter was added.

Changed in version 3.13: The recurse_symlinks parameter was added.

Changed in version 3.13: The pattern parameter accepts a path-like object.

Changed in version 3.13: Any OSError exceptions raised from scanning the filesystem are suppressed. In

previous versions, such exceptions are suppressed in many cases, but not all.

Path.rglob(pattern, *, case_sensitive=None, recurse_symlinks=False)

Glob the given relative pattern recursively. This is like calling Path.glob() with “**/” added in front of the

pattern.



µ See also

Pattern language and Path.glob() documentation.



Raises an auditing event pathlib.Path.rglob with arguments self, pattern.

Changed in version 3.12: The case_sensitive parameter was added.

Changed in version 3.13: The recurse_symlinks parameter was added.

Changed in version 3.13: The pattern parameter accepts a path-like object.

Path.walk(top_down=True, on_error=None, follow_symlinks=False)

Generate the file names in a directory tree by walking the tree either top-down or bottom-up.

For each directory in the directory tree rooted at self (including self but excluding ‘.’ and ‘..’), the method

yields a 3-tuple of (dirpath, dirnames, filenames).

dirpath is a Path to the directory currently being walked, dirnames is a list of strings for the names of subdirec-

tories in dirpath (excluding '.' and '..'), and filenames is a list of strings for the names of the non-directory The Python Library Reference, Release 3.13.2



files in dirpath. To get a full path (which begins with self) to a file or directory in dirpath, do dirpath /

name . Whether or not the lists are sorted is file system-dependent.

If the optional argument top_down is true (which is the default), the triple for a directory is generated before

the triples for any of its subdirectories (directories are walked top-down). If top_down is false, the triple for

a directory is generated after the triples for all of its subdirectories (directories are walked bottom-up). No

matter the value of top_down, the list of subdirectories is retrieved before the triples for the directory and its

subdirectories are walked.

When top_down is true, the caller can modify the dirnames list in-place (for example, using del or slice

assignment), and Path.walk() will only recurse into the subdirectories whose names remain in dirnames.

This can be used to prune the search, or to impose a specific order of visiting, or even to inform Path.walk()

about directories the caller creates or renames before it resumes Path.walk() again. Modifying dirnames

when top_down is false has no effect on the behavior of Path.walk() since the directories in dirnames have

already been generated by the time dirnames is yielded to the caller.

By default, errors from os.scandir() are ignored. If the optional argument on_error is specified, it should

be a callable; it will be called with one argument, an OSError instance. The callable can handle the error to

continue the walk or re-raise it to stop the walk. Note that the filename is available as the filename attribute

of the exception object.

By default, Path.walk() does not follow symbolic links, and instead adds them to the filenames list. Set

follow_symlinks to true to resolve symlinks and place them in dirnames and filenames as appropriate for their

targets, and consequently visit directories pointed to by symlinks (where supported).



® Note

Be aware that setting follow_symlinks to true can lead to infinite recursion if a link points to a parent

directory of itself. Path.walk() does not keep track of the directories it has already visited.



® Note

Path.walk() assumes the directories it walks are not modified during execution. For example, if a

directory from dirnames has been replaced with a symlink and follow_symlinks is false, Path.walk() will still try to descend into it. To prevent such behavior, remove directories from dirnames as appropriate.



® Note

Unlike os.walk(), Path.walk() lists symlinks to directories in filenames if follow_symlinks is false.



This example displays the number of bytes used by all files in each directory, while ignoring __pycache__

directories:

from pathlib import Path

for root, dirs, files in Path("cpython/Lib/concurrent").walk(on_error=print):

print(

root,

"consumes",

sum((root / file).stat().st_size for file in files),

"bytes in",

len(files),

"non-directory files"

)

if '__pycache__' in dirs:

dirs.remove('__pycache__')

The Python Library Reference, Release 3.13.2



This next example is a simple implementation of shutil.rmtree(). Walking the tree bottom-up is essential

as rmdir() doesn’t allow deleting a directory before it is empty:

# Delete everything reachable from the directory "top".

# CAUTION: This is dangerous! For example, if top == Path('/'),

# it could delete all of your files.

for root, dirs, files in top.walk(top_down=False):

for name in files:

(root / name).unlink()

for name in dirs:

(root / name).rmdir()



Added in version 3.12.



Creating files and directories

Path.touch(mode=0o666, exist_ok=True)

Create a file at this given path. If mode is given, it is combined with the process’s umask value to determine

the file mode and access flags. If the file already exists, the function succeeds when exist_ok is true (and its

modification time is updated to the current time), otherwise FileExistsError is raised.



µ See also

The open(), write_text() and write_bytes() methods are often used to create files.



Path.mkdir(mode=0o777, parents=False, exist_ok=False)

Create a new directory at this given path. If mode is given, it is combined with the process’s umask value to

determine the file mode and access flags. If the path already exists, FileExistsError is raised.

If parents is true, any missing parents of this path are created as needed; they are created with the default

permissions without taking mode into account (mimicking the POSIX mkdir -p command).

If parents is false (the default), a missing parent raises FileNotFoundError.

If exist_ok is false (the default), FileExistsError is raised if the target directory already exists.

If exist_ok is true, FileExistsError will not be raised unless the given path already exists in the file system

and is not a directory (same behavior as the POSIX mkdir -p command).

Changed in version 3.5: The exist_ok parameter was added.

Path.symlink_to(target, target_is_directory=False)

Make this path a symbolic link pointing to target.

On Windows, a symlink represents either a file or a directory, and does not morph to the target dynamically. If

the target is present, the type of the symlink will be created to match. Otherwise, the symlink will be created as

a directory if target_is_directory is true or a file symlink (the default) otherwise. On non-Windows platforms,

target_is_directory is ignored.

>>> p = Path('mylink')

>>> p.symlink_to('setup.py')

>>> p.resolve()

PosixPath('/home/antoine/pathlib/setup.py')

>>> p.stat().st_size

956

>>> p.lstat().st_size

8



The Python Library Reference, Release 3.13.2



® Note

The order of arguments (link, target) is the reverse of os.symlink()’s.



Changed in version 3.13: Raises UnsupportedOperation if os.symlink() is not available. In previous

versions, NotImplementedError was raised.

Path.hardlink_to(target)

Make this path a hard link to the same file as target.



® Note

The order of arguments (link, target) is the reverse of os.link()’s.



Added in version 3.10.

Changed in version 3.13: Raises UnsupportedOperation if os.link() is not available. In previous ver-

sions, NotImplementedError was raised.



Renaming and deleting

Path.rename(target)

Rename this file or directory to the given target, and return a new Path instance pointing to target. On Unix,

if target exists and is a file, it will be replaced silently if the user has permission. On Windows, if target exists,

FileExistsError will be raised. target can be either a string or another path object:

>>> p = Path('foo')

>>> p.open('w').write('some text')

9

>>> target = Path('bar')

>>> p.rename(target)

PosixPath('bar')

>>> target.open().read()

'some text'



The target path may be absolute or relative. Relative paths are interpreted relative to the current working

directory, not the directory of the Path object.

It is implemented in terms of os.rename() and gives the same guarantees.

Changed in version 3.8: Added return value, return the new Path instance.

Path.replace(target)

Rename this file or directory to the given target, and return a new Path instance pointing to target. If target

points to an existing file or empty directory, it will be unconditionally replaced.

The target path may be absolute or relative. Relative paths are interpreted relative to the current working

directory, not the directory of the Path object.

Changed in version 3.8: Added return value, return the new Path instance.

Path.unlink(missing_ok=False)

Remove this file or symbolic link. If the path points to a directory, use Path.rmdir() instead.

If missing_ok is false (the default), FileNotFoundError is raised if the path does not exist.

If missing_ok is true, FileNotFoundError exceptions will be ignored (same behavior as the POSIX rm -f

command).

Changed in version 3.8: The missing_ok parameter was added.

The Python Library Reference, Release 3.13.2



Path.rmdir()

Remove this directory. The directory must be empty.



Permissions and ownership

Path.owner(*, follow_symlinks=True)

Return the name of the user owning the file. KeyError is raised if the file’s user identifier (UID) isn’t found

in the system database.

This method normally follows symlinks; to get the owner of the symlink, add the argument

follow_symlinks=False .

Changed in version 3.13: Raises UnsupportedOperation if the pwd module is not available. In earlier

versions, NotImplementedError was raised.

Changed in version 3.13: The follow_symlinks parameter was added.

Path.group(*, follow_symlinks=True)

Return the name of the group owning the file. KeyError is raised if the file’s group identifier (GID) isn’t found

in the system database.

This method normally follows symlinks; to get the group of the symlink, add the argument

follow_symlinks=False .

Changed in version 3.13: Raises UnsupportedOperation if the grp module is not available. In earlier

versions, NotImplementedError was raised.

Changed in version 3.13: The follow_symlinks parameter was added.

Path.chmod(mode, *, follow_symlinks=True)

Change the file mode and permissions, like os.chmod().

This method normally follows symlinks. Some Unix flavours support changing permissions on the symlink

itself; on these platforms you may add the argument follow_symlinks=False, or use lchmod().

>>> p = Path('setup.py')

>>> p.stat().st_mode

33277

>>> p.chmod(0o444)

>>> p.stat().st_mode

33060



Changed in version 3.10: The follow_symlinks parameter was added.

Path.lchmod(mode)

Like Path.chmod() but, if the path points to a symbolic link, the symbolic link’s mode is changed rather

than its target’s.



11.1.5 Pattern language

The following wildcards are supported in patterns for full_match(), glob() and rglob():

** (entire segment)

Matches any number of file or directory segments, including zero.

* (entire segment)

Matches one file or directory segment.

* (part of a segment)

Matches any number of non-separator characters, including zero.

?

Matches one non-separator character.

The Python Library Reference, Release 3.13.2



[seq]

Matches one character in seq.

[!seq]

Matches one character not in seq.

For a literal match, wrap the meta-characters in brackets. For example, "[?]" matches the character "?".

The “**” wildcard enables recursive globbing. A few examples:



Pattern Meaning

“**/*” Any path with at least one segment.

“**/*.py” Any path with a final segment ending “.py”.

“assets/**” Any path starting with “assets/”.

“assets/**/*” Any path starting with “assets/”, excluding “assets/” itself.



® Note

Globbing with the “**” wildcard visits every directory in the tree. Large directory trees may take a long time to

search.



Changed in version 3.13: Globbing with a pattern that ends with “**” returns both files and directories. In previous versions, only directories were returned.

In Path.glob() and rglob(), a trailing slash may be added to the pattern to match only directories.

Changed in version 3.11: Globbing with a pattern that ends with a pathname components separator (sep or altsep) returns only directories.



11.1.6 Comparison to the glob module

The patterns accepted and results generated by Path.glob() and Path.rglob() differ slightly from those by the

glob module:

1. Files beginning with a dot are not special in pathlib. This is like passing include_hidden=True to glob.

glob() .

2. “**” pattern components are always recursive in pathlib. This is like passing recursive=True to glob.

glob() .

3. “**” pattern components do not follow symlinks by default in pathlib. This behaviour has no equivalent in

glob.glob(), but you can pass recurse_symlinks=True to Path.glob() for compatible behaviour.

4. Like all PurePath and Path objects, the values returned from Path.glob() and Path.rglob() don’t

include trailing slashes.

5. The values returned from pathlib’s path.glob() and path.rglob() include the path as a prefix, unlike the

results of glob.glob(root_dir=path).

6. The values returned from pathlib’s path.glob() and path.rglob() may include path itself, for example

when globbing “**”, whereas the results of glob.glob(root_dir=path) never include an empty string

that would correspond to path.



11.1.7 Comparison to the os and os.path modules

pathlib implements path operations using PurePath and Path objects, and so it’s said to be object-oriented. On the

other hand, the os and os.path modules supply functions that work with low-level str and bytes objects, which is a more procedural approach. Some users consider the object-oriented style to be more readable.

Many functions in os and os.path support bytes paths and paths relative to directory descriptors. These features aren’t available in pathlib.

The Python Library Reference, Release 3.13.2



Python’s str and bytes types, and portions of the os and os.path modules, are written in C and are very speedy. pathlib is written in pure Python and is often slower, but rarely slow enough to matter.

pathlib’s path normalization is slightly more opinionated and consistent than os.path. For example, whereas os.

path.abspath() eliminates “..” segments from a path, which may change its meaning if symlinks are involved,

Path.absolute() preserves these segments for greater safety.

pathlib’s path normalization may render it unsuitable for some applications:

1. pathlib normalizes Path("my_folder/") to Path("my_folder"), which changes a path’s meaning when

supplied to various operating system APIs and command-line utilities. Specifically, the absence of a trailing

separator may allow the path to be resolved as either a file or directory, rather than a directory only.

2. pathlib normalizes Path("./my_program") to Path("my_program"), which changes a path’s meaning

when used as an executable search path, such as in a shell or when spawning a child process. Specifically, the

absence of a separator in the path may force it to be looked up in PATH rather than the current directory.

As a consequence of these differences, pathlib is not a drop-in replacement for os.path.



Corresponding tools

Below is a table mapping various os functions to their corresponding PurePath/Path equivalent.



os and os.path pathlib

os.path.dirname() PurePath.parent

os.path.basename() PurePath.name

os.path.splitext() PurePath.stem, PurePath.suffix

os.path.join() PurePath.joinpath()

os.path.isabs() PurePath.is_absolute()

os.path.relpath() 1 PurePath.relative_to()

os.path.expanduser() 2 Path.expanduser()

os.path.realpath() Path.resolve()

os.path.abspath() 3 Path.absolute()

os.path.exists() Path.exists()

os.path.isfile() Path.is_file()

os.path.isdir() Path.is_dir()

os.path.islink() Path.is_symlink()

os.path.isjunction() Path.is_junction()

os.path.ismount() Path.is_mount()

os.path.samefile() Path.samefile()

os.getcwd() Path.cwd()

os.stat() Path.stat()

os.lstat() Path.lstat()

os.listdir() Path.iterdir()

os.walk() 4 Path.walk()

os.mkdir(), os.makedirs() Path.mkdir()

os.link() Path.hardlink_to()

os.symlink() Path.symlink_to()

os.readlink() Path.readlink()

os.rename() Path.rename()

os.replace() Path.replace()

os.remove(), os.unlink() Path.unlink()

os.rmdir() Path.rmdir()

os.chmod() Path.chmod()

os.lchmod() Path.lchmod()



The Python Library Reference, Release 3.13.2



11.2 os.path — Common pathname manipulations

Source code: Lib/genericpath.py, Lib/posixpath.py (for POSIX) and Lib/ntpath.py (for Windows).



This module implements some useful functions on pathnames. To read or write files see open(), and for accessing

the filesystem see the os module. The path parameters can be passed as strings, or bytes, or any object implementing

the os.PathLike protocol.

Unlike a Unix shell, Python does not do any automatic path expansions. Functions such as expanduser() and

expandvars() can be invoked explicitly when an application desires shell-like path expansion. (See also the glob module.)



µ See also

The pathlib module offers high-level path objects.



® Note

All of these functions accept either only bytes or only string objects as their parameters. The result is an object

of the same type, if a path or file name is returned.



® Note

Since different operating systems have different path name conventions, there are several versions of this module

in the standard library. The os.path module is always the path module suitable for the operating system Python

is running on, and therefore usable for local paths. However, you can also import and use the individual modules

if you want to manipulate a path that is always in one of the different formats. They all have the same interface:

• posixpath for UNIX-style paths

• ntpath for Windows paths



Changed in version 3.8: exists(), lexists(), isdir(), isfile(), islink(), and ismount() now return False instead of raising an exception for paths that contain characters or bytes unrepresentable at the OS level.

os.path.abspath(path)

Return a normalized absolutized version of the pathname path. On most platforms, this is equivalent to calling

the function normpath() as follows: normpath(join(os.getcwd(), path)).

Changed in version 3.6: Accepts a path-like object.

os.path.basename(path)

Return the base name of pathname path. This is the second element of the pair returned by passing path to the

function split(). Note that the result of this function is different from the Unix basename program; where

basename for '/foo/bar/' returns 'bar', the basename() function returns an empty string ('').

1 os.path.relpath() calls abspath() to make paths absolute and remove “..” parts, whereas PurePath.relative_to() is a lexical

operation that raises ValueError when its inputs’ anchors differ (e.g. if one path is absolute and the other relative.)

2 os.path.expanduser() returns the path unchanged if the home directory can’t be resolved, whereas Path.expanduser() raises

RuntimeError .

3 os.path.abspath() removes “..” components without resolving symlinks, which may change the meaning of the path, whereas Path.

absolute() leaves any “..” components in the path.

4 os.walk() always follows symlinks when categorizing paths into dirnames and filenames, whereas Path.walk() categorizes all symlinks

into filenames when follow_symlinks is false (the default.)

The Python Library Reference, Release 3.13.2



Changed in version 3.6: Accepts a path-like object.

os.path.commonpath(paths)

Return the longest common sub-path of each pathname in the iterable paths. Raise ValueError if paths

contain both absolute and relative pathnames, if paths are on different drives, or if paths is empty. Unlike

commonprefix(), this returns a valid path.

Added in version 3.5.

Changed in version 3.6: Accepts a sequence of path-like objects.

Changed in version 3.13: Any iterable can now be passed, rather than just sequences.

os.path.commonprefix(list)

Return the longest path prefix (taken character-by-character) that is a prefix of all paths in list. If list is empty,

return the empty string ('').



® Note

This function may return invalid paths because it works a character at a time. To obtain a valid path, see

commonpath() .

>>> os.path.commonprefix(['/usr/lib', '/usr/local/lib']) '/usr/l'

>>> os.path.commonpath(['/usr/lib', '/usr/local/lib']) '/usr'



Changed in version 3.6: Accepts a path-like object.

os.path.dirname(path)

Return the directory name of pathname path. This is the first element of the pair returned by passing path to

the function split().

Changed in version 3.6: Accepts a path-like object.

os.path.exists(path)

Return True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic

links. On some platforms, this function may return False if permission is not granted to execute os.stat()

on the requested file, even if the path physically exists.

Changed in version 3.3: path can now be an integer: True is returned if it is an open file descriptor, False

otherwise.

Changed in version 3.6: Accepts a path-like object.

os.path.lexists(path)

Return True if path refers to an existing path, including broken symbolic links. Equivalent to exists() on

platforms lacking os.lstat().

Changed in version 3.6: Accepts a path-like object.

os.path.expanduser(path)

On Unix and Windows, return the argument with an initial component of ~ or ~user replaced by that user’s

home directory.

On Unix, an initial ~ is replaced by the environment variable HOME if it is set; otherwise the current user’s

home directory is looked up in the password directory through the built-in module pwd. An initial ~user is

looked up directly in the password directory.

On Windows, USERPROFILE will be used if set, otherwise a combination of HOMEPATH and HOMEDRIVE will

be used. An initial ~user is handled by checking that the last directory component of the current user’s home

directory matches USERNAME, and replacing it if so.

The Python Library Reference, Release 3.13.2



If the expansion fails or if the path does not begin with a tilde, the path is returned unchanged.

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.8: No longer uses HOME on Windows.

os.path.expandvars(path)

Return the argument with environment variables expanded. Substrings of the form $name or ${name} are

replaced by the value of environment variable name. Malformed variable names and references to non-existing

variables are left unchanged.

On Windows, %name% expansions are supported in addition to $name and ${name}.

Changed in version 3.6: Accepts a path-like object.

os.path.getatime(path)

Return the time of last access of path. The return value is a floating-point number giving the number of seconds

since the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible.

os.path.getmtime(path)

Return the time of last modification of path. The return value is a floating-point number giving the number of

seconds since the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible.

Changed in version 3.6: Accepts a path-like object.

os.path.getctime(path)

Return the system’s ctime which, on some systems (like Unix) is the time of the last metadata change, and,

on others (like Windows), is the creation time for path. The return value is a number giving the number of

seconds since the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible.

Changed in version 3.6: Accepts a path-like object.

os.path.getsize(path)

Return the size, in bytes, of path. Raise OSError if the file does not exist or is inaccessible.

Changed in version 3.6: Accepts a path-like object.

os.path.isabs(path)

Return True if path is an absolute pathname. On Unix, that means it begins with a slash, on Windows that it

begins with two (back)slashes, or a drive letter, colon, and (back)slash together.

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.13: On Windows, returns False if the given path starts with exactly one (back)slash.

os.path.isfile(path)

Return True if path is an existing regular file. This follows symbolic links, so both islink() and

isfile() can be true for the same path.

Changed in version 3.6: Accepts a path-like object.

os.path.isdir(path)

Return True if path is an existing directory. This follows symbolic links, so both islink() and isdir()

can be true for the same path.

Changed in version 3.6: Accepts a path-like object.

os.path.isjunction(path)

Return True if path refers to an existing directory entry that is a junction. Always return False if junctions

are not supported on the current platform.

Added in version 3.12.

os.path.islink(path)

Return True if path refers to an existing directory entry that is a symbolic link. Always False if symbolic

links are not supported by the Python runtime.

Changed in version 3.6: Accepts a path-like object.

The Python Library Reference, Release 3.13.2



os.path.ismount(path)

Return True if pathname path is a mount point: a point in a file system where a different file system has been

mounted. On POSIX, the function checks whether path’s parent, path/.., is on a different device than path, or

whether path/.. and path point to the same i-node on the same device — this should detect mount points for

all Unix and POSIX variants. It is not able to reliably detect bind mounts on the same filesystem. On Windows,

a drive letter root and a share UNC are always mount points, and for any other path GetVolumePathName is

called to see if it is different from the input path.

Changed in version 3.4: Added support for detecting non-root mount points on Windows.

Changed in version 3.6: Accepts a path-like object.

os.path.isdevdrive(path)

Return True if pathname path is located on a Windows Dev Drive. A Dev Drive is optimized for developer

scenarios, and offers faster performance for reading and writing files. It is recommended for use for source

code, temporary build directories, package caches, and other IO-intensive operations.

May raise an error for an invalid path, for example, one without a recognizable drive, but returns False on

platforms that do not support Dev Drives. See the Windows documentation for information on enabling and

creating Dev Drives.

Added in version 3.12.

Changed in version 3.13: The function is now available on all platforms, and will always return False on those

that have no support for Dev Drives

os.path.isreserved(path)

Return True if path is a reserved pathname on the current system.

On Windows, reserved filenames include those that end with a space or dot; those that contain colons (i.e.

file streams such as “name:stream”), wildcard characters (i.e. '*?"<>'), pipe, or ASCII control characters;

as well as DOS device names such as “NUL”, “CON”, “CONIN$”, “CONOUT$”, “AUX”, “PRN”, “COM1”,

and “LPT1”.



® Note

This function approximates rules for reserved paths on most Windows systems. These rules change over time in various Windows releases. This function may be updated in future Python releases as changes to the rules become broadly available.



Availability: Windows.

Added in version 3.13.

os.path.join(path, *paths)

Join one or more path segments intelligently. The return value is the concatenation of path and all members of

*paths, with exactly one directory separator following each non-empty part, except the last. That is, the result

will only end in a separator if the last part is either empty or ends in a separator. If a segment is an absolute

path (which on Windows requires both a drive and a root), then all previous segments are ignored and joining

continues from the absolute path segment.

On Windows, the drive is not reset when a rooted path segment (e.g., r'\foo') is encountered. If a segment

is on a different drive or is an absolute path, all previous segments are ignored and the drive is reset. Note that

since there is a current directory for each drive, os.path.join("c:", "foo") represents a path relative

to the current directory on drive C: (c:foo), not c:\foo.

Changed in version 3.6: Accepts a path-like object for path and paths.

os.path.normcase(path)

Normalize the case of a pathname. On Windows, convert all characters in the pathname to lowercase, and also

convert forward slashes to backward slashes. On other operating systems, return the path unchanged.

Changed in version 3.6: Accepts a path-like object.

The Python Library Reference, Release 3.13.2



os.path.normpath(path)

Normalize a pathname by collapsing redundant separators and up-level references so that A//B, A/B/, A/

./B and A/foo/../B all become A/B. This string manipulation may change the meaning of a path that

contains symbolic links. On Windows, it converts forward slashes to backward slashes. To normalize case, use

normcase().



® Note

On POSIX systems, in accordance with IEEE Std 1003.1 2013 Edition; 4.13 Pathname Resolution, if a pathname begins with exactly two slashes, the first component following the leading characters may be interpreted in an implementation-defined manner, although more than two leading characters shall be treated as a single character.



Changed in version 3.6: Accepts a path-like object.

os.path.realpath(path, *, strict=False)

Return the canonical path of the specified filename, eliminating any symbolic links encountered in the path

(if they are supported by the operating system). On Windows, this function will also resolve MS-DOS (also

called 8.3) style names such as C:\\PROGRA~1 to C:\\Program Files.

If a path doesn’t exist or a symlink loop is encountered, and strict is True, OSError is raised. If strict is False

these errors are ignored, and so the result might be missing or otherwise inaccessible.



® Note

This function emulates the operating system’s procedure for making a path canonical, which differs slightly between Windows and UNIX with respect to how links and subsequent path components interact.

Operating system APIs make paths canonical as needed, so it’s not normally necessary to call this function.



Changed in version 3.6: Accepts a path-like object.

Changed in version 3.8: Symbolic links and junctions are now resolved on Windows.

Changed in version 3.10: The strict parameter was added.

os.path.relpath(path, start=os.curdir)

Return a relative filepath to path either from the current directory or from an optional start directory. This

is a path computation: the filesystem is not accessed to confirm the existence or nature of path or start. On

Windows, ValueError is raised when path and start are on different drives.

start defaults to os.curdir.

Changed in version 3.6: Accepts a path-like object.

os.path.samefile(path1, path2)

Return True if both pathname arguments refer to the same file or directory. This is determined by the device

number and i-node number and raises an exception if an os.stat() call on either pathname fails.

Changed in version 3.2: Added Windows support.

Changed in version 3.4: Windows now uses the same implementation as all other platforms.

Changed in version 3.6: Accepts a path-like object.

os.path.sameopenfile(fp1, fp2)

Return True if the file descriptors fp1 and fp2 refer to the same file.

Changed in version 3.2: Added Windows support.

Changed in version 3.6: Accepts a path-like object.

The Python Library Reference, Release 3.13.2



os.path.samestat(stat1, stat2)

Return True if the stat tuples stat1 and stat2 refer to the same file. These structures may have been returned

by os.fstat(), os.lstat(), or os.stat(). This function implements the underlying comparison used

by samefile() and sameopenfile().

Changed in version 3.4: Added Windows support.

Changed in version 3.6: Accepts a path-like object.

os.path.split(path)

Split the pathname path into a pair, (head, tail) where tail is the last pathname component and head is

everything leading up to that. The tail part will never contain a slash; if path ends in a slash, tail will be empty.

If there is no slash in path, head will be empty. If path is empty, both head and tail are empty. Trailing slashes

are stripped from head unless it is the root (one or more slashes only). In all cases, join(head, tail)

returns a path to the same location as path (but the strings may differ). Also see the functions dirname() and

basename().

Changed in version 3.6: Accepts a path-like object.

os.path.splitdrive(path)

Split the pathname path into a pair (drive, tail) where drive is either a mount point or the empty string.

On systems which do not use drive specifications, drive will always be the empty string. In all cases, drive +

tail will be the same as path.

On Windows, splits a pathname into drive/UNC sharepoint and relative path.

If the path contains a drive letter, drive will contain everything up to and including the colon:

>>> splitdrive("c:/dir")

("c:", "/dir")



If the path contains a UNC path, drive will contain the host name and share:

>>> splitdrive("//host/computer/dir")

("//host/computer", "/dir")



Changed in version 3.6: Accepts a path-like object.

os.path.splitroot(path)

Split the pathname path into a 3-item tuple (drive, root, tail) where drive is a device name or mount

point, root is a string of separators after the drive, and tail is everything after the root. Any of these items may

be the empty string. In all cases, drive + root + tail will be the same as path.

On POSIX systems, drive is always empty. The root may be empty (if path is relative), a single forward slash (if

path is absolute), or two forward slashes (implementation-defined per IEEE Std 1003.1-2017; 4.13 Pathname

Resolution.) For example:

>>> splitroot('/home/sam')

('', '/', 'home/sam')

>>> splitroot('//home/sam')

('', '//', 'home/sam')

>>> splitroot('///home/sam')

('', '/', '//home/sam')



On Windows, drive may be empty, a drive-letter name, a UNC share, or a device name. The root may be

empty, a forward slash, or a backward slash. For example:

>>> splitroot('C:/Users/Sam')

('C:', '/', 'Users/Sam')

>>> splitroot('//Server/Share/Users/Sam')

('//Server/Share', '/', 'Users/Sam')



Added in version 3.12.

The Python Library Reference, Release 3.13.2



os.path.splitext(path)

Split the pathname path into a pair (root, ext) such that root + ext == path, and the extension, ext,

is empty or begins with a period and contains at most one period.

If the path contains no extension, ext will be '':

>>> splitext('bar')

('bar', '')



If the path contains an extension, then ext will be set to this extension, including the leading period. Note that

previous periods will be ignored:

>>> splitext('foo.bar.exe')

('foo.bar', '.exe')

>>> splitext('/foo/bar.exe')

('/foo/bar', '.exe')



Leading periods of the last component of the path are considered to be part of the root:

>>> splitext('.cshrc')

('.cshrc', '')

>>> splitext('/foo/....jpg')

('/foo/....jpg', '')



Changed in version 3.6: Accepts a path-like object.

os.path.supports_unicode_filenames

True if arbitrary Unicode strings can be used as file names (within limitations imposed by the file system).



11.3 stat — Interpreting stat() results

Source code: Lib/stat.py



The stat module defines constants and functions for interpreting the results of os.stat(), os.fstat() and

os.lstat() (if they exist). For complete details about the stat(), fstat() and lstat() calls, consult the documentation for your system.

Changed in version 3.4: The stat module is backed by a C implementation.

The stat module defines the following functions to test for specific file types:

stat.S_ISDIR(mode)

Return non-zero if the mode is from a directory.

stat.S_ISCHR(mode)

Return non-zero if the mode is from a character special device file.

stat.S_ISBLK(mode)

Return non-zero if the mode is from a block special device file.

stat.S_ISREG(mode)

Return non-zero if the mode is from a regular file.

stat.S_ISFIFO(mode)

Return non-zero if the mode is from a FIFO (named pipe).

stat.S_ISLNK(mode)

Return non-zero if the mode is from a symbolic link.

The Python Library Reference, Release 3.13.2



stat.S_ISSOCK(mode)

Return non-zero if the mode is from a socket.

stat.S_ISDOOR(mode)

Return non-zero if the mode is from a door.

Added in version 3.4.

stat.S_ISPORT(mode)

Return non-zero if the mode is from an event port.

Added in version 3.4.

stat.S_ISWHT(mode)

Return non-zero if the mode is from a whiteout.

Added in version 3.4.

Two additional functions are defined for more general manipulation of the file’s mode:

stat.S_IMODE(mode)

Return the portion of the file’s mode that can be set by os.chmod()—that is, the file’s permission bits, plus

the sticky bit, set-group-id, and set-user-id bits (on systems that support them).

stat.S_IFMT(mode)

Return the portion of the file’s mode that describes the file type (used by the S_IS*() functions above).

Normally, you would use the os.path.is*() functions for testing the type of a file; the functions here are useful when you are doing multiple tests of the same file and wish to avoid the overhead of the stat() system call for each

test. These are also useful when checking for information about a file that isn’t handled by os.path, like the tests for block and character devices.

Example:

import os, sys

from stat import *

def walktree(top, callback):

'''recursively descend the directory tree rooted at top,

calling the callback function for each regular file'''

for f in os.listdir(top):

pathname = os.path.join(top, f)

mode = os.lstat(pathname).st_mode

if S_ISDIR(mode):

# It's a directory, recurse into it

walktree(pathname, callback)

elif S_ISREG(mode):

# It's a file, call the callback function

callback(pathname)

else:

# Unknown file type, print a message

print('Skipping %s' % pathname)

def visitfile(file):

print('visiting', file)

if __name__ == '__main__':

walktree(sys.argv[1], visitfile)



An additional utility function is provided to convert a file’s mode in a human readable string:

The Python Library Reference, Release 3.13.2



stat.filemode(mode)

Convert a file’s mode to a string of the form ‘-rwxrwxrwx’.

Added in version 3.3.

Changed in version 3.4: The function supports S_IFDOOR, S_IFPORT and S_IFWHT .

All the variables below are simply symbolic indexes into the 10-tuple returned by os.stat(), os.fstat() or

os.lstat().

stat.ST_MODE

Inode protection mode.

stat.ST_INO

Inode number.

stat.ST_DEV

Device inode resides on.

stat.ST_NLINK

Number of links to the inode.

stat.ST_UID

User id of the owner.

stat.ST_GID

Group id of the owner.

stat.ST_SIZE

Size in bytes of a plain file; amount of data waiting on some special files.

stat.ST_ATIME

Time of last access.

stat.ST_MTIME

Time of last modification.

stat.ST_CTIME

The “ctime” as reported by the operating system. On some systems (like Unix) is the time of the last metadata

change, and, on others (like Windows), is the creation time (see platform documentation for details).

The interpretation of “file size” changes according to the file type. For plain files this is the size of the file in bytes. For FIFOs and sockets under most flavors of Unix (including Linux in particular), the “size” is the number of bytes

waiting to be read at the time of the call to os.stat(), os.fstat(), or os.lstat(); this can sometimes be useful, especially for polling one of these special files after a non-blocking open. The meaning of the size field for other character and block devices varies more, depending on the implementation of the underlying system call.

The variables below define the flags used in the ST_MODE field.

Use of the functions above is more portable than use of the first set of flags:

stat.S_IFSOCK

Socket.

stat.S_IFLNK

Symbolic link.

stat.S_IFREG

Regular file.

stat.S_IFBLK

Block device.

stat.S_IFDIR

Directory.

The Python Library Reference, Release 3.13.2



stat.S_IFCHR

Character device.

stat.S_IFIFO

FIFO.

stat.S_IFDOOR

Door.

Added in version 3.4.

stat.S_IFPORT

Event port.

Added in version 3.4.

stat.S_IFWHT

Whiteout.

Added in version 3.4.



® Note

S_IFDOOR, S_IFPORT or S_IFWHT are defined as 0 when the platform does not have support for the file types.



The following flags can also be used in the mode argument of os.chmod():

stat.S_ISUID

Set UID bit.

stat.S_ISGID

Set-group-ID bit. This bit has several special uses. For a directory it indicates that BSD semantics is to be used

for that directory: files created there inherit their group ID from the directory, not from the effective group ID

of the creating process, and directories created there will also get the S_ISGID bit set. For a file that does not

have the group execution bit (S_IXGRP) set, the set-group-ID bit indicates mandatory file/record locking (see

also S_ENFMT).

stat.S_ISVTX

Sticky bit. When this bit is set on a directory it means that a file in that directory can be renamed or deleted

only by the owner of the file, by the owner of the directory, or by a privileged process.

stat.S_IRWXU

Mask for file owner permissions.

stat.S_IRUSR

Owner has read permission.

stat.S_IWUSR

Owner has write permission.

stat.S_IXUSR

Owner has execute permission.

stat.S_IRWXG

Mask for group permissions.

stat.S_IRGRP

Group has read permission.

stat.S_IWGRP

Group has write permission.

The Python Library Reference, Release 3.13.2



stat.S_IXGRP

Group has execute permission.

stat.S_IRWXO

Mask for permissions for others (not in group).

stat.S_IROTH

Others have read permission.

stat.S_IWOTH

Others have write permission.

stat.S_IXOTH

Others have execute permission.

stat.S_ENFMT

System V file locking enforcement. This flag is shared with S_ISGID: file/record locking is enforced on files

that do not have the group execution bit (S_IXGRP) set.

stat.S_IREAD

Unix V7 synonym for S_IRUSR.

stat.S_IWRITE

Unix V7 synonym for S_IWUSR.

stat.S_IEXEC

Unix V7 synonym for S_IXUSR.

The following flags can be used in the flags argument of os.chflags():

stat.UF_SETTABLE

All user settable flags.

Added in version 3.13.

stat.UF_NODUMP

Do not dump the file.

stat.UF_IMMUTABLE

The file may not be changed.

stat.UF_APPEND

The file may only be appended to.

stat.UF_OPAQUE

The directory is opaque when viewed through a union stack.

stat.UF_NOUNLINK

The file may not be renamed or deleted.

stat.UF_COMPRESSED

The file is stored compressed (macOS 10.6+).

stat.UF_TRACKED

Used for handling document IDs (macOS)

Added in version 3.13.

stat.UF_DATAVAULT

The file needs an entitlement for reading or writing (macOS 10.13+)

Added in version 3.13.



The Python Library Reference, Release 3.13.2



stat.UF_HIDDEN

The file should not be displayed in a GUI (macOS 10.5+).

stat.SF_SETTABLE

All super-user changeable flags

Added in version 3.13.

stat.SF_SUPPORTED

All super-user supported flags

Availability: macOS

Added in version 3.13.

stat.SF_SYNTHETIC

All super-user read-only synthetic flags

Availability: macOS

Added in version 3.13.

stat.SF_ARCHIVED

The file may be archived.

stat.SF_IMMUTABLE

The file may not be changed.

stat.SF_APPEND

The file may only be appended to.

stat.SF_RESTRICTED

The file needs an entitlement to write to (macOS 10.13+)

Added in version 3.13.

stat.SF_NOUNLINK

The file may not be renamed or deleted.

stat.SF_SNAPSHOT

The file is a snapshot file.

stat.SF_FIRMLINK

The file is a firmlink (macOS 10.15+)

Added in version 3.13.

stat.SF_DATALESS

The file is a dataless object (macOS 10.15+)

Added in version 3.13.

See the *BSD or macOS systems man page chflags(2) for more information.

On Windows, the following file attribute constants are available for use when testing bits in the

st_file_attributes member returned by os.stat(). See the Windows API documentation for more detail on the meaning of these constants.

stat.FILE_ATTRIBUTE_ARCHIVE

stat.FILE_ATTRIBUTE_COMPRESSED

stat.FILE_ATTRIBUTE_DEVICE

stat.FILE_ATTRIBUTE_DIRECTORY

stat.FILE_ATTRIBUTE_ENCRYPTED

stat.FILE_ATTRIBUTE_HIDDEN

stat.FILE_ATTRIBUTE_INTEGRITY_STREAM

The Python Library Reference, Release 3.13.2



stat.FILE_ATTRIBUTE_NORMAL

stat.FILE_ATTRIBUTE_NOT_CONTENT_INDEXED

stat.FILE_ATTRIBUTE_NO_SCRUB_DATA

stat.FILE_ATTRIBUTE_OFFLINE

stat.FILE_ATTRIBUTE_READONLY

stat.FILE_ATTRIBUTE_REPARSE_POINT

stat.FILE_ATTRIBUTE_SPARSE_FILE

stat.FILE_ATTRIBUTE_SYSTEM

stat.FILE_ATTRIBUTE_TEMPORARY

stat.FILE_ATTRIBUTE_VIRTUAL

Added in version 3.5.

On Windows, the following constants are available for comparing against the st_reparse_tag member returned

by os.lstat(). These are well-known constants, but are not an exhaustive list.

stat.IO_REPARSE_TAG_SYMLINK

stat.IO_REPARSE_TAG_MOUNT_POINT

stat.IO_REPARSE_TAG_APPEXECLINK

Added in version 3.8.



11.4 filecmp — File and Directory Comparisons

Source code: Lib/filecmp.py



The filecmp module defines functions to compare files and directories, with various optional time/correctness trade-

offs. For comparing files, see also the difflib module.

The filecmp module defines the following functions:

filecmp.cmp(f1, f2, shallow=True)

Compare the files named f1 and f2, returning True if they seem equal, False otherwise.

If shallow is true and the os.stat() signatures (file type, size, and modification time) of both files are iden-

tical, the files are taken to be equal.

Otherwise, the files are treated as different if their sizes or contents differ.

Note that no external programs are called from this function, giving it portability and efficiency.

This function uses a cache for past comparisons and the results, with cache entries invalidated if the os.stat()

information for the file changes. The entire cache may be cleared using clear_cache().

filecmp.cmpfiles(dir1, dir2, common, shallow=True)

Compare the files in the two directories dir1 and dir2 whose names are given by common.

Returns three lists of file names: match, mismatch, errors. match contains the list of files that match, mismatch

contains the names of those that don’t, and errors lists the names of files which could not be compared. Files

are listed in errors if they don’t exist in one of the directories, the user lacks permission to read them or if the

comparison could not be done for some other reason.

The shallow parameter has the same meaning and default value as for filecmp.cmp().

For example, cmpfiles('a', 'b', ['c', 'd/e']) will compare a/c with b/c and a/d/e with b/d/e.

'c' and 'd/e' will each be in one of the three returned lists.

filecmp.clear_cache()

Clear the filecmp cache. This may be useful if a file is compared so quickly after it is modified that it is within

the mtime resolution of the underlying filesystem.

Added in version 3.4.

The Python Library Reference, Release 3.13.2



11.4.1 The dircmp class

class filecmp.dircmp(a, b, ignore=None, hide=None, *, shallow=True)

Construct a new directory comparison object, to compare the directories a and b. ignore is a list of names to

ignore, and defaults to filecmp.DEFAULT_IGNORES. hide is a list of names to hide, and defaults to [os.

curdir, os.pardir] .

The dircmp class compares files by doing shallow comparisons as described for filecmp.cmp() by default

using the shallow parameter.

Changed in version 3.13: Added the shallow parameter.

The dircmp class provides the following methods:

report()

Print (to sys.stdout) a comparison between a and b.

report_partial_closure()

Print a comparison between a and b and common immediate subdirectories.

report_full_closure()

Print a comparison between a and b and common subdirectories (recursively).

The dircmp class offers a number of interesting attributes that may be used to get various bits of information

about the directory trees being compared.

Note that via __getattr__() hooks, all attributes are computed lazily, so there is no speed penalty if only

those attributes which are lightweight to compute are used.

left

The directory a.

right

The directory b.

left_list

Files and subdirectories in a, filtered by hide and ignore.

right_list

Files and subdirectories in b, filtered by hide and ignore.

common

Files and subdirectories in both a and b.

left_only

Files and subdirectories only in a.

right_only

Files and subdirectories only in b.

common_dirs

Subdirectories in both a and b.

common_files

Files in both a and b.

common_funny

Names in both a and b, such that the type differs between the directories, or names for which os.stat() reports an error.

same_files

Files which are identical in both a and b, using the class’s file comparison operator.



The Python Library Reference, Release 3.13.2



diff_files

Files which are in both a and b, whose contents differ according to the class’s file comparison operator.

funny_files

Files which are in both a and b, but could not be compared.

subdirs

A dictionary mapping names in common_dirs to dircmp instances (or MyDirCmp instances if this

instance is of type MyDirCmp, a subclass of dircmp).

Changed in version 3.10: Previously entries were always dircmp instances. Now entries are the same

type as self, if self is a subclass of dircmp.

filecmp.DEFAULT_IGNORES

Added in version 3.4.

List of directories ignored by dircmp by default.

Here is a simplified example of using the subdirs attribute to search recursively through two directories to show common different files:

>>> from filecmp import dircmp

>>> def print_diff_files(dcmp):

... for name in dcmp.diff_files:

... print("diff_file %s found in %s and %s" % (name, dcmp.left, ... dcmp.right))

... for sub_dcmp in dcmp.subdirs.values():

... print_diff_files(sub_dcmp)

...

>>> dcmp = dircmp('dir1', 'dir2')

>>> print_diff_files(dcmp)



11.5 tempfile — Generate temporary files and directories

Source code: Lib/tempfile.py



This module creates temporary files and directories. It works on all supported platforms. TemporaryFile,

NamedTemporaryFile, TemporaryDirectory, and SpooledTemporaryFile are high-level interfaces which

provide automatic cleanup and can be used as context managers. mkstemp() and mkdtemp() are lower-level func-tions which require manual cleanup.

All the user-callable functions and constructors take additional arguments which allow direct control over the location and name of temporary files and directories. Files names used by this module include a string of random characters which allows those files to be securely created in shared temporary directories. To maintain backward compatibility, the argument order is somewhat odd; it is recommended to use keyword arguments for clarity.

The module defines the following user-callable items:

tempfile.TemporaryFile(mode=’w+b’, buffering=-1, encoding=None, newline=None, suffix=None,

prefix=None, dir=None, *, errors=None)

Return a file-like object that can be used as a temporary storage area. The file is created securely, using the same

rules as mkstemp(). It will be destroyed as soon as it is closed (including an implicit close when the object

is garbage collected). Under Unix, the directory entry for the file is either not created at all or is removed

immediately after the file is created. Other platforms do not support this; your code should not rely on a

temporary file created using this function having or not having a visible name in the file system.

The resulting object can be used as a context manager (see Examples). On completion of the context or de-

struction of the file object the temporary file will be removed from the filesystem.

The Python Library Reference, Release 3.13.2



The mode parameter defaults to 'w+b' so that the file created can be read and written without being closed.

Binary mode is used so that it behaves consistently on all platforms without regard for the data that is stored.

buffering, encoding, errors and newline are interpreted as for open().

The dir, prefix and suffix parameters have the same meaning and defaults as with mkstemp().

The returned object is a true file object on POSIX platforms. On other platforms, it is a file-like object whose

file attribute is the underlying true file object.

The os.O_TMPFILE flag is used if it is available and works (Linux-specific, requires Linux kernel 3.11 or

later).

On platforms that are neither Posix nor Cygwin, TemporaryFile is an alias for NamedTemporaryFile.

Raises an auditing event tempfile.mkstemp with argument fullpath.

Changed in version 3.5: The os.O_TMPFILE flag is now used if available.

Changed in version 3.8: Added errors parameter.

tempfile.NamedTemporaryFile(mode=’w+b’, buffering=-1, encoding=None, newline=None, suffix=None,

prefix=None, dir=None, delete=True, *, errors=None, delete_on_close=True)

This function operates exactly as TemporaryFile() does, except the following differences:

• This function returns a file that is guaranteed to have a visible name in the file system.

• To manage the named file, it extends the parameters of TemporaryFile() with delete and

delete_on_close parameters that determine whether and how the named file should be automatically deleted.

The returned object is always a file-like object whose file attribute is the underlying true file object. This file-

like object can be used in a with statement, just like a normal file. The name of the temporary file can be re-

trieved from the name attribute of the returned file-like object. On Unix, unlike with the TemporaryFile(),

the directory entry does not get unlinked immediately after the file creation.

If delete is true (the default) and delete_on_close is true (the default), the file is deleted as soon as it is closed.

If delete is true and delete_on_close is false, the file is deleted on context manager exit only, or else when the

file-like object is finalized. Deletion is not always guaranteed in this case (see object.__del__()). If delete

is false, the value of delete_on_close is ignored.

Therefore to use the name of the temporary file to reopen the file after closing it, either make sure not to delete

the file upon closure (set the delete parameter to be false) or, in case the temporary file is created in a with

statement, set the delete_on_close parameter to be false. The latter approach is recommended as it provides

assistance in automatic cleaning of the temporary file upon the context manager exit.

Opening the temporary file again by its name while it is still open works as follows:

• On POSIX the file can always be opened again.

• On Windows, make sure that at least one of the following conditions are fulfilled:

– delete is false

– additional open shares delete access (e.g. by calling os.open() with the flag O_TEMPORARY)

– delete is true but delete_on_close is false. Note, that in this case the additional opens that do not share

delete access (e.g. created via builtin open()) must be closed before exiting the context manager,

else the os.unlink() call on context manager exit will fail with a PermissionError.

On Windows, if delete_on_close is false, and the file is created in a directory for which the user lacks delete

access, then the os.unlink() call on exit of the context manager will fail with a PermissionError. This

cannot happen when delete_on_close is true because delete access is requested by the open, which fails imme-

diately if the requested access is not granted.

On POSIX (only), a process that is terminated abruptly with SIGKILL cannot automatically delete any

NamedTemporaryFiles it created.

Raises an auditing event tempfile.mkstemp with argument fullpath.

The Python Library Reference, Release 3.13.2



Changed in version 3.8: Added errors parameter.

Changed in version 3.12: Added delete_on_close parameter.

class tempfile.SpooledTemporaryFile( max_size=0, mode=’w+b’ , buffering=-1, encoding=None,

newline=None, suffix=None, prefix=None, dir=None, *,

errors=None)

This class operates exactly as TemporaryFile() does, except that data is spooled in memory until the file

size exceeds max_size, or until the file’s fileno() method is called, at which point the contents are written to

disk and operation proceeds as with TemporaryFile().

rollover()

The resulting file has one additional method, rollover(), which causes the file to roll over to an on-disk file regardless of its size.

The returned object is a file-like object whose _file attribute is either an io.BytesIO or io.

TextIOWrapper object (depending on whether binary or text mode was specified) or a true file object, de-

pending on whether rollover() has been called. This file-like object can be used in a with statement, just

like a normal file.

Changed in version 3.3: the truncate method now accepts a size argument.

Changed in version 3.8: Added errors parameter.

Changed in version 3.11: Fully implements the io.BufferedIOBase and io.TextIOBase abstract base

classes (depending on whether binary or text mode was specified).

class tempfile.TemporaryDirectory(suffix=None, prefix=None, dir=None, ignore_cleanup_errors=False,

*, delete=True)

This class securely creates a temporary directory using the same rules as mkdtemp(). The resulting object can

be used as a context manager (see Examples). On completion of the context or destruction of the temporary

directory object, the newly created temporary directory and all its contents are removed from the filesystem.

name

The directory name can be retrieved from the name attribute of the returned object. When the returned

object is used as a context manager, the name will be assigned to the target of the as clause in the with statement, if there is one.

cleanup()

The directory can be explicitly cleaned up by calling the cleanup() method. If ignore_cleanup_errors

is true, any unhandled exceptions during explicit or implicit cleanup (such as a PermissionError removing open files on Windows) will be ignored, and the remaining removable items deleted on a “best-effort” basis. Otherwise, errors will be raised in whatever context cleanup occurs (the cleanup() call, exiting the context manager, when the object is garbage-collected or during interpreter shutdown).

The delete parameter can be used to disable cleanup of the directory tree upon exiting the context. While it

may seem unusual for a context manager to disable the action taken when exiting the context, it can be useful

during debugging or when you need your cleanup behavior to be conditional based on other logic.

Raises an auditing event tempfile.mkdtemp with argument fullpath.

Added in version 3.2.

Changed in version 3.10: Added ignore_cleanup_errors parameter.

Changed in version 3.12: Added the delete parameter.

tempfile.mkstemp(suffix=None, prefix=None, dir=None, text=False)

Creates a temporary file in the most secure manner possible. There are no race conditions in the file’s creation,

assuming that the platform properly implements the os.O_EXCL flag for os.open(). The file is readable

and writable only by the creating user ID. If the platform uses permission bits to indicate whether a file is

executable, the file is executable by no one. The file descriptor is not inherited by child processes.

Unlike TemporaryFile(), the user of mkstemp() is responsible for deleting the temporary file when done

with it.

The Python Library Reference, Release 3.13.2



If suffix is not None, the file name will end with that suffix, otherwise there will be no suffix. mkstemp() does

not put a dot between the file name and the suffix; if you need one, put it at the beginning of suffix.

If prefix is not None, the file name will begin with that prefix; otherwise, a default prefix is used. The default

is the return value of gettempprefix() or gettempprefixb(), as appropriate.

If dir is not None, the file will be created in that directory; otherwise, a default directory is used. The default

directory is chosen from a platform-dependent list, but the user of the application can control the directory

location by setting the TMPDIR, TEMP or TMP environment variables. There is thus no guarantee that the gen-

erated filename will have any nice properties, such as not requiring quoting when passed to external commands

via os.popen().

If any of suffix, prefix, and dir are not None, they must be the same type. If they are bytes, the returned name

will be bytes instead of str. If you want to force a bytes return value with otherwise default behavior, pass

suffix=b''.

If text is specified and true, the file is opened in text mode. Otherwise, (the default) the file is opened in binary

mode.

mkstemp() returns a tuple containing an OS-level handle to an open file (as would be returned by os.open())

and the absolute pathname of that file, in that order.

Raises an auditing event tempfile.mkstemp with argument fullpath.

Changed in version 3.5: suffix, prefix, and dir may now be supplied in bytes in order to obtain a bytes re-

turn value. Prior to this, only str was allowed. suffix and prefix now accept and default to None to cause an

appropriate default value to be used.

Changed in version 3.6: The dir parameter now accepts a path-like object.

tempfile.mkdtemp(suffix=None, prefix=None, dir=None)

Creates a temporary directory in the most secure manner possible. There are no race conditions in the direc-

tory’s creation. The directory is readable, writable, and searchable only by the creating user ID.

The user of mkdtemp() is responsible for deleting the temporary directory and its contents when done with

it.

The prefix, suffix, and dir arguments are the same as for mkstemp().

mkdtemp() returns the absolute pathname of the new directory.

Raises an auditing event tempfile.mkdtemp with argument fullpath.

Changed in version 3.5: suffix, prefix, and dir may now be supplied in bytes in order to obtain a bytes re-

turn value. Prior to this, only str was allowed. suffix and prefix now accept and default to None to cause an

appropriate default value to be used.

Changed in version 3.6: The dir parameter now accepts a path-like object.

Changed in version 3.12: mkdtemp() now always returns an absolute path, even if dir is relative.

tempfile.gettempdir()

Return the name of the directory used for temporary files. This defines the default value for the dir argument

to all functions in this module.

Python searches a standard list of directories to find one which the calling user can create files in. The list is:

1. The directory named by the TMPDIR environment variable.

2. The directory named by the TEMP environment variable.

3. The directory named by the TMP environment variable.

4. A platform-specific location:

• On Windows, the directories C:\TEMP, C:\TMP, \TEMP, and \TMP, in that order.

• On all other platforms, the directories /tmp, /var/tmp, and /usr/tmp, in that order.

5. As a last resort, the current working directory.

The Python Library Reference, Release 3.13.2



The result of this search is cached, see the description of tempdir below.

Changed in version 3.10: Always returns a str. Previously it would return any tempdir value regardless of

type so long as it was not None.

tempfile.gettempdirb()

Same as gettempdir() but the return value is in bytes.

Added in version 3.5.

tempfile.gettempprefix()

Return the filename prefix used to create temporary files. This does not contain the directory component.

tempfile.gettempprefixb()

Same as gettempprefix() but the return value is in bytes.

Added in version 3.5.

The module uses a global variable to store the name of the directory used for temporary files returned by

gettempdir(). It can be set directly to override the selection process, but this is discouraged. All functions in this module take a dir argument which can be used to specify the directory. This is the recommended approach that does not surprise other unsuspecting code by changing global API behavior.

tempfile.tempdir

When set to a value other than None, this variable defines the default value for the dir argument to the functions

defined in this module, including its type, bytes or str. It cannot be a path-like object.

If tempdir is None (the default) at any call to any of the above functions except gettempprefix() it is

initialized following the algorithm described in gettempdir().



® Note

Beware that if you set tempdir to a bytes value, there is a nasty side effect: The global default return type

of mkstemp() and mkdtemp() changes to bytes when no explicit prefix, suffix, or dir arguments of type str are supplied. Please do not write code expecting or depending on this. This awkward behavior is maintained for compatibility with the historical implementation.



11.5.1 Examples

Here are some examples of typical usage of the tempfile module:

>>> import tempfile

# create a temporary file and write some data to it >>> fp = tempfile.TemporaryFile()

>>> fp.write(b'Hello world!')

# read data from file

>>> fp.seek(0)

>>> fp.read()

b'Hello world!'

# close the file, it will be removed

>>> fp.close()

# create a temporary file using a context manager

>>> with tempfile.TemporaryFile() as fp:

... fp.write(b'Hello world!')

... fp.seek(0)

... fp.read()

b'Hello world!'

>>>

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

# file is now closed and removed

# create a temporary file using a context manager

# close the file, use the name to open the file again >>> with tempfile.NamedTemporaryFile(delete_on_close=False) as fp: ... fp.write(b'Hello world!')

... fp.close()

... # the file is closed, but not removed

... # open the file again by using its name

... with open(fp.name, mode='rb') as f:

... f.read()

b'Hello world!'

>>>

# file is now removed

# create a temporary directory using the context manager >>> with tempfile.TemporaryDirectory() as tmpdirname:

... print('created temporary directory', tmpdirname) >>>

# directory and contents have been removed



11.5.2 Deprecated functions and variables

A historical way to create temporary files was to first generate a file name with the mktemp() function and then create a file using this name. Unfortunately this is not secure, because a different process may create a file with this

name in the time between the call to mktemp() and the subsequent attempt to create the file by the first process. The

solution is to combine the two steps and create the file immediately. This approach is used by mkstemp() and the other functions described above.

tempfile.mktemp(suffix=”, prefix=’tmp’, dir=None)

Deprecated since version 2.3: Use mkstemp() instead.

Return an absolute pathname of a file that did not exist at the time the call is made. The prefix, suffix, and dir

arguments are similar to those of mkstemp(), except that bytes file names, suffix=None and prefix=None

are not supported.



Á Warning

Use of this function may introduce a security hole in your program. By the time you get around to doing

anything with the file name it returns, someone else may have beaten you to the punch. mktemp() usage

can be replaced easily with NamedTemporaryFile(), passing it the delete=False parameter:

>>> f = NamedTemporaryFile(delete=False)

>>> f.name

'/tmp/tmptjujjt'

>>> f.write(b"Hello World!\n")

13

>>> f.close()

>>> os.unlink(f.name)

>>> os.path.exists(f.name)

False



The Python Library Reference, Release 3.13.2



11.6 glob — Unix style pathname pattern expansion

Source code: Lib/glob.py



The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, although results are returned in arbitrary order. No tilde expansion is done, but *, ?, and character ranges expressed

with [] will be correctly matched. This is done by using the os.scandir() and fnmatch.fnmatch() functions in concert, and not by actually invoking a subshell.

Note that files beginning with a dot (.) can only be matched by patterns that also start with a dot, unlike fnmatch.

fnmatch() or pathlib.Path.glob(). (For tilde and shell variable expansion, use os.path.expanduser()

and os.path.expandvars().)

For a literal match, wrap the meta-characters in brackets. For example, '[?]' matches the character '?'.

The glob module defines the following functions:

glob.glob(pathname, *, root_dir=None, dir_fd=None, recursive=False, include_hidden=False)

Return a possibly empty list of path names that match pathname, which must be a string containing a path

specification. pathname can be either absolute (like /usr/src/Python-1.5/Makefile) or relative (like .

./../Tools/*/*.gif ), and can contain shell-style wildcards. Broken symlinks are included in the results (as

in the shell). Whether or not the results are sorted depends on the file system. If a file that satisfies conditions

is removed or added during the call of this function, whether a path name for that file will be included is

unspecified.

If root_dir is not None, it should be a path-like object specifying the root directory for searching. It has the

same effect on glob() as changing the current directory before calling it. If pathname is relative, the result

will contain paths relative to root_dir.

This function can support paths relative to directory descriptors with the dir_fd parameter.

If recursive is true, the pattern “**” will match any files and zero or more directories, subdirectories and

symbolic links to directories. If the pattern is followed by an os.sep or os.altsep then files will not match.

If include_hidden is true, “**” pattern will match hidden directories.

Raises an auditing event glob.glob with arguments pathname, recursive.

Raises an auditing event glob.glob/2 with arguments pathname, recursive, root_dir, dir_fd.



® Note

Using the “**” pattern in large directory trees may consume an inordinate amount of time.



® Note

This function may return duplicate path names if pathname contains multiple “**” patterns and recursive is true.



Changed in version 3.5: Support for recursive globs using “**”.

Changed in version 3.10: Added the root_dir and dir_fd parameters.

Changed in version 3.11: Added the include_hidden parameter.

glob.iglob(pathname, *, root_dir=None, dir_fd=None, recursive=False, include_hidden=False)

Return an iterator which yields the same values as glob() without actually storing them all simultaneously.

Raises an auditing event glob.glob with arguments pathname, recursive.

Raises an auditing event glob.glob/2 with arguments pathname, recursive, root_dir, dir_fd.

The Python Library Reference, Release 3.13.2



® Note

This function may return duplicate path names if pathname contains multiple “**” patterns and recursive is true.



Changed in version 3.5: Support for recursive globs using “**”.

Changed in version 3.10: Added the root_dir and dir_fd parameters.

Changed in version 3.11: Added the include_hidden parameter.

glob.escape(pathname)

Escape all special characters ('?', '*' and '['). This is useful if you want to match an arbitrary literal string

that may have special characters in it. Special characters in drive/UNC sharepoints are not escaped, e.g. on

Windows escape('//?/c:/Quo vadis?.txt') returns '//?/c:/Quo vadis[?].txt'.

Added in version 3.4.

glob.translate(pathname, *, recursive=False, include_hidden=False, seps=None)

Convert the given path specification to a regular expression for use with re.match(). The path specification

can contain shell-style wildcards.

For example:

>>> import glob, re

>>>

>>> regex = glob.translate('**/*.txt', recursive=True, include_hidden=True)

>>> regex

'(?s:(?:.+/)?[^/]*\\.txt)\\Z'

>>> reobj = re.compile(regex)

>>> reobj.match('foo/bar/baz.txt')





Path separators and segments are meaningful to this function, unlike fnmatch.translate(). By default

wildcards do not match path separators, and * pattern segments match precisely one path segment.

If recursive is true, the pattern segment “**” will match any number of path segments.

If include_hidden is true, wildcards can match path segments that start with a dot (.).

A sequence of path separators may be supplied to the seps argument. If not given, os.sep and altsep (if

available) are used.



µ See also

pathlib.PurePath.full_match() and pathlib.Path.glob() methods, which call this function to implement pattern matching and globbing.



Added in version 3.13.



11.6.1 Examples

Consider a directory containing the following files: 1.gif, 2.txt, card.gif and a subdirectory sub which contains

only the file 3.txt. glob() will produce the following results. Notice how any leading components of the path are preserved.

>>> import glob

>>> glob.glob('./[0-9].*')

['./1.gif', './2.txt']

>>> glob.glob('*.gif')

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

['1.gif', 'card.gif']

>>> glob.glob('?.gif')

['1.gif']

>>> glob.glob('**/*.txt', recursive=True)

['2.txt', 'sub/3.txt']

>>> glob.glob('./**/', recursive=True)

['./', './sub/']



If the directory contains files starting with . they won’t be matched by default. For example, consider a directory containing card.gif and .card.gif:

>>> import glob

>>> glob.glob('*.gif')

['card.gif']

>>> glob.glob('.c*')

['.card.gif']



µ See also

The fnmatch module offers shell-style filename (not path) expansion.



µ See also

The pathlib module offers high-level path objects.



11.7 fnmatch — Unix filename pattern matching

Source code: Lib/fnmatch.py



This module provides support for Unix shell-style wildcards, which are not the same as regular expressions (which

are documented in the re module). The special characters used in shell-style wildcards are:



Pattern Meaning

* matches everything

? matches any single character

[seq] matches any character in seq

[!seq] matches any character not in seq



For a literal match, wrap the meta-characters in brackets. For example, '[?]' matches the character '?'.

Note that the filename separator ('/' on Unix) is not special to this module. See module glob for pathname expan-

sion (glob uses filter() to match pathname segments). Similarly, filenames starting with a period are not special for this module, and are matched by the * and ? patterns.

Unless stated otherwise, “filename string” and “pattern string” either refer to str or ISO-8859-1 encoded bytes objects. Note that the functions documented below do not allow to mix a bytes pattern with a str filename, and vice-versa.

Finally, note that functools.lru_cache() with a maxsize of 32768 is used to cache the (typed) compiled regex

patterns in the following functions: fnmatch(), fnmatchcase(), filter().

The Python Library Reference, Release 3.13.2



fnmatch.fnmatch(name, pat)

Test whether the filename string name matches the pattern string pat, returning True or False. Both pa-

rameters are case-normalized using os.path.normcase(). fnmatchcase() can be used to perform a

case-sensitive comparison, regardless of whether that’s standard for the operating system.

This example will print all file names in the current directory with the extension .txt:

import fnmatch

import os

for file in os.listdir('.'):

if fnmatch.fnmatch(file, '*.txt'):

print(file)



fnmatch.fnmatchcase(name, pat)

Test whether the filename string name matches the pattern string pat, returning True or False; the comparison

is case-sensitive and does not apply os.path.normcase().

fnmatch.filter(names, pat)

Construct a list from those elements of the iterable of filename strings names that match the pattern string pat.

It is the same as [n for n in names if fnmatch(n, pat)], but implemented more efficiently.

fnmatch.translate(pat)

Return the shell-style pattern pat converted to a regular expression for using with re.match(). The pattern

is expected to be a str.

Example:

>>> import fnmatch, re

>>>

>>> regex = fnmatch.translate('*.txt')

>>> regex

'(?s:.*\\.txt)\\Z'

>>> reobj = re.compile(regex)

>>> reobj.match('foobar.txt')





µ See also

Module glob

Unix shell-style path expansion.



11.8 linecache — Random access to text lines

Source code: Lib/linecache.py



The linecache module allows one to get any line from a Python source file, while attempting to optimize internally,

using a cache, the common case where many lines are read from a single file. This is used by the traceback module to retrieve source lines for inclusion in the formatted traceback.

The tokenize.open() function is used to open files. This function uses tokenize.detect_encoding() to get the encoding of the file; in the absence of an encoding token, the file encoding defaults to UTF-8.

The linecache module defines the following functions:



The Python Library Reference, Release 3.13.2



linecache.getline(filename, lineno, module_globals=None)

Get line lineno from file named filename. This function will never raise an exception — it will return '' on

errors (the terminating newline character will be included for lines that are found).

If a file named filename is not found, the function first checks for a PEP 302 __loader__ in module_globals.

If there is such a loader and it defines a get_source method, then that determines the source lines (if

get_source() returns None, then '' is returned). Finally, if filename is a relative filename, it is looked

up relative to the entries in the module search path, sys.path.

linecache.clearcache()

Clear the cache. Use this function if you no longer need lines from files previously read using getline().

linecache.checkcache(filename=None)

Check the cache for validity. Use this function if files in the cache may have changed on disk, and you require

the updated version. If filename is omitted, it will check all the entries in the cache.

linecache.lazycache(filename, module_globals)

Capture enough detail about a non-file-based module to permit getting its lines later via getline() even if

module_globals is None in the later call. This avoids doing I/O until a line is actually needed, without having

to carry the module globals around indefinitely.

Added in version 3.5.

Example:

>>> import linecache

>>> linecache.getline(linecache.__file__, 8)

'import sys\n'



11.9 shutil — High-level file operations

Source code: Lib/shutil.py



The shutil module offers a number of high-level operations on files and collections of files. In particular, functions

are provided which support file copying and removal. For operations on individual files, see also the os module.



Á Warning

Even the higher-level file copying functions (shutil.copy(), shutil.copy2()) cannot copy all file metadata.

On POSIX platforms, this means that file owner and group are lost as well as ACLs. On Mac OS, the resource

fork and other metadata are not used. This means that resources will be lost and file type and creator codes will

not be correct. On Windows, file owners, ACLs and alternate data streams are not copied.



11.9.1 Directory and files operations

shutil.copyfileobj(fsrc, fdst [, length ])

Copy the contents of the file-like object fsrc to the file-like object fdst. The integer length, if given, is the

buffer size. In particular, a negative length value means to copy the data without looping over the source data

in chunks; by default the data is read in chunks to avoid uncontrolled memory consumption. Note that if the

current file position of the fsrc object is not 0, only the contents from the current file position to the end of the

file will be copied.

shutil.copyfile(src, dst, *, follow_symlinks=True)

Copy the contents (no metadata) of the file named src to a file named dst and return dst in the most efficient

way possible. src and dst are path-like objects or path names given as strings.

The Python Library Reference, Release 3.13.2



dst must be the complete target file name; look at copy() for a copy that accepts a target directory path. If

src and dst specify the same file, SameFileError is raised.

The destination location must be writable; otherwise, an OSError exception will be raised. If dst already

exists, it will be replaced. Special files such as character or block devices and pipes cannot be copied with this

function.

If follow_symlinks is false and src is a symbolic link, a new symbolic link will be created instead of copying

the file src points to.

Raises an auditing event shutil.copyfile with arguments src, dst.

Changed in version 3.3: IOError used to be raised instead of OSError. Added follow_symlinks argument.

Now returns dst.

Changed in version 3.4: Raise SameFileError instead of Error. Since the former is a subclass of the latter,

this change is backward compatible.

Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to copy the file

more efficiently. See Platform-dependent efficient copy operations section.

exception shutil.SameFileError

This exception is raised if source and destination in copyfile() are the same file.

Added in version 3.4.

shutil.copymode(src, dst, *, follow_symlinks=True)

Copy the permission bits from src to dst. The file contents, owner, and group are unaffected. src and dst are

path-like objects or path names given as strings. If follow_symlinks is false, and both src and dst are symbolic

links, copymode() will attempt to modify the mode of dst itself (rather than the file it points to). This

functionality is not available on every platform; please see copystat() for more information. If copymode()

cannot modify symbolic links on the local platform, and it is asked to do so, it will do nothing and return.

Raises an auditing event shutil.copymode with arguments src, dst.

Changed in version 3.3: Added follow_symlinks argument.

shutil.copystat(src, dst, *, follow_symlinks=True)

Copy the permission bits, last access time, last modification time, and flags from src to dst. On Linux,

copystat() also copies the “extended attributes” where possible. The file contents, owner, and group are

unaffected. src and dst are path-like objects or path names given as strings.

If follow_symlinks is false, and src and dst both refer to symbolic links, copystat() will operate on the

symbolic links themselves rather than the files the symbolic links refer to—reading the information from the

src symbolic link, and writing the information to the dst symbolic link.



® Note

Not all platforms provide the ability to examine and modify symbolic links. Python itself can tell you what functionality is locally available.

• If os.chmod in os.supports_follow_symlinks is True, copystat() can modify the per-

mission bits of a symbolic link.

• If os.utime in os.supports_follow_symlinks is True, copystat() can modify the last

access and modification times of a symbolic link.

• If os.chflags in os.supports_follow_symlinks is True, copystat() can modify the

flags of a symbolic link. (os.chflags is not available on all platforms.)

On platforms where some or all of this functionality is unavailable, when asked to modify a symbolic link,

copystat() will copy everything it can. copystat() never returns failure.

Please see os.supports_follow_symlinks for more information.

The Python Library Reference, Release 3.13.2



Raises an auditing event shutil.copystat with arguments src, dst.

Changed in version 3.3: Added follow_symlinks argument and support for Linux extended attributes.

shutil.copy(src, dst, *, follow_symlinks=True)

Copies the file src to the file or directory dst. src and dst should be path-like objects or strings. If dst specifies

a directory, the file will be copied into dst using the base filename from src. If dst specifies a file that already

exists, it will be replaced. Returns the path to the newly created file.

If follow_symlinks is false, and src is a symbolic link, dst will be created as a symbolic link. If follow_symlinks

is true and src is a symbolic link, dst will be a copy of the file src refers to.

copy() copies the file data and the file’s permission mode (see os.chmod()). Other metadata, like the file’s

creation and modification times, is not preserved. To preserve all file metadata from the original, use copy2()

instead.

Raises an auditing event shutil.copyfile with arguments src, dst.

Raises an auditing event shutil.copymode with arguments src, dst.

Changed in version 3.3: Added follow_symlinks argument. Now returns path to the newly created file.

Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to copy the file

more efficiently. See Platform-dependent efficient copy operations section.

shutil.copy2(src, dst, *, follow_symlinks=True)

Identical to copy() except that copy2() also attempts to preserve file metadata.

When follow_symlinks is false, and src is a symbolic link, copy2() attempts to copy all metadata from the

src symbolic link to the newly created dst symbolic link. However, this functionality is not available on all

platforms. On platforms where some or all of this functionality is unavailable, copy2() will preserve all the

metadata it can; copy2() never raises an exception because it cannot preserve file metadata.

copy2() uses copystat() to copy the file metadata. Please see copystat() for more information about

platform support for modifying symbolic link metadata.

Raises an auditing event shutil.copyfile with arguments src, dst.

Raises an auditing event shutil.copystat with arguments src, dst.

Changed in version 3.3: Added follow_symlinks argument, try to copy extended file system attributes too

(currently Linux only). Now returns path to the newly created file.

Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to copy the file

more efficiently. See Platform-dependent efficient copy operations section.

shutil.ignore_patterns(*patterns)

This factory function creates a function that can be used as a callable for copytree()’s ignore argument,

ignoring files and directories that match one of the glob-style patterns provided. See the example below.

shutil.copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2,

ignore_dangling_symlinks=False, dirs_exist_ok=False)

Recursively copy an entire directory tree rooted at src to a directory named dst and return the destination

directory. All intermediate directories needed to contain dst will also be created by default.

Permissions and times of directories are copied with copystat(), individual files are copied using copy2().

If symlinks is true, symbolic links in the source tree are represented as symbolic links in the new tree and the

metadata of the original links will be copied as far as the platform allows; if false or omitted, the contents and

metadata of the linked files are copied to the new tree.

When symlinks is false, if the file pointed to by the symlink doesn’t exist, an exception will be added in

the list of errors raised in an Error exception at the end of the copy process. You can set the optional ig-

nore_dangling_symlinks flag to true if you want to silence this exception. Notice that this option has no effect

on platforms that don’t support os.symlink().

The Python Library Reference, Release 3.13.2



If ignore is given, it must be a callable that will receive as its arguments the directory being visited by

copytree(), and a list of its contents, as returned by os.listdir(). Since copytree() is called re-

cursively, the ignore callable will be called once for each directory that is copied. The callable must return a

sequence of directory and file names relative to the current directory (i.e. a subset of the items in its second

argument); these names will then be ignored in the copy process. ignore_patterns() can be used to create

such a callable that ignores names based on glob-style patterns.

If exception(s) occur, an Error is raised with a list of reasons.

If copy_function is given, it must be a callable that will be used to copy each file. It will be called with the

source path and the destination path as arguments. By default, copy2() is used, but any function that supports

the same signature (like copy()) can be used.

If dirs_exist_ok is false (the default) and dst already exists, a FileExistsError is raised. If dirs_exist_ok is

true, the copying operation will continue if it encounters existing directories, and files within the dst tree will

be overwritten by corresponding files from the src tree.

Raises an auditing event shutil.copytree with arguments src, dst.

Changed in version 3.2: Added the copy_function argument to be able to provide a custom copy function.

Added the ignore_dangling_symlinks argument to silence dangling symlinks errors when symlinks is false.

Changed in version 3.3: Copy metadata when symlinks is false. Now returns dst.

Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to copy the file

more efficiently. See Platform-dependent efficient copy operations section.

Changed in version 3.8: Added the dirs_exist_ok parameter.

shutil.rmtree(path, ignore_errors=False, onerror=None, *, onexc=None, dir_fd=None)

Delete an entire directory tree; path must point to a directory (but not a symbolic link to a directory). If

ignore_errors is true, errors resulting from failed removals will be ignored; if false or omitted, such errors are

handled by calling a handler specified by onexc or onerror or, if both are omitted, exceptions are propagated

to the caller.

This function can support paths relative to directory descriptors.



® Note

On platforms that support the necessary fd-based functions a symlink attack resistant version of rmtree()

is used by default. On other platforms, the rmtree() implementation is susceptible to a symlink attack: given proper timing and circumstances, attackers can manipulate symlinks on the filesystem to delete files

they wouldn’t be able to access otherwise. Applications can use the rmtree.avoids_symlink_attacks function attribute to determine which case applies.



If onexc is provided, it must be a callable that accepts three parameters: function, path, and excinfo.

The first parameter, function, is the function which raised the exception; it depends on the platform and im-

plementation. The second parameter, path, will be the path name passed to function. The third parameter,

excinfo, is the exception that was raised. Exceptions raised by onexc will not be caught.

The deprecated onerror is similar to onexc, except that the third parameter it receives is the tuple returned

from sys.exc_info().

Raises an auditing event shutil.rmtree with arguments path, dir_fd.

Changed in version 3.3: Added a symlink attack resistant version that is used automatically if platform supports

fd-based functions.

Changed in version 3.8: On Windows, will no longer delete the contents of a directory junction before removing

the junction.

Changed in version 3.11: Added the dir_fd parameter.

Changed in version 3.12: Added the onexc parameter, deprecated onerror.

The Python Library Reference, Release 3.13.2



Changed in version 3.13: rmtree() now ignores FileNotFoundError exceptions for all but the top-level

path. Exceptions other than OSError and subclasses of OSError are now always propagated to the caller.

rmtree.avoids_symlink_attacks

Indicates whether the current platform and implementation provides a symlink attack resistant version of

rmtree(). Currently this is only true for platforms supporting fd-based directory access functions.

Added in version 3.3.

shutil.move(src, dst, copy_function=copy2)

Recursively move a file or directory (src) to another location and return the destination.

If dst is an existing directory or a symlink to a directory, then src is moved inside that directory. The destination

path in that directory must not already exist.

If dst already exists but is not a directory, it may be overwritten depending on os.rename() semantics.

If the destination is on the current filesystem, then os.rename() is used. Otherwise, src is copied to the

destination using copy_function and then removed. In case of symlinks, a new symlink pointing to the target

of src will be created as the destination and src will be removed.

If copy_function is given, it must be a callable that takes two arguments, src and the destination, and will

be used to copy src to the destination if os.rename() cannot be used. If the source is a directory,

copytree() is called, passing it the copy_function. The default copy_function is copy2(). Using copy() as

the copy_function allows the move to succeed when it is not possible to also copy the metadata, at the expense

of not copying any of the metadata.

Raises an auditing event shutil.move with arguments src, dst.

Changed in version 3.3: Added explicit symlink handling for foreign filesystems, thus adapting it to the behavior

of GNU’s mv. Now returns dst.

Changed in version 3.5: Added the copy_function keyword argument.

Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to copy the file

more efficiently. See Platform-dependent efficient copy operations section.

Changed in version 3.9: Accepts a path-like object for both src and dst.

shutil.disk_usage(path)

Return disk usage statistics about the given path as a named tuple with the attributes total, used and free, which

are the amount of total, used and free space, in bytes. path may be a file or a directory.



® Note

On Unix filesystems, path must point to a path within a mounted filesystem partition. On those platforms, CPython doesn’t attempt to retrieve disk usage information from non-mounted filesystems.



Added in version 3.3.

Changed in version 3.8: On Windows, path can now be a file or directory.

Availability: Unix, Windows.

shutil.chown(path, user=None, group=None, *, dir_fd=None, follow_symlinks=True)

Change owner user and/or group of the given path.

user can be a system user name or a uid; the same applies to group. At least one argument is required.

See also os.chown(), the underlying function.

Raises an auditing event shutil.chown with arguments path, user, group.

Availability: Unix.

Added in version 3.3.

The Python Library Reference, Release 3.13.2



Changed in version 3.13: Added dir_fd and follow_symlinks parameters.

shutil.which(cmd, mode=os.F_OK | os.X_OK, path=None)

Return the path to an executable which would be run if the given cmd was called. If no cmd would be called,

return None.

mode is a permission mask passed to os.access(), by default determining if the file exists and is executable.

path is a “PATH string” specifying the directories to look in, delimited by os.pathsep. When no path is

specified, the PATH environment variable is read from os.environ, falling back to os.defpath if it is not

set.

On Windows, the current directory is prepended to the path if mode does not include os.X_OK. When the

mode does include os.X_OK, the Windows API NeedCurrentDirectoryForExePathW will be consulted

to determine if the current directory should be prepended to path. To avoid consulting the current working

directory for executables: set the environment variable NoDefaultCurrentDirectoryInExePath.

Also on Windows, the PATHEXT environment variable is used to resolve commands that may not already

include an extension. For example, if you call shutil.which("python"), which() will search PATHEXT

to know that it should look for python.exe within the path directories. For example, on Windows:

>>> shutil.which("python")

'C:\\Python33\\python.EXE'



This is also applied when cmd is a path that contains a directory component:

>> shutil.which("C:\\Python33\\python")

'C:\\Python33\\python.EXE'



Added in version 3.3.

Changed in version 3.8: The bytes type is now accepted. If cmd type is bytes, the result type is also bytes.

Changed in version 3.12: On Windows, the current directory is no longer prepended to the search path if mode

includes os.X_OK and WinAPI NeedCurrentDirectoryForExePathW(cmd) is false, else the current di-

rectory is prepended even if it is already in the search path; PATHEXT is used now even when cmd includes a

directory component or ends with an extension that is in PATHEXT; and filenames that have no extension can

now be found.

exception shutil.Error

This exception collects exceptions that are raised during a multi-file operation. For copytree(), the exception

argument is a list of 3-tuples (srcname, dstname, exception).



Platform-dependent efficient copy operations

Starting from Python 3.8, all functions involving a file copy (copyfile(), copy(), copy2(), copytree(), and

move()) may use platform-specific “fast-copy” syscalls in order to copy the file more efficiently (see bpo-33671). “fast-copy” means that the copying operation occurs within the kernel, avoiding the use of userspace buffers in Python as in “outfd.write(infd.read())”.

On macOS fcopyfile is used to copy the file content (not metadata).

On Linux os.sendfile() is used.

On Windows shutil.copyfile() uses a bigger default buffer size (1 MiB instead of 64 KiB) and a

memoryview()-based variant of shutil.copyfileobj() is used.

If the fast-copy operation fails and no data was written in the destination file then shutil will silently fallback on using

less efficient copyfileobj() function internally.

Changed in version 3.8.



The Python Library Reference, Release 3.13.2



copytree example

An example that uses the ignore_patterns() helper:

from shutil import copytree, ignore_patterns

copytree(source, destination, ignore=ignore_patterns('*.pyc', 'tmp*'))



This will copy everything except .pyc files and files or directories whose name starts with tmp.

Another example that uses the ignore argument to add a logging call:

from shutil import copytree

import logging

def _logpath(path, names):

logging.info('Working in %s', path)

return [] # nothing will be ignored

copytree(source, destination, ignore=_logpath)



rmtree example

This example shows how to remove a directory tree on Windows where some of the files have their read-only bit set. It uses the onexc callback to clear the readonly bit and reattempt the remove. Any subsequent failure will propagate.

import os, stat

import shutil

def remove_readonly(func, path, _):

"Clear the readonly bit and reattempt the removal"

os.chmod(path, stat.S_IWRITE)

func(path)

shutil.rmtree(directory, onexc=remove_readonly)



11.9.2 Archiving operations

Added in version 3.2.

Changed in version 3.5: Added support for the xztar format.

High-level utilities to create and read compressed and archived files are also provided. They rely on the zipfile

and tarfile modules.

shutil.make_archive(base_name, format[, root_dir[, base_dir[, verbose[, dry_run[, owner[, group[, logger

]]]]]]])

Create an archive file (such as zip or tar) and return its name.

base_name is the name of the file to create, including the path, minus any format-specific extension.

format is the archive format: one of “zip” (if the zlib module is available), “tar”, “gztar” (if the zlib module

is available), “bztar” (if the bz2 module is available), or “xztar” (if the lzma module is available).

root_dir is a directory that will be the root directory of the archive, all paths in the archive will be relative to

it; for example, we typically chdir into root_dir before creating the archive.

base_dir is the directory where we start archiving from; i.e. base_dir will be the common prefix of all files and

directories in the archive. base_dir must be given relative to root_dir. See Archiving example with base_dir for

how to use base_dir and root_dir together.

root_dir and base_dir both default to the current directory.

The Python Library Reference, Release 3.13.2



If dry_run is true, no archive is created, but the operations that would be executed are logged to logger.

owner and group are used when creating a tar archive. By default, uses the current owner and group.

logger must be an object compatible with PEP 282, usually an instance of logging.Logger.

The verbose argument is unused and deprecated.

Raises an auditing event shutil.make_archive with arguments base_name, format, root_dir,

base_dir.



® Note

This function is not thread-safe when custom archivers registered with register_archive_format() do not support the root_dir argument. In this case it temporarily changes the current working directory of the process to root_dir to perform archiving.



Changed in version 3.8: The modern pax (POSIX.1-2001) format is now used instead of the legacy GNU

format for archives created with format="tar".

Changed in version 3.10.6: This function is now made thread-safe during creation of standard .zip and tar

archives.

shutil.get_archive_formats()

Return a list of supported formats for archiving. Each element of the returned sequence is a tuple (name,

description).

By default shutil provides these formats:

• zip: ZIP file (if the zlib module is available).

• tar: Uncompressed tar file. Uses POSIX.1-2001 pax format for new archives.

• gztar: gzip’ed tar-file (if the zlib module is available).

• bztar: bzip2’ed tar-file (if the bz2 module is available).

• xztar: xz’ed tar-file (if the lzma module is available).

You can register new formats or provide your own archiver for any existing formats, by using

register_archive_format().

shutil.register_archive_format(name, function[, extra_args[, description ]])

Register an archiver for the format name.

function is the callable that will be used to unpack archives. The callable will receive the base_name of the file

to create, followed by the base_dir (which defaults to os.curdir) to start archiving from. Further arguments

are passed as keyword arguments: owner, group, dry_run and logger (as passed in make_archive()).

If function has the custom attribute function.supports_root_dir set to True, the root_dir argument is

passed as a keyword argument. Otherwise the current working directory of the process is temporarily changed

to root_dir before calling function. In this case make_archive() is not thread-safe.

If given, extra_args is a sequence of (name, value) pairs that will be used as extra keywords arguments

when the archiver callable is used.

description is used by get_archive_formats() which returns the list of archivers. Defaults to an empty

string.

Changed in version 3.12: Added support for functions supporting the root_dir argument.

shutil.unregister_archive_format(name)

Remove the archive format name from the list of supported formats.



The Python Library Reference, Release 3.13.2



shutil.unpack_archive( filename[, extract_dir[, format[, filter ]]])

Unpack an archive. filename is the full path of the archive.

extract_dir is the name of the target directory where the archive is unpacked. If not provided, the current

working directory is used.

format is the archive format: one of “zip”, “tar”, “gztar”, “bztar”, or “xztar”. Or any other format registered

with register_unpack_format(). If not provided, unpack_archive() will use the archive file name

extension and see if an unpacker was registered for that extension. In case none is found, a ValueError is

raised.

The keyword-only filter argument is passed to the underlying unpacking function. For zip files, filter is not

accepted. For tar files, it is recommended to set it to 'data', unless using features specific to tar and UNIX-

like filesystems. (See Extraction filters for details.) The 'data' filter will become the default for tar files in

Python 3.14.

Raises an auditing event shutil.unpack_archive with arguments filename, extract_dir, format.



Á Warning

Never extract archives from untrusted sources without prior inspection. It is possible that files are created outside of the path specified in the extract_dir argument, e.g. members that have absolute filenames starting with “/” or filenames with two dots “..”.



Changed in version 3.7: Accepts a path-like object for filename and extract_dir.

Changed in version 3.12: Added the filter argument.

shutil.register_unpack_format(name, extensions, function[, extra_args[, description ]])

Registers an unpack format. name is the name of the format and extensions is a list of extensions corresponding

to the format, like .zip for Zip files.

function is the callable that will be used to unpack archives. The callable will receive:

• the path of the archive, as a positional argument;

• the directory the archive must be extracted to, as a positional argument;

• possibly a filter keyword argument, if it was given to unpack_archive();

• additional keyword arguments, specified by extra_args as a sequence of (name, value) tuples.

description can be provided to describe the format, and will be returned by the get_unpack_formats()

function.

shutil.unregister_unpack_format(name)

Unregister an unpack format. name is the name of the format.

shutil.get_unpack_formats()

Return a list of all registered formats for unpacking. Each element of the returned sequence is a tuple (name,

extensions, description).

By default shutil provides these formats:

• zip: ZIP file (unpacking compressed files works only if the corresponding module is available).

• tar: uncompressed tar file.

• gztar: gzip’ed tar-file (if the zlib module is available).

• bztar: bzip2’ed tar-file (if the bz2 module is available).

• xztar: xz’ed tar-file (if the lzma module is available).

You can register new formats or provide your own unpacker for any existing formats, by using

register_unpack_format().

The Python Library Reference, Release 3.13.2



Archiving example

In this example, we create a gzip’ed tar-file archive containing all files found in the .ssh directory of the user:

>>> from shutil import make_archive

>>> import os

>>> archive_name = os.path.expanduser(os.path.join('~', 'myarchive')) >>> root_dir = os.path.expanduser(os.path.join('~', '.ssh')) >>> make_archive(archive_name, 'gztar', root_dir)

'/Users/tarek/myarchive.tar.gz'



The resulting archive contains:

$ tar -tzvf /Users/tarek/myarchive.tar.gz

drwx------ tarek/staff 0 2010-02-01 16:23:40 ./

-rw-r--r-- tarek/staff 609 2008-06-09 13:26:54 ./authorized_keys-rwxr-xr-x tarek/staff 65 2008-06-09 13:26:54 ./config-rwx------ tarek/staff 668 2008-06-09 13:26:54 ./id_dsa-rwxr-xr-x tarek/staff 609 2008-06-09 13:26:54 ./id_dsa.pub-rw------- tarek/staff 1675 2008-06-09 13:26:54 ./id_rsa-rw-r--r-- tarek/staff 397 2008-06-09 13:26:54 ./id_rsa.pub-rw-r--r-- tarek/staff 37192 2010-02-06 18:23:10 ./known_hosts



Archiving example with base_dir

In this example, similar to the one above, we show how to use make_archive(), but this time with the usage of base_dir. We now have the following directory structure:

$ tree tmp

tmp

└── root

└── structure

├── content

└── please_add.txt

└── do_not_add.txt



In the final archive, please_add.txt should be included, but do_not_add.txt should not. Therefore we use the following:

>>> from shutil import make_archive

>>> import os

>>> archive_name = os.path.expanduser(os.path.join('~', 'myarchive')) >>> make_archive(

... archive_name,

... 'tar',

... root_dir='tmp/root',

... base_dir='structure/content',

... )

'/Users/tarek/my_archive.tar'



Listing the files in the resulting archive gives us:

$ python -m tarfile -l /Users/tarek/myarchive.tar

structure/content/

structure/content/please_add.txt



The Python Library Reference, Release 3.13.2



11.9.3 Querying the size of the output terminal

shutil.get_terminal_size(fallback=(columns, lines))

Get the size of the terminal window.

For each of the two dimensions, the environment variable, COLUMNS and LINES respectively, is checked. If

the variable is defined and the value is a positive integer, it is used.

When COLUMNS or LINES is not defined, which is the common case, the terminal connected to sys.

__stdout__ is queried by invoking os.get_terminal_size().

If the terminal size cannot be successfully queried, either because the system doesn’t support querying, or

because we are not connected to a terminal, the value given in fallback parameter is used. fallback

defaults to (80, 24) which is the default size used by many terminal emulators.

The value returned is a named tuple of type os.terminal_size.

See also: The Single UNIX Specification, Version 2, Other Environment Variables.

Added in version 3.3.

Changed in version 3.11: The fallback values are also used if os.get_terminal_size() returns zeroes.



µ See also

Module os

Operating system interfaces, including functions to work with files at a lower level than Python file objects.

Module io

Python’s built-in I/O library, including both abstract classes and some concrete classes such as file I/O.

Built-in function open()

The standard way to open files for reading and writing with Python.





CHAPTER




TWELVE



DATA PERSISTENCE



The modules described in this chapter support storing Python data in a persistent form on disk. The pickle and

marshal modules can turn many Python data types into a stream of bytes and then recreate the objects from the bytes. The various DBM-related modules support a family of hash-based file formats that store a mapping of strings to other strings.

The list of modules described in this chapter is:



12.1 pickle — Python object serialization

Source code: Lib/pickle.py



The pickle module implements binary protocols for serializing and de-serializing a Python object structure. “Pick-ling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse

operation, whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy.

Pickling (and unpickling) is alternatively known as “serialization”, “marshalling,”1 or “flattening”; however, to avoid confusion, the terms used here are “pickling” and “unpickling”.



Á Warning

The pickle module is not secure. Only unpickle data you trust.

It is possible to construct malicious pickle data which will execute arbitrary code during unpickling. Never

unpickle data that could have come from an untrusted source, or that could have been tampered with.

Consider signing data with hmac if you need to ensure that it has not been tampered with.

Safer serialization formats such as json may be more appropriate if you are processing untrusted data. See

Comparison with json.



12.1.1 Relationship to other Python modules

Comparison with marshal

Python has a more primitive serialization module called marshal, but in general pickle should always be the

preferred way to serialize Python objects. marshal exists primarily to support Python’s .pyc files.

The pickle module differs from marshal in several significant ways:

• The pickle module keeps track of the objects it has already serialized, so that later references to the same

object won’t be serialized again. marshal doesn’t do this.

This has implications both for recursive objects and object sharing. Recursive objects are objects that contain

references to themselves. These are not handled by marshal, and in fact, attempting to marshal recursive

objects will crash your Python interpreter. Object sharing happens when there are multiple references to the

1 Don’t confuse this with the marshal module

The Python Library Reference, Release 3.13.2



same object in different places in the object hierarchy being serialized. pickle stores such objects only once,

and ensures that all other references point to the master copy. Shared objects remain shared, which can be very

important for mutable objects.

• marshal cannot be used to serialize user-defined classes and their instances. pickle can save and restore

class instances transparently, however the class definition must be importable and live in the same module as

when the object was stored.

• The marshal serialization format is not guaranteed to be portable across Python versions. Because its primary

job in life is to support .pyc files, the Python implementers reserve the right to change the serialization format

in non-backwards compatible ways should the need arise. The pickle serialization format is guaranteed to be

backwards compatible across Python releases provided a compatible pickle protocol is chosen and pickling and

unpickling code deals with Python 2 to Python 3 type differences if your data is crossing that unique breaking

change language boundary.



Comparison with json

There are fundamental differences between the pickle protocols and JSON (JavaScript Object Notation):

• JSON is a text serialization format (it outputs unicode text, although most of the time it is then encoded to

utf-8 ), while pickle is a binary serialization format;

• JSON is human-readable, while pickle is not;

• JSON is interoperable and widely used outside of the Python ecosystem, while pickle is Python-specific;

• JSON, by default, can only represent a subset of the Python built-in types, and no custom classes; pickle can

represent an extremely large number of Python types (many of them automatically, by clever usage of Python’s

introspection facilities; complex cases can be tackled by implementing specific object APIs);

• Unlike pickle, deserializing untrusted JSON does not in itself create an arbitrary code execution vulnerability.



µ See also

The json module: a standard library module allowing JSON serialization and deserialization.



12.1.2 Data stream format

The data format used by pickle is Python-specific. This has the advantage that there are no restrictions imposed by external standards such as JSON (which can’t represent pointer sharing); however it means that non-Python programs may not be able to reconstruct pickled Python objects.

By default, the pickle data format uses a relatively compact binary representation. If you need optimal size char-

acteristics, you can efficiently compress pickled data.

The module pickletools contains tools for analyzing data streams generated by pickle. pickletools source code has extensive comments about opcodes used by pickle protocols.

There are currently 6 different protocols which can be used for pickling. The higher the protocol used, the more recent the version of Python needed to read the pickle produced.

• Protocol version 0 is the original “human-readable” protocol and is backwards compatible with earlier versions

of Python.

• Protocol version 1 is an old binary format which is also compatible with earlier versions of Python.

• Protocol version 2 was introduced in Python 2.3. It provides much more efficient pickling of new-style classes.

Refer to PEP 307 for information about improvements brought by protocol 2.

• Protocol version 3 was added in Python 3.0. It has explicit support for bytes objects and cannot be unpickled

by Python 2.x. This was the default protocol in Python 3.0–3.7.

• Protocol version 4 was added in Python 3.4. It adds support for very large objects, pickling more kinds of

objects, and some data format optimizations. It is the default protocol starting with Python 3.8. Refer to PEP

3154 for information about improvements brought by protocol 4.

The Python Library Reference, Release 3.13.2



• Protocol version 5 was added in Python 3.8. It adds support for out-of-band data and speedup for in-band data.

Refer to PEP 574 for information about improvements brought by protocol 5.



® Note

Serialization is a more primitive notion than persistence; although pickle reads and writes file objects, it does

not handle the issue of naming persistent objects, nor the (even more complicated) issue of concurrent access to

persistent objects. The pickle module can transform a complex object into a byte stream and it can transform

the byte stream into an object with the same internal structure. Perhaps the most obvious thing to do with these

byte streams is to write them onto a file, but it is also conceivable to send them across a network or store them in a

database. The shelve module provides a simple interface to pickle and unpickle objects on DBM-style database

files.



12.1.3 Module Interface

To serialize an object hierarchy, you simply call the dumps() function. Similarly, to de-serialize a data stream, you

call the loads() function. However, if you want more control over serialization and de-serialization, you can create

a Pickler or an Unpickler object, respectively.

The pickle module provides the following constants:

pickle.HIGHEST_PROTOCOL

An integer, the highest protocol version available. This value can be passed as a protocol value to functions

dump() and dumps() as well as the Pickler constructor.

pickle.DEFAULT_PROTOCOL

An integer, the default protocol version used for pickling. May be less than HIGHEST_PROTOCOL. Currently

the default protocol is 4, first introduced in Python 3.4 and incompatible with previous versions.

Changed in version 3.0: The default protocol is 3.

Changed in version 3.8: The default protocol is 4.

The pickle module provides the following functions to make the pickling process more convenient:

pickle.dump(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None)

Write the pickled representation of the object obj to the open file object file. This is equivalent to

Pickler(file, protocol).dump(obj) .

Arguments file, protocol, fix_imports and buffer_callback have the same meaning as in the Pickler construc-

tor.

Changed in version 3.8: The buffer_callback argument was added.

pickle.dumps(obj, protocol=None, *, fix_imports=True, buffer_callback=None)

Return the pickled representation of the object obj as a bytes object, instead of writing it to a file.

Arguments protocol, fix_imports and buffer_callback have the same meaning as in the Pickler constructor.

Changed in version 3.8: The buffer_callback argument was added.

pickle.load(file, *, fix_imports=True, encoding=’ASCII’ , errors=’strict’, buffers=None)

Read the pickled representation of an object from the open file object file and return the reconstituted object

hierarchy specified therein. This is equivalent to Unpickler(file).load().

The protocol version of the pickle is detected automatically, so no protocol argument is needed. Bytes past the

pickled representation of the object are ignored.

Arguments file, fix_imports, encoding, errors, strict and buffers have the same meaning as in the Unpickler

constructor.

Changed in version 3.8: The buffers argument was added.

The Python Library Reference, Release 3.13.2



pickle.loads(data, / , *, fix_imports=True, encoding=’ASCII’, errors=’strict’, buffers=None)

Return the reconstituted object hierarchy of the pickled representation data of an object. data must be a

bytes-like object.

The protocol version of the pickle is detected automatically, so no protocol argument is needed. Bytes past the

pickled representation of the object are ignored.

Arguments fix_imports, encoding, errors, strict and buffers have the same meaning as in the Unpickler con-

structor.

Changed in version 3.8: The buffers argument was added.

The pickle module defines three exceptions:

exception pickle.PickleError

Common base class for the other pickling exceptions. It inherits from Exception.

exception pickle.PicklingError

Error raised when an unpicklable object is encountered by Pickler. It inherits from PickleError.

Refer to What can be pickled and unpickled? to learn what kinds of objects can be pickled.

exception pickle.UnpicklingError

Error raised when there is a problem unpickling an object, such as a data corruption or a security violation. It

inherits from PickleError.

Note that other exceptions may also be raised during unpickling, including (but not necessarily limited to)

AttributeError, EOFError, ImportError, and IndexError.

The pickle module exports three classes, Pickler, Unpickler and PickleBuffer:

class pickle.Pickler(file, protocol=None, *, fix_imports=True, buffer_callback=None)

This takes a binary file for writing a pickle data stream.

The optional protocol argument, an integer, tells the pickler to use the given protocol; supported protocols

are 0 to HIGHEST_PROTOCOL. If not specified, the default is DEFAULT_PROTOCOL. If a negative number is

specified, HIGHEST_PROTOCOL is selected.

The file argument must have a write() method that accepts a single bytes argument. It can thus be an on-disk

file opened for binary writing, an io.BytesIO instance, or any other custom object that meets this interface.

If fix_imports is true and protocol is less than 3, pickle will try to map the new Python 3 names to the old

module names used in Python 2, so that the pickle data stream is readable with Python 2.

If buffer_callback is None (the default), buffer views are serialized into file as part of the pickle stream.

If buffer_callback is not None, then it can be called any number of times with a buffer view. If the callback

returns a false value (such as None), the given buffer is out-of-band; otherwise the buffer is serialized in-band,

i.e. inside the pickle stream.

It is an error if buffer_callback is not None and protocol is None or smaller than 5.

Changed in version 3.8: The buffer_callback argument was added.

dump(obj)

Write the pickled representation of obj to the open file object given in the constructor.

persistent_id(obj)

Do nothing by default. This exists so a subclass can override it.

If persistent_id() returns None, obj is pickled as usual. Any other value causes Pickler to emit the returned value as a persistent ID for obj. The meaning of this persistent ID should be defined by

Unpickler.persistent_load(). Note that the value returned by persistent_id() cannot itself have a persistent ID.

See Persistence of External Objects for details and examples of uses.

The Python Library Reference, Release 3.13.2



Changed in version 3.13: Add the default implementation of this method in the C implementation of Pickler .

dispatch_table

A pickler object’s dispatch table is a registry of reduction functions of the kind which can be declared

using copyreg.pickle(). It is a mapping whose keys are classes and whose values are reduction functions. A reduction function takes a single argument of the associated class and should conform to

the same interface as a __reduce__() method.

By default, a pickler object will not have a dispatch_table attribute, and it will instead use the global

dispatch table managed by the copyreg module. However, to customize the pickling for a specific

pickler object one can set the dispatch_table attribute to a dict-like object. Alternatively, if a subclass

of Pickler has a dispatch_table attribute then this will be used as the default dispatch table for instances of that class.

See Dispatch Tables for usage examples.

Added in version 3.3.

reducer_override( obj)

Special reducer that can be defined in Pickler subclasses. This method has priority over any reducer

in the dispatch_table. It should conform to the same interface as a __reduce__() method, and

can optionally return NotImplemented to fallback on dispatch_table-registered reducers to pickle obj.

For a detailed example, see Custom Reduction for Types, Functions, and Other Objects.

Added in version 3.8.

fast

Deprecated. Enable fast mode if set to a true value. The fast mode disables the usage of memo, therefore speeding the pickling process by not generating superfluous PUT opcodes. It should not be used with

self-referential objects, doing otherwise will cause Pickler to recurse infinitely.

Use pickletools.optimize() if you need more compact pickles.

class pickle.Unpickler(file, *, fix_imports=True, encoding=’ASCII’ , errors=’strict’, buffers=None)

This takes a binary file for reading a pickle data stream.

The protocol version of the pickle is detected automatically, so no protocol argument is needed.

The argument file must have three methods, a read() method that takes an integer argument, a readinto()

method that takes a buffer argument and a readline() method that requires no arguments, as in the io.

BufferedIOBase interface. Thus file can be an on-disk file opened for binary reading, an io.BytesIO

object, or any other custom object that meets this interface.

The optional arguments fix_imports, encoding and errors are used to control compatibility support for pickle

stream generated by Python 2. If fix_imports is true, pickle will try to map the old Python 2 names to the

new names used in Python 3. The encoding and errors tell pickle how to decode 8-bit string instances pickled

by Python 2; these default to ‘ASCII’ and ‘strict’, respectively. The encoding can be ‘bytes’ to read these 8-bit

string instances as bytes objects. Using encoding='latin1' is required for unpickling NumPy arrays and

instances of datetime, date and time pickled by Python 2.

If buffers is None (the default), then all data necessary for deserialization must be contained in the pickle

stream. This means that the buffer_callback argument was None when a Pickler was instantiated (or when

dump() or dumps() was called).

If buffers is not None, it should be an iterable of buffer-enabled objects that is consumed each time the pickle

stream references an out-of-band buffer view. Such buffers have been given in order to the buffer_callback of

a Pickler object.

Changed in version 3.8: The buffers argument was added.



The Python Library Reference, Release 3.13.2



load()

Read the pickled representation of an object from the open file object given in the constructor, and return the reconstituted object hierarchy specified therein. Bytes past the pickled representation of the object are ignored.

persistent_load(pid)

Raise an UnpicklingError by default.

If defined, persistent_load() should return the object specified by the persistent ID pid. If an invalid

persistent ID is encountered, an UnpicklingError should be raised.

See Persistence of External Objects for details and examples of uses.

Changed in version 3.13: Add the default implementation of this method in the C implementation of Unpickler.

find_class(module, name)

Import module if necessary and return the object called name from it, where the module and name argu-

ments are str objects. Note, unlike its name suggests, find_class() is also used for finding functions.

Subclasses may override this to gain control over what type of objects and how they can be loaded,

potentially reducing security risks. Refer to Restricting Globals for details.

Raises an auditing event pickle.find_class with arguments module, name.

class pickle.PickleBuffer(buffer)

A wrapper for a buffer representing picklable data. buffer must be a buffer-providing object, such as a bytes-like

object or a N-dimensional array.

PickleBuffer is itself a buffer provider, therefore it is possible to pass it to other APIs expecting a buffer-

providing object, such as memoryview.

PickleBuffer objects can only be serialized using pickle protocol 5 or higher. They are eligible for out-of-

band serialization.

Added in version 3.8.

raw()

Return a memoryview of the memory area underlying this buffer. The returned object is a one-

dimensional, C-contiguous memoryview with format B (unsigned bytes). BufferError is raised if the buffer is neither C- nor Fortran-contiguous.

release()

Release the underlying buffer exposed by the PickleBuffer object.



12.1.4 What can be pickled and unpickled?

The following types can be pickled:

• built-in constants (None, True, False, Ellipsis, and NotImplemented);

• integers, floating-point numbers, complex numbers;

• strings, bytes, bytearrays;

• tuples, lists, sets, and dictionaries containing only picklable objects;

• functions (built-in and user-defined) accessible from the top level of a module (using def, not lambda);

• classes accessible from the top level of a module;

• instances of such classes whose the result of calling __getstate__() is picklable (see section Pickling Class

Instances for details).

Attempts to pickle unpicklable objects will raise the PicklingError exception; when this happens, an unspecified number of bytes may have already been written to the underlying file. Trying to pickle a highly recursive data structure

The Python Library Reference, Release 3.13.2



may exceed the maximum recursion depth, a RecursionError will be raised in this case. You can carefully raise

this limit with sys.setrecursionlimit().

Note that functions (built-in and user-defined) are pickled by fully 2 qualified name , not by value. This means that only the function name is pickled, along with the name of the containing module and classes. Neither the function’s code, nor any of its function attributes are pickled. Thus the defining module must be importable in the unpickling

environment, and the module must contain the named object, otherwise an exception will be raised.3

Similarly, classes are pickled by fully qualified name, so the same restrictions in the unpickling environment apply. Note that none of the class’s code or data is pickled, so in the following example the class attribute attr is not restored in the unpickling environment:

class Foo:

attr = 'A class attribute'

picklestring = pickle.dumps(Foo)



These restrictions are why picklable functions and classes must be defined at the top level of a module.

Similarly, when class instances are pickled, their class’s code and data are not pickled along with them. Only the instance data are pickled. This is done on purpose, so you can fix bugs in a class or add methods to the class and still load objects that were created with an earlier version of the class. If you plan to have long-lived objects that will see many versions of a class, it may be worthwhile to put a version number in the objects so that suitable conversions can

be made by the class’s __setstate__() method.



12.1.5 Pickling Class Instances

In this section, we describe the general mechanisms available to you to define, customize, and control how class instances are pickled and unpickled.

In most cases, no additional code is needed to make instances picklable. By default, pickle will retrieve the class and the attributes of an instance via introspection. When a class instance is unpickled, its __init__() method is usually not invoked. The default behaviour first creates an uninitialized instance and then restores the saved attributes. The following code shows an implementation of this behaviour:

def save(obj):

return (obj.__class__, obj.__dict__)

def restore(cls, attributes):

obj = cls.__new__(cls)

obj.__dict__.update(attributes)

return obj



Classes can alter the default behaviour by providing one or several special methods:

object.__getnewargs_ex__()

In protocols 2 and newer, classes that implements the __getnewargs_ex__() method can dictate the values

passed to the __new__() method upon unpickling. The method must return a pair (args, kwargs) where

args is a tuple of positional arguments and kwargs a dictionary of named arguments for constructing the object.

Those will be passed to the __new__() method upon unpickling.

You should implement this method if the __new__() method of your class requires keyword-only arguments.

Otherwise, it is recommended for compatibility to implement __getnewargs__().

Changed in version 3.6: __getnewargs_ex__() is now used in protocols 2 and 3.

object.__getnewargs__()

This method serves a similar purpose as __getnewargs_ex__(), but supports only positional arguments. It

must return a tuple of arguments args which will be passed to the __new__() method upon unpickling.

2 This is why lambda functions cannot be pickled: all lambda functions share the same name: .

3 The exception raised will likely be an ImportError or an AttributeError but it could be something else.

The Python Library Reference, Release 3.13.2



__getnewargs__() will not be called if __getnewargs_ex__() is defined.

Changed in version 3.6: Before Python 3.6, __getnewargs__() was called instead of

__getnewargs_ex__() in protocols 2 and 3.

object.__getstate__()

Classes can further influence how their instances are pickled by overriding the method __getstate__(). It

is called and the returned object is pickled as the contents for the instance, instead of a default state. There are

several cases:

• For a class that has no instance __dict__ and no __slots__, the default state is None.

• For a class that has an instance __dict__ and no __slots__, the default state is self.__dict__.

• For a class that has an instance __dict__ and __slots__, the default state is a tuple consisting of two

dictionaries: self.__dict__, and a dictionary mapping slot names to slot values. Only slots that have a value are included in the latter.

• For a class that has __slots__ and no instance __dict__, the default state is a tuple whose first item is

None and whose second item is a dictionary mapping slot names to slot values described in the previous bullet.

Changed in version 3.11: Added the default implementation of the __getstate__() method in the object

class.

object.__setstate__(state)

Upon unpickling, if the class defines __setstate__(), it is called with the unpickled state. In that case,

there is no requirement for the state object to be a dictionary. Otherwise, the pickled state must be a dictionary

and its items are assigned to the new instance’s dictionary.



® Note

If __reduce__() returns a state with value None at pickling, the __setstate__() method will not be called upon unpickling.



Refer to the section Handling Stateful Objects for more information about how to use the methods __getstate__()

and __setstate__().



® Note

At unpickling time, some methods like __getattr__(), __getattribute__(), or __setattr__() may

be called upon the instance. In case those methods rely on some internal invariant being true, the type should

implement __new__() to establish such an invariant, as __init__() is not called when unpickling an instance.



As we shall see, pickle does not use directly the methods described above. In fact, these methods are part of the copy

protocol which implements the __reduce__() special method. The copy protocol provides a unified interface for

retrieving the data necessary for pickling and copying objects.4

Although powerful, implementing __reduce__() directly in your classes is error prone. For this rea-

son, class designers should use the high-level interface (i.e., __getnewargs_ex__(), __getstate__() and

__setstate__()) whenever possible. We will show, however, cases where using __reduce__() is the only option or leads to more efficient pickling or both.

object.__reduce__()

The interface is currently defined as follows. The __reduce__() method takes no argument and shall return

either a string or preferably a tuple (the returned object is often referred to as the “reduce value”).

If a string is returned, the string should be interpreted as the name of a global variable. It should be the object’s

local name relative to its module; the pickle module searches the module namespace to determine the object’s

module. This behaviour is typically useful for singletons.

4 The copy module uses this protocol for shallow and deep copying operations.

The Python Library Reference, Release 3.13.2



When a tuple is returned, it must be between two and six items long. Optional items can either be omitted, or

None can be provided as their value. The semantics of each item are in order:

• A callable object that will be called to create the initial version of the object.

• A tuple of arguments for the callable object. An empty tuple must be given if the callable does not accept

any argument.

• Optionally, the object’s state, which will be passed to the object’s __setstate__() method as previously

described. If the object has no such method then, the value must be a dictionary and it will be added to the object’s __dict__ attribute.

• Optionally, an iterator (and not a sequence) yielding successive items. These items will be appended

to the object either using obj.append(item) or, in batch, using obj.extend(list_of_items).

This is primarily used for list subclasses, but may be used by other classes as long as they have append

and extend methods with the appropriate signature. (Whether append() or extend() is used depends on which pickle protocol version is used as well as the number of items to append, so both must be supported.)

• Optionally, an iterator (not a sequence) yielding successive key-value pairs. These items will be stored

to the object using obj[key] = value. This is primarily used for dictionary subclasses, but may be used by other classes as long as they implement __setitem__().

• Optionally, a callable with a (obj, state) signature. This callable allows the user to programmatically

control the state-updating behavior of a specific object, instead of using obj’s static __setstate__()

method. If not None, this callable will have priority over obj’s __setstate__().

Added in version 3.8: The optional sixth tuple item, (obj, state), was added.

object.__reduce_ex__(protocol)

Alternatively, a __reduce_ex__() method may be defined. The only difference is this method should take

a single integer argument, the protocol version. When defined, pickle will prefer it over the __reduce__()

method. In addition, __reduce__() automatically becomes a synonym for the extended version. The main

use for this method is to provide backwards-compatible reduce values for older Python releases.



Persistence of External Objects

For the benefit of object persistence, the pickle module supports the notion of a reference to an object outside the pickled data stream. Such objects are referenced by a persistent ID, which should be either a string of alphanumeric

characters (for protocol 0)5 or just an arbitrary object (for any newer protocol).

The resolution of such persistent IDs is not defined by the pickle module; it will delegate this resolution to the

user-defined methods on the pickler and unpickler, persistent_id() and persistent_load() respectively.

To pickle objects that have an external persistent ID, the pickler must have a custom persistent_id() method that takes an object as an argument and returns either None or the persistent ID for that object. When None is returned, the pickler simply pickles the object as normal. When a persistent ID string is returned, the pickler will pickle that object, along with a marker so that the unpickler will recognize it as a persistent ID.

To unpickle external objects, the unpickler must have a custom persistent_load() method that takes a persistent ID object and returns the referenced object.

Here is a comprehensive example presenting how persistent ID can be used to pickle external objects by reference.

# Simple example presenting how persistent ID can be used to pickle # external objects by reference.

import pickle

import sqlite3

from collections import namedtuple



(continues on next page)

5 The limitation on alphanumeric characters is due to the fact that persistent IDs in protocol 0 are delimited by the newline character. Therefore

if any kind of newline characters occurs in persistent IDs, the resulting pickled data will become unreadable.

The Python Library Reference, Release 3.13.2



(continued from previous page)

# Simple class representing a record in our database. MemoRecord = namedtuple("MemoRecord", "key, task")

class DBPickler(pickle.Pickler):

def persistent_id(self, obj):

# Instead of pickling MemoRecord as a regular class instance, we emit a # persistent ID.

if isinstance(obj, MemoRecord):

# Here, our persistent ID is simply a tuple, containing a tag and a # key, which refers to a specific record in the database. return ("MemoRecord", obj.key)

else:

# If obj does not have a persistent ID, return None. This means obj # needs to be pickled as usual.

return None



class DBUnpickler(pickle.Unpickler):

def __init__(self, file, connection):

super().__init__(file)

self.connection = connection

def persistent_load(self, pid):

# This method is invoked whenever a persistent ID is encountered. # Here, pid is the tuple returned by DBPickler.

cursor = self.connection.cursor()

type_tag, key_id = pid

if type_tag == "MemoRecord":

# Fetch the referenced record from the database and return it. cursor.execute("SELECT * FROM memos WHERE key=?", (str(key_id),)) key, task = cursor.fetchone()

return MemoRecord(key, task)

else:

# Always raises an error if you cannot return the correct object. # Otherwise, the unpickler will think None is the object referenced # by the persistent ID.

raise pickle.UnpicklingError("unsupported persistent object")



def main():

import io

import pprint

# Initialize and populate our database.

conn = sqlite3.connect(":memory:")

cursor = conn.cursor()

cursor.execute("CREATE TABLE memos(key INTEGER PRIMARY KEY, task TEXT)")

tasks = (

'give food to fish',

'prepare group meeting',

'fight with a zebra',

)

for task in tasks:

cursor.execute("INSERT INTO memos VALUES(NULL, ?)", (task,))

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)



# Fetch the records to be pickled.

cursor.execute("SELECT * FROM memos")

memos = [MemoRecord(key, task) for key, task in cursor]

# Save the records using our custom DBPickler.

file = io.BytesIO()

DBPickler(file).dump(memos)

print("Pickled records:")

pprint.pprint(memos)

# Update a record, just for good measure.

cursor.execute("UPDATE memos SET task='learn italian' WHERE key=1")

# Load the records from the pickle data stream.

file.seek(0)

memos = DBUnpickler(file, conn).load()

print("Unpickled records:")

pprint.pprint(memos)



if __name__ == '__main__':

main()



Dispatch Tables

If one wants to customize pickling of some classes without disturbing any other code which depends on pickling, then one can create a pickler with a private dispatch table.

The global dispatch table managed by the copyreg module is available as copyreg.dispatch_table. Therefore, one may choose to use a modified copy of copyreg.dispatch_table as a private dispatch table.

For example

f = io.BytesIO()

p = pickle.Pickler(f)

p.dispatch_table = copyreg.dispatch_table.copy()

p.dispatch_table[SomeClass] = reduce_SomeClass



creates an instance of pickle.Pickler with a private dispatch table which handles the SomeClass class specially. Alternatively, the code

class MyPickler(pickle.Pickler):

dispatch_table = copyreg.dispatch_table.copy()

dispatch_table[SomeClass] = reduce_SomeClass

f = io.BytesIO()

p = MyPickler(f)



does the same but all instances of MyPickler will by default share the private dispatch table. On the other hand, the code

copyreg.pickle(SomeClass, reduce_SomeClass)

f = io.BytesIO()

p = pickle.Pickler(f)



modifies the global dispatch table shared by all users of the copyreg module.

The Python Library Reference, Release 3.13.2



Handling Stateful Objects

Here’s an example that shows how to modify pickling behavior for a class. The TextReader class below opens a text file, and returns the line number and line contents each time its readline() method is called. If a TextReader instance is pickled, all attributes except the file object member are saved. When the instance is unpickled, the file is reopened, and reading resumes from the last location. The __setstate__() and __getstate__() methods are used to implement this behavior.

class TextReader:

"""Print and number lines in a text file."""

def __init__(self, filename):

self.filename = filename

self.file = open(filename)

self.lineno = 0

def readline(self):

self.lineno += 1

line = self.file.readline()

if not line:

return None

if line.endswith('\n'):

line = line[:-1]

return "%i: %s" % (self.lineno, line)

def __getstate__(self):

# Copy the object's state from self.__dict__ which contains # all our instance attributes. Always use the dict.copy() # method to avoid modifying the original state.

state = self.__dict__.copy()

# Remove the unpicklable entries.

del state['file']

return state

def __setstate__(self, state):

# Restore instance attributes (i.e., filename and lineno). self.__dict__.update(state)

# Restore the previously opened file's state. To do so, we need to # reopen it and read from it until the line count is restored. file = open(self.filename)

for _ in range(self.lineno):

file.readline()

# Finally, save the file.

self.file = file



A sample usage might be something like this:

>>> reader = TextReader("hello.txt")

>>> reader.readline()

'1: Hello world!'

>>> reader.readline()

'2: I am line number two.'

>>> new_reader = pickle.loads(pickle.dumps(reader))

>>> new_reader.readline()

'3: Goodbye!'



The Python Library Reference, Release 3.13.2



12.1.6 Custom Reduction for Types, Functions, and Other Objects

Added in version 3.8.

Sometimes, dispatch_table may not be flexible enough. In particular we may want to customize pickling based on another criterion than the object’s type, or we may want to customize the pickling of functions and classes.

For those cases, it is possible to subclass from the Pickler class and implement a reducer_override()

method. This method can return an arbitrary reduction tuple (see __reduce__()). It can alternatively return

NotImplemented to fallback to the traditional behavior.

If both the dispatch_table and reducer_override() are defined, then reducer_override() method takes priority.



® Note

For performance reasons, reducer_override() may not be called for the following objects: None, True,

False , and exact instances of int, float, bytes, str, dict, set, frozenset, list and tuple.



Here is a simple example where we allow pickling and reconstructing a given class:

import io

import pickle

class MyClass:

my_attribute = 1

class MyPickler(pickle.Pickler):

def reducer_override(self, obj):

"""Custom reducer for MyClass."""

if getattr(obj, "__name__", None) == "MyClass":

return type, (obj.__name__, obj.__bases__,

{'my_attribute': obj.my_attribute})

else:

# For any other object, fallback to usual reduction return NotImplemented

f = io.BytesIO()

p = MyPickler(f)

p.dump(MyClass)

del MyClass

unpickled_class = pickle.loads(f.getvalue())

assert isinstance(unpickled_class, type)

assert unpickled_class.__name__ == "MyClass"

assert unpickled_class.my_attribute == 1



12.1.7 Out-of-band Buffers

Added in version 3.8.

In some contexts, the pickle module is used to transfer massive amounts of data. Therefore, it can be important to minimize the number of memory copies, to preserve performance and resource consumption. However, normal

operation of the pickle module, as it transforms a graph-like structure of objects into a sequential stream of bytes, intrinsically involves copying data to and from the pickle stream.

This constraint can be eschewed if both the provider (the implementation of the object types to be transferred) and the consumer (the implementation of the communications system) support the out-of-band transfer facilities provided The Python Library Reference, Release 3.13.2



by pickle protocol 5 and higher.



Provider API

The large data objects to be pickled must implement a __reduce_ex__() method specialized for protocol 5 and

higher, which returns a PickleBuffer instance (instead of e.g. a bytes object) for any large data.

A PickleBuffer object signals that the underlying buffer is eligible for out-of-band data transfer. Those objects

remain compatible with normal usage of the pickle module. However, consumers can also opt-in to tell pickle that they will handle those buffers by themselves.



Consumer API

A communications system can enable custom handling of the PickleBuffer objects generated when serializing an object graph.

On the sending side, it needs to pass a buffer_callback argument to Pickler (or to the dump() or dumps() function),

which will be called with each PickleBuffer generated while pickling the object graph. Buffers accumulated by the buffer_callback will not see their data copied into the pickle stream, only a cheap marker will be inserted.

On the receiving side, it needs to pass a buffers argument to Unpickler (or to the load() or loads() function), which is an iterable of the buffers which were passed to buffer_callback. That iterable should produce buffers in the same order as they were passed to buffer_callback. Those buffers will provide the data expected by the reconstructors

of the objects whose pickling produced the original PickleBuffer objects.

Between the sending side and the receiving side, the communications system is free to implement its own transfer mechanism for out-of-band buffers. Potential optimizations include the use of shared memory or datatype-dependent compression.



Example

Here is a trivial example where we implement a bytearray subclass able to participate in out-of-band buffer pick-ling:

class ZeroCopyByteArray(bytearray):

def __reduce_ex__(self, protocol):

if protocol >= 5:

return type(self)._reconstruct, (PickleBuffer(self),), None

else:

# PickleBuffer is forbidden with pickle protocols <= 4. return type(self)._reconstruct, (bytearray(self),)

@classmethod

def _reconstruct(cls, obj):

with memoryview(obj) as m:

# Get a handle over the original buffer object

obj = m.obj

if type(obj) is cls:

# Original buffer object is a ZeroCopyByteArray, return it # as-is.

return obj

else:

return cls(obj)



The reconstructor (the _reconstruct class method) returns the buffer’s providing object if it has the right type. This is an easy way to simulate zero-copy behaviour on this toy example.

On the consumer side, we can pickle those objects the usual way, which when unserialized will give us a copy of the original object:

The Python Library Reference, Release 3.13.2



b = ZeroCopyByteArray(b"abc")

data = pickle.dumps(b, protocol=5)

new_b = pickle.loads(data)

print(b == new_b) # True

print(b is new_b) # False: a copy was made



But if we pass a buffer_callback and then give back the accumulated buffers when unserializing, we are able to get back the original object:

b = ZeroCopyByteArray(b"abc")

buffers = []

data = pickle.dumps(b, protocol=5, buffer_callback=buffers.append) new_b = pickle.loads(data, buffers=buffers)

print(b == new_b) # True

print(b is new_b) # True: no copy was made



This example is limited by the fact that bytearray allocates its own memory: you cannot create a bytearray instance that is backed by another object’s memory. However, third-party datatypes such as NumPy arrays do not have this limitation, and allow use of zero-copy pickling (or making as few copies as possible) when transferring between distinct processes or systems.



µ See also

PEP 574 – Pickle protocol 5 with out-of-band data



12.1.8 Restricting Globals

By default, unpickling will import any class or function that it finds in the pickle data. For many applications, this behaviour is unacceptable as it permits the unpickler to import and invoke arbitrary code. Just consider what this hand-crafted pickle data stream does when loaded:

>>> import pickle

>>> pickle.loads(b"cos\nsystem\n(S'echo hello world'\ntR.") hello world

0



In this example, the unpickler imports the os.system() function and then apply the string argument “echo hello world”. Although this example is inoffensive, it is not difficult to imagine one that could damage your system.

For this reason, you may want to control what gets unpickled by customizing Unpickler.find_class(). Unlike

its name suggests, Unpickler.find_class() is called whenever a global (i.e., a class or a function) is requested. Thus it is possible to either completely forbid globals or restrict them to a safe subset.

Here is an example of an unpickler allowing only few safe classes from the builtins module to be loaded:

import builtins

import io

import pickle

safe_builtins = {

'range',

'complex',

'set',

'frozenset',

'slice',

}

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

class RestrictedUnpickler(pickle.Unpickler):

def find_class(self, module, name):

# Only allow safe classes from builtins.

if module == "builtins" and name in safe_builtins:

return getattr(builtins, name)

# Forbid everything else.

raise pickle.UnpicklingError("global '%s.%s' is forbidden" %

(module, name))

def restricted_loads(s):

"""Helper function analogous to pickle.loads()."""

return RestrictedUnpickler(io.BytesIO(s)).load()



A sample usage of our unpickler working as intended:

>>> restricted_loads(pickle.dumps([1, 2, range(15)])) [1, 2, range(0, 15)]

>>> restricted_loads(b"cos\nsystem\n(S'echo hello world'\ntR.") Traceback (most recent call last):

...

pickle.UnpicklingError: global 'os.system' is forbidden >>> restricted_loads(b'cbuiltins\neval\n'

... b'(S\'getattr(__import__("os"), "system")'

... b'("echo hello world")\'\ntR.')

Traceback (most recent call last):

...

pickle.UnpicklingError: global 'builtins.eval' is forbidden



As our examples shows, you have to be careful with what you allow to be unpickled. Therefore if security is a concern,

you may want to consider alternatives such as the marshalling API in xmlrpc.client or third-party solutions.



12.1.9 Performance

Recent versions of the pickle protocol (from protocol 2 and upwards) feature efficient binary encodings for several

common features and built-in types. Also, the pickle module has a transparent optimizer written in C.



12.1.10 Examples

For the simplest code, use the dump() and load() functions.

import pickle

# An arbitrary collection of objects supported by pickle. data = {

'a': [1, 2.0, 3+4j],

'b': ("character string", b"byte string"),

'c': {None, True, False}

}

with open('data.pickle', 'wb') as f:

# Pickle the 'data' dictionary using the highest protocol available.

pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)



The following example reads the resulting pickled data.



The Python Library Reference, Release 3.13.2



import pickle

with open('data.pickle', 'rb') as f:

# The protocol version used is detected automatically, so we do not

# have to specify it.

data = pickle.load(f)



µ See also

Module copyreg

Pickle interface constructor registration for extension types.

Module pickletools

Tools for working with and analyzing pickled data.

Module shelve

Indexed databases of objects; uses pickle.

Module copy

Shallow and deep object copying.

Module marshal

High-performance serialization of built-in types.



12.2 copyreg — Register pickle support functions

Source code: Lib/copyreg.py



The copyreg module offers a way to define functions used while pickling specific objects. The pickle and copy modules use those functions when pickling/copying those objects. The module provides configuration information about object constructors which are not classes. Such constructors may be factory functions or class instances.

copyreg.constructor(object)

Declares object to be a valid constructor. If object is not callable (and hence not valid as a constructor), raises

TypeError.

copyreg.pickle(type, function, constructor_ob=None)

Declares that function should be used as a “reduction” function for objects of type type. function must return

either a string or a tuple containing between two and six elements. See the dispatch_table for more details

on the interface of function.

The constructor_ob parameter is a legacy feature and is now ignored, but if passed it must be a callable.

Note that the dispatch_table attribute of a pickler object or subclass of pickle.Pickler can also be

used for declaring reduction functions.



12.2.1 Example

The example below would like to show how to register a pickle function and how it will be used:

>>> import copyreg, copy, pickle

>>> class C:

... def __init__(self, a):

... self.a = a

...

>>> def pickle_c(c):

... print("pickling a C instance...")

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... return C, (c.a,)

...

>>> copyreg.pickle(C, pickle_c)

>>> c = C(1)

>>> d = copy.copy(c)

pickling a C instance...

>>> p = pickle.dumps(c)

pickling a C instance...



12.3 shelve — Python object persistence

Source code: Lib/shelve.py



A “shelf” is a persistent, dictionary-like object. The difference with “dbm” databases is that the values (not the keys!)

in a shelf can be essentially arbitrary Python objects — anything that the pickle module can handle. This includes most class instances, recursive data types, and objects containing lots of shared sub-objects. The keys are ordinary strings.

shelve.open(filename, flag=’c’, protocol=None, writeback=False)

Open a persistent dictionary. The filename specified is the base filename for the underlying database. As a

side-effect, an extension may be added to the filename and more than one file may be created. By default,

the underlying database file is opened for reading and writing. The optional flag parameter has the same

interpretation as the flag parameter of dbm.open().

By default, pickles created with pickle.DEFAULT_PROTOCOL are used to serialize values. The version of

the pickle protocol can be specified with the protocol parameter.

Because of Python semantics, a shelf cannot know when a mutable persistent-dictionary entry is modified. By

default modified objects are written only when assigned to the shelf (see Example). If the optional writeback

parameter is set to True, all entries accessed are also cached in memory, and written back on sync() and

close() ; this can make it handier to mutate mutable entries in the persistent dictionary, but, if many entries

are accessed, it can consume vast amounts of memory for the cache, and it can make the close operation

very slow since all accessed entries are written back (there is no way to determine which accessed entries are

mutable, nor which ones were actually mutated).

Changed in version 3.10: pickle.DEFAULT_PROTOCOL is now used as the default pickle protocol.

Changed in version 3.11: Accepts path-like object for filename.



® Note

Do not rely on the shelf being closed automatically; always call close() explicitly when you don’t need it

any more, or use shelve.open() as a context manager:

with shelve.open('spam') as db:

db['eggs'] = 'eggs'



Á Warning

Because the shelve module is backed by pickle, it is insecure to load a shelf from an untrusted source. Like

with pickle, loading a shelf can execute arbitrary code.



Shelf objects support most of methods and operations supported by dictionaries (except copying, constructors and operators | and |=). This eases the transition from dictionary based scripts to those requiring persistent storage.

The Python Library Reference, Release 3.13.2



Two additional methods are supported:

Shelf.sync()

Write back all entries in the cache if the shelf was opened with writeback set to True. Also empty the cache

and synchronize the persistent dictionary on disk, if feasible. This is called automatically when the shelf is

closed with close().

Shelf.close()

Synchronize and close the persistent dict object. Operations on a closed shelf will fail with a ValueError.



µ See also

Persistent dictionary recipe with widely supported storage formats and having the speed of native dictionaries.



12.3.1 Restrictions

• The choice of which database package will be used (such as dbm.ndbm or dbm.gnu) depends on which in-

terface is available. Therefore it is not safe to open the database directly using dbm. The database is also

(unfortunately) subject to the limitations of dbm, if it is used — this means that (the pickled representation

of) the objects stored in the database should be fairly small, and in rare cases key collisions may cause the

database to refuse updates.

• The shelve module does not support concurrent read/write access to shelved objects. (Multiple simultaneous

read accesses are safe.) When a program has a shelf open for writing, no other program should have it open

for reading or writing. Unix file locking can be used to solve this, but this differs across Unix versions and

requires knowledge about the database implementation used.

• On macOS dbm.ndbm can silently corrupt the database file on updates, which can cause hard crashes when

trying to read from the database.

class shelve.Shelf(dict, protocol=None, writeback=False, keyencoding=’utf-8’ )

A subclass of collections.abc.MutableMapping which stores pickled values in the dict object.

By default, pickles created with pickle.DEFAULT_PROTOCOL are used to serialize values. The version of the

pickle protocol can be specified with the protocol parameter. See the pickle documentation for a discussion

of the pickle protocols.

If the writeback parameter is True, the object will hold a cache of all entries accessed and write them back

to the dict at sync and close times. This allows natural operations on mutable entries, but can consume much

more memory and make sync and close take a long time.

The keyencoding parameter is the encoding used to encode keys before they are used with the underlying dict.

A Shelf object can also be used as a context manager, in which case it will be automatically closed when the

with block ends.

Changed in version 3.2: Added the keyencoding parameter; previously, keys were always encoded in UTF-8.

Changed in version 3.4: Added context manager support.

Changed in version 3.10: pickle.DEFAULT_PROTOCOL is now used as the default pickle protocol.

class shelve.BsdDbShelf(dict, protocol=None, writeback=False, keyencoding=’utf-8’)

A subclass of Shelf which exposes first(), next(), previous(), last() and set_location() meth-

ods. These are available in the third-party bsddb module from pybsddb but not in other database modules.

The dict object passed to the constructor must support those methods. This is generally accomplished by call-

ing one of bsddb.hashopen(), bsddb.btopen() or bsddb.rnopen(). The optional protocol, writeback,

and keyencoding parameters have the same interpretation as for the Shelf class.

class shelve.DbfilenameShelf(filename, flag=’c’, protocol=None, writeback=False)

A subclass of Shelf which accepts a filename instead of a dict-like object. The underlying file will be opened

using dbm.open(). By default, the file will be created and opened for both read and write. The optional The Python Library Reference, Release 3.13.2



flag parameter has the same interpretation as for the open() function. The optional protocol and writeback

parameters have the same interpretation as for the Shelf class.



12.3.2 Example

To summarize the interface (key is a string, data is an arbitrary object):

import shelve

d = shelve.open(filename) # open -- file may get suffix added by low-level

# library

d[key] = data # store data at key (overwrites old data if

# using an existing key)

data = d[key] # retrieve a COPY of data at key (raise KeyError

# if no such key)

del d[key] # delete data stored at key (raises KeyError

# if no such key)

flag = key in d # true if the key exists

klist = list(d.keys()) # a list of all existing keys (slow!)

# as d was opened WITHOUT writeback=True, beware:

d['xx'] = [0, 1, 2] # this works as expected, but...

d['xx'].append(3) # *this doesn't!* -- d['xx'] is STILL [0, 1, 2]!

# having opened d without writeback=True, you need to code carefully: temp = d['xx'] # extracts the copy

temp.append(5) # mutates the copy

d['xx'] = temp # stores the copy right back, to persist it

# or, d=shelve.open(filename,writeback=True) would let you just code # d['xx'].append(5) and have it work as expected, BUT it would also # consume more memory and make the d.close() operation slower.

d.close() # close it



µ See also

Module dbm

Generic interface to dbm-style databases.

Module pickle

Object serialization used by shelve.



12.4 marshal — Internal Python object serialization



This module contains functions that can read and write Python values in a binary format. The format is specific to Python, but independent of machine architecture issues (e.g., you can write a Python value to a file on a PC, transport the file to a Mac, and read it back there). Details of the format are undocumented on purpose; it may change between

Python versions (although it rarely does).1

1 The name of this module stems from a bit of terminology used by the designers of Modula-3 (amongst others), who use the term “marshalling”

for shipping of data around in a self-contained form. Strictly speaking, “to marshal” means to convert some data from internal to external form (in an RPC buffer for instance) and “unmarshalling” for the reverse process.

The Python Library Reference, Release 3.13.2



This is not a general “persistence” module. For general persistence and transfer of Python objects through RPC

calls, see the modules pickle and shelve. The marshal module exists mainly to support reading and writing the “pseudo-compiled” code for Python modules of .pyc files. Therefore, the Python maintainers reserve the right to modify the marshal format in backward incompatible ways should the need arise. The format of code objects is not compatible between Python versions, even if the version of the format is the same. De-serializing a code object in the incorrect Python version has undefined behavior. If you’re serializing and de-serializing Python objects, use the

pickle module instead – the performance is comparable, version independence is guaranteed, and pickle supports a substantially wider range of objects than marshal.



Á Warning

The marshal module is not intended to be secure against erroneous or maliciously constructed data. Never

unmarshal data received from an untrusted or unauthenticated source.



Not all Python object types are supported; in general, only objects whose value is independent from a particular invocation of Python can be written and read by this module. The following types are supported: booleans, integers, floating-point numbers, complex numbers, strings, bytes, bytearrays, tuples, lists, sets, frozensets, dictionaries, and code objects (if allow_code is true), where it should be understood that tuples, lists, sets, frozensets and dictionaries

are only supported as long as the values contained therein are themselves supported. The singletons None, Ellipsis

and StopIteration can also be marshalled and unmarshalled. For format version lower than 3, recursive lists, sets and dictionaries cannot be written (see below).

There are functions that read/write files as well as functions operating on bytes-like objects.

The module defines these functions:

marshal.dump(value, file, version=version, / , *, allow_code=True)

Write the value on the open file. The value must be a supported type. The file must be a writeable binary file.

If the value has (or contains an object that has) an unsupported type, a ValueError exception is raised —

but garbage data will also be written to the file. The object will not be properly read back by load(). Code

objects are only supported if allow_code is true.

The version argument indicates the data format that dump should use (see below).

Raises an auditing event marshal.dumps with arguments value, version.

Changed in version 3.13: Added the allow_code parameter.

marshal.load(file, / , *, allow_code=True)

Read one value from the open file and return it. If no valid value is read (e.g. because the data has a different

Python version’s incompatible marshal format), raise EOFError, ValueError or TypeError. Code objects

are only supported if allow_code is true. The file must be a readable binary file.

Raises an auditing event marshal.load with no arguments.



® Note

If an object containing an unsupported type was marshalled with dump(), load() will substitute None for the unmarshallable type.



Changed in version 3.10: This call used to raise a code.__new__ audit event for each code object. Now it

raises a single marshal.load event for the entire load operation.

Changed in version 3.13: Added the allow_code parameter.

marshal.dumps(value, version=version, / , *, allow_code=True)

Return the bytes object that would be written to a file by dump(value, file). The value must be a supported

type. Raise a ValueError exception if value has (or contains an object that has) an unsupported type. Code

objects are only supported if allow_code is true.

The Python Library Reference, Release 3.13.2



The version argument indicates the data format that dumps should use (see below).

Raises an auditing event marshal.dumps with arguments value, version.

Changed in version 3.13: Added the allow_code parameter.

marshal.loads(bytes, / , *, allow_code=True)

Convert the bytes-like object to a value. If no valid value is found, raise EOFError, ValueError or

TypeError. Code objects are only supported if allow_code is true. Extra bytes in the input are ignored.

Raises an auditing event marshal.loads with argument bytes.

Changed in version 3.10: This call used to raise a code.__new__ audit event for each code object. Now it

raises a single marshal.loads event for the entire load operation.

Changed in version 3.13: Added the allow_code parameter.

In addition, the following constants are defined:

marshal.version

Indicates the format that the module uses. Version 0 is the historical format, version 1 shares interned strings

and version 2 uses a binary format for floating-point numbers. Version 3 adds support for object instancing

and recursion. The current version is 4.



12.5 dbm — Interfaces to Unix “databases”

Source code: Lib/dbm/__init__.py



dbm is a generic interface to variants of the DBM database:

• dbm.sqlite3

• dbm.gnu

• dbm.ndbm

If none of these modules are installed, the slow-but-simple implementation in module dbm.dumb will be used. There

is a third party interface to the Oracle Berkeley DB.

exception dbm.error

A tuple containing the exceptions that can be raised by each of the supported modules, with a unique exception

also named dbm.error as the first item — the latter is used when dbm.error is raised.

dbm.whichdb(filename)

This function attempts to guess which of the several simple database modules available — dbm.sqlite3,

dbm.gnu , dbm.ndbm, or dbm.dumb — should be used to open a given file.

Return one of the following values:

• None if the file can’t be opened because it’s unreadable or doesn’t exist

• the empty string ('') if the file’s format can’t be guessed

• a string containing the required module name, such as 'dbm.ndbm' or 'dbm.gnu'

Changed in version 3.11: filename accepts a path-like object.

dbm.open(file, flag=’r’ , mode=0o666)

Open a database and return the corresponding database object.

Parameters

• file (path-like object) – The database file to open.

If the database file already exists, the whichdb() function is used to determine its type and the appropriate module is used; if it does not exist, the first submodule listed above that can be imported is used.

The Python Library Reference, Release 3.13.2



• flag (str) –

– 'r' (default): Open existing database for reading only.

– 'w': Open existing database for reading and writing.

– 'c': Open database for reading and writing, creating it if it doesn’t exist.

– 'n': Always create a new, empty database, open for reading and writing.

• mode (int) – The Unix file access mode of the file (default: octal 0o666), used only when

the database has to be created.

Changed in version 3.11: file accepts a path-like object.

The object returned by open() supports the same basic functionality as a dict; keys and their corresponding values can be stored, retrieved, and deleted, and the in operator and the keys() method are available, as well as get() and setdefault() methods.

Key and values are always stored as bytes. This means that when strings are used they are implicitly converted to the default encoding before being stored.

These objects also support being used in a with statement, which will automatically close them when done.

Changed in version 3.2: get() and setdefault() methods are now available for all dbm backends.

Changed in version 3.4: Added native support for the context management protocol to the objects returned by

open().

Changed in version 3.8: Deleting a key from a read-only database raises a database module specific exception instead

of KeyError.

The following example records some hostnames and a corresponding title, and then prints out the contents of the database:

import dbm

# Open database, creating it if necessary.

with dbm.open('cache', 'c') as db:

# Record some values

db[b'hello'] = b'there'

db['www.python.org'] = 'Python Website'

db['www.cnn.com'] = 'Cable News Network'

# Note that the keys are considered bytes now.

assert db[b'www.python.org'] == b'Python Website'

# Notice how the value is now in bytes.

assert db['www.cnn.com'] == b'Cable News Network'

# Often-used methods of the dict interface work too.

print(db.get('python.org', b'not present'))

# Storing a non-string key or value will raise an exception (most

# likely a TypeError).

db['www.yahoo.com'] = 4

# db is automatically closed when leaving the with statement.



µ See also

Module shelve

Persistence module which stores non-string data.

The Python Library Reference, Release 3.13.2



The individual submodules are described in the following sections.



12.5.1 dbm.sqlite3 — SQLite backend for dbm

Added in version 3.13.

Source code: Lib/dbm/sqlite3.py



This module uses the standard library sqlite3 module to provide an SQLite backend for the dbm module. The files

created by dbm.sqlite3 can thus be opened by sqlite3, or any other SQLite browser, including the SQLite CLI.

Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.

dbm.sqlite3.open(filename, / , flag=’r’ , mode=0o666)

Open an SQLite database. The returned object behaves like a mapping, implements a close() method, and

supports a “closing” context manager via the with keyword.

Parameters

• filename (path-like object) – The path to the database to be opened.

• flag (str) –

– 'r' (default): Open existing database for reading only.

– 'w': Open existing database for reading and writing.

– 'c': Open database for reading and writing, creating it if it doesn’t exist.

– 'n': Always create a new, empty database, open for reading and writing.

• mode – The Unix file access mode of the file (default: octal 0o666), used only when the

database has to be created.



12.5.2 dbm.gnu — GNU database manager

Source code: Lib/dbm/gnu.py



The dbm.gnu module provides an interface to the GDBM (GNU dbm) library, similar to the dbm.ndbm module, but with additional functionality like crash tolerance.



® Note

The file formats created by dbm.gnu and dbm.ndbm are incompatible and can not be used interchangeably.



Availability: not Android, not iOS, not WASI.

This module is not supported on mobile platforms or WebAssembly platforms.

exception dbm.gnu.error

Raised on dbm.gnu-specific errors, such as I/O errors. KeyError is raised for general mapping errors like

specifying an incorrect key.

dbm.gnu.open(filename, flag=’r’ , mode=0o666, / )

Open a GDBM database and return a gdbm object.

Parameters

• filename (path-like object) – The database file to open.

• flag (str) –

The Python Library Reference, Release 3.13.2



– 'r' (default): Open existing database for reading only.

– 'w': Open existing database for reading and writing.

– 'c': Open database for reading and writing, creating it if it doesn’t exist.

– 'n': Always create a new, empty database, open for reading and writing.

The following additional characters may be appended to control how the database is opened:

– 'f': Open the database in fast mode. Writes to the database will not be synchronized.

– 's': Synchronized mode. Changes to the database will be written immediately to the

file.

– 'u': Do not lock database.

Not all flags are valid for all versions of GDBM. See the open_flags member for a list of supported flag characters.

• mode (int) – The Unix file access mode of the file (default: octal 0o666), used only when

the database has to be created.

Raises

error – If an invalid flag argument is passed.

Changed in version 3.11: filename accepts a path-like object.

dbm.gnu.open_flags

A string of characters the flag parameter of open() supports.

gdbm objects behave similar to mappings, but items() and values() methods are not supported. The

following methods are also provided:

gdbm.firstkey()

It’s possible to loop over every key in the database using this method and the nextkey() method. The traversal is ordered by GDBM’s internal hash values, and won’t be sorted by the key values. This method returns the starting key.

gdbm.nextkey(key)

Returns the key that follows key in the traversal. The following code prints every key in the database db, without having to create a list in memory that contains them all:

k = db.firstkey()

while k is not None:

print(k)

k = db.nextkey(k)



gdbm.reorganize()

If you have carried out a lot of deletions and would like to shrink the space used by the GDBM file, this routine will reorganize the database. gdbm objects will not shorten the length of a database file except by using this reorganization; otherwise, deleted file space will be kept and reused as new (key, value) pairs are added.

gdbm.sync()

When the database has been opened in fast mode, this method forces any unwritten data to be written to the disk.

gdbm.close()

Close the GDBM database.

gdbm.clear()

Remove all items from the GDBM database.

Added in version 3.13.

The Python Library Reference, Release 3.13.2



12.5.3 dbm.ndbm — New Database Manager

Source code: Lib/dbm/ndbm.py



The dbm.ndbm module provides an interface to the NDBM (New Database Manager) library. This module can be used with the “classic” NDBM interface or the GDBM compatibility interface.



® Note

The file formats created by dbm.gnu and dbm.ndbm are incompatible and can not be used interchangeably.



Á Warning

The NDBM library shipped as part of macOS has an undocumented limitation on the size of values, which can

result in corrupted database files when storing values larger than this limit. Reading such corrupted files can result

in a hard crash (segmentation fault).



Availability: not Android, not iOS, not WASI.

This module is not supported on mobile platforms or WebAssembly platforms.

exception dbm.ndbm.error

Raised on dbm.ndbm-specific errors, such as I/O errors. KeyError is raised for general mapping errors like

specifying an incorrect key.

dbm.ndbm.library

Name of the NDBM implementation library used.

dbm.ndbm.open(filename, flag=’r’ , mode=0o666, / )

Open an NDBM database and return an ndbm object.

Parameters

• filename (path-like object) – The basename of the database file (without the .dir or

.pag extensions).

• flag (str) –

– 'r' (default): Open existing database for reading only.

– 'w': Open existing database for reading and writing.

– 'c': Open database for reading and writing, creating it if it doesn’t exist.

– 'n': Always create a new, empty database, open for reading and writing.

• mode (int) – The Unix file access mode of the file (default: octal 0o666), used only when

the database has to be created.

ndbm objects behave similar to mappings, but items() and values() methods are not supported. The

following methods are also provided:

Changed in version 3.11: Accepts path-like object for filename.

ndbm.close()

Close the NDBM database.

ndbm.clear()

Remove all items from the NDBM database.

Added in version 3.13.

The Python Library Reference, Release 3.13.2



12.5.4 dbm.dumb — Portable DBM implementation

Source code: Lib/dbm/dumb.py



® Note

The dbm.dumb module is intended as a last resort fallback for the dbm module when a more robust module is not

available. The dbm.dumb module is not written for speed and is not nearly as heavily used as the other database

modules.



The dbm.dumb module provides a persistent dict-like interface which is written entirely in Python. Unlike other

dbm backends, such as dbm.gnu, no external library is required.

The dbm.dumb module defines the following:

exception dbm.dumb.error

Raised on dbm.dumb-specific errors, such as I/O errors. KeyError is raised for general mapping errors like

specifying an incorrect key.

dbm.dumb.open(filename, flag=’c’, mode=0o666)

Open a dbm.dumb database. The returned database object behaves similar to a mapping, in addition to pro-

viding sync() and close() methods.

Parameters

• filename – The basename of the database file (without extensions). A new database

creates the following files:

– filename.dat

– filename.dir

• flag (str) –

– 'r': Open existing database for reading only.

– 'w': Open existing database for reading and writing.

– 'c' (default): Open database for reading and writing, creating it if it doesn’t exist.

– 'n': Always create a new, empty database, open for reading and writing.

• mode (int) – The Unix file access mode of the file (default: octal 0o666), used only when

the database has to be created.



Á Warning

It is possible to crash the Python interpreter when loading a database with a sufficiently large/complex entry due to stack depth limitations in Python’s AST compiler.



Changed in version 3.5: open() always creates a new database when flag is 'n'.

Changed in version 3.8: A database opened read-only if flag is 'r'. A database is not created if it does not

exist if flag is 'r' or 'w'.

Changed in version 3.11: filename accepts a path-like object.

In addition to the methods provided by the collections.abc.MutableMapping class, the following meth-

ods are provided:

dumbdbm.sync()

Synchronize the on-disk directory and data files. This method is called by the shelve.Shelf.sync() method.

The Python Library Reference, Release 3.13.2



dumbdbm.close()

Close the database.



12.6 sqlite3 — DB-API 2.0 interface for SQLite databases

Source code: Lib/sqlite3/ SQLite is a C library that provides a lightweight disk-based database that doesn’t require a separate server process and allows accessing the database using a nonstandard variant of the SQL query language. Some applications can use SQLite for internal data storage. It’s also possible to prototype an application using SQLite and then port the code to a larger database such as PostgreSQL or Oracle.

The sqlite3 module was written by Gerhard Häring. It provides an SQL interface compliant with the DB-API 2.0

specification described by PEP 249, and requires SQLite 3.15.2 or newer.

This document includes four main sections:

• Tutorial teaches how to use the sqlite3 module.

• Reference describes the classes and functions this module defines.

• How-to guides details how to handle specific tasks.

• Explanation provides in-depth background on transaction control.



µ See also

https://www.sqlite.org

The SQLite web page; the documentation describes the syntax and the available data types for the supported SQL dialect.

https://www.w3schools.com/sql/

Tutorial, reference and examples for learning SQL syntax.

PEP 249- Database API Specification 2.0

PEP written by Marc-André Lemburg.



12.6.1 Tutorial

In this tutorial, you will create a database of Monty Python movies using basic sqlite3 functionality. It assumes a

fundamental understanding of database concepts, including cursors and transactions.

First, we need to create a new database and open a database connection to allow sqlite3 to work with it. Call

sqlite3.connect() to create a connection to the database tutorial.db in the current working directory, im-plicitly creating it if it does not exist:

import sqlite3

con = sqlite3.connect("tutorial.db")



The returned Connection object con represents the connection to the on-disk database.

In order to execute SQL statements and fetch results from SQL queries, we will need to use a database cursor. Call

con.cursor() to create the Cursor:

cur = con.cursor()



Now that we’ve got a database connection and a cursor, we can create a database table movie with columns for title, release year, and review score. For simplicity, we can just use column names in the table declaration – thanks to the

flexible typing feature of SQLite, specifying the data types is optional. Execute the CREATE TABLE statement by

calling cur.execute(...):

cur.execute("CREATE TABLE movie(title, year, score)")

The Python Library Reference, Release 3.13.2



We can verify that the new table has been created by querying the sqlite_master table built-in to SQLite, which

should now contain an entry for the movie table definition (see The Schema Table for details). Execute that query

by calling cur.execute(...), assign the result to res, and call res.fetchone() to fetch the resulting row:

>>> res = cur.execute("SELECT name FROM sqlite_master") >>> res.fetchone()

('movie',)



We can see that the table has been created, as the query returns a tuple containing the table’s name. If we query sqlite_master for a non-existent table spam, res.fetchone() will return None:

>>> res = cur.execute("SELECT name FROM sqlite_master WHERE name='spam'") >>> res.fetchone() is None

True



Now, add two rows of data supplied as SQL literals by executing an INSERT statement, once again by calling cur.

execute(...):

cur.execute("""

INSERT INTO movie VALUES

('Monty Python and the Holy Grail', 1975, 8.2),

('And Now for Something Completely Different', 1971, 7.5)

""")



The INSERT statement implicitly opens a transaction, which needs to be committed before changes are saved in

the database (see Transaction control for details). Call con.commit() on the connection object to commit the transaction:

con.commit()



We can verify that the data was inserted correctly by executing a SELECT query. Use the now-familiar cur.

execute(...) to assign the result to res, and call res.fetchall() to return all resulting rows:

>>> res = cur.execute("SELECT score FROM movie")

>>> res.fetchall()

[(8.2,), (7.5,)]



The result is a list of two tuples, one per row, each containing that row’s score value.

Now, insert three more rows by calling cur.executemany(...):

data = [

("Monty Python Live at the Hollywood Bowl", 1982, 7.9),

("Monty Python's The Meaning of Life", 1983, 7.5),

("Monty Python's Life of Brian", 1979, 8.0),

]

cur.executemany("INSERT INTO movie VALUES(?, ?, ?)", data) con.commit() # Remember to commit the transaction after executing INSERT.



Notice that ? placeholders are used to bind data to the query. Always use placeholders instead of string formatting

to bind Python values to SQL statements, to avoid SQL injection attacks (see How to use placeholders to bind values

in SQL queries for more details).

We can verify that the new rows were inserted by executing a SELECT query, this time iterating over the results of the query:

>>> for row in cur.execute("SELECT year, title FROM movie ORDER BY year"): ... print(row)

(1971, 'And Now for Something Completely Different') (1975, 'Monty Python and the Holy Grail')

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

(1979, "Monty Python's Life of Brian")

(1982, 'Monty Python Live at the Hollywood Bowl')

(1983, "Monty Python's The Meaning of Life")



Each row is a two-item tuple of (year, title), matching the columns selected in the query.

Finally, verify that the database has been written to disk by calling con.close() to close the existing connection, opening a new one, creating a new cursor, then querying the database:

>>> con.close()

>>> new_con = sqlite3.connect("tutorial.db")

>>> new_cur = new_con.cursor()

>>> res = new_cur.execute("SELECT title, year FROM movie ORDER BY score DESC") >>> title, year = res.fetchone()

>>> print(f'The highest scoring Monty Python movie is {title!r}, released in {year}

, →')

The highest scoring Monty Python movie is 'Monty Python and the Holy Grail',␣

, →released in 1975

>>> new_con.close()



You’ve now created an SQLite database using the sqlite3 module, inserted data and retrieved values from it in multiple ways.



µ See also

• How-to guides for further reading:

– How to use placeholders to bind values in SQL queries

– How to adapt custom Python types to SQLite values

– How to convert SQLite values to custom Python types

– How to use the connection context manager

– How to create and use row factories

• Explanation for in-depth background on transaction control.



12.6.2 Reference

Module functions

sqlite3.connect(database, timeout=5.0, detect_types=0, isolation_level=’DEFERRED’,

check_same_thread=True, factory=sqlite3.Connection, cached_statements=128, uri=False, *, autocommit=sqlite3.LEGACY_TRANSACTION_CONTROL)

Open a connection to an SQLite database.

Parameters

• database (path-like object) – The path to the database file to be opened. You can pass

":memory:" to create an SQLite database existing only in memory, and open a connec-tion to it.

• timeout (float) – How many seconds the connection should wait before raising an

OperationalError when a table is locked. If another connection opens a transaction to modify a table, that table will be locked until the transaction is committed. Default five seconds.

• detect_types (int) – Control whether and how data types not natively supported by

SQLite are looked up to be converted to Python types, using the converters registered

with register_converter(). Set it to any combination (using |, bitwise or) of

The Python Library Reference, Release 3.13.2



PARSE_DECLTYPES and PARSE_COLNAMES to enable this. Column names takes prece-dence over declared types if both flags are set. Types cannot be detected for generated

fields (for example max(data)), even when the detect_types parameter is set; str will be returned instead. By default (0), type detection is disabled.

• isolation_level (str | None) – Control legacy transaction handling behaviour.

See Connection.isolation_level and Transaction control via the isolation_level

attribute for more information. Can be "DEFERRED" (default), "EXCLUSIVE" or "IMMEDIATE" ; or None to disable opening transactions implicitly. Has no effect unless

Connection.autocommit is set to LEGACY_TRANSACTION_CONTROL (the default).

• check_same_thread (bool) – If True (default), ProgrammingError will be raised if

the database connection is used by a thread other than the one that created it. If False, the connection may be accessed in multiple threads; write operations may need to be serialized

by the user to avoid data corruption. See threadsafety for more information.

• factory (Connection) – A custom subclass of Connection to create the connection

with, if not the default Connection class.

• cached_statements (int) – The number of statements that sqlite3 should internally

cache for this connection, to avoid parsing overhead. By default, 128 statements.

• uri (bool) – If set to True, database is interpreted as a URI (Uniform Resource Iden-

tifier) with a file path and an optional query string. The scheme part must be "file:", and the path can be relative or absolute. The query string allows passing parameters to

SQLite, enabling various How to work with SQLite URIs.

• autocommit (bool) – Control PEP 249 transaction handling behaviour. See

Connection.autocommit and Transaction control via the autocommit attribute for more

information. autocommit currently defaults to LEGACY_TRANSACTION_CONTROL. The default will change to False in a future Python release.

Return type

Connection

Raises an auditing event sqlite3.connect with argument database.

Raises an auditing event sqlite3.connect/handle with argument connection_handle.

Changed in version 3.4: Added the uri parameter.

Changed in version 3.7: database can now also be a path-like object, not only a string.

Changed in version 3.10: Added the sqlite3.connect/handle auditing event.

Changed in version 3.12: Added the autocommit parameter.

Changed in version 3.13: Positional use of the parameters timeout, detect_types, isolation_level,

check_same_thread, factory, cached_statements, and uri is deprecated. They will become keyword-only pa-

rameters in Python 3.15.

sqlite3.complete_statement(statement)

Return True if the string statement appears to contain one or more complete SQL statements. No syntactic

verification or parsing of any kind is performed, other than checking that there are no unclosed string literals

and the statement is terminated by a semicolon.

For example:

>>> sqlite3.complete_statement("SELECT foo FROM bar;")

True

>>> sqlite3.complete_statement("SELECT foo")

False



This function may be useful during command-line input to determine if the entered text seems to form a

complete SQL statement, or if additional input is needed before calling execute().

See runsource() in Lib/sqlite3/__main__.py for real-world use.

The Python Library Reference, Release 3.13.2



sqlite3.enable_callback_tracebacks(flag, / )

Enable or disable callback tracebacks. By default you will not get any tracebacks in user-defined functions,

aggregates, converters, authorizer callbacks etc. If you want to debug them, you can call this function with flag

set to True. Afterwards, you will get tracebacks from callbacks on sys.stderr. Use False to disable the

feature again.



® Note

Errors in user-defined function callbacks are logged as unraisable exceptions. Use an unraisable hook

handler for introspection of the failed callback.



sqlite3.register_adapter(type, adapter, / )

Register an adapter callable to adapt the Python type type into an SQLite type. The adapter is called with a

Python object of type type as its sole argument, and must return a value of a type that SQLite natively under-

stands.

sqlite3.register_converter(typename, converter, / )

Register the converter callable to convert SQLite objects of type typename into a Python object of a specific

type. The converter is invoked for all SQLite values of type typename; it is passed a bytes object and should

return an object of the desired Python type. Consult the parameter detect_types of connect() for information

regarding how type detection works.

Note: typename and the name of the type in your query are matched case-insensitively.



Module constants

sqlite3.LEGACY_TRANSACTION_CONTROL

Set autocommit to this constant to select old style (pre-Python 3.12) transaction control behaviour. See

Transaction control via the isolation_level attribute for more information.

sqlite3.PARSE_COLNAMES

Pass this flag value to the detect_types parameter of connect() to look up a converter function by using the

type name, parsed from the query column name, as the converter dictionary key. The type name must be

wrapped in square brackets ([]).

SELECT p as "p [point]" FROM test; ! will look up converter "point"



This flag may be combined with PARSE_DECLTYPES using the | (bitwise or) operator.

sqlite3.PARSE_DECLTYPES

Pass this flag value to the detect_types parameter of connect() to look up a converter function using the

declared types for each column. The types are declared when the database table is created. sqlite3 will look

up a converter function using the first word of the declared type as the converter dictionary key. For example:

CREATE TABLE test(

i integer primary key, ! will look up a converter named "integer" p point, ! will look up a converter named "point"

n number(10) ! will look up a converter named "number"

)



This flag may be combined with PARSE_COLNAMES using the | (bitwise or) operator.

sqlite3.SQLITE_OK

sqlite3.SQLITE_DENY

sqlite3.SQLITE_IGNORE

Flags that should be returned by the authorizer_callback callable passed to Connection.

set_authorizer(), to indicate whether:

• Access is allowed (SQLITE_OK),

The Python Library Reference, Release 3.13.2



• The SQL statement should be aborted with an error (SQLITE_DENY)

• The column should be treated as a NULL value (SQLITE_IGNORE)

sqlite3.apilevel

String constant stating the supported DB-API level. Required by the DB-API. Hard-coded to "2.0".

sqlite3.paramstyle

String constant stating the type of parameter marker formatting expected by the sqlite3 module. Required

by the DB-API. Hard-coded to "qmark".



® Note

The named DB-API parameter style is also supported.



sqlite3.sqlite_version

Version number of the runtime SQLite library as a string.

sqlite3.sqlite_version_info

Version number of the runtime SQLite library as a tuple of integers.

sqlite3.threadsafety

Integer constant required by the DB-API 2.0, stating the level of thread safety the sqlite3 module supports.

This attribute is set based on the default threading mode the underlying SQLite library is compiled with. The

SQLite threading modes are:

1. Single-thread: In this mode, all mutexes are disabled and SQLite is unsafe to use in more than a single

thread at once.

2. Multi-thread: In this mode, SQLite can be safely used by multiple threads provided that no single

database connection is used simultaneously in two or more threads.

3. Serialized: In serialized mode, SQLite can be safely used by multiple threads with no restriction.

The mappings from SQLite threading modes to DB-API 2.0 threadsafety levels are as follows:



SQLite threading thread- SQLITE_THREADSAFE DB-API 2.0 meaning

mode safety

single-thread 0 0 Threads may not share the module

multi-thread 1 2 Threads may share the module, but not con-

nections

serialized 3 1 Threads may share the module, connections

and cursors



Changed in version 3.11: Set threadsafety dynamically instead of hard-coding it to 1.

sqlite3.version

Version number of this module as a string. This is not the version of the SQLite library.

Deprecated since version 3.12, will be removed in version 3.14: This constant used to reflect the version

number of the pysqlite package, a third-party library which used to upstream changes to sqlite3. Today,

it carries no meaning or practical value.

sqlite3.version_info

Version number of this module as a tuple of integers. This is not the version of the SQLite library.

Deprecated since version 3.12, will be removed in version 3.14: This constant used to reflect the version

number of the pysqlite package, a third-party library which used to upstream changes to sqlite3. Today,

it carries no meaning or practical value.

sqlite3.SQLITE_DBCONFIG_DEFENSIVE

The Python Library Reference, Release 3.13.2



sqlite3.SQLITE_DBCONFIG_DQS_DDL

sqlite3.SQLITE_DBCONFIG_DQS_DML

sqlite3.SQLITE_DBCONFIG_ENABLE_FKEY

sqlite3.SQLITE_DBCONFIG_ENABLE_FTS3_TOKENIZER

sqlite3.SQLITE_DBCONFIG_ENABLE_LOAD_EXTENSION

sqlite3.SQLITE_DBCONFIG_ENABLE_QPSG

sqlite3.SQLITE_DBCONFIG_ENABLE_TRIGGER

sqlite3.SQLITE_DBCONFIG_ENABLE_VIEW

sqlite3.SQLITE_DBCONFIG_LEGACY_ALTER_TABLE

sqlite3.SQLITE_DBCONFIG_LEGACY_FILE_FORMAT

sqlite3.SQLITE_DBCONFIG_NO_CKPT_ON_CLOSE

sqlite3.SQLITE_DBCONFIG_RESET_DATABASE

sqlite3.SQLITE_DBCONFIG_TRIGGER_EQP

sqlite3.SQLITE_DBCONFIG_TRUSTED_SCHEMA

sqlite3.SQLITE_DBCONFIG_WRITABLE_SCHEMA

These constants are used for the Connection.setconfig() and getconfig() methods.

The availability of these constants varies depending on the version of SQLite Python was compiled with.

Added in version 3.12.



µ See also



https://www.sqlite.org/c3ref/c_dbconfig_defensive.html

SQLite docs: Database Connection Configuration Options



Connection objects

class sqlite3.Connection

Each open SQLite database is represented by a Connection object, which is created using sqlite3.

connect(). Their main purpose is creating Cursor objects, and Transaction control.



µ See also



• How to use connection shortcut methods

• How to use the connection context manager



Changed in version 3.13: A ResourceWarning is emitted if close() is not called before a Connection

object is deleted.

An SQLite database connection has the following attributes and methods:

cursor(factory=Cursor)

Create and return a Cursor object. The cursor method accepts a single optional parameter factory. If

supplied, this must be a callable returning an instance of Cursor or its subclasses.

blobopen(table, column, row, / , *, readonly=False, name=’main’)

Open a Blob handle to an existing BLOB (Binary Large OBject).

Parameters

• table (str) – The name of the table where the blob is located.

• column (str) – The name of the column where the blob is located.

The Python Library Reference, Release 3.13.2



• row (str) – The name of the row where the blob is located.

• readonly (bool) – Set to True if the blob should be opened without write permissions.

Defaults to False.

• name (str) – The name of the database where the blob is located. Defaults to "main".

Raises

OperationalError – When trying to open a blob in a WITHOUT ROWID table.

Return type

Blob



® Note

The blob size cannot be changed using the Blob class. Use the SQL function zeroblob to create a blob with a fixed size.



Added in version 3.11.

commit()

Commit any pending transaction to the database. If autocommit is True, or there is no open transaction, this method does nothing. If autocommit is False, a new transaction is implicitly opened if a pending transaction was committed by this method.

rollback()

Roll back to the start of any pending transaction. If autocommit is True, or there is no open transaction, this method does nothing. If autocommit is False, a new transaction is implicitly opened if a pending transaction was rolled back by this method.

close()

Close the database connection. If autocommit is False, any pending transaction is implicitly rolled

back. If autocommit is True or LEGACY_TRANSACTION_CONTROL, no implicit transaction control is

executed. Make sure to commit() before closing to avoid losing pending changes.

execute(sql, parameters=(), / )

Create a new Cursor object and call execute() on it with the given sql and parameters. Return the new cursor object.

executemany(sql, parameters, / )

Create a new Cursor object and call executemany() on it with the given sql and parameters. Return the new cursor object.

executescript(sql_script, / )

Create a new Cursor object and call executescript() on it with the given sql_script. Return the new cursor object.

create_function(name, narg, func, *, deterministic=False)

Create or remove a user-defined SQL function.

Parameters

• name (str) – The name of the SQL function.

• narg (int) – The number of arguments the SQL function can accept. If-1, it may take

any number of arguments.

• func (callback | None) – A callable that is called when the SQL function is invoked.

The callable must return a type natively supported by SQLite. Set to None to remove an existing SQL function.

• deterministic (bool) – If True, the created SQL function is marked as determin-

istic, which allows SQLite to perform additional optimizations.

The Python Library Reference, Release 3.13.2



Changed in version 3.8: Added the deterministic parameter.

Example:

>>> import hashlib

>>> def md5sum(t):

... return hashlib.md5(t).hexdigest()

>>> con = sqlite3.connect(":memory:")

>>> con.create_function("md5", 1, md5sum)

>>> for row in con.execute("SELECT md5(?)", (b"foo",)): ... print(row)

('acbd18db4cc2f85cedef654fccc4a4d8',)

>>> con.close()



Changed in version 3.13: Passing name, narg, and func as keyword arguments is deprecated. These parameters will become positional-only in Python 3.15.

create_aggregate( name, n_arg, aggregate_class)

Create or remove a user-defined SQL aggregate function.

Parameters

• name (str) – The name of the SQL aggregate function.

• n_arg (int) – The number of arguments the SQL aggregate function can accept. If

-1, it may take any number of arguments.

• aggregate_class (class | None) – A class must implement the following methods:

– step(): Add a row to the aggregate.

– finalize(): Return the final result of the aggregate as a type natively supported by

SQLite.

The number of arguments that the step() method must accept is controlled by n_arg.

Set to None to remove an existing SQL aggregate function.

Example:

class MySum:

def __init__(self):

self.count = 0

def step(self, value):

self.count += value

def finalize(self):

return self.count

con = sqlite3.connect(":memory:")

con.create_aggregate("mysum", 1, MySum)

cur = con.execute("CREATE TABLE test(i)")

cur.execute("INSERT INTO test(i) VALUES(1)")

cur.execute("INSERT INTO test(i) VALUES(2)")

cur.execute("SELECT mysum(i) FROM test")

print(cur.fetchone()[0])

con.close()



Changed in version 3.13: Passing name, n_arg, and aggregate_class as keyword arguments is deprecated. These parameters will become positional-only in Python 3.15.

The Python Library Reference, Release 3.13.2



create_window_function(name, num_params, aggregate_class, / )

Create or remove a user-defined aggregate window function.

Parameters

• name (str) – The name of the SQL aggregate window function to create or remove.

• num_params (int) – The number of arguments the SQL aggregate window function

can accept. If-1, it may take any number of arguments.

• aggregate_class (class | None) – A class that must implement the following methods:

– step(): Add a row to the current window.

– value(): Return the current value of the aggregate.

– inverse(): Remove a row from the current window.

– finalize(): Return the final result of the aggregate as a type natively supported by

SQLite.

The number of arguments that the step() and value() methods must accept is con-trolled by num_params.

Set to None to remove an existing SQL aggregate window function.

Raises

NotSupportedError – If used with a version of SQLite older than 3.25.0, which does not support aggregate window functions.

Added in version 3.11.

Example:

# Example taken from https://www.sqlite.org/windowfunctions.html#udfwinfunc class WindowSumInt:

def __init__(self):

self.count = 0

def step(self, value):

"""Add a row to the current window."""

self.count += value

def value(self):

"""Return the current value of the aggregate."""

return self.count

def inverse(self, value):

"""Remove a row from the current window."""

self.count-= value

def finalize(self):

"""Return the final value of the aggregate.

Any clean-up actions should be placed here.

"""

return self.count



con = sqlite3.connect(":memory:")

cur = con.execute("CREATE TABLE test(x, y)")

values = [

("a", 4),

("b", 5),

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

("c", 3),

("d", 8),

("e", 1),

]

cur.executemany("INSERT INTO test VALUES(?, ?)", values) con.create_window_function("sumint", 1, WindowSumInt) cur.execute("""

SELECT x, sumint(y) OVER (

ORDER BY x ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING

) AS sum_y

FROM test ORDER BY x

""")

print(cur.fetchall())

con.close()



create_collation( name, callable, / )

Create a collation named name using the collating function callable. callable is passed two string

arguments, and it should return an integer:

• 1 if the first is ordered higher than the second

•-1 if the first is ordered lower than the second

• 0 if they are ordered equal

The following example shows a reverse sorting collation:

def collate_reverse(string1, string2):

if string1 == string2:

return 0

elif string1 < string2:

return 1

else:

return-1

con = sqlite3.connect(":memory:")

con.create_collation("reverse", collate_reverse)

cur = con.execute("CREATE TABLE test(x)")

cur.executemany("INSERT INTO test(x) VALUES(?)", [("a",), ("b",)]) cur.execute("SELECT x FROM test ORDER BY x COLLATE reverse") for row in cur:

print(row)

con.close()



Remove a collation function by setting callable to None.

Changed in version 3.11: The collation name can contain any Unicode character. Earlier, only ASCII characters were allowed.

interrupt()

Call this method from a different thread to abort any queries that might be executing on the connection.

Aborted queries will raise an OperationalError.

set_authorizer(authorizer_callback)

Register callable authorizer_callback to be invoked for each attempt to access a column of a table in the

database. The callback should return one of SQLITE_OK, SQLITE_DENY, or SQLITE_IGNORE to signal how access to the column should be handled by the underlying SQLite library.

The first argument to the callback signifies what kind of operation is to be authorized. The second and third argument will be arguments or None depending on the first argument. The 4th argument is the name

The Python Library Reference, Release 3.13.2



of the database (“main”, “temp”, etc.) if applicable. The 5th argument is the name of the inner-most trigger or view that is responsible for the access attempt or None if this access attempt is directly from input SQL code.

Please consult the SQLite documentation about the possible values for the first argument and the meaning of the second and third argument depending on the first one. All necessary constants are available in the sqlite3 module.

Passing None as authorizer_callback will disable the authorizer.

Changed in version 3.11: Added support for disabling the authorizer using None.

Changed in version 3.13: Passing authorizer_callback as a keyword argument is deprecated. The param-eter will become positional-only in Python 3.15.

set_progress_handler(progress_handler, n)

Register callable progress_handler to be invoked for every n instructions of the SQLite virtual machine. This is useful if you want to get called from SQLite during long-running operations, for example to update a GUI.

If you want to clear any previously installed progress handler, call the method with None for progress_handler.

Returning a non-zero value from the handler function will terminate the currently executing query and

cause it to raise a DatabaseError exception.

Changed in version 3.13: Passing progress_handler as a keyword argument is deprecated. The parameter will become positional-only in Python 3.15.

set_trace_callback(trace_callback)

Register callable trace_callback to be invoked for each SQL statement that is actually executed by the SQLite backend.

The only argument passed to the callback is the statement (as str) that is being executed. The return value of the callback is ignored. Note that the backend does not only run statements passed to the

Cursor.execute() methods. Other sources include the transaction management of the sqlite3 module and the execution of triggers defined in the current database.

Passing None as trace_callback will disable the trace callback.



® Note

Exceptions raised in the trace callback are not propagated. As a development and debugging aid, use

enable_callback_tracebacks() to enable printing tracebacks from exceptions raised in the trace callback.



Added in version 3.3.

Changed in version 3.13: Passing trace_callback as a keyword argument is deprecated. The parameter will become positional-only in Python 3.15.

enable_load_extension(enabled, / )

Enable the SQLite engine to load SQLite extensions from shared libraries if enabled is True; else, dis-allow loading SQLite extensions. SQLite extensions can define new functions, aggregates or whole new virtual table implementations. One well-known extension is the fulltext-search extension distributed with SQLite.



® Note

The sqlite3 module is not built with loadable extension support by default, because some plat-forms (notably macOS) have SQLite libraries which are compiled without this feature. To get load-The Python Library Reference, Release 3.13.2



able extension support, you must pass the--enable-loadable-sqlite-extensions option to configure.



Raises an auditing event sqlite3.enable_load_extension with arguments connection, enabled .

Added in version 3.2.

Changed in version 3.10: Added the sqlite3.enable_load_extension auditing event.

con.enable_load_extension(True)

# Load the fulltext search extension

con.execute("select load_extension('./fts3.so')")

# alternatively you can load the extension using an API call: # con.load_extension("./fts3.so")

# disable extension loading again

con.enable_load_extension(False)

# example from SQLite wiki

con.execute("CREATE VIRTUAL TABLE recipe USING fts3(name, ingredients)") con.executescript("""

INSERT INTO recipe (name, ingredients) VALUES('broccoli stew',

, →'broccoli peppers cheese tomatoes');

INSERT INTO recipe (name, ingredients) VALUES('pumpkin stew', 'pumpkin␣

, →onions garlic celery');

INSERT INTO recipe (name, ingredients) VALUES('broccoli pie',

, →'broccoli cheese onions flour');

INSERT INTO recipe (name, ingredients) VALUES('pumpkin pie', 'pumpkin␣

, →sugar flour butter');

""")

for row in con.execute("SELECT rowid, name, ingredients FROM recipe WHERE␣

, →name MATCH 'pie'"):

print(row)



load_extension(path, / , *, entrypoint=None)

Load an SQLite extension from a shared library. Enable extension loading with

enable_load_extension() before calling this method.

Parameters

• path (str) – The path to the SQLite extension.

• entrypoint (str | None) – Entry point name. If None (the default), SQLite will

come up with an entry point name of its own; see the SQLite docs Loading an Extension for details.

Raises an auditing event sqlite3.load_extension with arguments connection, path.

Added in version 3.2.

Changed in version 3.10: Added the sqlite3.load_extension auditing event.

Changed in version 3.12: Added the entrypoint parameter.

iterdump(*, filter=None)

Return an iterator to dump the database as SQL source code. Useful when saving an in-memory database for later restoration. Similar to the .dump command in the sqlite3 shell.

The Python Library Reference, Release 3.13.2



Parameters

filter (str | None) – An optional LIKE pattern for database objects to dump, e.g. prefix_% . If None (the default), all database objects will be included.

Example:

# Convert file example.db to SQL dump file dump.sql con = sqlite3.connect('example.db')

with open('dump.sql', 'w') as f:

for line in con.iterdump():

f.write('%s\n' % line)

con.close()



µ See also

How to handle non-UTF-8 text encodings



Changed in version 3.13: Added the filter parameter.

backup(target, *, pages=-1, progress=None, name=’main’ , sleep=0.250)

Create a backup of an SQLite database.

Works even if the database is being accessed by other clients or concurrently by the same connection.

Parameters

• target (Connection) – The database connection to save the backup to.

• pages (int) – The number of pages to copy at a time. If equal to or less than 0, the

entire database is copied in a single step. Defaults to-1.

• progress (callback | None) – If set to a callable, it is invoked with three integer argu-

ments for every backup iteration: the status of the last iteration, the remaining number of pages still to be copied, and the total number of pages. Defaults to None.

• name (str) – The name of the database to back up. Either "main" (the default) for the

main database, "temp" for the temporary database, or the name of a custom database as attached using the ATTACH DATABASE SQL statement.

• sleep (float) – The number of seconds to sleep between successive attempts to back

up remaining pages.

Example 1, copy an existing database into another:

def progress(status, remaining, total):

print(f'Copied {total-remaining} of {total} pages...')

src = sqlite3.connect('example.db')

dst = sqlite3.connect('backup.db')

with dst:

src.backup(dst, pages=1, progress=progress)

dst.close()

src.close()



Example 2, copy an existing database into a transient copy:

src = sqlite3.connect('example.db')

dst = sqlite3.connect(':memory:')

src.backup(dst)

dst.close()

src.close()

The Python Library Reference, Release 3.13.2



Added in version 3.7.



µ See also

How to handle non-UTF-8 text encodings



getlimit(category, / )

Get a connection runtime limit.

Parameters

category (int) – The SQLite limit category to be queried.

Return type

int

Raises

ProgrammingError – If category is not recognised by the underlying SQLite library.

Example, query the maximum length of an SQL statement for Connection con (the default is 1000000000):

>>> con.getlimit(sqlite3.SQLITE_LIMIT_SQL_LENGTH)

1000000000



Added in version 3.11.

setlimit(category, limit, / )

Set a connection runtime limit. Attempts to increase a limit above its hard upper bound are silently truncated to the hard upper bound. Regardless of whether or not the limit was changed, the prior value of the limit is returned.

Parameters

• category (int) – The SQLite limit category to be set.

• limit (int) – The value of the new limit. If negative, the current limit is unchanged.

Return type

int

Raises

ProgrammingError – If category is not recognised by the underlying SQLite library.

Example, limit the number of attached databases to 1 for Connection con (the default limit is 10):

>>> con.setlimit(sqlite3.SQLITE_LIMIT_ATTACHED, 1)

10

>>> con.getlimit(sqlite3.SQLITE_LIMIT_ATTACHED)

1



Added in version 3.11.

getconfig(op, / )

Query a boolean connection configuration option.

Parameters

op (int) – A SQLITE_DBCONFIG code.

Return type

bool

Added in version 3.12.



The Python Library Reference, Release 3.13.2



setconfig(op, enable=True, / )

Set a boolean connection configuration option.

Parameters

• op (int) – A SQLITE_DBCONFIG code.

• enable (bool) – True if the configuration option should be enabled (default); False

if it should be disabled.

Added in version 3.12.

serialize(*, name=’main’)

Serialize a database into a bytes object. For an ordinary on-disk database file, the serialization is just a copy of the disk file. For an in-memory database or a “temp” database, the serialization is the same sequence of bytes which would be written to disk if that database were backed up to disk.

Parameters

name (str) – The database name to be serialized. Defaults to "main".

Return type

bytes



® Note

This method is only available if the underlying SQLite library has the serialize API.



Added in version 3.11.

deserialize(data, / , *, name=’main’ )

Deserialize a serialized database into a Connection. This method causes the database connection to disconnect from database name, and reopen name as an in-memory database based on the serialization contained in data.

Parameters

• data (bytes) – A serialized database.

• name (str) – The database name to deserialize into. Defaults to "main".

Raises

• OperationalError – If the database connection is currently involved in a read trans-

action or a backup operation.

• DatabaseError – If data does not contain a valid SQLite database.

• OverflowError – If len(data) is larger than 2**63 - 1.



® Note

This method is only available if the underlying SQLite library has the deserialize API.



Added in version 3.11.

autocommit

This attribute controls PEP 249-compliant transaction behaviour. autocommit has three allowed val-ues:

• False: Select PEP 249-compliant transaction behaviour, implying that sqlite3 ensures a trans-

action is always open. Use commit() and rollback() to close transactions.

This is the recommended value of autocommit.

• True: Use SQLite’s autocommit mode. commit() and rollback() have no effect in this mode.

The Python Library Reference, Release 3.13.2



• LEGACY_TRANSACTION_CONTROL: Pre-Python 3.12 (non-PEP 249-compliant) transaction con-

trol. See isolation_level for more details.

This is currently the default value of autocommit.

Changing autocommit to False will open a new transaction, and changing it to True will commit any pending transaction.

See Transaction control via the autocommit attribute for more details.



® Note

The isolation_level attribute has no effect unless autocommit is

LEGACY_TRANSACTION_CONTROL.



Added in version 3.12.

in_transaction

This read-only attribute corresponds to the low-level SQLite autocommit mode.

True if a transaction is active (there are uncommitted changes), False otherwise.

Added in version 3.2.

isolation_level

Controls the legacy transaction handling mode of sqlite3. If set to None, transactions are never im-plicitly opened. If set to one of "DEFERRED", "IMMEDIATE", or "EXCLUSIVE", corresponding to the

underlying SQLite transaction behaviour, implicit transaction management is performed.

If not overridden by the isolation_level parameter of connect(), the default is "", which is an alias for "DEFERRED".



® Note

Using autocommit to control transaction handling is recommended over using isolation_level.

isolation_level has no effect unless autocommit is set to LEGACY_TRANSACTION_CONTROL (the default).



row_factory

The initial row_factory for Cursor objects created from this connection. Assigning to this attribute does not affect the row_factory of existing cursors belonging to this connection, only new ones. Is

None by default, meaning each row is returned as a tuple.

See How to create and use row factories for more details.

text_factory

A callable that accepts a bytes parameter and returns a text representation of it. The callable is invoked

for SQLite values with the TEXT data type. By default, this attribute is set to str.

See How to handle non-UTF-8 text encodings for more details.

total_changes

Return the total number of database rows that have been modified, inserted, or deleted since the database connection was opened.



Cursor objects

A Cursor object represents a database cursor which is used to execute SQL statements, and manage

the context of a fetch operation. Cursors are created using Connection.cursor(), or by using any

of the connection shortcut methods.

The Python Library Reference, Release 3.13.2



Cursor objects are iterators, meaning that if you execute() a SELECT query, you can simply iterate

over the cursor to fetch the resulting rows:

for row in cur.execute("SELECT t FROM data"):

print(row)



class sqlite3.Cursor

A Cursor instance has the following attributes and methods.

execute(sql, parameters=(), / )

Execute a single SQL statement, optionally binding Python values using placeholders.

Parameters

• sql (str) – A single SQL statement.

• parameters (dict | sequence) – Python values to bind to placeholders in sql. A dict

if named placeholders are used. A sequence if unnamed placeholders are used. See How

to use placeholders to bind values in SQL queries.

Raises

ProgrammingError – If sql contains more than one SQL statement.

If autocommit is LEGACY_TRANSACTION_CONTROL, isolation_level is not None, sql is an INSERT , UPDATE, DELETE, or REPLACE statement, and there is no open transaction, a transaction is implicitly opened before executing sql.

Deprecated since version 3.12, will be removed in version 3.14: DeprecationWarning is emitted if

named placeholders are used and parameters is a sequence instead of a dict. Starting with Python 3.14,

ProgrammingError will be raised instead.

Use executescript() to execute multiple SQL statements.

executemany(sql, parameters, / )

For every item in parameters, repeatedly execute the parameterized DML (Data Manipulation Language) SQL statement sql.

Uses the same implicit transaction handling as execute().

Parameters

• sql (str) – A single SQL DML statement.

• parameters (iterable) – An iterable of parameters to bind with the placeholders in sql.

See How to use placeholders to bind values in SQL queries.

Raises

ProgrammingError – If sql contains more than one SQL statement, or is not a DML statement.

Example:

rows = [

("row1",),

("row2",),

]

# cur is an sqlite3.Cursor object

cur.executemany("INSERT INTO data VALUES(?)", rows)



® Note

Any resulting rows are discarded, including DML statements with RETURNING clauses.



The Python Library Reference, Release 3.13.2



Deprecated since version 3.12, will be removed in version 3.14: DeprecationWarning is emitted if

named placeholders are used and the items in parameters are sequences instead of dicts. Starting with

Python 3.14, ProgrammingError will be raised instead.

executescript(sql_script, / )

Execute the SQL statements in sql_script. If the autocommit is LEGACY_TRANSACTION_CONTROL and there is a pending transaction, an implicit COMMIT statement is executed first. No other implicit transaction control is performed; any transaction control must be added to sql_script.

sql_script must be a string.

Example:

# cur is an sqlite3.Cursor object

cur.executescript("""

BEGIN;

CREATE TABLE person(firstname, lastname, age);

CREATE TABLE book(title, author, published);

CREATE TABLE publisher(name, address);

COMMIT;

""")



fetchone()

If row_factory is None, return the next row query result set as a tuple. Else, pass it to the row factory and return its result. Return None if no more data is available.

fetchmany(size=cursor.arraysize)

Return the next set of rows of a query result as a list. Return an empty list if no more rows are available.

The number of rows to fetch per call is specified by the size parameter. If size is not given, arraysize determines the number of rows to be fetched. If fewer than size rows are available, as many rows as are available are returned.

Note there are performance considerations involved with the size parameter. For optimal performance, it is usually best to use the arraysize attribute. If the size parameter is used, then it is best for it to retain

the same value from one fetchmany() call to the next.

fetchall()

Return all (remaining) rows of a query result as a list. Return an empty list if no rows are available.

Note that the arraysize attribute can affect the performance of this operation.

close()

Close the cursor now (rather than whenever __del__ is called).

The cursor will be unusable from this point forward; a ProgrammingError exception will be raised if any operation is attempted with the cursor.

setinputsizes(sizes, / )

Required by the DB-API. Does nothing in sqlite3.

setoutputsize(size, column=None, / )

Required by the DB-API. Does nothing in sqlite3.

arraysize

Read/write attribute that controls the number of rows returned by fetchmany(). The default value is 1 which means a single row would be fetched per call.

connection

Read-only attribute that provides the SQLite database Connection belonging to the cursor. A Cursor

object created by calling con.cursor() will have a connection attribute that refers to con:



The Python Library Reference, Release 3.13.2



>>> con = sqlite3.connect(":memory:")

>>> cur = con.cursor()

>>> cur.connection == con

True

>>> con.close()



description

Read-only attribute that provides the column names of the last query. To remain compatible with the Python DB API, it returns a 7-tuple for each column where the last six items of each tuple are None.

It is set for SELECT statements without any matching rows as well.

lastrowid

Read-only attribute that provides the row id of the last inserted row. It is only updated after suc-

cessful INSERT or REPLACE statements using the execute() method. For other statements, after

executemany() or executescript(), or if the insertion failed, the value of lastrowid is left unchanged. The initial value of lastrowid is None.



® Note

Inserts into WITHOUT ROWID tables are not recorded.



Changed in version 3.6: Added support for the REPLACE statement.

rowcount

Read-only attribute that provides the number of modified rows for INSERT, UPDATE, DELETE, and REPLACE statements; is-1 for other statements, including CTE (Common Table Expression) queries.

It is only updated by the execute() and executemany() methods, after the statement has run to completion. This means that any resulting rows must be fetched in order for rowcount to be updated.

row_factory

Control how a row fetched from this Cursor is represented. If None, a row is represented as a tuple.

Can be set to the included sqlite3.Row; or a callable that accepts two arguments, a Cursor object and the tuple of row values, and returns a custom object representing an SQLite row.

Defaults to what Connection.row_factory was set to when the Cursor was created. Assigning to

this attribute does not affect Connection.row_factory of the parent connection.

See How to create and use row factories for more details.



Row objects

class sqlite3.Row

A Row instance serves as a highly optimized row_factory for Connection objects. It supports iteration,

equality testing, len(), and mapping access by column name and index.

Two Row objects compare equal if they have identical column names and values.

See How to create and use row factories for more details.

keys()

Return a list of column names as strings. Immediately after a query, it is the first member of each

tuple in Cursor.description.

Changed in version 3.5: Added support of slicing.



The Python Library Reference, Release 3.13.2



Blob objects

class sqlite3.Blob

Added in version 3.11.

A Blob instance is a file-like object that can read and write data in an SQLite BLOB. Call len(blob) to get

the size (number of bytes) of the blob. Use indices and slices for direct access to the blob data.

Use the Blob as a context manager to ensure that the blob handle is closed after use.

con = sqlite3.connect(":memory:")

con.execute("CREATE TABLE test(blob_col blob)")

con.execute("INSERT INTO test(blob_col) VALUES(zeroblob(13))")

# Write to our blob, using two write operations:

with con.blobopen("test", "blob_col", 1) as blob:

blob.write(b"hello, ")

blob.write(b"world.")

# Modify the first and last bytes of our blob

blob[0] = ord("H")

blob[-1] = ord("!")

# Read the contents of our blob

with con.blobopen("test", "blob_col", 1) as blob:

greeting = blob.read()

print(greeting) # outputs "b'Hello, world!'"

con.close()



close()

Close the blob.

The blob will be unusable from this point onward. An Error (or subclass) exception will be raised if any further operation is attempted with the blob.

read(length=-1, / )

Read length bytes of data from the blob at the current offset position. If the end of the blob is reached,

the data up to EOF (End of File) will be returned. When length is not specified, or is negative, read() will read until the end of the blob.

write(data, / )

Write data to the blob at the current offset. This function cannot change the blob length. Writing beyond

the end of the blob will raise ValueError.

tell()

Return the current access position of the blob.

seek(offset, origin=os.SEEK_SET, / )

Set the current access position of the blob to offset. The origin argument defaults to os.SEEK_SET (ab-

solute blob positioning). Other values for origin are os.SEEK_CUR (seek relative to the current position)

and os.SEEK_END (seek relative to the blob’s end).



PrepareProtocol objects

class sqlite3.PrepareProtocol

The PrepareProtocol type’s single purpose is to act as a PEP 246 style adaption protocol for objects that can

adapt themselves to native SQLite types.



The Python Library Reference, Release 3.13.2



Exceptions

The exception hierarchy is defined by the DB-API 2.0 (PEP 249).

exception sqlite3.Warning

This exception is not currently raised by the sqlite3 module, but may be raised by applications using

sqlite3 , for example if a user-defined function truncates data while inserting. Warning is a subclass of

Exception.

exception sqlite3.Error

The base class of the other exceptions in this module. Use this to catch all errors with one single except

statement. Error is a subclass of Exception.

If the exception originated from within the SQLite library, the following two attributes are added to the ex-

ception:

sqlite_errorcode

The numeric error code from the SQLite API

Added in version 3.11.

sqlite_errorname

The symbolic name of the numeric error code from the SQLite API

Added in version 3.11.

exception sqlite3.InterfaceError

Exception raised for misuse of the low-level SQLite C API. In other words, if this exception is raised, it

probably indicates a bug in the sqlite3 module. InterfaceError is a subclass of Error.

exception sqlite3.DatabaseError

Exception raised for errors that are related to the database. This serves as the base exception for several types of

database errors. It is only raised implicitly through the specialised subclasses. DatabaseError is a subclass

of Error.

exception sqlite3.DataError

Exception raised for errors caused by problems with the processed data, like numeric values out of range, and

strings which are too long. DataError is a subclass of DatabaseError.

exception sqlite3.OperationalError

Exception raised for errors that are related to the database’s operation, and not necessarily under the control

of the programmer. For example, the database path is not found, or a transaction could not be processed.

OperationalError is a subclass of DatabaseError.

exception sqlite3.IntegrityError

Exception raised when the relational integrity of the database is affected, e.g. a foreign key check fails. It is a

subclass of DatabaseError.

exception sqlite3.InternalError

Exception raised when SQLite encounters an internal error. If this is raised, it may indicate that there is a

problem with the runtime SQLite library. InternalError is a subclass of DatabaseError.

exception sqlite3.ProgrammingError

Exception raised for sqlite3 API programming errors, for example supplying the wrong number of bind-

ings to a query, or trying to operate on a closed Connection. ProgrammingError is a subclass of

DatabaseError .

exception sqlite3.NotSupportedError

Exception raised in case a method or database API is not supported by the underlying SQLite library. For

example, setting deterministic to True in create_function(), if the underlying SQLite library does not

support deterministic functions. NotSupportedError is a subclass of DatabaseError.

The Python Library Reference, Release 3.13.2



SQLite and Python types

SQLite natively supports the following types: NULL, INTEGER, REAL, TEXT, BLOB.

The following Python types can thus be sent to SQLite without any problem:



Python type SQLite type

None NULL

int INTEGER

float REAL

str TEXT

bytes BLOB



This is how SQLite types are converted to Python types by default:



SQLite type Python type

NULL None

INTEGER int

REAL float

TEXT depends on text_factory, str by default

BLOB bytes



The type system of the sqlite3 module is extensible in two ways: you can store additional Python types in an

SQLite database via object adapters, and you can let the sqlite3 module convert SQLite types to Python types via

converters.



Default adapters and converters (deprecated)



® Note

The default adapters and converters are deprecated as of Python 3.12. Instead, use the Adapter and converter

recipes and tailor them to your needs.



The deprecated default adapters and converters consist of:

• An adapter for datetime.date objects to strings in ISO 8601 format.

• An adapter for datetime.datetime objects to strings in ISO 8601 format.

• A converter for declared “date” types to datetime.date objects.

• A converter for declared “timestamp” types to datetime.datetime objects. Fractional parts will be trun-

cated to 6 digits (microsecond precision).



® Note

The default “timestamp” converter ignores UTC offsets in the database and always returns a naive datetime.

datetime object. To preserve UTC offsets in timestamps, either leave converters disabled, or register an offset-

aware converter with register_converter().



Deprecated since version 3.12.



The Python Library Reference, Release 3.13.2



Command-line interface

The sqlite3 module can be invoked as a script, using the interpreter’s-m switch, in order to provide a simple SQLite shell. The argument signature is as follows:

python-m sqlite3 [-h] [-v] [filename] [sql]



Type .quit or CTRL-D to exit the shell.

-h,--help

Print CLI help.

-v,--version

Print underlying SQLite library version.

Added in version 3.12.



12.6.3 How-to guides

How to use placeholders to bind values in SQL queries

SQL operations usually need to use values from Python variables. However, beware of using Python’s string opera-

tions to assemble queries, as they are vulnerable to SQL injection attacks. For example, an attacker can simply close the single quote and inject OR TRUE to select all rows:

>>> # Never do this -- insecure!

>>> symbol = input()

' OR TRUE; --

>>> sql = "SELECT * FROM stocks WHERE symbol = '%s'" % symbol >>> print(sql)

SELECT * FROM stocks WHERE symbol = '' OR TRUE; --' >>> cur.execute(sql)



Instead, use the DB-API’s parameter substitution. To insert a variable into a query string, use a placeholder in the

string, and substitute the actual values into the query by providing them as a tuple of values to the second argument

of the cursor’s execute() method.

An SQL statement may use one of two kinds of placeholders: question marks (qmark style) or named placeholders

(named style). For the qmark style, parameters must be a sequence whose length must match the number of place-

holders, or a ProgrammingError is raised. For the named style, parameters must be an instance of a dict (or a subclass), which must contain keys for all named parameters; any extra items are ignored. Here’s an example of both styles:

con = sqlite3.connect(":memory:")

cur = con.execute("CREATE TABLE lang(name, first_appeared)")

# This is the named style used with executemany(): data = (

{"name": "C", "year": 1972},

{"name": "Fortran", "year": 1957},

{"name": "Python", "year": 1991},

{"name": "Go", "year": 2009},

)

cur.executemany("INSERT INTO lang VALUES(:name, :year)", data)

# This is the qmark style used in a SELECT query:

params = (1972,)

cur.execute("SELECT * FROM lang WHERE first_appeared = ?", params) print(cur.fetchall())

con.close()

The Python Library Reference, Release 3.13.2



® Note

PEP 249 numeric placeholders are not supported. If used, they will be interpreted as named placeholders.



How to adapt custom Python types to SQLite values

SQLite supports only a limited set of data types natively. To store custom Python types in SQLite databases, adapt

them to one of the Python types SQLite natively understands.

There are two ways to adapt Python objects to SQLite types: letting your object adapt itself, or using an adapter callable. The latter will take precedence above the former. For a library that exports a custom type, it may make sense to enable that type to adapt itself. As an application developer, it may make more sense to take direct control by registering custom adapter functions.



How to write adaptable objects

Suppose we have a Point class that represents a pair of coordinates, x and y, in a Cartesian coordinate system. The coordinate pair will be stored as a text string in the database, using a semicolon to separate the coordinates. This can be implemented by adding a __conform__(self, protocol) method which returns the adapted value. The

object passed to protocol will be of type PrepareProtocol.

class Point:

def __init__(self, x, y):

self.x, self.y = x, y

def __conform__(self, protocol):

if protocol is sqlite3.PrepareProtocol:

return f"{self.x};{self.y}"

con = sqlite3.connect(":memory:")

cur = con.cursor()

cur.execute("SELECT ?", (Point(4.0,-3.2),))

print(cur.fetchone()[0])

con.close()



How to register adapter callables

The other possibility is to create a function that converts the Python object to an SQLite-compatible type. This

function can then be registered using register_adapter().

class Point:

def __init__(self, x, y):

self.x, self.y = x, y

def adapt_point(point):

return f"{point.x};{point.y}"

sqlite3.register_adapter(Point, adapt_point)

con = sqlite3.connect(":memory:")

cur = con.cursor()

cur.execute("SELECT ?", (Point(1.0, 2.5),))

print(cur.fetchone()[0])

con.close()

The Python Library Reference, Release 3.13.2



How to convert SQLite values to custom Python types

Writing an adapter lets you convert from custom Python types to SQLite values. To be able to convert from SQLite values to custom Python types, we use converters.

Let’s go back to the Point class. We stored the x and y coordinates separated via semicolons as strings in SQLite.

First, we’ll define a converter function that accepts the string as a parameter and constructs a Point object from it.



® Note

Converter functions are always passed a bytes object, no matter the underlying SQLite data type.



def convert_point(s):

x, y = map(float, s.split(b";"))

return Point(x, y)



We now need to tell sqlite3 when it should convert a given SQLite value. This is done when connecting to a

database, using the detect_types parameter of connect(). There are three options:

• Implicit: set detect_types to PARSE_DECLTYPES

• Explicit: set detect_types to PARSE_COLNAMES

• Both: set detect_types to sqlite3.PARSE_DECLTYPES | sqlite3.PARSE_COLNAMES. Column names

take precedence over declared types.

The following example illustrates the implicit and explicit approaches:

class Point:

def __init__(self, x, y):

self.x, self.y = x, y

def __repr__(self):

return f"Point({self.x}, {self.y})"

def adapt_point(point):

return f"{point.x};{point.y}"

def convert_point(s):

x, y = list(map(float, s.split(b";")))

return Point(x, y)

# Register the adapter and converter

sqlite3.register_adapter(Point, adapt_point)

sqlite3.register_converter("point", convert_point)

# 1) Parse using declared types

p = Point(4.0,-3.2)

con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES) cur = con.execute("CREATE TABLE test(p point)")

cur.execute("INSERT INTO test(p) VALUES(?)", (p,)) cur.execute("SELECT p FROM test")

print("with declared types:", cur.fetchone()[0])

cur.close()

con.close()

# 2) Parse using column names

con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_COLNAMES)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

cur = con.execute("CREATE TABLE test(p)")

cur.execute("INSERT INTO test(p) VALUES(?)", (p,)) cur.execute('SELECT p AS "p [point]" FROM test')

print("with column names:", cur.fetchone()[0])

cur.close()

con.close()



Adapter and converter recipes

This section shows recipes for common adapters and converters.

import datetime

import sqlite3

def adapt_date_iso(val):

"""Adapt datetime.date to ISO 8601 date."""

return val.isoformat()

def adapt_datetime_iso(val):

"""Adapt datetime.datetime to timezone-naive ISO 8601 date."""

return val.isoformat()

def adapt_datetime_epoch(val):

"""Adapt datetime.datetime to Unix timestamp."""

return int(val.timestamp())

sqlite3.register_adapter(datetime.date, adapt_date_iso) sqlite3.register_adapter(datetime.datetime, adapt_datetime_iso) sqlite3.register_adapter(datetime.datetime, adapt_datetime_epoch)

def convert_date(val):

"""Convert ISO 8601 date to datetime.date object."""

return datetime.date.fromisoformat(val.decode())

def convert_datetime(val):

"""Convert ISO 8601 datetime to datetime.datetime object."""

return datetime.datetime.fromisoformat(val.decode())

def convert_timestamp(val):

"""Convert Unix epoch timestamp to datetime.datetime object."""

return datetime.datetime.fromtimestamp(int(val))

sqlite3.register_converter("date", convert_date)

sqlite3.register_converter("datetime", convert_datetime) sqlite3.register_converter("timestamp", convert_timestamp)



How to use connection shortcut methods

Using the execute(), executemany(), and executescript() methods of the Connection class, your code

can be written more concisely because you don’t have to create the (often superfluous) Cursor objects explicitly.

Instead, the Cursor objects are created implicitly and these shortcut methods return the cursor objects. This way,

you can execute a SELECT statement and iterate over it directly using only a single call on the Connection object.

# Create and fill the table.

con = sqlite3.connect(":memory:")

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

con.execute("CREATE TABLE lang(name, first_appeared)") data = [

("C++", 1985),

("Objective-C", 1984),

]

con.executemany("INSERT INTO lang(name, first_appeared) VALUES(?, ?)", data)

# Print the table contents

for row in con.execute("SELECT name, first_appeared FROM lang"):

print(row)

print("I just deleted", con.execute("DELETE FROM lang").rowcount, "rows")

# close() is not a shortcut method and it's not called automatically; # the connection object should be closed manually

con.close()



How to use the connection context manager

A Connection object can be used as a context manager that automatically commits or rolls back open transactions when leaving the body of the context manager. If the body of the with statement finishes without exceptions, the transaction is committed. If this commit fails, or if the body of the with statement raises an uncaught exception,

the transaction is rolled back. If autocommit is False, a new transaction is implicitly opened after committing or rolling back.

If there is no open transaction upon leaving the body of the with statement, or if autocommit is True, the context manager does nothing.



® Note

The context manager neither implicitly opens a new transaction nor closes the connection. If you need a closing

context manager, consider using contextlib.closing().



con = sqlite3.connect(":memory:")

con.execute("CREATE TABLE lang(id INTEGER PRIMARY KEY, name VARCHAR UNIQUE)")

# Successful, con.commit() is called automatically afterwards with con:

con.execute("INSERT INTO lang(name) VALUES(?)", ("Python",))

# con.rollback() is called after the with block finishes with an exception, # the exception is still raised and must be caught try:

with con:

con.execute("INSERT INTO lang(name) VALUES(?)", ("Python",))

except sqlite3.IntegrityError:

print("couldn't add Python twice")

# Connection object used as context manager only commits or rollbacks transactions, # so the connection object should be closed manually con.close()



The Python Library Reference, Release 3.13.2



How to work with SQLite URIs

Some useful URI tricks include:

• Open a database in read-only mode:

>>> con = sqlite3.connect("file:tutorial.db?mode=ro", uri=True) >>> con.execute("CREATE TABLE readonly(data)")

Traceback (most recent call last):

OperationalError: attempt to write a readonly database >>> con.close()



• Do not implicitly create a new database file if it does not already exist; will raise OperationalError if

unable to create a new file:

>>> con = sqlite3.connect("file:nosuchdb.db?mode=rw", uri=True) Traceback (most recent call last):

OperationalError: unable to open database file



• Create a shared named in-memory database:

db = "file:mem1?mode=memory&cache=shared"

con1 = sqlite3.connect(db, uri=True)

con2 = sqlite3.connect(db, uri=True)

with con1:

con1.execute("CREATE TABLE shared(data)")

con1.execute("INSERT INTO shared VALUES(28)")

res = con2.execute("SELECT data FROM shared")

assert res.fetchone() == (28,)

con1.close()

con2.close()



More information about this feature, including a list of parameters, can be found in the SQLite URI documentation.



How to create and use row factories

By default, sqlite3 represents each row as a tuple. If a tuple does not suit your needs, you can use the sqlite3.

Row class or a custom row_factory.

While row_factory exists as an attribute both on the Cursor and the Connection, it is recommended to set

Connection.row_factory, so all cursors created from the connection will use the same row factory.

Row provides indexed and case-insensitive named access to columns, with minimal memory overhead and perfor-mance impact over a tuple. To use Row as a row factory, assign it to the row_factory attribute:

>>> con = sqlite3.connect(":memory:")

>>> con.row_factory = sqlite3.Row



Queries now return Row objects:

>>> res = con.execute("SELECT 'Earth' AS name, 6378 AS radius") >>> row = res.fetchone()

>>> row.keys()

['name', 'radius']

>>> row[0] # Access by index.

'Earth'

>>> row["name"] # Access by name.

'Earth'

>>> row["RADIUS"] # Column names are case-insensitive.

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

6378

>>> con.close()



® Note

The FROM clause can be omitted in the SELECT statement, as in the above example. In such cases, SQLite returns

a single row with columns defined by expressions, e.g. literals, with the given aliases expr AS alias.



You can create a custom row_factory that returns each row as a dict, with column names mapped to values:

def dict_factory(cursor, row):

fields = [column[0] for column in cursor.description]

return {key: value for key, value in zip(fields, row)}



Using it, queries now return a dict instead of a tuple:

>>> con = sqlite3.connect(":memory:")

>>> con.row_factory = dict_factory

>>> for row in con.execute("SELECT 1 AS a, 2 AS b"):

... print(row)

{'a': 1, 'b': 2}

>>> con.close()



The following row factory returns a named tuple:

from collections import namedtuple

def namedtuple_factory(cursor, row):

fields = [column[0] for column in cursor.description]

cls = namedtuple("Row", fields)

return cls._make(row)



namedtuple_factory() can be used as follows:

>>> con = sqlite3.connect(":memory:")

>>> con.row_factory = namedtuple_factory

>>> cur = con.execute("SELECT 1 AS a, 2 AS b")

>>> row = cur.fetchone()

>>> row

Row(a=1, b=2)

>>> row[0] # Indexed access.

1

>>> row.b # Attribute access.

2

>>> con.close()



With some adjustments, the above recipe can be adapted to use a dataclass, or any other custom class, instead of

a namedtuple.



How to handle non-UTF-8 text encodings

By default, sqlite3 uses str to adapt SQLite values with the TEXT data type. This works well for UTF-8 encoded

text, but it might fail for other encodings and invalid UTF-8. You can use a custom text_factory to handle such cases.

Because of SQLite’s flexible typing, it is not uncommon to encounter table columns with the TEXT data type containing non-UTF-8 encodings, or even arbitrary data. To demonstrate, let’s assume we have a database with The Python Library Reference, Release 3.13.2



ISO-8859-2 (Latin-2) encoded text, for example a table of Czech-English dictionary entries. Assuming we now

have a Connection instance con connected to this database, we can decode the Latin-2 encoded text using this

text_factory:

con.text_factory = lambda data: str(data, encoding="latin2")



For invalid UTF-8 or arbitrary data in stored in TEXT table columns, you can use the following technique, borrowed from the unicode-howto:

con.text_factory = lambda data: str(data, errors="surrogateescape")



® Note

The sqlite3 module API does not support strings containing surrogates.



µ See also

unicode-howto



12.6.4 Explanation

Transaction control

sqlite3 offers multiple methods of controlling whether, when and how database transactions are opened and closed.

Transaction control via the autocommit attribute is recommended, while Transaction control via the isolation_level

attribute retains the pre-Python 3.12 behaviour.



Transaction control via the autocommit attribute

The recommended way of controlling transaction behaviour is through the Connection.autocommit attribute,

which should preferably be set using the autocommit parameter of connect().

It is suggested to set autocommit to False, which implies PEP 249-compliant transaction control. This means:

• sqlite3 ensures that a transaction is always open, so connect(), Connection.commit(), and

Connection.rollback() will implicitly open a new transaction (immediately after closing the pending

one, for the latter two). sqlite3 uses BEGIN DEFERRED statements when opening transactions.

• Transactions should be committed explicitly using commit().

• Transactions should be rolled back explicitly using rollback().

• An implicit rollback is performed if the database is close()-ed with pending changes.

Set autocommit to True to enable SQLite’s autocommit mode. In this mode, Connection.commit() and

Connection.rollback() have no effect. Note that SQLite’s autocommit mode is distinct from the PEP

249-compliant Connection.autocommit attribute; use Connection.in_transaction to query the low-level SQLite autocommit mode.

Set autocommit to LEGACY_TRANSACTION_CONTROL to leave transaction control behaviour to the Connection.

isolation_level attribute. See Transaction control via the isolation_level attribute for more information.



Transaction control via the isolation_level attribute



® Note

The recommended way of controlling transactions is via the autocommit attribute. See Transaction control via

the autocommit attribute.

The Python Library Reference, Release 3.13.2



If Connection.autocommit is set to LEGACY_TRANSACTION_CONTROL (the default), transaction behaviour is

controlled using the Connection.isolation_level attribute. Otherwise, isolation_level has no effect.

If the connection attribute isolation_level is not None, new transactions are implicitly opened before

execute() and executemany() executes INSERT, UPDATE, DELETE, or REPLACE statements; for other state-

ments, no implicit transaction handling is performed. Use the commit() and rollback() methods to respectively

commit and roll back pending transactions. You can choose the underlying SQLite transaction behaviour — that is,

whether and what type of BEGIN statements sqlite3 implicitly executes – via the isolation_level attribute.

If isolation_level is set to None, no transactions are implicitly opened at all. This leaves the underlying SQLite

library in autocommit mode, but also allows the user to perform their own transaction handling using explicit SQL

statements. The underlying SQLite library autocommit mode can be queried using the in_transaction attribute.

The executescript() method implicitly commits any pending transaction before execution of the given SQL

script, regardless of the value of isolation_level.

Changed in version 3.6: sqlite3 used to implicitly commit an open transaction before DDL statements. This is no longer the case.

Changed in version 3.12: The recommended way of controlling transactions is now via the autocommit attribute.



The Python Library Reference, Release 3.13.2





CHAPTER




THIRTEEN



DATA COMPRESSION AND ARCHIVING



The modules described in this chapter support data compression with the zlib, gzip, bzip2 and lzma algorithms, and

the creation of ZIP- and tar-format archives. See also Archiving operations provided by the shutil module.



13.1 zlib — Compression compatible with gzip



For applications that require data compression, the functions in this module allow compression and decompression,

using the zlib library. The zlib library has its own home page at https://www.zlib.net. There are known incompatibil-

ities between the Python module and versions of the zlib library earlier than 1.1.3; 1.1.3 has a security vulnerability, so we recommend using 1.1.4 or later.

zlib’s functions have many options and often need to be used in a particular order. This documentation doesn’t

attempt to cover all of the permutations; consult the zlib manual at http://www.zlib.net/manual.html for authoritative information.

For reading and writing .gz files see the gzip module.

The available exception and functions in this module are:

exception zlib.error

Exception raised on compression and decompression errors.

zlib.adler32(data[, value ])

Computes an Adler-32 checksum of data. (An Adler-32 checksum is almost as reliable as a CRC32 but can

be computed much more quickly.) The result is an unsigned 32-bit integer. If value is present, it is used as

the starting value of the checksum; otherwise, a default value of 1 is used. Passing in value allows computing

a running checksum over the concatenation of several inputs. The algorithm is not cryptographically strong,

and should not be used for authentication or digital signatures. Since the algorithm is designed for use as a

checksum algorithm, it is not suitable for use as a general hash algorithm.

Changed in version 3.0: The result is always unsigned.

zlib.compress(data, / , level=-1, wbits=MAX_WBITS)

Compresses the bytes in data, returning a bytes object containing compressed data. level is an integer from 0

to 9 or-1 controlling the level of compression; 1 (Z_BEST_SPEED) is fastest and produces the least com-

pression, 9 (Z_BEST_COMPRESSION) is slowest and produces the most. 0 (Z_NO_COMPRESSION) is

no compression. The default value is-1 (Z_DEFAULT_COMPRESSION). Z_DEFAULT_COMPRESSION

represents a default compromise between speed and compression (currently equivalent to level 6).

The wbits argument controls the size of the history buffer (or the “window size”) used when compressing data,

and whether a header and trailer is included in the output. It can take several ranges of values, defaulting to

15 (MAX_WBITS):

• +9 to +15: The base-two logarithm of the window size, which therefore ranges between 512 and 32768.

Larger values produce better compression at the expense of greater memory usage. The resulting output will include a zlib-specific header and trailer.

The Python Library Reference, Release 3.13.2



• −9 to −15: Uses the absolute value of wbits as the window size logarithm, while producing a raw output

stream with no header or trailing checksum.

• +25 to +31 = 16 + (9 to 15): Uses the low 4 bits of the value as the window size logarithm, while including

a basic gzip header and trailing checksum in the output.

Raises the error exception if any error occurs.

Changed in version 3.6: level can now be used as a keyword parameter.

Changed in version 3.11: The wbits parameter is now available to set window bits and compression type.

zlib.compressobj(level=-1, method=DEFLATED, wbits=MAX_WBITS, memLevel=DEF_MEM_LEVEL,

strategy=Z_DEFAULT_STRATEGY [, zdict ])

Returns a compression object, to be used for compressing data streams that won’t fit into memory at once.

level is the compression level – an integer from 0 to 9 or-1. A value of 1 (Z_BEST_SPEED) is fastest and pro-

duces the least compression, while a value of 9 (Z_BEST_COMPRESSION) is slowest and produces the most.

0 (Z_NO_COMPRESSION) is no compression. The default value is-1 (Z_DEFAULT_COMPRESSION).

Z_DEFAULT_COMPRESSION represents a default compromise between speed and compression (currently

equivalent to level 6).

method is the compression algorithm. Currently, the only supported value is DEFLATED.

The wbits parameter controls the size of the history buffer (or the “window size”), and what header and trailer

format will be used. It has the same meaning as described for compress().

The memLevel argument controls the amount of memory used for the internal compression state. Valid values

range from 1 to 9. Higher values use more memory, but are faster and produce smaller output.

strategy is used to tune the compression algorithm. Possible values are Z_DEFAULT_STRATEGY, Z_FILTERED,

Z_HUFFMAN_ONLY, Z_RLE (zlib 1.2.0.1) and Z_FIXED (zlib 1.2.2.2).

zdict is a predefined compression dictionary. This is a sequence of bytes (such as a bytes object) containing

subsequences that are expected to occur frequently in the data that is to be compressed. Those subsequences

that are expected to be most common should come at the end of the dictionary.

Changed in version 3.3: Added the zdict parameter and keyword argument support.

zlib.crc32(data[, value ])

Computes a CRC (Cyclic Redundancy Check) checksum of data. The result is an unsigned 32-bit integer. If

value is present, it is used as the starting value of the checksum; otherwise, a default value of 0 is used. Passing

in value allows computing a running checksum over the concatenation of several inputs. The algorithm is not

cryptographically strong, and should not be used for authentication or digital signatures. Since the algorithm

is designed for use as a checksum algorithm, it is not suitable for use as a general hash algorithm.

Changed in version 3.0: The result is always unsigned.

zlib.decompress(data, / , wbits=MAX_WBITS, bufsize=DEF_BUF_SIZE)

Decompresses the bytes in data, returning a bytes object containing the uncompressed data. The wbits param-

eter depends on the format of data, and is discussed further below. If bufsize is given, it is used as the initial

size of the output buffer. Raises the error exception if any error occurs.

The wbits parameter controls the size of the history buffer (or “window size”), and what header and trailer

format is expected. It is similar to the parameter for compressobj(), but accepts more ranges of values:

• +8 to +15: The base-two logarithm of the window size. The input must include a zlib header and trailer.

• 0: Automatically determine the window size from the zlib header. Only supported since zlib 1.2.3.5.

• −8 to −15: Uses the absolute value of wbits as the window size logarithm. The input must be a raw

stream with no header or trailer.

• +24 to +31 = 16 + (8 to 15): Uses the low 4 bits of the value as the window size logarithm. The input

must include a gzip header and trailer.

• +40 to +47 = 32 + (8 to 15): Uses the low 4 bits of the value as the window size logarithm, and automat-

ically accepts either the zlib or gzip format.

The Python Library Reference, Release 3.13.2



When decompressing a stream, the window size must not be smaller than the size originally used to compress

the stream; using a too-small value may result in an error exception. The default wbits value corresponds to

the largest window size and requires a zlib header and trailer to be included.

bufsize is the initial size of the buffer used to hold decompressed data. If more space is required, the buffer

size will be increased as needed, so you don’t have to get this value exactly right; tuning it will only save a few

calls to malloc().

Changed in version 3.6: wbits and bufsize can be used as keyword arguments.

zlib.decompressobj(wbits=MAX_WBITS [, zdict ])

Returns a decompression object, to be used for decompressing data streams that won’t fit into memory at once.

The wbits parameter controls the size of the history buffer (or the “window size”), and what header and trailer

format is expected. It has the same meaning as described for decompress().

The zdict parameter specifies a predefined compression dictionary. If provided, this must be the same dictio-

nary as was used by the compressor that produced the data that is to be decompressed.



® Note

If zdict is a mutable object (such as a bytearray), you must not modify its contents between the call to

decompressobj() and the first call to the decompressor’s decompress() method.



Changed in version 3.3: Added the zdict parameter.

Compression objects support the following methods:

Compress.compress(data)

Compress data, returning a bytes object containing compressed data for at least part of the data in data. This

data should be concatenated to the output produced by any preceding calls to the compress() method. Some

input may be kept in internal buffers for later processing.

Compress.flush( mode [ ])

All pending input is processed, and a bytes object containing the remaining compressed output is re-

turned. mode can be selected from the constants Z_NO_FLUSH, Z_PARTIAL_FLUSH, Z_SYNC_FLUSH,

Z_FULL_FLUSH, Z_BLOCK (zlib 1.2.3.4), or Z_FINISH, defaulting to Z_FINISH. Except Z_FINISH, all con-

stants allow compressing further bytestrings of data, while Z_FINISH finishes the compressed stream and

prevents compressing any more data. After calling flush() with mode set to Z_FINISH, the compress()

method cannot be called again; the only realistic action is to delete the object.

Compress.copy()

Returns a copy of the compression object. This can be used to efficiently compress a set of data that share a

common initial prefix.

Changed in version 3.8: Added copy.copy() and copy.deepcopy() support to compression objects.

Decompression objects support the following methods and attributes:

Decompress.unused_data

A bytes object which contains any bytes past the end of the compressed data. That is, this remains b"" until the

last byte that contains compression data is available. If the whole bytestring turned out to contain compressed

data, this is b"", an empty bytes object.

Decompress.unconsumed_tail

A bytes object that contains any data that was not consumed by the last decompress() call because it exceeded

the limit for the uncompressed data buffer. This data has not yet been seen by the zlib machinery, so you must

feed it (possibly with further data concatenated to it) back to a subsequent decompress() method call in

order to get correct output.



The Python Library Reference, Release 3.13.2



Decompress.eof

A boolean indicating whether the end of the compressed data stream has been reached.

This makes it possible to distinguish between a properly formed compressed stream, and an incomplete or

truncated one.

Added in version 3.3.

Decompress.decompress( data, max_length=0)

Decompress data, returning a bytes object containing the uncompressed data corresponding to at least part

of the data in string. This data should be concatenated to the output produced by any preceding calls to the

decompress() method. Some of the input data may be preserved in internal buffers for later processing.

If the optional parameter max_length is non-zero then the return value will be no longer than max_length. This

may mean that not all of the compressed input can be processed; and unconsumed data will be stored in the at-

tribute unconsumed_tail. This bytestring must be passed to a subsequent call to decompress() if decom-

pression is to continue. If max_length is zero then the whole input is decompressed, and unconsumed_tail

is empty.

Changed in version 3.6: max_length can be used as a keyword argument.

Decompress.flush( length [ ])

All pending input is processed, and a bytes object containing the remaining uncompressed output is returned.

After calling flush(), the decompress() method cannot be called again; the only realistic action is to delete

the object.

The optional parameter length sets the initial size of the output buffer.

Decompress.copy()

Returns a copy of the decompression object. This can be used to save the state of the decompressor midway

through the data stream in order to speed up random seeks into the stream at a future point.

Changed in version 3.8: Added copy.copy() and copy.deepcopy() support to decompression objects.

Information about the version of the zlib library in use is available through the following constants:

zlib.ZLIB_VERSION

The version string of the zlib library that was used for building the module. This may be different from the

zlib library actually used at runtime, which is available as ZLIB_RUNTIME_VERSION.

zlib.ZLIB_RUNTIME_VERSION

The version string of the zlib library actually loaded by the interpreter.

Added in version 3.3.



µ See also

Module gzip

Reading and writing gzip-format files.

http://www.zlib.net

The zlib library home page.

http://www.zlib.net/manual.html

The zlib manual explains the semantics and usage of the library’s many functions.



13.2 gzip — Support for gzip files

Source code: Lib/gzip.py



This module provides a simple interface to compress and decompress files just like the GNU programs gzip and gunzip would.

The Python Library Reference, Release 3.13.2



The data compression is provided by the zlib module.

The gzip module provides the GzipFile class, as well as the open(), compress() and decompress() con-

venience functions. The GzipFile class reads and writes gzip-format files, automatically compressing or decom-

pressing the data so that it looks like an ordinary file object.

Note that additional file formats which can be decompressed by the gzip and gunzip programs, such as those produced by compress and pack, are not supported by this module.

The module defines the following items:

gzip.open(filename, mode=’rb’, compresslevel=9, encoding=None, errors=None, newline=None)

Open a gzip-compressed file in binary or text mode, returning a file object.

The filename argument can be an actual filename (a str or bytes object), or an existing file object to read

from or write to.

The mode argument can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x' or 'xb' for binary mode, or 'rt',

'at' , 'wt', or 'xt' for text mode. The default is 'rb'.

The compresslevel argument is an integer from 0 to 9, as for the GzipFile constructor.

For binary mode, this function is equivalent to the GzipFile constructor: GzipFile(filename, mode,

compresslevel). In this case, the encoding, errors and newline arguments must not be provided.

For text mode, a GzipFile object is created, and wrapped in an io.TextIOWrapper instance with the

specified encoding, error handling behavior, and line ending(s).

Changed in version 3.3: Added support for filename being a file object, support for text mode, and the encoding,

errors and newline arguments.

Changed in version 3.4: Added support for the 'x', 'xb' and 'xt' modes.

Changed in version 3.6: Accepts a path-like object.

exception gzip.BadGzipFile

An exception raised for invalid gzip files. It inherits from OSError. EOFError and zlib.error can also

be raised for invalid gzip files.

Added in version 3.8.

class gzip.GzipFile(filename=None, mode=None, compresslevel=9, fileobj=None, mtime=None)

Constructor for the GzipFile class, which simulates most of the methods of a file object, with the exception

of the truncate() method. At least one of fileobj and filename must be given a non-trivial value.

The new class instance is based on fileobj, which can be a regular file, an io.BytesIO object, or any other

object which simulates a file. It defaults to None, in which case filename is opened to provide a file object.

When fileobj is not None, the filename argument is only used to be included in the gzip file header, which

may include the original filename of the uncompressed file. It defaults to the filename of fileobj, if discernible;

otherwise, it defaults to the empty string, and in this case the original filename is not included in the header.

The mode argument can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x', or 'xb', depending on whether

the file will be read or written. The default is the mode of fileobj if discernible; otherwise, the default is 'rb'.

In future Python releases the mode of fileobj will not be used. It is better to always specify mode for writing.

Note that the file is always opened in binary mode. To open a compressed file in text mode, use open() (or

wrap your GzipFile with an io.TextIOWrapper).

The compresslevel argument is an integer from 0 to 9 controlling the level of compression; 1 is fastest and

produces the least compression, and 9 is slowest and produces the most compression. 0 is no compression.

The default is 9.

The optional mtime argument is the timestamp requested by gzip. The time is in Unix format, i.e., seconds

since 00:00:00 UTC, January 1, 1970. If mtime is omitted or None, the current time is used. Use mtime = 0

to generate a compressed stream that does not depend on creation time.

See below for the mtime attribute that is set when decompressing.

The Python Library Reference, Release 3.13.2



Calling a GzipFile object’s close() method does not close fileobj, since you might wish to append more

material after the compressed data. This also allows you to pass an io.BytesIO object opened for writing as

fileobj, and retrieve the resulting memory buffer using the io.BytesIO object’s getvalue() method.

GzipFile supports the io.BufferedIOBase interface, including iteration and the with statement. Only

the truncate() method isn’t implemented.

GzipFile also provides the following method and attribute:

peek(n)

Read n uncompressed bytes without advancing the file position. At most one single read on the com-pressed stream is done to satisfy the call. The number of bytes returned may be more or less than requested.



® Note

While calling peek() does not change the file position of the GzipFile, it may change the position

of the underlying file object (e.g. if the GzipFile was constructed with the fileobj parameter).



Added in version 3.2.

mode

'rb' for reading and 'wb' for writing.

Changed in version 3.13: In previous versions it was an integer 1 or 2.

mtime

When decompressing, this attribute is set to the last timestamp in the most recently read header. It is an integer, holding the number of seconds since the Unix epoch (00:00:00 UTC, January 1, 1970). The initial value before reading any headers is None.

name

The path to the gzip file on disk, as a str or bytes. Equivalent to the output of os.fspath() on the original input path, with no other normalization, resolution or expansion.

Changed in version 3.1: Support for the with statement was added, along with the mtime constructor argument

and mtime attribute.

Changed in version 3.2: Support for zero-padded and unseekable files was added.

Changed in version 3.3: The io.BufferedIOBase.read1() method is now implemented.

Changed in version 3.4: Added support for the 'x' and 'xb' modes.

Changed in version 3.5: Added support for writing arbitrary bytes-like objects. The read() method now

accepts an argument of None.

Changed in version 3.6: Accepts a path-like object.

Deprecated since version 3.9: Opening GzipFile for writing without specifying the mode argument is dep-

recated.

Changed in version 3.12: Remove the filename attribute, use the name attribute instead.

gzip.compress(data, compresslevel=9, *, mtime=None)

Compress the data, returning a bytes object containing the compressed data. compresslevel and mtime have

the same meaning as in the GzipFile constructor above.

Added in version 3.2.

Changed in version 3.8: Added the mtime parameter for reproducible output.

Changed in version 3.11: Speed is improved by compressing all data at once instead of in a streamed fashion.

Calls with mtime set to 0 are delegated to zlib.compress() for better speed. In this situation the output

The Python Library Reference, Release 3.13.2



may contain a gzip header “OS” byte value other than 255 “unknown” as supplied by the underlying zlib

implementation.

Changed in version 3.13: The gzip header OS byte is guaranteed to be set to 255 when this function is used as

was the case in 3.10 and earlier.

gzip.decompress(data)

Decompress the data, returning a bytes object containing the uncompressed data. This function is capable of

decompressing multi-member gzip data (multiple gzip blocks concatenated together). When the data is certain

to contain only one member the zlib.decompress() function with wbits set to 31 is faster.

Added in version 3.2.

Changed in version 3.11: Speed is improved by decompressing members at once in memory instead of in a

streamed fashion.



13.2.1 Examples of usage

Example of how to read a compressed file:

import gzip

with gzip.open('/home/joe/file.txt.gz', 'rb') as f:

file_content = f.read()



Example of how to create a compressed GZIP file:

import gzip

content = b"Lots of content here"

with gzip.open('/home/joe/file.txt.gz', 'wb') as f:

f.write(content)



Example of how to GZIP compress an existing file:

import gzip

import shutil

with open('/home/joe/file.txt', 'rb') as f_in:

with gzip.open('/home/joe/file.txt.gz', 'wb') as f_out:

shutil.copyfileobj(f_in, f_out)



Example of how to GZIP compress a binary string:

import gzip

s_in = b"Lots of content here"

s_out = gzip.compress(s_in)



µ See also

Module zlib

The basic data compression module needed to support the gzip file format.



13.2.2 Command Line Interface

The gzip module provides a simple command line interface to compress or decompress files.

Once executed the gzip module keeps the input file(s).

Changed in version 3.8: Add a new command line interface with a usage. By default, when you will execute the CLI, the default compression level is 6.

The Python Library Reference, Release 3.13.2



Command line options

file

If file is not specified, read from sys.stdin.

--fast

Indicates the fastest compression method (less compression).

--best

Indicates the slowest compression method (best compression).

-d,--decompress

Decompress the given file.

-h,--help

Show the help message.



13.3 bz2 — Support for bzip2 compression

Source code: Lib/bz2.py



This module provides a comprehensive interface for compressing and decompressing data using the bzip2 compres-sion algorithm.

The bz2 module contains:

• The open() function and BZ2File class for reading and writing compressed files.

• The BZ2Compressor and BZ2Decompressor classes for incremental (de)compression.

• The compress() and decompress() functions for one-shot (de)compression.



13.3.1 (De)compression of files

bz2.open(filename, mode=’rb’, compresslevel=9, encoding=None, errors=None, newline=None)

Open a bzip2-compressed file in binary or text mode, returning a file object.

As with the constructor for BZ2File, the filename argument can be an actual filename (a str or bytes

object), or an existing file object to read from or write to.

The mode argument can be any of 'r', 'rb', 'w', 'wb', 'x', 'xb', 'a' or 'ab' for binary mode, or 'rt',

'wt' , 'xt', or 'at' for text mode. The default is 'rb'.

The compresslevel argument is an integer from 1 to 9, as for the BZ2File constructor.

For binary mode, this function is equivalent to the BZ2File constructor: BZ2File(filename, mode,

compresslevel=compresslevel). In this case, the encoding, errors and newline arguments must not be

provided.

For text mode, a BZ2File object is created, and wrapped in an io.TextIOWrapper instance with the spec-

ified encoding, error handling behavior, and line ending(s).

Added in version 3.3.

Changed in version 3.4: The 'x' (exclusive creation) mode was added.

Changed in version 3.6: Accepts a path-like object.

class bz2.BZ2File(filename, mode=’r’, *, compresslevel=9)

Open a bzip2-compressed file in binary mode.

If filename is a str or bytes object, open the named file directly. Otherwise, filename should be a file object,

which will be used to read or write the compressed data.

The Python Library Reference, Release 3.13.2



The mode argument can be either 'r' for reading (default), 'w' for overwriting, 'x' for exclusive creation,

or 'a' for appending. These can equivalently be given as 'rb', 'wb', 'xb' and 'ab' respectively.

If filename is a file object (rather than an actual file name), a mode of 'w' does not truncate the file, and is

instead equivalent to 'a'.

If mode is 'w' or 'a', compresslevel can be an integer between 1 and 9 specifying the level of compression:

1 produces the least compression, and 9 (default) produces the most compression.

If mode is 'r', the input file may be the concatenation of multiple compressed streams.

BZ2File provides all of the members specified by the io.BufferedIOBase, except for detach() and

truncate(). Iteration and the with statement are supported.

BZ2File also provides the following methods and attributes:

peek( n [ ])

Return buffered data without advancing the file position. At least one byte of data will be returned (unless at EOF). The exact number of bytes returned is unspecified.



® Note

While calling peek() does not change the file position of the BZ2File, it may change the position of

the underlying file object (e.g. if the BZ2File was constructed by passing a file object for filename).



Added in version 3.3.

fileno()

Return the file descriptor for the underlying file.

Added in version 3.3.

readable()

Return whether the file was opened for reading.

Added in version 3.3.

seekable()

Return whether the file supports seeking.

Added in version 3.3.

writable()

Return whether the file was opened for writing.

Added in version 3.3.

read1(size=-1)

Read up to size uncompressed bytes, while trying to avoid making multiple reads from the underlying stream. Reads up to a buffer’s worth of data if size is negative.

Returns b'' if the file is at EOF.

Added in version 3.3.

readinto(b)

Read bytes into b.

Returns the number of bytes read (0 for EOF).

Added in version 3.3.

mode

'rb' for reading and 'wb' for writing.

Added in version 3.13.

The Python Library Reference, Release 3.13.2



name

The bzip2 file name. Equivalent to the name attribute of the underlying file object .

Added in version 3.13.

Changed in version 3.1: Support for the with statement was added.

Changed in version 3.3: Support was added for filename being a file object instead of an actual filename.

The 'a' (append) mode was added, along with support for reading multi-stream files.

Changed in version 3.4: The 'x' (exclusive creation) mode was added.

Changed in version 3.5: The read() method now accepts an argument of None.

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.9: The buffering parameter has been removed. It was ignored and deprecated since

Python 3.0. Pass an open file object to control how the file is opened.

The compresslevel parameter became keyword-only.

Changed in version 3.10: This class is thread unsafe in the face of multiple simultaneous readers or writers,

just like its equivalent classes in gzip and lzma have always been.



13.3.2 Incremental (de)compression

class bz2.BZ2Compressor(compresslevel=9)

Create a new compressor object. This object may be used to compress data incrementally. For one-shot

compression, use the compress() function instead.

compresslevel, if given, must be an integer between 1 and 9. The default is 9.

compress(data)

Provide data to the compressor object. Returns a chunk of compressed data if possible, or an empty byte string otherwise.

When you have finished providing data to the compressor, call the flush() method to finish the com-pression process.

flush()

Finish the compression process. Returns the compressed data left in internal buffers.

The compressor object may not be used after this method has been called.

class bz2.BZ2Decompressor

Create a new decompressor object. This object may be used to decompress data incrementally. For one-shot

compression, use the decompress() function instead.



® Note

This class does not transparently handle inputs containing multiple compressed streams, unlike

decompress() and BZ2File. If you need to decompress a multi-stream input with BZ2Decompressor, you must use a new decompressor for each stream.



decompress(data, max_length=-1)

Decompress data (a bytes-like object), returning uncompressed data as bytes. Some of data may be

buffered internally, for use in later calls to decompress(). The returned data should be concatenated

with the output of any previous calls to decompress().

If max_length is nonnegative, returns at most max_length bytes of decompressed data. If this limit is

reached and further output can be produced, the needs_input attribute will be set to False. In this

case, the next call to decompress() may provide data as b'' to obtain more of the output.

The Python Library Reference, Release 3.13.2



If all of the input data was decompressed and returned (either because this was less than max_length

bytes, or because max_length was negative), the needs_input attribute will be set to True.

Attempting to decompress data after the end of stream is reached raises an EOFError. Any data found

after the end of the stream is ignored and saved in the unused_data attribute.

Changed in version 3.5: Added the max_length parameter.

eof

True if the end-of-stream marker has been reached.

Added in version 3.3.

unused_data

Data found after the end of the compressed stream.

If this attribute is accessed before the end of the stream has been reached, its value will be b''.

needs_input

False if the decompress() method can provide more decompressed data before requiring new un-compressed input.

Added in version 3.5.



13.3.3 One-shot (de)compression

bz2.compress(data, compresslevel=9)

Compress data, a bytes-like object.

compresslevel, if given, must be an integer between 1 and 9. The default is 9.

For incremental compression, use a BZ2Compressor instead.

bz2.decompress(data)

Decompress data, a bytes-like object.

If data is the concatenation of multiple compressed streams, decompress all of the streams.

For incremental decompression, use a BZ2Decompressor instead.

Changed in version 3.3: Support for multi-stream inputs was added.



13.3.4 Examples of usage

Below are some examples of typical usage of the bz2 module.

Using compress() and decompress() to demonstrate round-trip compression:

>>> import bz2

>>> data = b"""\

... Donec rhoncus quis sapien sit amet molestie. Fusce scelerisque vel augue ... nec ullamcorper. Nam rutrum pretium placerat. Aliquam vel tristique lorem, ... sit amet cursus ante. In interdum laoreet mi, sit amet ultrices purus ... pulvinar a. Nam gravida euismod magna, non varius justo tincidunt feugiat. ... Aliquam pharetra lacus non risus vehicula rutrum. Maecenas aliquam leo ... felis. Pellentesque semper nunc sit amet nibh ullamcorper, ac elementum ... dolor luctus. Curabitur lacinia mi ornare consectetur vestibulum.""" >>> c = bz2.compress(data)

>>> len(data) / len(c) # Data compression ratio

1.513595166163142

>>> d = bz2.decompress(c)

>>> data == d # Check equality to original object after round-trip True



Using BZ2Compressor for incremental compression:

The Python Library Reference, Release 3.13.2



>>> import bz2

>>> def gen_data(chunks=10, chunksize=1000):

... """Yield incremental blocks of chunksize bytes.""" ... for _ in range(chunks):

... yield b"z" * chunksize

...

>>> comp = bz2.BZ2Compressor()

>>> out = b""

>>> for chunk in gen_data():

... # Provide data to the compressor object

... out = out + comp.compress(chunk)

...

>>> # Finish the compression process. Call this once you have >>> # finished providing data to the compressor.

>>> out = out + comp.flush()



The example above uses a very “nonrandom” stream of data (a stream of b"z" chunks). Random data tends to compress poorly, while ordered, repetitive data usually yields a high compression ratio.

Writing and reading a bzip2-compressed file in binary mode:

>>> import bz2

>>> data = b"""\

... Donec rhoncus quis sapien sit amet molestie. Fusce scelerisque vel augue ... nec ullamcorper. Nam rutrum pretium placerat. Aliquam vel tristique lorem, ... sit amet cursus ante. In interdum laoreet mi, sit amet ultrices purus ... pulvinar a. Nam gravida euismod magna, non varius justo tincidunt feugiat. ... Aliquam pharetra lacus non risus vehicula rutrum. Maecenas aliquam leo ... felis. Pellentesque semper nunc sit amet nibh ullamcorper, ac elementum ... dolor luctus. Curabitur lacinia mi ornare consectetur vestibulum.""" >>> with bz2.open("myfile.bz2", "wb") as f:

... # Write compressed data to file

... unused = f.write(data)

...

>>> with bz2.open("myfile.bz2", "rb") as f:

... # Decompress data from file

... content = f.read()

...

>>> content == data # Check equality to original object after round-trip True



13.4 lzma — Compression using the LZMA algorithm

Added in version 3.3.

Source code: Lib/lzma.py



This module provides classes and convenience functions for compressing and decompressing data using the LZMA compression algorithm. Also included is a file interface supporting the .xz and legacy .lzma file formats used by the xz utility, as well as raw compressed streams.

The interface provided by this module is very similar to that of the bz2 module. Note that LZMAFile and bz2.

BZ2File are not thread-safe, so if you need to use a single LZMAFile instance from multiple threads, it is necessary to protect it with a lock.

exception lzma.LZMAError

This exception is raised when an error occurs during compression or decompression, or while initializing the

compressor/decompressor state.

The Python Library Reference, Release 3.13.2



13.4.1 Reading and writing compressed files

lzma.open(filename, mode=’rb’, *, format=None, check=-1, preset=None, filters=None, encoding=None,

errors=None, newline=None)

Open an LZMA-compressed file in binary or text mode, returning a file object.

The filename argument can be either an actual file name (given as a str, bytes or path-like object), in which

case the named file is opened, or it can be an existing file object to read from or write to.

The mode argument can be any of "r", "rb", "w", "wb", "x", "xb", "a" or "ab" for binary mode, or "rt",

"wt" , "xt", or "at" for text mode. The default is "rb".

When opening a file for reading, the format and filters arguments have the same meanings as for

LZMADecompressor . In this case, the check and preset arguments should not be used.

When opening a file for writing, the format, check, preset and filters arguments have the same meanings as for

LZMACompressor .

For binary mode, this function is equivalent to the LZMAFile constructor: LZMAFile(filename, mode,

...) . In this case, the encoding, errors and newline arguments must not be provided.

For text mode, a LZMAFile object is created, and wrapped in an io.TextIOWrapper instance with the

specified encoding, error handling behavior, and line ending(s).

Changed in version 3.4: Added support for the "x", "xb" and "xt" modes.

Changed in version 3.6: Accepts a path-like object.

class lzma.LZMAFile(filename=None, mode=’r’ , *, format=None, check=-1, preset=None, filters=None)

Open an LZMA-compressed file in binary mode.

An LZMAFile can wrap an already-open file object, or operate directly on a named file. The filename argument

specifies either the file object to wrap, or the name of the file to open (as a str, bytes or path-like object).

When wrapping an existing file object, the wrapped file will not be closed when the LZMAFile is closed.

The mode argument can be either "r" for reading (default), "w" for overwriting, "x" for exclusive creation,

or "a" for appending. These can equivalently be given as "rb", "wb", "xb" and "ab" respectively.

If filename is a file object (rather than an actual file name), a mode of "w" does not truncate the file, and is

instead equivalent to "a".

When opening a file for reading, the input file may be the concatenation of multiple separate compressed

streams. These are transparently decoded as a single logical stream.

When opening a file for reading, the format and filters arguments have the same meanings as for

LZMADecompressor . In this case, the check and preset arguments should not be used.

When opening a file for writing, the format, check, preset and filters arguments have the same meanings as for

LZMACompressor .

LZMAFile supports all the members specified by io.BufferedIOBase, except for detach() and

truncate(). Iteration and the with statement are supported.

The following method and attributes are also provided:

peek(size=-1)

Return buffered data without advancing the file position. At least one byte of data will be returned, unless EOF has been reached. The exact number of bytes returned is unspecified (the size argument is ignored).



® Note

While calling peek() does not change the file position of the LZMAFile, it may change the position

of the underlying file object (e.g. if the LZMAFile was constructed by passing a file object for filename).



The Python Library Reference, Release 3.13.2



mode

'rb' for reading and 'wb' for writing.

Added in version 3.13.

name

The lzma file name. Equivalent to the name attribute of the underlying file object.

Added in version 3.13.

Changed in version 3.4: Added support for the "x" and "xb" modes.

Changed in version 3.5: The read() method now accepts an argument of None.

Changed in version 3.6: Accepts a path-like object.



13.4.2 Compressing and decompressing data in memory

class lzma.LZMACompressor(format=FORMAT_XZ, check=-1, preset=None, filters=None)

Create a compressor object, which can be used to compress data incrementally.

For a more convenient way of compressing a single chunk of data, see compress().

The format argument specifies what container format should be used. Possible values are:

• FORMAT_XZ: The .xz container format.

This is the default format.

• FORMAT_ALONE: The legacy .lzma container format.

This format is more limited than .xz – it does not support integrity checks or multiple filters.

• FORMAT_RAW: A raw data stream, not using any container format.

This format specifier does not support integrity checks, and requires that you always specify a custom filter chain (for both compression and decompression). Additionally, data compressed in this manner

cannot be decompressed using FORMAT_AUTO (see LZMADecompressor).

The check argument specifies the type of integrity check to include in the compressed data. This check is used

when decompressing, to ensure that the data has not been corrupted. Possible values are:

• CHECK_NONE: No integrity check. This is the default (and the only acceptable value) for FORMAT_ALONE

and FORMAT_RAW.

• CHECK_CRC32: 32-bit Cyclic Redundancy Check.

• CHECK_CRC64: 64-bit Cyclic Redundancy Check. This is the default for FORMAT_XZ.

• CHECK_SHA256: 256-bit Secure Hash Algorithm.

If the specified check is not supported, an LZMAError is raised.

The compression settings can be specified either as a preset compression level (with the preset argument), or

in detail as a custom filter chain (with the filters argument).

The preset argument (if provided) should be an integer between 0 and 9 (inclusive), optionally OR-ed

with the constant PRESET_EXTREME. If neither preset nor filters are given, the default behavior is to use

PRESET_DEFAULT (preset level 6). Higher presets produce smaller output, but make the compression process

slower.



® Note

In addition to being more CPU-intensive, compression with higher presets also requires much more mem-ory (and produces output that needs more memory to decompress). With preset 9 for example, the over-

head for an LZMACompressor object can be as high as 800 MiB. For this reason, it is generally best to stick with the default preset.



The Python Library Reference, Release 3.13.2



The filters argument (if provided) should be a filter chain specifier. See Specifying custom filter chains for

details.

compress(data)

Compress data (a bytes object), returning a bytes object containing compressed data for at least part of

the input. Some of data may be buffered internally, for use in later calls to compress() and flush().

The returned data should be concatenated with the output of any previous calls to compress().

flush()

Finish the compression process, returning a bytes object containing any data stored in the compressor’s internal buffers.

The compressor cannot be used after this method has been called.

class lzma.LZMADecompressor(format=FORMAT_AUTO, memlimit=None, filters=None)

Create a decompressor object, which can be used to decompress data incrementally.

For a more convenient way of decompressing an entire compressed stream at once, see decompress().

The format argument specifies the container format that should be used. The default is FORMAT_AUTO, which

can decompress both .xz and .lzma files. Other possible values are FORMAT_XZ, FORMAT_ALONE, and

FORMAT_RAW.

The memlimit argument specifies a limit (in bytes) on the amount of memory that the decompressor can use.

When this argument is used, decompression will fail with an LZMAError if it is not possible to decompress

the input within the given memory limit.

The filters argument specifies the filter chain that was used to create the stream being decompressed. This

argument is required if format is FORMAT_RAW, but should not be used for other formats. See Specifying

custom filter chains for more information about filter chains.



® Note

This class does not transparently handle inputs containing multiple compressed streams, unlike

decompress() and LZMAFile. To decompress a multi-stream input with LZMADecompressor, you must create a new decompressor for each stream.



decompress(data, max_length=-1)

Decompress data (a bytes-like object), returning uncompressed data as bytes. Some of data may be

buffered internally, for use in later calls to decompress(). The returned data should be concatenated

with the output of any previous calls to decompress().

If max_length is nonnegative, returns at most max_length bytes of decompressed data. If this limit is

reached and further output can be produced, the needs_input attribute will be set to False. In this

case, the next call to decompress() may provide data as b'' to obtain more of the output.

If all of the input data was decompressed and returned (either because this was less than max_length

bytes, or because max_length was negative), the needs_input attribute will be set to True.

Attempting to decompress data after the end of stream is reached raises an EOFError. Any data found

after the end of the stream is ignored and saved in the unused_data attribute.

Changed in version 3.5: Added the max_length parameter.

check

The ID of the integrity check used by the input stream. This may be CHECK_UNKNOWN until enough of the input has been decoded to determine what integrity check it uses.

eof

True if the end-of-stream marker has been reached.



The Python Library Reference, Release 3.13.2



unused_data

Data found after the end of the compressed stream.

Before the end of the stream is reached, this will be b"".

needs_input

False if the decompress() method can provide more decompressed data before requiring new un-compressed input.

Added in version 3.5.

lzma.compress(data, format=FORMAT_XZ , check=-1, preset=None, filters=None)

Compress data (a bytes object), returning the compressed data as a bytes object.

See LZMACompressor above for a description of the format, check, preset and filters arguments.

lzma.decompress(data, format=FORMAT_AUTO, memlimit=None, filters=None)

Decompress data (a bytes object), returning the uncompressed data as a bytes object.

If data is the concatenation of multiple distinct compressed streams, decompress all of these streams, and

return the concatenation of the results.

See LZMADecompressor above for a description of the format, memlimit and filters arguments.



13.4.3 Miscellaneous

lzma.is_check_supported(check)

Return True if the given integrity check is supported on this system.

CHECK_NONE and CHECK_CRC32 are always supported. CHECK_CRC64 and CHECK_SHA256 may be unavail-

able if you are using a version of liblzma that was compiled with a limited feature set.



13.4.4 Specifying custom filter chains

A filter chain specifier is a sequence of dictionaries, where each dictionary contains the ID and options for a single filter. Each dictionary must contain the key "id", and may contain additional keys to specify filter-dependent options. Valid filter IDs are as follows:

• Compression filters:

– FILTER_LZMA1 (for use with FORMAT_ALONE)

– FILTER_LZMA2 (for use with FORMAT_XZ and FORMAT_RAW)

• Delta filter:

– FILTER_DELTA

• Branch-Call-Jump (BCJ) filters:

– FILTER_X86

– FILTER_IA64

– FILTER_ARM

– FILTER_ARMTHUMB

– FILTER_POWERPC

– FILTER_SPARC

A filter chain can consist of up to 4 filters, and cannot be empty. The last filter in the chain must be a compression filter, and any other filters must be delta or BCJ filters.

Compression filters support the following options (specified as additional entries in the dictionary representing the filter):

• preset: A compression preset to use as a source of default values for options that are not specified explicitly.

The Python Library Reference, Release 3.13.2



• dict_size: Dictionary size in bytes. This should be between 4 KiB and 1.5 GiB (inclusive).

• lc: Number of literal context bits.

• lp: Number of literal position bits. The sum lc + lp must be at most 4.

• pb: Number of position bits; must be at most 4.

• mode: MODE_FAST or MODE_NORMAL.

• nice_len: What should be considered a “nice length” for a match. This should be 273 or less.

• mf: What match finder to use – MF_HC3, MF_HC4, MF_BT2, MF_BT3, or MF_BT4.

• depth: Maximum search depth used by match finder. 0 (default) means to select automatically based on other

filter options.

The delta filter stores the differences between bytes, producing more repetitive input for the compressor in certain circumstances. It supports one option, dist. This indicates the distance between bytes to be subtracted. The default is 1, i.e. take the differences between adjacent bytes.

The BCJ filters are intended to be applied to machine code. They convert relative branches, calls and jumps in the code to use absolute addressing, with the aim of increasing the redundancy that can be exploited by the compressor. These filters support one option, start_offset. This specifies the address that should be mapped to the beginning of the input data. The default is 0.



13.4.5 Examples

Reading in a compressed file:

import lzma

with lzma.open("file.xz") as f:

file_content = f.read()



Creating a compressed file:

import lzma

data = b"Insert Data Here"

with lzma.open("file.xz", "w") as f:

f.write(data)



Compressing data in memory:

import lzma

data_in = b"Insert Data Here"

data_out = lzma.compress(data_in)



Incremental compression:

import lzma

lzc = lzma.LZMACompressor()

out1 = lzc.compress(b"Some data\n")

out2 = lzc.compress(b"Another piece of data\n")

out3 = lzc.compress(b"Even more data\n")

out4 = lzc.flush()

# Concatenate all the partial results:

result = b"".join([out1, out2, out3, out4])



Writing compressed data to an already-open file:

import lzma

with open("file.xz", "wb") as f:

f.write(b"This data will not be compressed\n")

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

with lzma.open(f, "w") as lzf:

lzf.write(b"This *will* be compressed\n")

f.write(b"Not compressed\n")



Creating a compressed file using a custom filter chain:

import lzma

my_filters = [

{"id": lzma.FILTER_DELTA, "dist": 5},

{"id": lzma.FILTER_LZMA2, "preset": 7 | lzma.PRESET_EXTREME},

]

with lzma.open("file.xz", "w", filters=my_filters) as f:

f.write(b"blah blah blah")



13.5 zipfile — Work with ZIP archives

Source code: Lib/zipfile/



The ZIP file format is a common archive and compression standard. This module provides tools to create, read, write, append, and list a ZIP file. Any advanced use of this module will require an understanding of the format, as defined

in PKZIP Application Note.

This module does not currently handle multi-disk ZIP files. It can handle ZIP files that use the ZIP64 extensions (that is ZIP files that are more than 4 GiB in size). It supports decryption of encrypted files in ZIP archives, but it currently cannot create an encrypted file. Decryption is extremely slow as it is implemented in native Python rather than C.

The module defines the following items:

exception zipfile.BadZipFile

The error raised for bad ZIP files.

Added in version 3.2.

exception zipfile.BadZipfile

Alias of BadZipFile, for compatibility with older Python versions.

Deprecated since version 3.2.

exception zipfile.LargeZipFile

The error raised when a ZIP file would require ZIP64 functionality but that has not been enabled.

class zipfile.ZipFile

The class for reading and writing ZIP files. See section ZipFile Objects for constructor details.

class zipfile.Path

Class that implements a subset of the interface provided by pathlib.Path, including the full importlib.

resources.abc.Traversable interface.

Added in version 3.8.

class zipfile.PyZipFile

Class for creating ZIP archives containing Python libraries.

class zipfile.ZipInfo( filename=’NoName’, date_time=(1980, 1, 1, 0, 0, 0))

Class used to represent information about a member of an archive. Instances of this class are returned by the

getinfo() and infolist() methods of ZipFile objects. Most users of the zipfile module will not

need to create these, but only use those created by this module. filename should be the full name of the archive

The Python Library Reference, Release 3.13.2



member, and date_time should be a tuple containing six fields which describe the time of the last modification

to the file; the fields are described in section ZipInfo Objects.

Changed in version 3.13: A public compress_level attribute has been added to expose the formerly pro-

tected _compresslevel. The older protected name continues to work as a property for backwards compat-

ibility.

zipfile.is_zipfile(filename)

Returns True if filename is a valid ZIP file based on its magic number, otherwise returns False. filename

may be a file or file-like object too.

Changed in version 3.1: Support for file and file-like objects.

zipfile.ZIP_STORED

The numeric constant for an uncompressed archive member.

zipfile.ZIP_DEFLATED

The numeric constant for the usual ZIP compression method. This requires the zlib module.

zipfile.ZIP_BZIP2

The numeric constant for the BZIP2 compression method. This requires the bz2 module.

Added in version 3.3.

zipfile.ZIP_LZMA

The numeric constant for the LZMA compression method. This requires the lzma module.

Added in version 3.3.



® Note

The ZIP file format specification has included support for bzip2 compression since 2001, and for LZMA compression since 2006. However, some tools (including older Python releases) do not support these compression methods, and may either refuse to process the ZIP file altogether, or fail to extract individual files.



µ See also

PKZIP Application Note

Documentation on the ZIP file format by Phil Katz, the creator of the format and algorithms used.

Info-ZIP Home Page

Information about the Info-ZIP project’s ZIP archive programs and development libraries.



13.5.1 ZipFile Objects

class zipfile.ZipFile( file, mode=’r’ , compression=ZIP_STORED, allowZip64=True, compresslevel=None, *,

strict_timestamps=True, metadata_encoding=None)

Open a ZIP file, where file can be a path to a file (a string), a file-like object or a path-like object.

The mode parameter should be 'r' to read an existing file, 'w' to truncate and write a new file, 'a' to append

to an existing file, or 'x' to exclusively create and write a new file. If mode is 'x' and file refers to an existing

file, a FileExistsError will be raised. If mode is 'a' and file refers to an existing ZIP file, then additional

files are added to it. If file does not refer to a ZIP file, then a new ZIP archive is appended to the file. This is

meant for adding a ZIP archive to another file (such as python.exe). If mode is 'a' and the file does not

exist at all, it is created. If mode is 'r' or 'a', the file should be seekable.

compression is the ZIP compression method to use when writing the archive, and should be ZIP_STORED,

ZIP_DEFLATED, ZIP_BZIP2 or ZIP_LZMA; unrecognized values will cause NotImplementedError to be The Python Library Reference, Release 3.13.2



raised. If ZIP_DEFLATED, ZIP_BZIP2 or ZIP_LZMA is specified but the corresponding module (zlib, bz2

or lzma) is not available, RuntimeError is raised. The default is ZIP_STORED.

If allowZip64 is True (the default) zipfile will create ZIP files that use the ZIP64 extensions when the zipfile

is larger than 4 GiB. If it is false zipfile will raise an exception when the ZIP file would require ZIP64

extensions.

The compresslevel parameter controls the compression level to use when writing files to the archive. When

using ZIP_STORED or ZIP_LZMA it has no effect. When using ZIP_DEFLATED integers 0 through 9 are

accepted (see zlib for more information). When using ZIP_BZIP2 integers 1 through 9 are accepted (see

bz2 for more information).

The strict_timestamps argument, when set to False, allows to zip files older than 1980-01-01 at the cost of

setting the timestamp to 1980-01-01. Similar behavior occurs with files newer than 2107-12-31, the timestamp

is also set to the limit.

When mode is 'r', metadata_encoding may be set to the name of a codec, which will be used to decode

metadata such as the names of members and ZIP comments.

If the file is created with mode 'w', 'x' or 'a' and then closed without adding any files to the archive, the

appropriate ZIP structures for an empty archive will be written to the file.

ZipFile is also a context manager and therefore supports the with statement. In the example, myzip is closed

after the with statement’s suite is finished—even if an exception occurs:

with ZipFile('spam.zip', 'w') as myzip:

myzip.write('eggs.txt')



® Note

metadata_encoding is an instance-wide setting for the ZipFile. It is not currently possible to set this on a per-member basis.

This attribute is a workaround for legacy implementations which produce archives with names in the current locale encoding or code page (mostly on Windows). According to the .ZIP standard, the encoding of metadata may be specified to be either IBM code page (default) or UTF-8 by a flag in the archive header. That flag takes precedence over metadata_encoding, which is a Python-specific extension.



Changed in version 3.2: Added the ability to use ZipFile as a context manager.

Changed in version 3.3: Added support for bzip2 and lzma compression.

Changed in version 3.4: ZIP64 extensions are enabled by default.

Changed in version 3.5: Added support for writing to unseekable streams. Added support for the 'x' mode.

Changed in version 3.6: Previously, a plain RuntimeError was raised for unrecognized compression values.

Changed in version 3.6.2: The file parameter accepts a path-like object.

Changed in version 3.7: Add the compresslevel parameter.

Changed in version 3.8: The strict_timestamps keyword-only parameter.

Changed in version 3.11: Added support for specifying member name encoding for reading metadata in the

zipfile’s directory and file headers.

ZipFile.close()

Close the archive file. You must call close() before exiting your program or essential records will not be

written.

ZipFile.getinfo(name)

Return a ZipInfo object with information about the archive member name. Calling getinfo() for a name

not currently contained in the archive will raise a KeyError.

The Python Library Reference, Release 3.13.2



ZipFile.infolist()

Return a list containing a ZipInfo object for each member of the archive. The objects are in the same order

as their entries in the actual ZIP file on disk if an existing archive was opened.

ZipFile.namelist()

Return a list of archive members by name.

ZipFile.open(name, mode=’r’, pwd=None, *, force_zip64=False)

Access a member of the archive as a binary file-like object. name can be either the name of a file within the

archive or a ZipInfo object. The mode parameter, if included, must be 'r' (the default) or 'w'. pwd is the

password used to decrypt encrypted ZIP files as a bytes object.

open() is also a context manager and therefore supports the with statement:

with ZipFile('spam.zip') as myzip:

with myzip.open('eggs.txt') as myfile:

print(myfile.read())



With mode 'r' the file-like object (ZipExtFile) is read-only and provides the following methods: read(),

readline(), readlines(), seek(), tell(), __iter__(), __next__(). These objects can operate

independently of the ZipFile.

With mode='w', a writable file handle is returned, which supports the write() method. While a writable

file handle is open, attempting to read or write other files in the ZIP file will raise a ValueError.

In both cases the file-like object has also attributes name, which is equivalent to the name of a file within the

archive, and mode, which is 'rb' or 'wb' depending on the input mode.

When writing a file, if the file size is not known in advance but may exceed 2 GiB, pass force_zip64=True to

ensure that the header format is capable of supporting large files. If the file size is known in advance, construct

a ZipInfo object with file_size set, and use that as the name parameter.



® Note

The open(), read() and extract() methods can take a filename or a ZipInfo object. You will appreciate this when trying to read a ZIP file that contains members with duplicate names.



Changed in version 3.6: Removed support of mode='U'. Use io.TextIOWrapper for reading compressed

text files in universal newlines mode.

Changed in version 3.6: ZipFile.open() can now be used to write files into the archive with the mode='w'

option.

Changed in version 3.6: Calling open() on a closed ZipFile will raise a ValueError. Previously, a

RuntimeError was raised.

Changed in version 3.13: Added attributes name and mode for the writeable file-like object. The value of the

mode attribute for the readable file-like object was changed from 'r' to 'rb'.

ZipFile.extract(member, path=None, pwd=None)

Extract a member from the archive to the current working directory; member must be its full name or a

ZipInfo object. Its file information is extracted as accurately as possible. path specifies a different directory

to extract to. member can be a filename or a ZipInfo object. pwd is the password used for encrypted files as

a bytes object.

Returns the normalized path created (a directory or new file).



® Note

If a member filename is an absolute path, a drive/UNC sharepoint and leading (back)slashes will be stripped, e.g.: ///foo/bar becomes foo/bar on Unix, and C:\foo\bar becomes foo\bar on Win-The Python Library Reference, Release 3.13.2



dows. And all ".." components in a member filename will be removed, e.g.: ../../foo../../ba..r becomes foo../ba..r. On Windows illegal characters (:, <, >, |, ", ?, and *) replaced by underscore (_).



Changed in version 3.6: Calling extract() on a closed ZipFile will raise a ValueError. Previously, a

RuntimeError was raised.

Changed in version 3.6.2: The path parameter accepts a path-like object.

ZipFile.extractall(path=None, members=None, pwd=None)

Extract all members from the archive to the current working directory. path specifies a different directory to

extract to. members is optional and must be a subset of the list returned by namelist(). pwd is the password

used for encrypted files as a bytes object.



Á Warning

Never extract archives from untrusted sources without prior inspection. It is possible that files are created outside of path, e.g. members that have absolute filenames starting with "/" or filenames with two dots

"..". This module attempts to prevent that. See extract() note.



Changed in version 3.6: Calling extractall() on a closed ZipFile will raise a ValueError. Previously, a

RuntimeError was raised.

Changed in version 3.6.2: The path parameter accepts a path-like object.

ZipFile.printdir()

Print a table of contents for the archive to sys.stdout.

ZipFile.setpassword(pwd)

Set pwd (a bytes object) as default password to extract encrypted files.

ZipFile.read(name, pwd=None)

Return the bytes of the file name in the archive. name is the name of the file in the archive, or a ZipInfo

object. The archive must be open for read or append. pwd is the password used for encrypted files as a bytes

object and, if specified, overrides the default password set with setpassword(). Calling read() on a ZipFile

that uses a compression method other than ZIP_STORED, ZIP_DEFLATED, ZIP_BZIP2 or ZIP_LZMA will

raise a NotImplementedError. An error will also be raised if the corresponding compression module is not

available.

Changed in version 3.6: Calling read() on a closed ZipFile will raise a ValueError. Previously, a

RuntimeError was raised.

ZipFile.testzip()

Read all the files in the archive and check their CRC’s and file headers. Return the name of the first bad file,

or else return None.

Changed in version 3.6: Calling testzip() on a closed ZipFile will raise a ValueError. Previously, a

RuntimeError was raised.

ZipFile.write(filename, arcname=None, compress_type=None, compresslevel=None)

Write the file named filename to the archive, giving it the archive name arcname (by default, this will be the

same as filename, but without a drive letter and with leading path separators removed). If given, compress_type

overrides the value given for the compression parameter to the constructor for the new entry. Similarly, com-

presslevel will override the constructor if given. The archive must be open with mode 'w', 'x' or 'a'.



® Note

The ZIP file standard historically did not specify a metadata encoding, but strongly recommended CP437 (the original IBM PC encoding) for interoperability. Recent versions allow use of UTF-8 (only). In this

The Python Library Reference, Release 3.13.2



module, UTF-8 will automatically be used to write the member names if they contain any non-ASCII characters. It is not possible to write member names in any encoding other than ASCII or UTF-8.



® Note

Archive names should be relative to the archive root, that is, they should not start with a path separator.



® Note

If arcname (or filename, if arcname is not given) contains a null byte, the name of the file in the archive will be truncated at the null byte.



® Note

A leading slash in the filename may lead to the archive being impossible to open in some zip programs on Windows systems.



Changed in version 3.6: Calling write() on a ZipFile created with mode 'r' or a closed ZipFile will raise

a ValueError. Previously, a RuntimeError was raised.

ZipFile.writestr(zinfo_or_arcname, data, compress_type=None, compresslevel=None)

Write a file into the archive. The contents is data, which may be either a str or a bytes instance; if it is a

str , it is encoded as UTF-8 first. zinfo_or_arcname is either the file name it will be given in the archive, or

a ZipInfo instance. If it’s an instance, at least the filename, date, and time must be given. If it’s a name, the

date and time is set to the current date and time. The archive must be opened with mode 'w', 'x' or 'a'.

If given, compress_type overrides the value given for the compression parameter to the constructor for the new

entry, or in the zinfo_or_arcname (if that is a ZipInfo instance). Similarly, compresslevel will override the

constructor if given.



® Note

When passing a ZipInfo instance as the zinfo_or_arcname parameter, the compression method used will

be that specified in the compress_type member of the given ZipInfo instance. By default, the ZipInfo

constructor sets this member to ZIP_STORED.



Changed in version 3.2: The compress_type argument.

Changed in version 3.6: Calling writestr() on a ZipFile created with mode 'r' or a closed ZipFile will

raise a ValueError. Previously, a RuntimeError was raised.

ZipFile.mkdir(zinfo_or_directory, mode=511)

Create a directory inside the archive. If zinfo_or_directory is a string, a directory is created inside the archive

with the mode that is specified in the mode argument. If, however, zinfo_or_directory is a ZipInfo instance

then the mode argument is ignored.

The archive must be opened with mode 'w', 'x' or 'a'.

Added in version 3.11.

The following data attributes are also available:

ZipFile.filename

Name of the ZIP file.

The Python Library Reference, Release 3.13.2



ZipFile.debug

The level of debug output to use. This may be set from 0 (the default, no output) to 3 (the most output).

Debugging information is written to sys.stdout.

ZipFile.comment

The comment associated with the ZIP file as a bytes object. If assigning a comment to a ZipFile instance

created with mode 'w', 'x' or 'a', it should be no longer than 65535 bytes. Comments longer than this will

be truncated.



13.5.2 Path Objects

class zipfile.Path(root, at=”)

Construct a Path object from a root zipfile (which may be a ZipFile instance or file suitable for passing

to the ZipFile constructor).

at specifies the location of this Path within the zipfile, e.g. ‘dir/file.txt’, ‘dir/’, or ‘’. Defaults to the empty string,

indicating the root.

Path objects expose the following features of pathlib.Path objects:

Path objects are traversable using the / operator or joinpath.

Path.name

The final path component.

Path.open(mode=’r’, *, pwd, **)

Invoke ZipFile.open() on the current path. Allows opening for read or write, text or binary through sup-

ported modes: ‘r’, ‘w’, ‘rb’, ‘wb’. Positional and keyword arguments are passed through to io.TextIOWrapper

when opened as text and ignored otherwise. pwd is the pwd parameter to ZipFile.open().

Changed in version 3.9: Added support for text and binary modes for open. Default mode is now text.

Changed in version 3.11.2: The encoding parameter can be supplied as a positional argument without causing

a TypeError. As it could in 3.9. Code needing to be compatible with unpatched 3.10 and 3.11 versions must

pass all io.TextIOWrapper arguments, encoding included, as keywords.

Path.iterdir()

Enumerate the children of the current directory.

Path.is_dir()

Return True if the current context references a directory.

Path.is_file()

Return True if the current context references a file.

Path.is_symlink()

Return True if the current context references a symbolic link.

Added in version 3.12.

Changed in version 3.13: Previously, is_symlink would unconditionally return False.

Path.exists()

Return True if the current context references a file or directory in the zip file.

Path.suffix

The last dot-separated portion of the final component, if any. This is commonly called the file extension.

Added in version 3.11: Added Path.suffix property.

Path.stem

The final path component, without its suffix.

Added in version 3.11: Added Path.stem property.

The Python Library Reference, Release 3.13.2



Path.suffixes

A list of the path’s suffixes, commonly called file extensions.

Added in version 3.11: Added Path.suffixes property.

Path.read_text(*, **)

Read the current file as unicode text. Positional and keyword arguments are passed through to io.

TextIOWrapper (except buffer, which is implied by the context).

Changed in version 3.11.2: The encoding parameter can be supplied as a positional argument without causing

a TypeError. As it could in 3.9. Code needing to be compatible with unpatched 3.10 and 3.11 versions must

pass all io.TextIOWrapper arguments, encoding included, as keywords.

Path.read_bytes()

Read the current file as bytes.

Path.joinpath(*other)

Return a new Path object with each of the other arguments joined. The following are equivalent:

>>> Path(...).joinpath('child').joinpath('grandchild')

>>> Path(...).joinpath('child', 'grandchild')

>>> Path(...) / 'child' / 'grandchild'



Changed in version 3.10: Prior to 3.10, joinpath was undocumented and accepted exactly one parameter.

The zipp project provides backports of the latest path object functionality to older Pythons. Use zipp.Path in place of zipfile.Path for early access to changes.



13.5.3 PyZipFile Objects

The PyZipFile constructor takes the same parameters as the ZipFile constructor, and one additional parameter, optimize.

class zipfile.PyZipFile(file, mode=’r’ , compression=ZIP_STORED, allowZip64=True, optimize=-1)

Changed in version 3.2: Added the optimize parameter.

Changed in version 3.4: ZIP64 extensions are enabled by default.

Instances have one method in addition to those of ZipFile objects:

writepy(pathname, basename=”, filterfunc=None)

Search for files *.py and add the corresponding file to the archive.

If the optimize parameter to PyZipFile was not given or-1, the corresponding file is a *.pyc file, compiling if necessary.

If the optimize parameter to PyZipFile was 0, 1 or 2, only files with that optimization level (see

compile()) are added to the archive, compiling if necessary.

If pathname is a file, the filename must end with .py, and just the (corresponding *.pyc) file is added at

the top level (no path information). If pathname is a file that does not end with .py, a RuntimeError will be raised. If it is a directory, and the directory is not a package directory, then all the files *.pyc are added at the top level. If the directory is a package directory, then all *.pyc are added under the package name as a file path, and if any subdirectories are package directories, all of these are added recursively in sorted order.

basename is intended for internal use only.

filterfunc, if given, must be a function taking a single string argument. It will be passed each path (in-cluding each individual full file path) before it is added to the archive. If filterfunc returns a false value, the path will not be added, and if it is a directory its contents will be ignored. For example, if our test files are all either in test directories or start with the string test_, we can use a filterfunc to exclude them:

The Python Library Reference, Release 3.13.2



>>> zf = PyZipFile('myprog.zip')

>>> def notests(s):

... fn = os.path.basename(s)

... return (not (fn == 'test' or fn.startswith('test_')))

...

>>> zf.writepy('myprog', filterfunc=notests)



The writepy() method makes archives with file names like this:

string.pyc # Top level name

test/__init__.pyc # Package directory

test/testall.pyc # Module test.testall

test/bogus/__init__.pyc # Subpackage directory

test/bogus/myfile.pyc # Submodule test.bogus.myfile



Changed in version 3.4: Added the filterfunc parameter.

Changed in version 3.6.2: The pathname parameter accepts a path-like object.

Changed in version 3.7: Recursion sorts directory entries.



13.5.4 ZipInfo Objects

Instances of the ZipInfo class are returned by the getinfo() and infolist() methods of ZipFile objects. Each object stores information about a single member of the ZIP archive.

There is one classmethod to make a ZipInfo instance for a filesystem file:

classmethod ZipInfo.from_file(filename, arcname=None, *, strict_timestamps=True)

Construct a ZipInfo instance for a file on the filesystem, in preparation for adding it to a zip file.

filename should be the path to a file or directory on the filesystem.

If arcname is specified, it is used as the name within the archive. If arcname is not specified, the name will be

the same as filename, but with any drive letter and leading path separators removed.

The strict_timestamps argument, when set to False, allows to zip files older than 1980-01-01 at the cost of

setting the timestamp to 1980-01-01. Similar behavior occurs with files newer than 2107-12-31, the timestamp

is also set to the limit.

Added in version 3.6.

Changed in version 3.6.2: The filename parameter accepts a path-like object.

Changed in version 3.8: Added the strict_timestamps keyword-only parameter.

Instances have the following methods and attributes:

ZipInfo.is_dir()

Return True if this archive member is a directory.

This uses the entry’s name: directories should always end with /.

Added in version 3.6.

ZipInfo.filename

Name of the file in the archive.

ZipInfo.date_time

The time and date of the last modification to the archive member. This is a tuple of six values:



The Python Library Reference, Release 3.13.2



Index Value

0 Year (>= 1980)

1 Month (one-based)

2 Day of month (one-based)

3 Hours (zero-based)

4 Minutes (zero-based)

5 Seconds (zero-based)



® Note

The ZIP file format does not support timestamps before 1980.



ZipInfo.compress_type

Type of compression for the archive member.

ZipInfo.comment

Comment for the individual archive member as a bytes object.

ZipInfo.extra

Expansion field data. The PKZIP Application Note contains some comments on the internal structure of the

data contained in this bytes object.

ZipInfo.create_system

System which created ZIP archive.

ZipInfo.create_version

PKZIP version which created ZIP archive.

ZipInfo.extract_version

PKZIP version needed to extract archive.

ZipInfo.reserved

Must be zero.

ZipInfo.flag_bits

ZIP flag bits.

ZipInfo.volume

Volume number of file header.

ZipInfo.internal_attr

Internal attributes.

ZipInfo.external_attr

External file attributes.

ZipInfo.header_offset

Byte offset to the file header.

ZipInfo.CRC

CRC-32 of the uncompressed file.

ZipInfo.compress_size

Size of the compressed data.

ZipInfo.file_size

Size of the uncompressed file.

The Python Library Reference, Release 3.13.2



13.5.5 Command-Line Interface

The zipfile module provides a simple command-line interface to interact with ZIP archives.

If you want to create a new ZIP archive, specify its name after the-c option and then list the filename(s) that should be included:

$ python -m zipfile -c monty.zip spam.txt eggs.txt



Passing a directory is also acceptable:

$ python -m zipfile -c monty.zip life-of-brian_1979/



If you want to extract a ZIP archive into the specified directory, use the-e option:

$ python -m zipfile -e monty.zip target-dir/



For a list of the files in a ZIP archive, use the-l option:

$ python -m zipfile -l monty.zip



Command-line options

-l

--list

List files in a zipfile.

-c ...

--create ...

Create zipfile from source files.

-e

--extract

Extract zipfile into target directory.

-t

--test

Test whether the zipfile is valid or not.

--metadata-encoding

Specify encoding of member names for-l,-e and-t.

Added in version 3.11.



13.5.6 Decompression pitfalls

The extraction in zipfile module might fail due to some pitfalls listed below.



From file itself

Decompression may fail due to incorrect password / CRC checksum / ZIP format or unsupported compression method / decryption.



File System limitations

Exceeding limitations on different file systems can cause decompression failed. Such as allowable characters in the directory entries, length of the file name, length of the pathname, size of a single file, and number of files, etc.



The Python Library Reference, Release 3.13.2



Resources limitations

The lack of memory or disk volume would lead to decompression failed. For example, decompression bombs (aka

ZIP bomb) apply to zipfile library that can cause disk volume exhaustion.



Interruption

Interruption during the decompression, such as pressing control-C or killing the decompression process may result in incomplete decompression of the archive.



Default behaviors of extraction

Not knowing the default extraction behaviors can cause unexpected decompression results. For example, when ex-tracting the same archive twice, it overwrites files without asking.



13.6 tarfile — Read and write tar archive files

Source code: Lib/tarfile.py



The tarfile module makes it possible to read and write tar archives, including those using gzip, bz2 and lzma

compression. Use the zipfile module to read or write .zip files, or the higher-level functions in shutil.

Some facts and figures:

• reads and writes gzip, bz2 and lzma compressed archives if the respective modules are available.

• read/write support for the POSIX.1-1988 (ustar) format.

• read/write support for the GNU tar format including longname and longlink extensions, read-only support for

all variants of the sparse extension including restoration of sparse files.

• read/write support for the POSIX.1-2001 (pax) format.

• handles directories, regular files, hardlinks, symbolic links, fifos, character devices and block devices and is

able to acquire and restore file information like timestamp, access permissions and owner.

Changed in version 3.3: Added support for lzma compression.

Changed in version 3.12: Archives are extracted using a filter, which makes it possible to either limit surpris-ing/dangerous features, or to acknowledge that they are expected and the archive is fully trusted. By default, archives are fully trusted, but this default is deprecated and slated to change in Python 3.14.

tarfile.open(name=None, mode=’r’, fileobj=None, bufsize=10240, **kwargs)

Return a TarFile object for the pathname name. For detailed information on TarFile objects and the

keyword arguments that are allowed, see TarFile Objects.

mode has to be a string of the form 'filemode[:compression]', it defaults to 'r'. Here is a full list of

mode combinations:



The Python Library Reference, Release 3.13.2



mode action

'r' or Open for reading with transparent compression (recommended). 'r:*'

'r:' Open for reading exclusively without compression.

'r:gz' Open for reading with gzip compression.

'r:bz2' Open for reading with bzip2 compression.

'r:xz' Open for reading with lzma compression.

'x' or 'x:' Create a tarfile exclusively without compression. Raise a FileExistsError exception

if it already exists.

'x:gz' Create a tarfile with gzip compression. Raise a FileExistsError exception if it already

exists.

'x:bz2' Create a tarfile with bzip2 compression. Raise a FileExistsError exception if it al-

ready exists.

'x:xz' Create a tarfile with lzma compression. Raise a FileExistsError exception if it already

exists.

'a' or Open for appending with no compression. The file is created if it does not exist. 'a:'

'w' or Open for uncompressed writing.

'w:'

'w:gz' Open for gzip compressed writing.

'w:bz2' Open for bzip2 compressed writing.

'w:xz' Open for lzma compressed writing.



Note that 'a:gz', 'a:bz2' or 'a:xz' is not possible. If mode is not suitable to open a certain (compressed)

file for reading, ReadError is raised. Use mode 'r' to avoid this. If a compression method is not supported,

CompressionError is raised.

If fileobj is specified, it is used as an alternative to a file object opened in binary mode for name. It is supposed

to be at position 0.

For modes 'w:gz', 'x:gz', 'w|gz', 'w:bz2', 'x:bz2', 'w|bz2', tarfile.open() accepts the key-

word argument compresslevel (default 9) to specify the compression level of the file.

For modes 'w:xz' and 'x:xz', tarfile.open() accepts the keyword argument preset to specify the com-

pression level of the file.

For special purposes, there is a second format for mode: 'filemode|[compression]'. tarfile.open()

will return a TarFile object that processes its data as a stream of blocks. No random seeking will be done on

the file. If given, fileobj may be any object that has a read() or write() method (depending on the mode)

that works with bytes. bufsize specifies the blocksize and defaults to 20 * 512 bytes. Use this variant in

combination with e.g. sys.stdin.buffer, a socket file object or a tape device. However, such a TarFile

object is limited in that it does not allow random access, see Examples. The currently possible modes:



Mode Action

'r|*' Open a stream of tar blocks for reading with transparent compression. 'r|' Open a stream of uncompressed tar blocks for reading.

'r|gz' Open a gzip compressed stream for reading.

'r|bz2' Open a bzip2 compressed stream for reading.

'r|xz' Open an lzma compressed stream for reading.

'w|' Open an uncompressed stream for writing.

'w|gz' Open a gzip compressed stream for writing.

'w|bz2' Open a bzip2 compressed stream for writing.

'w|xz' Open an lzma compressed stream for writing.



Changed in version 3.5: The 'x' (exclusive creation) mode was added.

Changed in version 3.6: The name parameter accepts a path-like object.

The Python Library Reference, Release 3.13.2



Changed in version 3.12: The compresslevel keyword argument also works for streams.

class tarfile.TarFile

Class for reading and writing tar archives. Do not use this class directly: use tarfile.open() instead. See

TarFile Objects.

tarfile.is_tarfile(name)

Return True if name is a tar archive file, that the tarfile module can read. name may be a str, file, or

file-like object.

Changed in version 3.9: Support for file and file-like objects.

The tarfile module defines the following exceptions:

exception tarfile.TarError

Base class for all tarfile exceptions.

exception tarfile.ReadError

Is raised when a tar archive is opened, that either cannot be handled by the tarfile module or is somehow

invalid.

exception tarfile.CompressionError

Is raised when a compression method is not supported or when the data cannot be decoded properly.

exception tarfile.StreamError

Is raised for the limitations that are typical for stream-like TarFile objects.

exception tarfile.ExtractError

Is raised for non-fatal errors when using TarFile.extract(), but only if TarFile.errorlevel== 2.

exception tarfile.HeaderError

Is raised by TarInfo.frombuf() if the buffer it gets is invalid.

exception tarfile.FilterError

Base class for members refused by filters.

tarinfo

Information about the member that the filter refused to extract, as TarInfo.

exception tarfile.AbsolutePathError

Raised to refuse extracting a member with an absolute path.

exception tarfile.OutsideDestinationError

Raised to refuse extracting a member outside the destination directory.

exception tarfile.SpecialFileError

Raised to refuse extracting a special file (e.g. a device or pipe).

exception tarfile.AbsoluteLinkError

Raised to refuse extracting a symbolic link with an absolute path.

exception tarfile.LinkOutsideDestinationError

Raised to refuse extracting a symbolic link pointing outside the destination directory.

The following constants are available at the module level:

tarfile.ENCODING

The default character encoding: 'utf-8' on Windows, the value returned by sys.

getfilesystemencoding() otherwise.

tarfile.REGTYPE

tarfile.AREGTYPE

A regular file type.

The Python Library Reference, Release 3.13.2



tarfile.LNKTYPE

A link (inside tarfile) type.

tarfile.SYMTYPE

A symbolic link type.

tarfile.CHRTYPE

A character special device type.

tarfile.BLKTYPE

A block special device type.

tarfile.DIRTYPE

A directory type.

tarfile.FIFOTYPE

A FIFO special device type.

tarfile.CONTTYPE

A contiguous file type.

tarfile.GNUTYPE_LONGNAME

A GNU tar longname type.

tarfile.GNUTYPE_LONGLINK

A GNU tar longlink type.

tarfile.GNUTYPE_SPARSE

A GNU tar sparse file type.

Each of the following constants defines a tar archive format that the tarfile module is able to create. See section

Supported tar formats for details.

tarfile.USTAR_FORMAT

POSIX.1-1988 (ustar) format.

tarfile.GNU_FORMAT

GNU tar format.

tarfile.PAX_FORMAT

POSIX.1-2001 (pax) format.

tarfile.DEFAULT_FORMAT

The default format for creating archives. This is currently PAX_FORMAT.

Changed in version 3.8: The default format for new archives was changed to PAX_FORMAT from GNU_FORMAT.



µ See also

Module zipfile

Documentation of the zipfile standard module.

Archiving operations

Documentation of the higher-level archiving facilities provided by the standard shutil module.

GNU tar manual, Basic Tar Format

Documentation for tar archive files, including GNU tar extensions.



The Python Library Reference, Release 3.13.2



13.6.1 TarFile Objects

The TarFile object provides an interface to a tar archive. A tar archive is a sequence of blocks. An archive member (a stored file) is made up of a header block followed by data blocks. It is possible to store a file in a tar archive several

times. Each archive member is represented by a TarInfo object, see TarInfo Objects for details.

A TarFile object can be used as a context manager in a with statement. It will automatically be closed when the block is completed. Please note that in the event of an exception an archive opened for writing will not be finalized;

only the internally used file object will be closed. See the Examples section for a use case.

Added in version 3.2: Added support for the context management protocol.

class tarfile.TarFile( name=None, mode=’r’ , fileobj=None, format=DEFAULT_FORMAT , tarinfo=TarInfo,

dereference=False, ignore_zeros=False, encoding=ENCODING,

errors=’surrogateescape’, pax_headers=None, debug=0, errorlevel=1, stream=False)

All following arguments are optional and can be accessed as instance attributes as well.

name is the pathname of the archive. name may be a path-like object. It can be omitted if fileobj is given. In

this case, the file object’s name attribute is used if it exists.

mode is either 'r' to read from an existing archive, 'a' to append data to an existing file, 'w' to create a new

file overwriting an existing one, or 'x' to create a new file only if it does not already exist.

If fileobj is given, it is used for reading or writing data. If it can be determined, mode is overridden by fileobj’s

mode. fileobj will be used from position 0.



® Note

fileobj is not closed, when TarFile is closed.



format controls the archive format for writing. It must be one of the constants USTAR_FORMAT, GNU_FORMAT

or PAX_FORMAT that are defined at module level. When reading, format will be automatically detected, even

if different formats are present in a single archive.

The tarinfo argument can be used to replace the default TarInfo class with a different one.

If dereference is False, add symbolic and hard links to the archive. If it is True, add the content of the target

files to the archive. This has no effect on systems that do not support symbolic links.

If ignore_zeros is False, treat an empty block as the end of the archive. If it is True, skip empty (and invalid)

blocks and try to get as many members as possible. This is only useful for reading concatenated or damaged

archives.

debug can be set from 0 (no debug messages) up to 3 (all debug messages). The messages are written to

sys.stderr.

errorlevel controls how extraction errors are handled, see the corresponding attribute.

The encoding and errors arguments define the character encoding to be used for reading or writing the archive

and how conversion errors are going to be handled. The default settings will work for most users. See section

Unicode issues for in-depth information.

The pax_headers argument is an optional dictionary of strings which will be added as a pax global header if

format is PAX_FORMAT.

If stream is set to True then while reading the archive info about files in the archive are not cached, saving

memory.

Changed in version 3.2: Use 'surrogateescape' as the default for the errors argument.

Changed in version 3.5: The 'x' (exclusive creation) mode was added.

Changed in version 3.6: The name parameter accepts a path-like object.

Changed in version 3.13: Add the stream parameter.

The Python Library Reference, Release 3.13.2



classmethod TarFile.open(...)

Alternative constructor. The tarfile.open() function is actually a shortcut to this classmethod.

TarFile.getmember(name)

Return a TarInfo object for member name. If name can not be found in the archive, KeyError is raised.



® Note

If a member occurs more than once in the archive, its last occurrence is assumed to be the most up-to-date version.



TarFile.getmembers()

Return the members of the archive as a list of TarInfo objects. The list has the same order as the members

in the archive.

TarFile.getnames()

Return the members as a list of their names. It has the same order as the list returned by getmembers().

TarFile.list(verbose=True, *, members=None)

Print a table of contents to sys.stdout. If verbose is False, only the names of the members are printed. If

it is True, output similar to that of ls -l is produced. If optional members is given, it must be a subset of

the list returned by getmembers().

Changed in version 3.5: Added the members parameter.

TarFile.next()

Return the next member of the archive as a TarInfo object, when TarFile is opened for reading. Return

None if there is no more available.

TarFile.extractall(path=’.’, members=None, *, numeric_owner=False, filter=None)

Extract all members from the archive to the current working directory or directory path. If optional members

is given, it must be a subset of the list returned by getmembers(). Directory information like owner, mod-

ification time and permissions are set after all members have been extracted. This is done to work around

two problems: A directory’s modification time is reset each time a file is created in it. And, if a directory’s

permissions do not allow writing, extracting files to it will fail.

If numeric_owner is True, the uid and gid numbers from the tarfile are used to set the owner/group for the

extracted files. Otherwise, the named values from the tarfile are used.

The filter argument specifies how members are modified or rejected before extraction. See Extraction filters

for details. It is recommended to set this explicitly depending on which tar features you need to support.



Á Warning

Never extract archives from untrusted sources without prior inspection. It is possible that files are created outside of path, e.g. members that have absolute filenames starting with "/" or filenames with two dots "..".

Set filter='data' to prevent the most dangerous security issues, and read the Extraction filters section for details.



Changed in version 3.5: Added the numeric_owner parameter.

Changed in version 3.6: The path parameter accepts a path-like object.

Changed in version 3.12: Added the filter parameter.

TarFile.extract(member, path=”, set_attrs=True, *, numeric_owner=False, filter=None)

Extract a member from the archive to the current working directory, using its full name. Its file information

is extracted as accurately as possible. member may be a filename or a TarInfo object. You can specify a

The Python Library Reference, Release 3.13.2



different directory using path. path may be a path-like object. File attributes (owner, mtime, mode) are set

unless set_attrs is false.

The numeric_owner and filter arguments are the same as for extractall().



® Note

The extract() method does not take care of several extraction issues. In most cases you should consider

using the extractall() method.



Á Warning

See the warning for extractall().

Set filter='data' to prevent the most dangerous security issues, and read the Extraction filters section for details.



Changed in version 3.2: Added the set_attrs parameter.

Changed in version 3.5: Added the numeric_owner parameter.

Changed in version 3.6: The path parameter accepts a path-like object.

Changed in version 3.12: Added the filter parameter.

TarFile.extractfile(member)

Extract a member from the archive as a file object. member may be a filename or a TarInfo object. If member

is a regular file or a link, an io.BufferedReader object is returned. For all other existing members, None

is returned. If member does not appear in the archive, KeyError is raised.

Changed in version 3.3: Return an io.BufferedReader object.

Changed in version 3.13: The returned io.BufferedReader object has the mode attribute which is always

equal to 'rb'.

TarFile.errorlevel: int

If errorlevel is 0, errors are ignored when using TarFile.extract() and TarFile.extractall(). Nev-

ertheless, they appear as error messages in the debug output when debug is greater than 0. If 1 (the default),

all fatal errors are raised as OSError or FilterError exceptions. If 2, all non-fatal errors are raised as

TarError exceptions as well.

Some exceptions, e.g. ones caused by wrong argument types or data corruption, are always raised.

Custom extraction filters should raise FilterError for fatal errors and ExtractError for non-fatal ones.

Note that when an exception is raised, the archive may be partially extracted. It is the user’s responsibility to

clean up.

TarFile.extraction_filter

Added in version 3.12.

The extraction filter used as a default for the filter argument of extract() and extractall().

The attribute may be None or a callable. String names are not allowed for this attribute, unlike the filter

argument to extract().

If extraction_filter is None (the default), calling an extraction method without a filter argument will raise

a DeprecationWarning, and fall back to the fully_trusted filter, whose dangerous behavior matches

previous versions of Python.

In Python 3.14+, leaving extraction_filter=None will cause extraction methods to use the data filter

by default.

The Python Library Reference, Release 3.13.2



The attribute may be set on instances or overridden in subclasses. It also is possible to set it on the TarFile

class itself to set a global default, although, since it affects all uses of tarfile, it is best practice to only do so in

top-level applications or site configuration. To set a global default this way, a filter function needs to

be wrapped in staticmethod() to prevent injection of a self argument.

TarFile.add(name, arcname=None, recursive=True, *, filter=None)

Add the file name to the archive. name may be any type of file (directory, fifo, symbolic link, etc.). If given,

arcname specifies an alternative name for the file in the archive. Directories are added recursively by default.

This can be avoided by setting recursive to False. Recursion adds entries in sorted order. If filter is given,

it should be a function that takes a TarInfo object argument and returns the changed TarInfo object. If it

instead returns None the TarInfo object will be excluded from the archive. See Examples for an example.

Changed in version 3.2: Added the filter parameter.

Changed in version 3.7: Recursion adds entries in sorted order.

TarFile.addfile(tarinfo, fileobj=None)

Add the TarInfo object tarinfo to the archive. If tarinfo represents a non zero-size regular file, the fileobj

argument should be a binary file, and tarinfo.size bytes are read from it and added to the archive. You

can create TarInfo objects directly, or by using gettarinfo().

Changed in version 3.13: fileobj must be given for non-zero-sized regular files.

TarFile.gettarinfo(name=None, arcname=None, fileobj=None)

Create a TarInfo object from the result of os.stat() or equivalent on an existing file. The file is either

named by name, or specified as a file object fileobj with a file descriptor. name may be a path-like object.

If given, arcname specifies an alternative name for the file in the archive, otherwise, the name is taken from

fileobj’s name attribute, or the name argument. The name should be a text string.

You can modify some of the TarInfo’s attributes before you add it using addfile(). If the file object is

not an ordinary file object positioned at the beginning of the file, attributes such as size may need modifying.

This is the case for objects such as GzipFile. The name may also be modified, in which case arcname could

be a dummy string.

Changed in version 3.6: The name parameter accepts a path-like object.

TarFile.close()

Close the TarFile. In write mode, two finishing zero blocks are appended to the archive.

TarFile.pax_headers: dict

A dictionary containing key-value pairs of pax global headers.



13.6.2 TarInfo Objects

A TarInfo object represents one member in a TarFile. Aside from storing all required attributes of a file (like file type, size, time, permissions, owner etc.), it provides some useful methods to determine its type. It does not contain the file’s data itself.

TarInfo objects are returned by TarFile’s methods getmember(), getmembers() and gettarinfo().

Modifying the objects returned by getmember() or getmembers() will affect all subsequent operations on the

archive. For cases where this is unwanted, you can use copy.copy() or call the replace() method to create a modified copy in one step.

Several attributes can be set to None to indicate that a piece of metadata is unused or unknown. Different TarInfo methods handle None differently:

• The extract() or extractall() methods will ignore the corresponding metadata, leaving it set to a default.

• addfile() will fail.

• list() will print a placeholder string.

class tarfile.TarInfo( name=”)

Create a TarInfo object.

The Python Library Reference, Release 3.13.2



classmethod TarInfo.frombuf(buf, encoding, errors)

Create and return a TarInfo object from string buffer buf.

Raises HeaderError if the buffer is invalid.

classmethod TarInfo.fromtarfile(tarfile)

Read the next member from the TarFile object tarfile and return it as a TarInfo object.

TarInfo.tobuf(format=DEFAULT_FORMAT, encoding=ENCODING, errors=’surrogateescape’)

Create a string buffer from a TarInfo object. For information on the arguments see the constructor of the

TarFile class.

Changed in version 3.2: Use 'surrogateescape' as the default for the errors argument.

A TarInfo object has the following public data attributes:

TarInfo.name: str

Name of the archive member.

TarInfo.size: int

Size in bytes.

TarInfo.mtime: int | float

Time of last modification in seconds since the epoch, as in os.stat_result.st_mtime.

Changed in version 3.12: Can be set to None for extract() and extractall(), causing extraction to skip

applying this attribute.

TarInfo.mode: int

Permission bits, as for os.chmod().

Changed in version 3.12: Can be set to None for extract() and extractall(), causing extraction to skip

applying this attribute.

TarInfo.type

File type. type is usually one of these constants: REGTYPE, AREGTYPE, LNKTYPE, SYMTYPE, DIRTYPE,

FIFOTYPE, CONTTYPE, CHRTYPE, BLKTYPE, GNUTYPE_SPARSE. To determine the type of a TarInfo object

more conveniently, use the is*() methods below.

TarInfo.linkname: str

Name of the target file name, which is only present in TarInfo objects of type LNKTYPE and SYMTYPE.

For symbolic links (SYMTYPE), the linkname is relative to the directory that contains the link. For hard links

(LNKTYPE), the linkname is relative to the root of the archive.

TarInfo.uid: int

User ID of the user who originally stored this member.

Changed in version 3.12: Can be set to None for extract() and extractall(), causing extraction to skip

applying this attribute.

TarInfo.gid: int

Group ID of the user who originally stored this member.

Changed in version 3.12: Can be set to None for extract() and extractall(), causing extraction to skip

applying this attribute.

TarInfo.uname: str

User name.

Changed in version 3.12: Can be set to None for extract() and extractall(), causing extraction to skip

applying this attribute.



The Python Library Reference, Release 3.13.2



TarInfo.gname: str

Group name.

Changed in version 3.12: Can be set to None for extract() and extractall(), causing extraction to skip

applying this attribute.

TarInfo.chksum: int

Header checksum.

TarInfo.devmajor: int

Device major number.

TarInfo.devminor: int

Device minor number.

TarInfo.offset: int

The tar header starts here.

TarInfo.offset_data: int

The file’s data starts here.

TarInfo.sparse

Sparse member information.

TarInfo.pax_headers: dict

A dictionary containing key-value pairs of an associated pax extended header.

TarInfo.replace(name=..., mtime=..., mode=..., linkname=..., uid=..., gid=..., uname=..., gname=...,

deep=True)

Added in version 3.12.

Return a new copy of the TarInfo object with the given attributes changed. For example, to return a TarInfo

with the group name set to 'staff', use:

new_tarinfo = old_tarinfo.replace(gname='staff')



By default, a deep copy is made. If deep is false, the copy is shallow, i.e. pax_headers and any custom

attributes are shared with the original TarInfo object.

A TarInfo object also provides some convenient query methods:

TarInfo.isfile()

Return True if the TarInfo object is a regular file.

TarInfo.isreg()

Same as isfile().

TarInfo.isdir()

Return True if it is a directory.

TarInfo.issym()

Return True if it is a symbolic link.

TarInfo.islnk()

Return True if it is a hard link.

TarInfo.ischr()

Return True if it is a character device.

TarInfo.isblk()

Return True if it is a block device.

TarInfo.isfifo()

Return True if it is a FIFO.

The Python Library Reference, Release 3.13.2



TarInfo.isdev()

Return True if it is one of character device, block device or FIFO.



13.6.3 Extraction filters

Added in version 3.12.

The tar format is designed to capture all details of a UNIX-like filesystem, which makes it very powerful. Unfor-tunately, the features make it easy to create tar files that have unintended – and possibly malicious – effects when extracted. For example, extracting a tar file can overwrite arbitrary files in various ways (e.g. by using absolute paths, .. path components, or symlinks that affect later members).

In most cases, the full functionality is not needed. Therefore, tarfile supports extraction filters: a mechanism to limit functionality, and thus mitigate some of the security issues.



µ See also

PEP 706

Contains further motivation and rationale behind the design.



The filter argument to TarFile.extract() or extractall() can be:

• the string 'fully_trusted': Honor all metadata as specified in the archive. Should be used if the user trusts

the archive completely, or implements their own complex verification.

• the string 'tar': Honor most tar-specific features (i.e. features of UNIX-like filesystems), but block features

that are very likely to be surprising or malicious. See tar_filter() for details.

• the string 'data': Ignore or block most features specific to UNIX-like filesystems. Intended for extracting

cross-platform data archives. See data_filter() for details.

• None (default): Use TarFile.extraction_filter.

If that is also None (the default), raise a DeprecationWarning, and fall back to the 'fully_trusted'

filter, whose dangerous behavior matches previous versions of Python.

In Python 3.14, the 'data' filter will become the default instead. It’s possible to switch earlier; see TarFile.

extraction_filter .

• A callable which will be called for each extracted member with a TarInfo describing the member and the

destination path to where the archive is extracted (i.e. the same path is used for all members):

filter(member: TarInfo, path: str, /)-> TarInfo | None



The callable is called just before each member is extracted, so it can take the current state of the disk into

account. It can:

– return a TarInfo object which will be used instead of the metadata in the archive, or

– return None, in which case the member will be skipped, or

– raise an exception to abort the operation or skip the member, depending on errorlevel. Note that when

extraction is aborted, extractall() may leave the archive partially extracted. It does not attempt to clean up.



Default named filters

The pre-defined, named filters are available as functions, so they can be reused in custom filters:

tarfile.fully_trusted_filter(member, path)

Return member unchanged.

This implements the 'fully_trusted' filter.

The Python Library Reference, Release 3.13.2



tarfile.tar_filter(member, path)

Implements the 'tar' filter.

• Strip leading slashes (/ and os.sep) from filenames.

• Refuse to extract files with absolute paths (in case the name is absolute even after stripping slashes, e.g.

C:/foo on Windows). This raises AbsolutePathError.

• Refuse to extract files whose absolute path (after following symlinks) would end up outside the destination.

This raises OutsideDestinationError.

• Clear high mode bits (setuid, setgid, sticky) and group/other write bits (S_IWGRP | S_IWOTH).

Return the modified TarInfo member.

tarfile.data_filter(member, path)

Implements the 'data' filter. In addition to what tar_filter does:

• Refuse to extract links (hard or soft) that link to absolute paths, or ones that link outside the destination.

This raises AbsoluteLinkError or LinkOutsideDestinationError.

Note that such files are refused even on platforms that do not support symbolic links.

• Refuse to extract device files (including pipes). This raises SpecialFileError.

• For regular files, including hard links:

– Set the owner read and write permissions (S_IRUSR | S_IWUSR).

– Remove the group & other executable permission (S_IXGRP | S_IXOTH) if the owner doesn’t have

it (S_IXUSR).

• For other files (directories), set mode to None, so that extraction methods skip applying permission bits.

• Set user and group info (uid, gid, uname, gname) to None, so that extraction methods skip setting it.

Return the modified TarInfo member.



Filter errors

When a filter refuses to extract a file, it will raise an appropriate exception, a subclass of FilterError. This will

abort the extraction if TarFile.errorlevel is 1 or more. With errorlevel=0 the error will be logged and the member will be skipped, but extraction will continue.



Hints for further verification

Even with filter='data', tarfile is not suited for extracting untrusted files without prior inspection. Among other issues, the pre-defined filters do not prevent denial-of-service attacks. Users should do additional checks.

Here is an incomplete list of things to consider:

• Extract to a new temporary directory to prevent e.g. exploiting pre-existing links, and to make it easier

to clean up after a failed extraction.

• When working with untrusted data, use external (e.g. OS-level) limits on disk, memory and CPU usage.

• Check filenames against an allow-list of characters (to filter out control characters, confusables, foreign path

separators, etc.).

• Check that filenames have expected extensions (discouraging files that execute when you “click on them”, or

extension-less files like Windows special device names).

• Limit the number of extracted files, total size of extracted data, filename length (including symlink length),

and size of individual files.

• Check for files that would be shadowed on case-insensitive filesystems.

Also note that:

The Python Library Reference, Release 3.13.2



• Tar files may contain multiple versions of the same file. Later ones are expected to overwrite any earlier ones.

This feature is crucial to allow updating tape archives, but can be abused maliciously.

• tarfile does not protect against issues with “live” data, e.g. an attacker tinkering with the destination (or source)

directory while extraction (or archiving) is in progress.



Supporting older Python versions

Extraction filters were added to Python 3.12, but may be backported to older versions as security updates. To check whether the feature is available, use e.g. hasattr(tarfile, 'data_filter') rather than checking the Python version.

The following examples show how to support Python versions with and without the feature. Note that setting extraction_filter will affect any subsequent operations.

• Fully trusted archive:

my_tarfile.extraction_filter = (lambda member, path: member)

my_tarfile.extractall()



• Use the 'data' filter if available, but revert to Python 3.11 behavior ('fully_trusted') if this feature is

not available:

my_tarfile.extraction_filter = getattr(tarfile, 'data_filter',

(lambda member, path: member))

my_tarfile.extractall()



• Use the 'data' filter; fail if it is not available:

my_tarfile.extractall(filter=tarfile.data_filter)



or:

my_tarfile.extraction_filter = tarfile.data_filter

my_tarfile.extractall()



• Use the 'data' filter; warn if it is not available:

if hasattr(tarfile, 'data_filter'):

my_tarfile.extractall(filter='data')

else:

# remove this when no longer needed

warn_the_user('Extracting may be unsafe; consider updating Python') my_tarfile.extractall()



Stateful extraction filter example

While tarfile’s extraction methods take a simple filter callable, custom filters may be more complex objects with an internal state. It may be useful to write these as context managers, to be used like this:

with StatefulFilter() as filter_func:

tar.extractall(path, filter=filter_func)



Such a filter can be written as, for example:

class StatefulFilter:

def __init__(self):

self.file_count = 0

def __enter__(self):

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

return self

def __call__(self, member, path):

self.file_count += 1

return member

def __exit__(self, *exc_info):

print(f'{self.file_count} files extracted')



13.6.4 Command-Line Interface

Added in version 3.4.

The tarfile module provides a simple command-line interface to interact with tar archives.

If you want to create a new tar archive, specify its name after the-c option and then list the filename(s) that should be included:

$ python -m tarfile -c monty.tar spam.txt eggs.txt



Passing a directory is also acceptable:

$ python -m tarfile -c monty.tar life-of-brian_1979/



If you want to extract a tar archive into the current directory, use the-e option:

$ python -m tarfile -e monty.tar



You can also extract a tar archive into a different directory by passing the directory’s name:

$ python -m tarfile -e monty.tar other-dir/



For a list of the files in a tar archive, use the-l option:

$ python -m tarfile -l monty.tar



Command-line options

-l

--list

List files in a tarfile.

-c ...

--create ...

Create tarfile from source files.

-e []

--extract []

Extract tarfile into the current directory if output_dir is not specified.

-t

--test

Test whether the tarfile is valid or not.

-v,--verbose

Verbose output.

The Python Library Reference, Release 3.13.2



--filter

Specifies the filter for--extract. See Extraction filters for details. Only string names are accepted (that is,

fully_trusted, tar, and data).



13.6.5 Examples

How to extract an entire tar archive to the current working directory:

import tarfile

tar = tarfile.open("sample.tar.gz")

tar.extractall(filter='data')

tar.close()



How to extract a subset of a tar archive with TarFile.extractall() using a generator function instead of a list:

import os

import tarfile

def py_files(members):

for tarinfo in members:

if os.path.splitext(tarinfo.name)[1] == ".py":

yield tarinfo

tar = tarfile.open("sample.tar.gz")

tar.extractall(members=py_files(tar))

tar.close()



How to create an uncompressed tar archive from a list of filenames:

import tarfile

tar = tarfile.open("sample.tar", "w")

for name in ["foo", "bar", "quux"]:

tar.add(name)

tar.close()



The same example using the with statement:

import tarfile

with tarfile.open("sample.tar", "w") as tar:

for name in ["foo", "bar", "quux"]:

tar.add(name)



How to read a gzip compressed tar archive and display some member information:

import tarfile

tar = tarfile.open("sample.tar.gz", "r:gz")

for tarinfo in tar:

print(tarinfo.name, "is", tarinfo.size, "bytes in size and is ", end="")

if tarinfo.isreg():

print("a regular file.")

elif tarinfo.isdir():

print("a directory.")

else:

print("something else.")

tar.close()



How to create an archive and reset the user information using the filter parameter in TarFile.add():

The Python Library Reference, Release 3.13.2



import tarfile

def reset(tarinfo):

tarinfo.uid = tarinfo.gid = 0

tarinfo.uname = tarinfo.gname = "root"

return tarinfo

tar = tarfile.open("sample.tar.gz", "w:gz")

tar.add("foo", filter=reset)

tar.close()



13.6.6 Supported tar formats

There are three tar formats that can be created with the tarfile module:

• The POSIX.1-1988 ustar format (USTAR_FORMAT). It supports filenames up to a length of at best 256 char-

acters and linknames up to 100 characters. The maximum file size is 8 GiB. This is an old and limited but

widely supported format.

• The GNU tar format (GNU_FORMAT). It supports long filenames and linknames, files bigger than 8 GiB and

sparse files. It is the de facto standard on GNU/Linux systems. tarfile fully supports the GNU tar extensions

for long names, sparse file support is read-only.

• The POSIX.1-2001 pax format (PAX_FORMAT). It is the most flexible format with virtually no limits. It sup-

ports long filenames and linknames, large files and stores pathnames in a portable way. Modern tar imple-

mentations, including GNU tar, bsdtar/libarchive and star, fully support extended pax features; some old or

unmaintained libraries may not, but should treat pax archives as if they were in the universally supported ustar

format. It is the current default format for new archives.

It extends the existing ustar format with extra headers for information that cannot be stored otherwise. There

are two flavours of pax headers: Extended headers only affect the subsequent file header, global headers are

valid for the complete archive and affect all following files. All the data in a pax header is encoded in UTF-8

for portability reasons.

There are some more variants of the tar format which can be read, but not created:

• The ancient V7 format. This is the first tar format from Unix Seventh Edition, storing only regular files and

directories. Names must not be longer than 100 characters, there is no user/group name information. Some

archives have miscalculated header checksums in case of fields with non-ASCII characters.

• The SunOS tar extended format. This format is a variant of the POSIX.1-2001 pax format, but is not compat-

ible.



13.6.7 Unicode issues

The tar format was originally conceived to make backups on tape drives with the main focus on preserving file system information. Nowadays tar archives are commonly used for file distribution and exchanging archives over networks. One problem of the original format (which is the basis of all other formats) is that there is no concept of supporting different character encodings. For example, an ordinary tar archive created on a UTF-8 system cannot be read correctly on a Latin-1 system if it contains non-ASCII characters. Textual metadata (like filenames, linknames, user/group names) will appear damaged. Unfortunately, there is no way to autodetect the encoding of an archive. The pax format was designed to solve this problem. It stores non-ASCII metadata using the universal character encoding UTF-8.

The details of character conversion in tarfile are controlled by the encoding and errors keyword arguments of the

TarFile class.

encoding defines the character encoding to use for the metadata in the archive. The default value is sys.

getfilesystemencoding() or 'ascii' as a fallback. Depending on whether the archive is read or written, the metadata must be either decoded or encoded. If encoding is not set appropriately, this conversion may fail.

The errors argument defines how characters are treated that cannot be converted. Possible values are listed in section

Error Handlers. The default scheme is 'surrogateescape' which Python also uses for its file system calls, see

File Names, Command Line Arguments, and Environment Variables.

The Python Library Reference, Release 3.13.2



For PAX_FORMAT archives (the default), encoding is generally not needed because all the metadata is stored using UTF-8. encoding is only used in the rare cases when binary pax headers are decoded or when strings with surrogate characters are stored.



The Python Library Reference, Release 3.13.2





CHAPTER




FOURTEEN



FILE FORMATS



The modules described in this chapter parse various miscellaneous file formats that aren’t markup languages and are not related to e-mail.



14.1 csv — CSV File Reading and Writing

Source code: Lib/csv.py



The so-called CSV (Comma Separated Values) format is the most common import and export format for spreadsheets and databases. CSV format was used for many years prior to attempts to describe the format in a standardized way

in RFC 4180. The lack of a well-defined standard means that subtle differences often exist in the data produced and consumed by different applications. These differences can make it annoying to process CSV files from multiple sources. Still, while the delimiters and quoting characters vary, the overall format is similar enough that it is possible to write a single module which can efficiently manipulate such data, hiding the details of reading and writing the data from the programmer.

The csv module implements classes to read and write tabular data in CSV format. It allows programmers to say, “write this data in the format preferred by Excel,” or “read data from this file which was generated by Excel,” without knowing the precise details of the CSV format used by Excel. Programmers can also describe the CSV formats understood by other applications or define their own special-purpose CSV formats.

The csv module’s reader and writer objects read and write sequences. Programmers can also read and write data

in dictionary form using the DictReader and DictWriter classes.



µ See also

PEP 305- CSV File API

The Python Enhancement Proposal which proposed this addition to Python.



14.1.1 Module Contents

The csv module defines the following functions:

csv.reader(csvfile, dialect=’excel’, **fmtparams)

Return a reader object that will process lines from the given csvfile. A csvfile must be an iterable of strings, each

in the reader’s defined csv format. A csvfile is most commonly a file-like object or list. If csvfile is a file object,

it should be opened with 1 newline='' . An optional dialect parameter can be given which is used to define a

set of parameters specific to a particular CSV dialect. It may be an instance of a subclass of the Dialect class

or one of the strings returned by the list_dialects() function. The other optional fmtparams keyword

arguments can be given to override individual formatting parameters in the current dialect. For full details

about the dialect and formatting parameters, see section Dialects and Formatting Parameters.

1 If newline='' is not specified, newlines embedded inside quoted fields will not be interpreted correctly, and on platforms that use \r\n

linendings on write an extra \r will be added. It should always be safe to specify newline='', since the csv module does its own (universal) newline handling.

The Python Library Reference, Release 3.13.2



Each row read from the csv file is returned as a list of strings. No automatic data type conversion is performed

unless the QUOTE_NONNUMERIC format option is specified (in which case unquoted fields are transformed into

floats).

A short usage example:

>>> import csv

>>> with open('eggs.csv', newline='') as csvfile:

... spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')

... for row in spamreader:

... print(', '.join(row))

Spam, Spam, Spam, Spam, Spam, Baked Beans

Spam, Lovely Spam, Wonderful Spam



csv.writer(csvfile, dialect=’excel’, **fmtparams)

Return a writer object responsible for converting the user’s data into delimited strings on the given file-like

object. csvfile can be any object with a write() method. If csvfile is a file object, it should be opened with

newline=''Page 605, 1. An optional dialect parameter can be given which is used to define a set of parameters

specific to a particular CSV dialect. It may be an instance of a subclass of the Dialect class or one of the

strings returned by the list_dialects() function. The other optional fmtparams keyword arguments can

be given to override individual formatting parameters in the current dialect. For full details about dialects and

formatting parameters, see the Dialects and Formatting Parameters section. To make it as easy as possible to

interface with modules which implement the DB API, the value None is written as the empty string. While

this isn’t a reversible transformation, it makes it easier to dump SQL NULL data values to CSV files without

preprocessing the data returned from a cursor.fetch* call. All other non-string data are stringified with

str() before being written.

A short usage example:

import csv

with open('eggs.csv', 'w', newline='') as csvfile:

spamwriter = csv.writer(csvfile, delimiter=' ',

quotechar='|', quoting=csv.QUOTE_MINIMAL)

spamwriter.writerow(['Spam'] * 5 + ['Baked Beans'])

spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam'])



csv.register_dialect(name[, dialect[, **fmtparams ]])

Associate dialect with name. name must be a string. The dialect can be specified either by passing a sub-class

of Dialect, or by fmtparams keyword arguments, or both, with keyword arguments overriding parameters

of the dialect. For full details about dialects and formatting parameters, see section Dialects and Formatting

Parameters.

csv.unregister_dialect(name)

Delete the dialect associated with name from the dialect registry. An Error is raised if name is not a registered

dialect name.

csv.get_dialect(name)

Return the dialect associated with name. An Error is raised if name is not a registered dialect name. This

function returns an immutable Dialect.

csv.list_dialects()

Return the names of all registered dialects.

csv.field_size_limit( new_limit [ ])

Returns the current maximum field size allowed by the parser. If new_limit is given, this becomes the new

limit.

The csv module defines the following classes:



The Python Library Reference, Release 3.13.2



class csv.DictReader(f , fieldnames=None, restkey=None, restval=None, dialect=’excel’, *args, **kwds)

Create an object that operates like a regular reader but maps the information in each row to a dict whose keys

are given by the optional fieldnames parameter.

The fieldnames parameter is a sequence. If fieldnames is omitted, the values in the first row of file f will be

used as the fieldnames and will be omitted from the results. If fieldnames is provided, they will be used and

the first row will be included in the results. Regardless of how the fieldnames are determined, the dictionary

preserves their original ordering.

If a row has more fields than fieldnames, the remaining data is put in a list and stored with the fieldname

specified by restkey (which defaults to None). If a non-blank row has fewer fields than fieldnames, the missing

values are filled-in with the value of restval (which defaults to None).

All other optional or keyword arguments are passed to the underlying reader instance.

If the argument passed to fieldnames is an iterator, it will be coerced to a list.

Changed in version 3.6: Returned rows are now of type OrderedDict.

Changed in version 3.8: Returned rows are now of type dict.

A short usage example:

>>> import csv

>>> with open('names.csv', newline='') as csvfile:

... reader = csv.DictReader(csvfile)

... for row in reader:

... print(row['first_name'], row['last_name'])

...

Eric Idle

John Cleese

>>> print(row)

{'first_name': 'John', 'last_name': 'Cleese'}



class csv.DictWriter(f , fieldnames, restval=”, extrasaction=’raise’, dialect=’excel’, *args, **kwds)

Create an object which operates like a regular writer but maps dictionaries onto output rows. The field-

names parameter is a sequence of keys that identify the order in which values in the dictionary passed to the

writerow() method are written to file f. The optional restval parameter specifies the value to be written if

the dictionary is missing a key in fieldnames. If the dictionary passed to the writerow() method contains

a key not found in fieldnames, the optional extrasaction parameter indicates what action to take. If it is set to

'raise' , the default value, a ValueError is raised. If it is set to 'ignore', extra values in the dictionary

are ignored. Any other optional or keyword arguments are passed to the underlying writer instance.

Note that unlike the DictReader class, the fieldnames parameter of the DictWriter class is not optional.

If the argument passed to fieldnames is an iterator, it will be coerced to a list.

A short usage example:

import csv

with open('names.csv', 'w', newline='') as csvfile:

fieldnames = ['first_name', 'last_name']

writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

writer.writeheader()

writer.writerow({'first_name': 'Baked', 'last_name': 'Beans'}) writer.writerow({'first_name': 'Lovely', 'last_name': 'Spam'}) writer.writerow({'first_name': 'Wonderful', 'last_name': 'Spam'})



class csv.Dialect

The Dialect class is a container class whose attributes contain information for how to handle doublequotes, The Python Library Reference, Release 3.13.2



whitespace, delimiters, etc. Due to the lack of a strict CSV specification, different applications produce subtly

different CSV data. Dialect instances define how reader and writer instances behave.

All available Dialect names are returned by list_dialects(), and they can be registered with specific

reader and writer classes through their initializer (__init__) functions like this:

import csv

with open('students.csv', 'w', newline='') as csvfile:

writer = csv.writer(csvfile, dialect='unix')



class csv.excel

The excel class defines the usual properties of an Excel-generated CSV file. It is registered with the dialect

name 'excel'.

class csv.excel_tab

The excel_tab class defines the usual properties of an Excel-generated TAB-delimited file. It is registered

with the dialect name 'excel-tab'.

class csv.unix_dialect

The unix_dialect class defines the usual properties of a CSV file generated on UNIX systems, i.e. using

'\n' as line terminator and quoting all fields. It is registered with the dialect name 'unix'.

Added in version 3.2.

class csv.Sniffer

The Sniffer class is used to deduce the format of a CSV file.

The Sniffer class provides two methods:

sniff(sample, delimiters=None)

Analyze the given sample and return a Dialect subclass reflecting the parameters found. If the optional delimiters parameter is given, it is interpreted as a string containing possible valid delimiter characters.

has_header(sample)

Analyze the sample text (presumed to be in CSV format) and return True if the first row appears to be a series of column headers. Inspecting each column, one of two key criteria will be considered to estimate if the sample contains a header:

• the second through n-th rows contain numeric values

• the second through n-th rows contain strings where at least one value’s length differs from that of the

putative header of that column.

Twenty rows after the first row are sampled; if more than half of columns + rows meet the criteria, True is returned.



® Note

This method is a rough heuristic and may produce both false positives and negatives.



An example for Sniffer use:

with open('example.csv', newline='') as csvfile:

dialect = csv.Sniffer().sniff(csvfile.read(1024))

csvfile.seek(0)

reader = csv.reader(csvfile, dialect)

# ... process CSV file contents here ...



The csv module defines the following constants:

The Python Library Reference, Release 3.13.2



csv.QUOTE_ALL

Instructs writer objects to quote all fields.

csv.QUOTE_MINIMAL

Instructs writer objects to only quote those fields which contain special characters such as delimiter, quotechar

or any of the characters in lineterminator.

csv.QUOTE_NONNUMERIC

Instructs writer objects to quote all non-numeric fields.

Instructs reader objects to convert all non-quoted fields to type float.

csv.QUOTE_NONE

Instructs writer objects to never quote fields. When the current delimiter occurs in output data it is preceded

by the current escapechar character. If escapechar is not set, the writer will raise Error if any characters that

require escaping are encountered.

Instructs reader objects to perform no special processing of quote characters.

csv.QUOTE_NOTNULL

Instructs writer objects to quote all fields which are not None. This is similar to QUOTE_ALL, except that if

a field value is None an empty (unquoted) string is written.

Instructs reader objects to interpret an empty (unquoted) field as None and to otherwise behave as

QUOTE_ALL.

Added in version 3.12.

csv.QUOTE_STRINGS

Instructs writer objects to always place quotes around fields which are strings. This is similar to

QUOTE_NONNUMERIC , except that if a field value is None an empty (unquoted) string is written.

Instructs reader objects to interpret an empty (unquoted) string as None and to otherwise behave as

QUOTE_NONNUMERIC .

Added in version 3.12.

The csv module defines the following exception:

exception csv.Error

Raised by any of the functions when an error is detected.



14.1.2 Dialects and Formatting Parameters

To make it easier to specify the format of input and output records, specific formatting parameters are grouped

together into dialects. A dialect is a subclass of the Dialect class containing various attributes describing the

format of the CSV file. When creating reader or writer objects, the programmer can specify a string or a subclass

of the Dialect class as the dialect parameter. In addition to, or instead of, the dialect parameter, the programmer can also specify individual formatting parameters, which have the same names as the attributes defined below for the

Dialect class.

Dialects support the following attributes:

Dialect.delimiter

A one-character string used to separate fields. It defaults to ','.

Dialect.doublequote

Controls how instances of quotechar appearing inside a field should themselves be quoted. When True, the

character is doubled. When False, the escapechar is used as a prefix to the quotechar. It defaults to True.

On output, if doublequote is False and no escapechar is set, Error is raised if a quotechar is found in a field.



The Python Library Reference, Release 3.13.2



Dialect.escapechar

A one-character string used by the writer to escape the delimiter if quoting is set to QUOTE_NONE and the

quotechar if doublequote is False. On reading, the escapechar removes any special meaning from the follow-

ing character. It defaults to None, which disables escaping.

Changed in version 3.11: An empty escapechar is not allowed.

Dialect.lineterminator

The string used to terminate lines produced by the writer. It defaults to '\r\n'.



® Note

The reader is hard-coded to recognise either '\r' or '\n' as end-of-line, and ignores lineterminator. This behavior may change in the future.



Dialect.quotechar

A one-character string used to quote fields containing special characters, such as the delimiter or quotechar, or

which contain new-line characters. It defaults to '"'.

Changed in version 3.11: An empty quotechar is not allowed.

Dialect.quoting

Controls when quotes should be generated by the writer and recognised by the reader. It can take on any of

the QUOTE_* constants and defaults to QUOTE_MINIMAL.

Dialect.skipinitialspace

When True, spaces immediately following the delimiter are ignored. The default is False.

Dialect.strict

When True, raise exception Error on bad CSV input. The default is False.



14.1.3 Reader Objects

Reader objects (DictReader instances and objects returned by the reader() function) have the following public methods:

csvreader.__next__()

Return the next row of the reader’s iterable object as a list (if the object was returned from reader()) or a

dict (if it is a DictReader instance), parsed according to the current Dialect. Usually you should call this

as next(reader).

Reader objects have the following public attributes:

csvreader.dialect

A read-only description of the dialect in use by the parser.

csvreader.line_num

The number of lines read from the source iterator. This is not the same as the number of records returned, as

records can span multiple lines.

DictReader objects have the following public attribute:

DictReader.fieldnames

If not passed as a parameter when creating the object, this attribute is initialized upon first access or when the

first record is read from the file.



14.1.4 Writer Objects

writer objects (DictWriter instances and objects returned by the writer() function) have the following public

methods. A row must be an iterable of strings or numbers for writer objects and a dictionary mapping fieldnames to

strings or numbers (by passing them through str() first) for DictWriter objects. Note that complex numbers are

The Python Library Reference, Release 3.13.2



written out surrounded by parens. This may cause some problems for other programs which read CSV files (assuming they support complex numbers at all).

csvwriter.writerow(row)

Write the row parameter to the writer’s file object, formatted according to the current Dialect. Return the

return value of the call to the write method of the underlying file object.

Changed in version 3.5: Added support of arbitrary iterables.

csvwriter.writerows(rows)

Write all elements in rows (an iterable of row objects as described above) to the writer’s file object, formatted

according to the current dialect.

Writer objects have the following public attribute:

csvwriter.dialect

A read-only description of the dialect in use by the writer.

DictWriter objects have the following public method:

DictWriter.writeheader()

Write a row with the field names (as specified in the constructor) to the writer’s file object, formatted according

to the current dialect. Return the return value of the csvwriter.writerow() call used internally.

Added in version 3.2.

Changed in version 3.8: writeheader() now also returns the value returned by the csvwriter.

writerow() method it uses internally.



14.1.5 Examples

The simplest example of reading a CSV file:

import csv

with open('some.csv', newline='') as f:

reader = csv.reader(f)

for row in reader:

print(row)



Reading a file with an alternate format:

import csv

with open('passwd', newline='') as f:

reader = csv.reader(f, delimiter=':', quoting=csv.QUOTE_NONE)

for row in reader:

print(row)



The corresponding simplest possible writing example is:

import csv

with open('some.csv', 'w', newline='') as f:

writer = csv.writer(f)

writer.writerows(someiterable)



Since open() is used to open a CSV file for reading, the file will by default be decoded into unicode using the system

default encoding (see locale.getencoding()). To decode a file using a different encoding, use the encoding argument of open:

import csv

with open('some.csv', newline='', encoding='utf-8') as f:

reader = csv.reader(f)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

for row in reader:

print(row)



The same applies to writing in something other than the system default encoding: specify the encoding argument when opening the output file.

Registering a new dialect:

import csv

csv.register_dialect('unixpwd', delimiter=':', quoting=csv.QUOTE_NONE) with open('passwd', newline='') as f:

reader = csv.reader(f, 'unixpwd')



A slightly more advanced use of the reader — catching and reporting errors:

import csv, sys

filename = 'some.csv'

with open(filename, newline='') as f:

reader = csv.reader(f)

try:

for row in reader:

print(row)

except csv.Error as e:

sys.exit('file {}, line {}: {}'.format(filename, reader.line_num, e))



And while the module doesn’t directly support parsing strings, it can easily be done:

import csv

for row in csv.reader(['one,two,three']):

print(row)



14.2 configparser — Configuration file parser

Source code: Lib/configparser.py



This module provides the ConfigParser class which implements a basic configuration language which provides a structure similar to what’s found in Microsoft Windows INI files. You can use this to write Python programs which can be customized by end users easily.



® Note

This library does not interpret or write the value-type prefixes used in the Windows Registry extended version of

INI syntax.



µ See also

Module tomllib

TOML is a well-specified format for application configuration files. It is specifically designed to be an improved version of INI.

Module shlex

Support for creating Unix shell-like mini-languages which can also be used for application configuration files.

The Python Library Reference, Release 3.13.2



Module json

The json module implements a subset of JavaScript syntax which is sometimes used for configuration, but does not support comments.



14.2.1 Quick Start

Let’s take a very basic configuration file that looks like this:

[DEFAULT]

ServerAliveInterval = 45

Compression = yes

CompressionLevel = 9

ForwardX11 = yes

[forge.example]

User = hg

[topsecret.server.example]

Port = 50022

ForwardX11 = no



The structure of INI files is described in the following section. Essentially, the file consists of sections, each of which

contains keys with values. configparser classes can read and write such files. Let’s start by creating the above configuration file programmatically.

>>> import configparser

>>> config = configparser.ConfigParser()

>>> config['DEFAULT'] = {'ServerAliveInterval': '45',

... 'Compression': 'yes',

... 'CompressionLevel': '9'}

>>> config['forge.example'] = {}

>>> config['forge.example']['User'] = 'hg'

>>> config['topsecret.server.example'] = {}

>>> topsecret = config['topsecret.server.example']

>>> topsecret['Port'] = '50022' # mutates the parser

>>> topsecret['ForwardX11'] = 'no' # same here

>>> config['DEFAULT']['ForwardX11'] = 'yes'

>>> with open('example.ini', 'w') as configfile:

... config.write(configfile)

...



As you can see, we can treat a config parser much like a dictionary. There are differences, outlined later, but the behavior is very close to what you would expect from a dictionary.

Now that we have created and saved a configuration file, let’s read it back and explore the data it holds.

>>> config = configparser.ConfigParser()

>>> config.sections()

[]

>>> config.read('example.ini')

['example.ini']

>>> config.sections()

['forge.example', 'topsecret.server.example']

>>> 'forge.example' in config

True

>>> 'python.org' in config

False

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> config['forge.example']['User']

'hg'

>>> config['DEFAULT']['Compression']

'yes'

>>> topsecret = config['topsecret.server.example']

>>> topsecret['ForwardX11']

'no'

>>> topsecret['Port']

'50022'

>>> for key in config['forge.example']:

... print(key)

user

compressionlevel

serveraliveinterval

compression

forwardx11

>>> config['forge.example']['ForwardX11']

'yes'



As we can see above, the API is pretty straightforward. The only bit of magic involves the DEFAULT section which

provides default values for all other sections1. Note also that keys in sections are case-insensitive and stored in

lowercase1.

It is possible to read several configurations into a single ConfigParser, where the most recently added configuration has the highest priority. Any conflicting keys are taken from the more recent configuration while the previously existing keys are retained. The example below reads in an override.ini file, which will override any conflicting keys from the example.ini file.

[DEFAULT]

ServerAliveInterval =-1



>>> config_override = configparser.ConfigParser()

>>> config_override['DEFAULT'] = {'ServerAliveInterval': '-1'} >>> with open('override.ini', 'w') as configfile:

... config_override.write(configfile)

...

>>> config_override = configparser.ConfigParser()

>>> config_override.read(['example.ini', 'override.ini']) ['example.ini', 'override.ini']

>>> print(config_override.get('DEFAULT', 'ServerAliveInterval'))-1



This behaviour is equivalent to a ConfigParser.read() call with several files passed to the filenames parameter.



14.2.2 Supported Datatypes

Config parsers do not guess datatypes of values in configuration files, always storing them internally as strings. This means that if you need other datatypes, you should convert on your own:

>>> int(topsecret['Port'])

50022

>>> float(topsecret['CompressionLevel'])

9.0



Since this task is so common, config parsers provide a range of handy getter methods to handle integers, floats and booleans. The last one is the most interesting because simply passing the value to bool() would do no

1 Config parsers allow for heavy customization. If you are interested in changing the behaviour outlined by the footnote reference, consult the

Customizing Parser Behaviour section.

The Python Library Reference, Release 3.13.2



good since bool('False') is still True. This is why config parsers also provide getboolean(). This method is case-insensitive and recognizes Boolean values from 'yes'/'no', 'on'/'off', 'true'/'false' and

'1' Page 614, 1 / '0'. For example:

>>> topsecret.getboolean('ForwardX11')

False

>>> config['forge.example'].getboolean('ForwardX11') True

>>> config.getboolean('forge.example', 'Compression') True



Apart from getboolean(), config parsers also provide equivalent getint() and getfloat() methods. You can

register your own converters and customize the provided ones.Page 614, 1



14.2.3 Fallback Values

As with a dictionary, you can use a section’s get() method to provide fallback values:

>>> topsecret.get('Port')

'50022'

>>> topsecret.get('CompressionLevel')

'9'

>>> topsecret.get('Cipher')

>>> topsecret.get('Cipher', '3des-cbc')

'3des-cbc'



Please note that default values have precedence over fallback values. For instance, in our example the

'CompressionLevel' key was specified only in the 'DEFAULT' section. If we try to get it from the section 'topsecret.server.example', we will always get the default, even if we specify a fallback:

>>> topsecret.get('CompressionLevel', '3')

'9'



One more thing to be aware of is that the parser-level get() method provides a custom, more complex interface, maintained for backwards compatibility. When using this method, a fallback value can be provided via the fallback keyword-only argument:

>>> config.get('forge.example', 'monster',

... fallback='No such things as monsters')

'No such things as monsters'



The same fallback argument can be used with the getint(), getfloat() and getboolean() methods, for example:

>>> 'BatchMode' in topsecret

False

>>> topsecret.getboolean('BatchMode', fallback=True) True

>>> config['DEFAULT']['BatchMode'] = 'no'

>>> topsecret.getboolean('BatchMode', fallback=True) False



14.2.4 Supported INI File Structure

A configuration file consists of sections, each led by a [section] header, followed by key/value entries separated

by a specific string ( Page 614, 1 Page 614, 1 = or : by default ). By default, section names are case sensitive but keys are not.

Leading and trailing whitespace is removed from keys and values. Values can be omitted if the parser is configured

to allow itPage 614, 1, in which case the key/value delimiter may also be left out. Values can also span multiple lines, The Python Library Reference, Release 3.13.2



as long as they are indented deeper than the first line of the value. Depending on the parser’s mode, blank lines may be treated as parts of multiline values or ignored.

By default, a valid section name can be any string that does not contain ‘\n’. To change this, see ConfigParser.

SECTCRE .

The first section name may be omitted if the parser is configured to allow an unnamed top level section with

allow_unnamed_section=True. In this case, the keys/values may be retrieved by UNNAMED_SECTION as in config[UNNAMED_SECTION].

Configuration files may include comments, prefixed by specific characters ( Page 614, 1 # and ; by default). Comments

may appear on their own on an otherwise empty line, possibly indented.Page 614, 1

For example:

[Simple Values]

key=value

spaces in keys=allowed

spaces in values=allowed as well

spaces around the delimiter = obviously

you can also use : to delimit keys from values

[All Values Are Strings]

values like this: 1000000

or this: 3.14159265359

are they treated as numbers? : no

integers, floats and booleans are held as: strings

can use the API to get converted values directly: true

[Multiline Values]

chorus: I'm a lumberjack, and I'm okay

I sleep all night and I work all day

[No Values]

key_without_value

empty string value here =

[You can use comments]

# like this

; or this

# By default only in an empty line.

# Inline comments can be harmful because they prevent users # from using the delimiting characters as parts of values. # That being said, this can be customized.

[Sections Can Be Indented]

can_values_be_as_well = True

does_that_mean_anything_special = False

purpose = formatting for readability

multiline_values = are

handled just fine as

long as they are indented

deeper than the first line

of a value

# Did I mention we can indent comments, too?



The Python Library Reference, Release 3.13.2



14.2.5 Unnamed Sections

The name of the first section (or unique) may be omitted and values retrieved by the UNNAMED_SECTION attribute.

>>> config = """

... option = value

...

... [ Section 2 ]

... another = val

... """

>>> unnamed = configparser.ConfigParser(allow_unnamed_section=True) >>> unnamed.read_string(config)

>>> unnamed.get(configparser.UNNAMED_SECTION, 'option') 'value'



14.2.6 Interpolation of values

On top of the core functionality, ConfigParser supports interpolation. This means values can be preprocessed before returning them from get() calls.

class configparser.BasicInterpolation

The default implementation used by ConfigParser. It enables values to contain format strings which refer

to other values in the same section, or values in the special default section Page 614, 1. Additional default values

can be provided on initialization.

For example:

[Paths]

home_dir: /Users

my_dir: %(home_dir)s/lumberjack

my_pictures: %(my_dir)s/Pictures

[Escape]

# use a %% to escape the % sign (% is the only character that needs to be␣

, →escaped):

gain: 80%%



In the example above, ConfigParser with interpolation set to BasicInterpolation() would resolve

%(home_dir)s to the value of home_dir (/Users in this case). %(my_dir)s in effect would resolve to

/Users/lumberjack . All interpolations are done on demand so keys used in the chain of references do not

have to be specified in any specific order in the configuration file.

With interpolation set to None, the parser would simply return %(my_dir)s/Pictures as the value of

my_pictures and %(home_dir)s/lumberjack as the value of my_dir.

class configparser.ExtendedInterpolation

An alternative handler for interpolation which implements a more advanced syntax, used for instance in zc.

buildout. Extended interpolation is using ${section:option} to denote a value from a foreign section.

Interpolation can span multiple levels. For convenience, if the section: part is omitted, interpolation defaults

to the current section (and possibly the default values from the special section).

For example, the configuration specified above with basic interpolation, would look like this with extended

interpolation:

[Paths]

home_dir: /Users

my_dir: ${home_dir}/lumberjack

my_pictures: ${my_dir}/Pictures

[Escape]

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

# use a $$ to escape the $ sign ($ is the only character that needs to be␣

, →escaped):

cost: $$80



Values from other sections can be fetched as well:

[Common]

home_dir: /Users

library_dir: /Library

system_dir: /System

macports_dir: /opt/local

[Frameworks]

Python: 3.2

path: ${Common:system_dir}/Library/Frameworks/

[Arthur]

nickname: Two Sheds

last_name: Jackson

my_dir: ${Common:home_dir}/twosheds

my_pictures: ${my_dir}/Pictures

python_dir: ${Frameworks:path}/Python/Versions/${Frameworks:Python}



14.2.7 Mapping Protocol Access

Added in version 3.2.

Mapping protocol access is a generic name for functionality that enables using custom objects as if

they were dictionaries. In case of configparser, the mapping interface implementation is using the parser['section']['option'] notation.

parser['section'] in particular returns a proxy for the section’s data in the parser. This means that the values are not copied but they are taken from the original parser on demand. What’s even more important is that when values are changed on a section proxy, they are actually mutated in the original parser.

configparser objects behave as close to actual dictionaries as possible. The mapping interface is complete and

adheres to the MutableMapping ABC. However, there are a few differences that should be taken into account:

• By default, all keys in sections are accessible in a case-insensitive mannerPage 614, 1. E.g. for option in

parser["section"] yields only optionxform’ed option key names. This means lowercased keys by de-

fault. At the same time, for a section that holds the key 'a', both expressions return True:

"a" in parser["section"]

"A" in parser["section"]



• All sections include DEFAULTSECT values as well which means that .clear() on a section may not leave the

section visibly empty. This is because default values cannot be deleted from the section (because technically

they are not there). If they are overridden in the section, deleting causes the default value to be visible again.

Trying to delete a default value causes a KeyError.

• DEFAULTSECT cannot be removed from the parser:

– trying to delete it raises ValueError,

– parser.clear() leaves it intact,

– parser.popitem() never returns it.

• parser.get(section, option, **kwargs)- the second argument is not a fallback value. Note how-

ever that the section-level get() methods are compatible both with the mapping protocol and the classic

configparser API.

The Python Library Reference, Release 3.13.2



• parser.items() is compatible with the mapping protocol (returns a list of section_name, section_proxy

pairs including the DEFAULTSECT). However, this method can also be invoked with arguments: parser.

items(section, raw, vars). The latter call returns a list of option, value pairs for a specified section,

with all interpolations expanded (unless raw=True is provided).

The mapping protocol is implemented on top of the existing legacy API so that subclasses overriding the original interface still should have mappings working as expected.



14.2.8 Customizing Parser Behaviour

There are nearly as many INI format variants as there are applications using it. configparser goes a long way to provide support for the largest sensible set of INI styles available. The default functionality is mainly dictated by historical background and it’s very likely that you will want to customize some of the features.

The most common way to change the way a specific config parser works is to use the __init__() options:

• defaults, default value: None

This option accepts a dictionary of key-value pairs which will be initially put in the DEFAULT section. This

makes for an elegant way to support concise configuration files that don’t specify values which are the same as

the documented default.

Hint: if you want to specify default values for a specific section, use read_dict() before you read the actual

file.

• dict_type, default value: dict

This option has a major impact on how the mapping protocol will behave and how the written configuration

files look. With the standard dictionary, every section is stored in the order they were added to the parser.

Same goes for options within sections.

An alternative dictionary type can be used for example to sort sections and options on write-back.

Please note: there are ways to add a set of key-value pairs in a single operation. When you use a regular

dictionary in those operations, the order of the keys will be ordered. For example:

>>> parser = configparser.ConfigParser()

>>> parser.read_dict({'section1': {'key1': 'value1',

... 'key2': 'value2',

... 'key3': 'value3'},

... 'section2': {'keyA': 'valueA',

... 'keyB': 'valueB',

... 'keyC': 'valueC'},

... 'section3': {'foo': 'x',

... 'bar': 'y',

... 'baz': 'z'}

... })

>>> parser.sections()

['section1', 'section2', 'section3']

>>> [option for option in parser['section3']]

['foo', 'bar', 'baz']



• allow_no_value, default value: False

Some configuration files are known to include settings without values, but which otherwise conform to the

syntax supported by configparser. The allow_no_value parameter to the constructor can be used to indicate

that such values should be accepted:

>>> import configparser

>>> sample_config = """

... [mysqld]

... user = mysql

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... pid-file = /var/run/mysqld/mysqld.pid

... skip-external-locking

... old_passwords = 1

... skip-bdb

... # we don't need ACID today

... skip-innodb

... """

>>> config = configparser.ConfigParser(allow_no_value=True)

>>> config.read_string(sample_config)

>>> # Settings with values are treated as before:

>>> config["mysqld"]["user"]

'mysql'

>>> # Settings without values provide None:

>>> config["mysqld"]["skip-bdb"]

>>> # Settings which aren't specified still raise an error:

>>> config["mysqld"]["does-not-exist"]

Traceback (most recent call last):

...

KeyError: 'does-not-exist'



• delimiters, default value: ('=', ':')

Delimiters are substrings that delimit keys from values within a section. The first occurrence of a delimiting

substring on a line is considered a delimiter. This means values (but not keys) can contain the delimiters.

See also the space_around_delimiters argument to ConfigParser.write().

• comment_prefixes, default value: ('#', ';')

• inline_comment_prefixes, default value: None

Comment prefixes are strings that indicate the start of a valid comment within a config file. comment_prefixes

are used only on otherwise empty lines (optionally indented) whereas inline_comment_prefixes can be used

after every valid value (e.g. section names, options and empty lines as well). By default inline comments are

disabled and '#' and ';' are used as prefixes for whole line comments.

Changed in version 3.2: In previous versions of configparser behaviour matched

comment_prefixes=('#',';') and inline_comment_prefixes=(';',).

Please note that config parsers don’t support escaping of comment prefixes so using inline_comment_prefixes

may prevent users from specifying option values with characters used as comment prefixes. When in doubt,

avoid setting inline_comment_prefixes. In any circumstances, the only way of storing comment prefix characters

at the beginning of a line in multiline values is to interpolate the prefix, for example:

>>> from configparser import ConfigParser, ExtendedInterpolation

>>> parser = ConfigParser(interpolation=ExtendedInterpolation())

>>> # the default BasicInterpolation could be used as well

>>> parser.read_string("""

... [DEFAULT]

... hash = #

...

... [hashes]

... shebang =

... ${hash}!/usr/bin/env python

... ${hash}-*- coding: utf-8 -*-

...

... extensions =

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... enabled_extension

... another_extension

... #disabled_by_comment

... yet_another_extension

...

... interpolation not necessary = if # is not at line start

... even in multiline values = line #1

... line #2

... line #3

... """)

>>> print(parser['hashes']['shebang'])

#!/usr/bin/env python

# -*- coding: utf-8 -*-

>>> print(parser['hashes']['extensions'])

enabled_extension

another_extension

yet_another_extension

>>> print(parser['hashes']['interpolation not necessary'])

if # is not at line start

>>> print(parser['hashes']['even in multiline values'])

line #1

line #2

line #3



• strict, default value: True

When set to True, the parser will not allow for any section or option duplicates while reading from a single

source (using read_file(), read_string() or read_dict()). It is recommended to use strict parsers

in new applications.

Changed in version 3.2: In previous versions of configparser behaviour matched strict=False.

• empty_lines_in_values, default value: True

In config parsers, values can span multiple lines as long as they are indented more than the key that holds them.

By default parsers also let empty lines to be parts of values. At the same time, keys can be arbitrarily indented

themselves to improve readability. In consequence, when configuration files get big and complex, it is easy for

the user to lose track of the file structure. Take for instance:

[Section]

key = multiline

value with a gotcha

this = is still a part of the multiline value of 'key'



This can be especially problematic for the user to see if she’s using a proportional font to edit the file. That is

why when your application does not need values with empty lines, you should consider disallowing them. This

will make empty lines split keys every time. In the example above, it would produce two keys, key and this.

• default_section, default value: configparser.DEFAULTSECT (that is: "DEFAULT")

The convention of allowing a special section of default values for other sections or interpolation purposes

is a powerful concept of this library, letting users create complex declarative configurations. This section is

normally called "DEFAULT" but this can be customized to point to any other valid section name. Some typical

values include: "general" or "common". The name provided is used for recognizing default sections when

reading from any source and is used when writing configuration back to a file. Its current value can be retrieved

using the parser_instance.default_section attribute and may be modified at runtime (i.e. to convert

files from one format to another).

The Python Library Reference, Release 3.13.2



• interpolation, default value: configparser.BasicInterpolation

Interpolation behaviour may be customized by providing a custom handler through the interpolation argu-

ment. None can be used to turn off interpolation completely, ExtendedInterpolation() provides a more

advanced variant inspired by zc.buildout. More on the subject in the dedicated documentation section.

RawConfigParser has a default value of None.

• converters, default value: not set

Config parsers provide option value getters that perform type conversion. By default getint(),

getfloat(), and getboolean() are implemented. Should other getters be desirable, users may de-

fine them in a subclass or pass a dictionary where each key is a name of the converter and each value

is a callable implementing said conversion. For instance, passing {'decimal': decimal.Decimal}

would add getdecimal() on both the parser object and all section proxies. In other words, it will

be possible to write both parser_instance.getdecimal('section', 'key', fallback=0) and

parser_instance['section'].getdecimal('key', 0) .

If the converter needs to access the state of the parser, it can be implemented as a method on a config parser

subclass. If the name of this method starts with get, it will be available on all section proxies, in the dict-

compatible form (see the getdecimal() example above).

More advanced customization may be achieved by overriding default values of these parser attributes. The defaults are defined on the classes, so they may be overridden by subclasses or by attribute assignment.

ConfigParser.BOOLEAN_STATES

By default when using getboolean(), config parsers consider the following values True: '1', 'yes',

'true' , 'on' and the following values False: '0', 'no', 'false', 'off'. You can override this by

specifying a custom dictionary of strings and their Boolean outcomes. For example:

>>> custom = configparser.ConfigParser()

>>> custom['section1'] = {'funky': 'nope'}

>>> custom['section1'].getboolean('funky')

Traceback (most recent call last):

...

ValueError: Not a boolean: nope

>>> custom.BOOLEAN_STATES = {'sure': True, 'nope': False}

>>> custom['section1'].getboolean('funky')

False



Other typical Boolean pairs include accept/reject or enabled/disabled.

ConfigParser.optionxform(option)

This method transforms option names on every read, get, or set operation. The default converts the name to

lowercase. This also means that when a configuration file gets written, all keys will be lowercase. Override this

method if that’s unsuitable. For example:

>>> config = """

... [Section1]

... Key = Value

...

... [Section2]

... AnotherKey = Value

... """

>>> typical = configparser.ConfigParser()

>>> typical.read_string(config)

>>> list(typical['Section1'].keys())

['key']

>>> list(typical['Section2'].keys())

['anotherkey']

>>> custom = configparser.RawConfigParser()

>>> custom.optionxform = lambda option: option

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

>>> custom.read_string(config)

>>> list(custom['Section1'].keys())

['Key']

>>> list(custom['Section2'].keys())

['AnotherKey']



® Note

The optionxform function transforms option names to a canonical form. This should be an idempotent function: if the name is already in canonical form, it should be returned unchanged.



ConfigParser.SECTCRE

A compiled regular expression used to parse section headers. The default matches [section] to the name

"section". Whitespace is considered part of the section name, thus [ larch ] will be read as a section of

name " larch ". Override this attribute if that’s unsuitable. For example:

>>> import re

>>> config = """

... [Section 1]

... option = value

...

... [ Section 2 ]

... another = val

... """

>>> typical = configparser.ConfigParser()

>>> typical.read_string(config)

>>> typical.sections()

['Section 1', ' Section 2 ']

>>> custom = configparser.ConfigParser()

>>> custom.SECTCRE = re.compile(r"\[ *(?P [^]]+?) *\]"





® Note

While ConfigParser objects also use an attribute for recognizing option lines, it’s not recommended to override it because that would interfere with constructor options allow_no_value and delimiters.





Mainly because of backwards compatibility concerns, provides also a legacy API with explicit / methods. While there are valid use cases for the methods outlined below, mapping protocol access is preferred for new projects. The legacy API is at times more advanced, low-level and downright counterintuitive.

An example of writing to a configuration file:





The Python Library Reference, Release 3.13.2





An example of reading the configuration file again:





To get interpolation, use :





The Python Library Reference, Release 3.13.2





Default values are available in both types of ConfigParsers. They are used in interpolation if an option used is not defined elsewhere.





defaults=None, dict_type=dict, allow_no_value=False, *,

delimiters=(’=’, ’:’), comment_prefixes=(’#’, ’;’),

inline_comment_prefixes=None, strict=True,

empty_lines_in_values=True,

default_section=configparser.DEFAULTSECT,

interpolation=BasicInterpolation(), converters={},

allow_unnamed_section=False

The main configuration parser. When defaults is given, it is initialized into the dictionary of intrinsic defaults.

When dict_type is given, it will be used to create the dictionary objects for the list of sections, for the options

within a section, and for the default values.

When delimiters is given, it is used as the set of substrings that divide keys from values. When comment_prefixes

is given, it will be used as the set of substrings that prefix comments in otherwise empty lines. Comments can be

indented. When inline_comment_prefixes is given, it will be used as the set of substrings that prefix comments

in non-empty lines.

When strict is (the default), the parser won’t allow for any section or option duplicates while reading from

a single source (file, string or dictionary), raising or .

When empty_lines_in_values is (default: ), each empty line marks the end of an option. Otherwise,

internal empty lines of a multiline option are kept as part of the value. When allow_no_value is (default:

), options without values are accepted; the value held for these is and they are serialized without

the trailing delimiter.

When default_section is given, it specifies the name for the special section holding default values for other

sections and interpolation purposes (normally named ). This value can be retrieved and changed

at runtime using the instance attribute. This won’t re-evaluate an already parsed config

file, but will be used when writing parsed settings to a new config file.

Interpolation behaviour may be customized by providing a custom handler through the interpolation argu-

ment. can be used to turn off interpolation completely, provides a more

advanced variant inspired by . More on the subject in the dedicated documentation section.

All option names used in interpolation will be passed through the method just like any other

option name reference. For example, using the default implementation of (which converts

option names to lower case), the values and are equivalent.

The Python Library Reference, Release 3.13.2



When converters is given, it should be a dictionary where each key represents the name of a type converter and

each value is a callable implementing the conversion from string to the desired datatype. Every converter gets

its own corresponding method on the parser object and section proxies.

When allow_unnamed_section is (default: ), the first section name can be omitted. See the “Un-

named Sections” section.

It is possible to read several configurations into a single , where the most recently added con-

figuration has the highest priority. Any conflicting keys are taken from the more recent configuration while the

previously existing keys are retained. The example below reads in an file, which will override

any conflicting keys from the file.





Changed in version 3.1: The default dict_type is .

Changed in version 3.2: allow_no_value, delimiters, comment_prefixes, strict, empty_lines_in_values, de-

fault_section and interpolation were added.

Changed in version 3.5: The converters argument was added.

Changed in version 3.7: The defaults argument is read with , providing consistent behavior

across the parser: non-string keys and values are implicitly converted to strings.

Changed in version 3.8: The default dict_type is , since it now preserves insertion order.

Changed in version 3.13: Raise a when allow_no_value is , and a

key without a value is continued with an indented line.

Changed in version 3.13: The allow_unnamed_section argument was added.



Return a dictionary containing the instance-wide defaults.



Return a list of the sections available; the default section is not included in the list.

section

Add a section named section to the instance.

is raised. If the default section name is passed, is raised.

The name of the section must be a string; if not, is raised.

Changed in version 3.2: Non-string section names raise .

section

Indicates whether the named section is present in the configuration. The default section is not acknowl-edged.

section

Return a list of options available in the specified section.

The Python Library Reference, Release 3.13.2



section, option

If the given section exists, and contains the given option, return ; otherwise return . If the

specified section is or an empty string, DEFAULT is assumed.

filenames, encoding=None

Attempt to read and parse an iterable of filenames, returning a list of filenames which were successfully parsed.

If filenames is a string, a object or a path-like object, it is treated as a single filename. If a file named in filenames cannot be opened, that file will be ignored. This is designed so that you can specify an iterable of potential configuration file locations (for example, the current directory, the user’s home directory, and some system-wide directory), and all existing configuration files in the iterable will be read.

If none of the named files exist, the instance will contain an empty dataset. An appli-cation which requires initial values to be loaded from a file should load the required file or files using

before calling for any optional files:





Changed in version 3.2: Added the encoding parameter. Previously, all files were read using the default

encoding for .

Changed in version 3.6.1: The filenames parameter accepts a path-like object.

Changed in version 3.7: The filenames parameter accepts a object.

f, source=None

Read and parse configuration data from f which must be an iterable yielding Unicode strings (for example files opened in text mode).

Optional argument source specifies the name of the file being read. If not given and f has a attribute, that is used for source; the default is .

Added in version 3.2: Replaces .

string, source=’<string>’

Parse configuration data from a string.

Optional argument source specifies a context-specific name of the string passed.

is used. This should commonly be a filesystem path or a URL.

Added in version 3.2.

dictionary, source=’<dict>’

Load configuration from any object that provides a dict-like method. Keys are section names, values are dictionaries with keys and values that should be present in the section. If the used dictionary type preserves order, sections and their keys will be added in order. Values are automatically converted to strings.

Optional argument source specifies a context-specific name of the dictionary passed. If not given, is used.

This method can be used to copy state between parsers.

Added in version 3.2.

section, option, *, raw=False, vars=None, fallback

Get an option value for the named section. If vars is provided, it must be a dictionary. The option is looked up in vars (if provided), section, and in DEFAULTSECT in that order. If the key is not found and fallback is provided, it is used as a fallback value. can be provided as a fallback value.

The Python Library Reference, Release 3.13.2



All the interpolations are expanded in the return values, unless the raw argument is true. Values for interpolation keys are looked up in the same manner as the option.

Changed in version 3.2: Arguments raw, vars and fallback are keyword only to protect users from trying to use the third argument as the fallback fallback (especially when using the mapping protocol).

section, option, *, raw=False, vars=None, fallback

A convenience method which coerces the option in the specified section to an integer. See for explanation of raw, vars and fallback.

section, option, *, raw=False, vars=None, fallback

A convenience method which coerces the option in the specified section to a floating-point number. See

for explanation of raw, vars and fallback.

section, option, *, raw=False, vars=None, fallback

A convenience method which coerces the option in the specified section to a Boolean value. Note that the accepted values for the option are , , , and , which cause this method to return , and , , , and , which cause it to return . These string values are

checked in a case-insensitive manner. Any other value will cause it to raise . See for explanation of raw, vars and fallback.

raw=False, vars=None

section, raw=False, vars=None

When section is not given, return a list of section_name, section_proxy pairs, including DEFAULTSECT.

Otherwise, return a list of name, value pairs for the options in the given section. Optional arguments have

the same meaning as for the method.

Changed in version 3.8: Items present in vars no longer appear in the result. The previous behaviour mixed actual parser options with variables provided for interpolation.

section, option, value

If the given section exists, set the given option to the specified value; otherwise raise .

option and value must be strings; if not, is raised.

fileobject, space_around_delimiters=True

Write a representation of the configuration to the specified file object, which must be opened in

text mode (accepting strings). This representation can be parsed by a future call. If space_around_delimiters is true, delimiters between keys and values are surrounded by spaces.



® Note

Comments in the original configuration file are not preserved when writing the configuration back. What is considered a comment, depends on the given values for comment_prefix and inline_comment_prefix.



section, option

Remove the specified option from the specified section.

. If the option existed to be removed, return ; otherwise return .

section

Remove the specified section from the configuration. If the section in fact existed, return . Otherwise return .

option

Transforms the option name option as found in an input file or as passed in by client code to the form that should be used in the internal structures. The default implementation returns a lower-case version of option; subclasses may override this or client code can set an attribute of this name on instances to affect this behavior.



The Python Library Reference, Release 3.13.2



You don’t need to subclass the parser to use this method, you can also set it on an instance, to a function that takes a string argument and returns a string. Setting it to , for example, would make option names case sensitive:





Note that when reading configuration files, whitespace around the option names is stripped before

is called.



A special object representing a section name used to reference the unnamed section (see Unnamed Sections).



The maximum depth for recursive interpolation for when the raw parameter is false. This is relevant

only when the default interpolation is used.





defaults=None, dict_type=dict, allow_no_value=False, *,

delimiters=(’=’, ’:’), comment_prefixes=(’#’, ’;’),

inline_comment_prefixes=None, strict=True,

empty_lines_in_values=True,

default_section=configparser.DEFAULTSECT,

interpolation=BasicInterpolation(), converters={},

allow_unnamed_section=False

Legacy variant of the . It has interpolation disabled by default and allows for non-string sec-

tion names, option names, and values via its unsafe and methods, as well as the legacy

keyword argument handling.

Changed in version 3.2: allow_no_value, delimiters, comment_prefixes, strict, empty_lines_in_values, de-

fault_section and interpolation were added.

Changed in version 3.5: The converters argument was added.

Changed in version 3.8: The default dict_type is , since it now preserves insertion order.

Changed in version 3.13: The allow_unnamed_section argument was added.



® Note

Consider using instead which checks types of the values to be stored internally. If you don’t want interpolation, you can use .



section

Add a section named section to the instance.

is raised. If the default section name is passed, is raised.

Type of section is not checked which lets users create non-string named sections. This behaviour is unsupported and may cause internal errors.

section, option, value

If the given section exists, set the given option to the specified value; otherwise raise .

While it is possible to use (or with raw parameters set to true) for internal storage of non-string values, full functionality (including interpolation and output to files) can only be achieved using string values.

This method lets users assign non-string values to keys internally. This behaviour is unsupported and will cause errors when attempting to write to a file or get it in non-raw mode. Use the mapping protocol API which does not allow such assignments to take place.

The Python Library Reference, Release 3.13.2





Base class for all other exceptions.



Exception raised when a specified section is not found.



Exception raised if is called with the name of a section that is already present or in strict

parsers when a section if found more than once in a single input file, string or dictionary.

Changed in version 3.2: Added the optional source and lineno attributes and parameters to .



Exception raised by strict parsers if a single option appears twice during reading from a single file, string or

dictionary. This catches misspellings and case sensitivity-related errors, e.g. a dictionary may have two keys

representing the same case-insensitive configuration key.



Exception raised when a specified option is not found in the specified section.



Base class for exceptions raised when problems occur performing string interpolation.



Exception raised when string interpolation cannot be completed because the number of iterations exceeds

. Subclass of .



Exception raised when an option referenced from a value does not exist. Subclass of .



Exception raised when the source text into which substitutions are made does not conform to the required

syntax. Subclass of .



Exception raised when attempting to parse a file which has no section headers.



Exception raised when errors occur attempting to parse a file.

Changed in version 3.12: The attribute and constructor argument were removed.

They have been available using the name since 3.2.



Exception raised when a key without a corresponding value is continued with an indented line.

Added in version 3.13.





Added in version 3.11.

Source code: Lib/tomllib



This module provides an interface for parsing TOML 1.0.0 (Tom’s Obvious Minimal Language, https://toml.io). This module does not support writing TOML.



The Python Library Reference, Release 3.13.2



µ See also

The Tomli-W package is a TOML writer that can be used in conjunction with this module, providing a write API

familiar to users of the standard library and modules.



µ See also

The TOML Kit package is a style-preserving TOML library with both read and write capability. It is a recom-

mended replacement for this module for editing already existing TOML files.



This module defines the following functions:

fp, / , *, parse_float=float

Read a TOML file. The first argument should be a readable and binary file object. Return a . Convert

TOML types to Python using this conversion table.

parse_float will be called with the string of every TOML float to be decoded. By default, this is equivalent

to . This can be used to use another datatype or parser for TOML floats (e.g.

). The callable must not return a or a , else a is raised.

A will be raised on an invalid TOML document.

s, / , *, parse_float=float

Load TOML from a object. Return a . Convert TOML types to Python using this conversion table.

The parse_float argument has the same meaning as in .

A will be raised on an invalid TOML document.

The following exceptions are available:



Subclass of .





Parsing a TOML file:





Parsing a TOML string:





The Python Library Reference, Release 3.13.2





TOML Python

TOML document dict

string str

integer int

float float (configurable with parse_float)

boolean bool

offset date-time datetime.datetime ( attribute set to an instance of )

local date-time datetime.datetime ( attribute set to )

local date datetime.date

local time datetime.time

array list

table dict

inline table dict

array of tables list of dicts





Source code: Lib/netrc.py



The class parses and encapsulates the netrc file format used by the Unix program and other FTP clients.

file

A instance or subclass instance encapsulates data from a netrc file. The initialization argument, if

present, specifies the file to parse. If no argument is given, the file in the user’s home directory – as

determined by – will be read. Otherwise, a exception will

be raised. Parse errors will raise with diagnostic information including the file name, line

number, and terminating token. If no argument is specified on a POSIX system, the presence of passwords in

the file will raise a if the file ownership or permissions are insecure (owned by a

user other than the user running the process, or accessible for read or write by any other user). This implements

security behavior equivalent to that of ftp and other programs that use .

Changed in version 3.4: Added the POSIX permission check.

Changed in version 3.7: is used to find the location of the file when file

is not passed as argument.

Changed in version 3.10: try UTF-8 encoding before using locale specific encoding. The entry in the

netrc file no longer needs to contain all tokens. The missing tokens’ value default to an empty string. All the

tokens and their values now can contain arbitrary characters, like whitespace and non-ASCII characters. If the

login name is anonymous, it won’t trigger the security check.



Exception raised by the class when syntactical errors are encountered in source text. Instances of this

exception provide three interesting attributes:



Textual explanation of the error.



The name of the source file.



The line number on which the error was found.



The Python Library Reference, Release 3.13.2





A instance has the following methods:

host

Return a 3-tuple of authenticators for host. If the netrc file did not contain

an entry for the given host, return the tuple associated with the ‘default’ entry. If neither matching host nor

default entry is available, return .



Dump the class data as a string in the format of a netrc file. (This discards comments and may reorder the

entries.)

Instances of have public instance variables:



Dictionary mapping host names to tuples. The ‘default’ entry, if any, is

represented as a pseudo-host by that name.



Dictionary mapping macro names to string lists.





Source code: Lib/plistlib.py



This module provides an interface for reading and writing the “property list” files used by Apple, primarily on macOS and iOS. This module supports both binary and XML plist files.

The property list () file format is a simple serialization supporting basic object types, like dictionaries, lists, numbers and strings. Usually the top level object is a dictionary.

To write out and to parse a plist file, use the and functions.

To work with plist data in bytes or string objects, use and .

Values can be strings, integers, floats, booleans, tuples, lists, dictionaries (but only with string keys), ,

or objects.

Changed in version 3.4: New API, old API deprecated. Support for binary format plists added.

Changed in version 3.8: Support added for reading and writing tokens in binary plists as used by NSKeyedArchiver and NSKeyedUnarchiver.

Changed in version 3.9: Old API removed.



µ See also

PList manual page

Apple’s documentation of the file format.



This module defines the following functions:

fp, *, fmt=None, dict_type=dict, aware_datetime=False

Read a plist file. fp should be a readable and binary file object. Return the unpacked root object (which usually

is a dictionary).

The fmt is the format of the file and the following values are valid:

• : Autodetect the file format

• : XML file format

The Python Library Reference, Release 3.13.2



• : Binary plist format

The dict_type is the type used for dictionaries that are read from the plist file.

When aware_datetime is true, fields with type will be created as aware object, with

as .

XML data for the format is parsed using the Expat parser from – see its

documentation for possible exceptions on ill-formed XML. Unknown elements will simply be ignored by the

plist parser.

The parser for the binary format raises when the file cannot be parsed.

Added in version 3.4.

Changed in version 3.13: The keyword-only parameter aware_datetime has been added.

data, *, fmt=None, dict_type=dict, aware_datetime=False

Load a plist from a bytes or string object. See for an explanation of the keyword arguments.

Added in version 3.4.

Changed in version 3.13: data can be a string when fmt equals .

value, fp, *, fmt=FMT_XML, sort_keys=True, skipkeys=False, aware_datetime=False

Write value to a plist file. fp should be a writable, binary file object.

The fmt argument specifies the format of the plist file and can be one of the following values:

• : XML formatted plist file

• : Binary formatted plist file

When sort_keys is true (the default) the keys for dictionaries will be written to the plist in sorted order, otherwise

they will be written in the iteration order of the dictionary.

When skipkeys is false (the default) the function raises when a key of a dictionary is not a string,

otherwise such keys are skipped.

When aware_datetime is true and any field with type is set as an aware object, it will

convert to UTC timezone before writing it.

A will be raised if the object is of an unsupported type or a container that contains objects of

unsupported types.

An will be raised for integer values that cannot be represented in (binary) plist files.

Added in version 3.4.

Changed in version 3.13: The keyword-only parameter aware_datetime has been added.

value, *, fmt=FMT_XML, sort_keys=True, skipkeys=False, aware_datetime=False

Return value as a plist-formatted bytes object. See the documentation for for an explanation of the

keyword arguments of this function.

Added in version 3.4.

The following classes are available:

data

Wraps an . This is used when reading or writing NSKeyedArchiver encoded data, which contains UID

(see PList manual).

It has one attribute, , which can be used to retrieve the int value of the UID. must be in the range

.

Added in version 3.8.

The following constants are available:

The Python Library Reference, Release 3.13.2





The XML format for plist files.

Added in version 3.4.



The binary format for plist files

Added in version 3.4.





Generating a plist:





Parsing a plist:





The Python Library Reference, Release 3.13.2





CHAPTER





The modules described in this chapter implement various algorithms of a cryptographic nature. They are available at the discretion of the installation. Here’s an overview:





Source code: Lib/hashlib.py



This module implements a common interface to many different secure hash and message digest algorithms. Included

are the FIPS secure hash algorithms SHA1, SHA224, SHA256, SHA384, SHA512, (defined in the FIPS 180-4

standard), the SHA-3 series (defined in the FIPS 202 standard) as well as RSA’s MD5 algorithm (defined in internet

RFC 1321). The terms “secure hash” and “message digest” are interchangeable. Older algorithms were called message digests. The modern term is secure hash.



® Note

If you want the adler32 or crc32 hash functions, they are available in the module.





There is one constructor method named for each type of hash. All return a hash object with the same simple interface.

For example: use to create a SHA-256 hash object. You can now feed this object with bytes-like objects

(normally ) using the method. At any point you can ask it for the digest of the concatenation of the

data fed to it so far using the or methods.

To allow multithreading, the Python GIL is released while computing a hash supplied more than 2047 bytes of data

at once in its constructor or method.

Constructors for hash algorithms that are always present in this module are , , ,

, , , , , , ,

, , and . is normally available as well, though it may be missing or

blocked if you are using a rare “FIPS compliant” build of Python. These correspond to .

Additional algorithms may also be available if your Python distribution’s was linked against a build of OpenSSL that provides others. Others are not guaranteed available on all installations and will only be accessible by

name via . See .



Á Warning

Some algorithms have known hash collision weaknesses (including MD5 and SHA1). Refer to Attacks on cryp-

tographic hash algorithms and the hashlib-seealso section at the end of this document.



Added in version 3.6: SHA3 (Keccak) and SHAKE constructors , , ,

, , were added. and were added. Changed in The Python Library Reference, Release 3.13.2



version 3.9: All hashlib constructors take a keyword-only argument usedforsecurity with default value . A false value allows the use of insecure and blocked hashing algorithms in restricted environments. indicates that the hashing algorithm is not used in a security context, e.g. as a non-cryptographic one-way compression function.

Changed in version 3.9: Hashlib now uses SHA3 and SHAKE from OpenSSL if it provides it.

Changed in version 3.12: For any of the MD5, SHA1, SHA2, or SHA3 algorithms that the linked OpenSSL does

not provide we fall back to a verified implementation from the HACL* project.





To obtain the digest of the byte string :





More condensed:





name, data, *, usedforsecurity=True

Is a generic constructor that takes the string name of the desired algorithm as its first parameter. It also exists

to allow access to the above listed hashes as well as any other algorithms that your OpenSSL library may offer.

Using with an algorithm name:





data , *, usedforsecurity=True

data , *, usedforsecurity=True

data , *, usedforsecurity=True

data , *, usedforsecurity=True

data , *, usedforsecurity=True

data , *, usedforsecurity=True

data , *, usedforsecurity=True

data , *, usedforsecurity=True

data , *, usedforsecurity=True

The Python Library Reference, Release 3.13.2



data , *, usedforsecurity=True

Named constructors such as these are faster than passing an algorithm name to .





Hashlib provides the following constant module attributes:



A set containing the names of the hash algorithms guaranteed to be supported by this module on all platforms.

Note that ‘md5’ is in this list despite some upstream vendors offering an odd “FIPS compliant” Python build

that excludes it.

Added in version 3.2.



A set containing the names of the hash algorithms that are available in the running Python interpreter. These

names will be recognized when passed to . will always be a subset. The

same algorithm may appear multiple times in this set under different names (thanks to OpenSSL).

Added in version 3.2.





The following values are provided as constant attributes of the hash objects returned by the constructors:



The size of the resulting hash in bytes.



The internal block size of the hash algorithm in bytes.

A hash object has the following attributes:



The canonical name of this hash, always lowercase and always suitable as a parameter to to create

another hash of this type.

Changed in version 3.4: The name attribute has been present in CPython since its inception, but until Python

3.4 was not formally specified, so may not exist on some platforms.

A hash object has the following methods:

data

Update the hash object with the bytes-like object. Repeated calls are equivalent to a single call with the con-

catenation of all the arguments: is equivalent to .



Return the digest of the data passed to the method so far. This is a bytes object of size

which may contain bytes in the whole range from 0 to 255.



Like except the digest is returned as a string object of double length, containing only hexadecimal

digits. This may be used to exchange the value safely in email or other non-binary environments.



Return a copy (“clone”) of the hash object. This can be used to efficiently compute the digests of data sharing

a common initial substring.



The Python Library Reference, Release 3.13.2





data , *, usedforsecurity=True

data , *, usedforsecurity=True

The and algorithms provide variable length digests with length_in_bits//2 up to 128 or 256 bits of security. As such, their digest methods require a length. Maximum length is not limited by the SHAKE algorithm.

length

Return the digest of the data passed to the method so far. This is a bytes object of size length which

may contain bytes in the whole range from 0 to 255.

length

Like except the digest is returned as a string object of double length, containing only hexadecimal

digits. This may be used to exchange the value in email or other non-binary environments.

Example use:





The hashlib module provides a helper function for efficient hashing of a file or file-like object.

fileobj, digest, /

Return a digest object that has been updated with contents of file object.

fileobj must be a file-like object opened for reading in binary mode. It accepts file objects from builtin ,

instances, SocketIO objects from , and similar. The function may

bypass Python’s I/O and use the file descriptor from directly. fileobj must be assumed to be in an

unknown state after this function returns or raises. It is up to the caller to close fileobj.

digest must either be a hash algorithm name as a str, a hash constructor, or a callable that returns a hash object.

Example:





Added in version 3.11.



The Python Library Reference, Release 3.13.2





Key derivation and key stretching algorithms are designed for secure password hashing. Naive algorithms such as are not resistant against brute-force attacks. A good password hashing function must be tunable,

slow, and include a salt.

hash_name, password, salt, iterations, dklen=None

The function provides PKCS#5 password-based key derivation function 2. It uses HMAC as pseudorandom

function.

The string hash_name is the desired name of the hash digest algorithm for HMAC, e.g. ‘sha1’ or ‘sha256’.

password and salt are interpreted as buffers of bytes. Applications and libraries should limit password to a

sensible length (e.g. 1024). salt should be about 16 or more bytes from a proper source, e.g. .

The number of iterations should be chosen based on the hash algorithm and computing power. As of 2022,

hundreds of thousands of iterations of SHA-256 are suggested. For rationale as to why and how to choose what

is best for your application, read Appendix A.2.2 of NIST-SP-800-132. The answers on the stackexchange

pbkdf2 iterations question explain in detail.

dklen is the length of the derived key in bytes. If dklen is then the digest size of the hash algorithm

hash_name is used, e.g. 64 for SHA-512.





Function only available when Python is compiled with OpenSSL.

Added in version 3.4.

Changed in version 3.12: Function now only available when Python is built with OpenSSL. The slow pure

Python implementation has been removed.

password, *, salt, n, r, p, maxmem=0, dklen=64

The function provides scrypt password-based key derivation function as defined in RFC 7914.

password and salt must be bytes-like objects. Applications and libraries should limit password to a sensible

length (e.g. 1024). salt should be about 16 or more bytes from a proper source, e.g. .

n is the CPU/Memory cost factor, r the block size, p parallelization factor and maxmem limits memory

(OpenSSL 1.1.0 defaults to 32 MiB). dklen is the length of the derived key in bytes.

Added in version 3.6.





BLAKE2 is a cryptographic hash function defined in RFC 7693 that comes in two flavors:

• BLAKE2b, optimized for 64-bit platforms and produces digests of any size between 1 and 64 bytes,

• BLAKE2s, optimized for 8- to 32-bit platforms and produces digests of any size between 1 and 32 bytes.

BLAKE2 supports keyed mode (a faster and simpler replacement for HMAC), salted hashing, personalization, and tree hashing.

Hash objects from this module follow the API of standard library’s objects.



Creating hash objects

New hash objects are created by calling constructor functions:

data=b”, *, digest_size=64, key=b”, salt=b”, person=b”, fanout=1, depth=1, leaf_size=0,

node_offset=0, node_depth=0, inner_size=0, last_node=False, usedforsecurity=True

The Python Library Reference, Release 3.13.2



data=b”, *, digest_size=32, key=b”, salt=b”, person=b”, fanout=1, depth=1, leaf_size=0,

node_offset=0, node_depth=0, inner_size=0, last_node=False, usedforsecurity=True

These functions return the corresponding hash objects for calculating BLAKE2b or BLAKE2s. They optionally take these general parameters:

• data: initial chunk of data to hash, which must be bytes-like object. It can be passed only as positional argument.

• digest_size: size of output digest in bytes.

• key: key for keyed hashing (up to 64 bytes for BLAKE2b, up to 32 bytes for BLAKE2s).

• salt: salt for randomized hashing (up to 16 bytes for BLAKE2b, up to 8 bytes for BLAKE2s).

• person: personalization string (up to 16 bytes for BLAKE2b, up to 8 bytes for BLAKE2s).

The following table shows limits for general parameters (in bytes):



Hash digest_size len(key) len(salt) len(person)

BLAKE2b 64 64 16 16

BLAKE2s 32 32 8 8



® Note

BLAKE2 specification defines constant lengths for salt and personalization parameters, however, for convenience,

this implementation accepts byte strings of any size up to the specified length. If the length of the parameter is

less than specified, it is padded with zeros, thus, for example, and is the same value.

(This is not the case for key.)



These sizes are available as module constants described below.

Constructor functions also accept the following tree hashing parameters:

• fanout: fanout (0 to 255, 0 if unlimited, 1 in sequential mode).

• depth: maximal depth of tree (1 to 255, 255 if unlimited, 1 in sequential mode).

• leaf_size: maximal byte length of leaf (0 to , 0 if unlimited or in sequential mode).

• node_offset: node offset (0 to for BLAKE2b, 0 to for BLAKE2s, 0 for the first, leftmost,

leaf, or in sequential mode).

• node_depth: node depth (0 to 255, 0 for leaves, or in sequential mode).

• inner_size: inner digest size (0 to 64 for BLAKE2b, 0 to 32 for BLAKE2s, 0 in sequential mode).

• last_node: boolean indicating whether the processed node is the last one ( for sequential mode).

See section 2.10 in BLAKE2 specification for comprehensive review of tree hashing.



Constants





Salt length (maximum length accepted by constructors).





Personalization string length (maximum length accepted by constructors).

The Python Library Reference, Release 3.13.2





Maximum key size.





Maximum digest size that the hash function can output.



Examples

Simple hashing

To calculate hash of some data, you should first construct a hash object by calling the appropriate constructor function

( or ), then update it with the data by calling on the object, and, finally, get the

digest out of the object by calling (or for hex-encoded string).





As a shortcut, you can pass the first chunk of data to update directly to the constructor as the positional argument:





The Python Library Reference, Release 3.13.2





You can call as many times as you need to iteratively update the hash:





Using different digest sizes

BLAKE2 has configurable size of digests up to 64 bytes for BLAKE2b and up to 32 bytes for BLAKE2s. For example, to replace SHA-1 with BLAKE2b without changing the size of output, we can tell BLAKE2b to produce 20-byte digests:





Hash objects with different digest sizes have completely different outputs (shorter hashes are not prefixes of longer hashes); BLAKE2b and BLAKE2s produce different outputs even if the output length is the same:





Keyed hashing

Keyed hashing can be used for authentication as a faster and simpler replacement for Hash-based message authenti-

cation code (HMAC). BLAKE2 can be securely used in prefix-MAC mode thanks to the indifferentiability property inherited from BLAKE.

This example shows how to get a (hex-encoded) 128-bit authentication code for message with key :





The Python Library Reference, Release 3.13.2





As a practical example, a web application can symmetrically sign cookies sent to users and later verify them to make sure they weren’t tampered with:





Even though there’s a native keyed hashing mode, BLAKE2 can, of course, be used in HMAC construction with

module:





Randomized hashing

By setting salt parameter users can introduce randomization to the hash function. Randomized hashing is useful for protecting against collision attacks on the hash function used in digital signatures.

Randomized hashing is designed for situations where one party, the message preparer, generates all

or part of a message to be signed by a second party, the message signer. If the message preparer is

able to find cryptographic hash function collisions (i.e., two messages producing the same hash value),

then they might prepare meaningful versions of the message that would produce the same hash value

and digital signature, but with different results (e.g., transferring $1,000,000 to an account, rather than

$10). Cryptographic hash functions have been designed with collision resistance as a major goal, but

the current concentration on attacking cryptographic hash functions may result in a given cryptographic

hash function providing less collision resistance than expected. Randomized hashing offers the signer

additional protection by reducing the likelihood that a preparer can generate two or more messages

that ultimately yield the same hash value during the digital signature generation process — even if it is The Python Library Reference, Release 3.13.2



practical to find collisions for the hash function. However, the use of randomized hashing may reduce

the amount of security provided by a digital signature when all portions of the message are prepared by

the signer.

(NIST SP-800-106 “Randomized Hashing for Digital Signatures”)

In BLAKE2 the salt is processed as a one-time input to the hash function during initialization, rather than as an input to each compression function.



Á Warning

Salted hashing (or just hashing) with BLAKE2 or any other general-purpose cryptographic hash function, such

as SHA-256, is not suitable for hashing passwords. See BLAKE2 FAQ for more information.





Personalization

Sometimes it is useful to force hash function to produce different digests for the same input for different purposes. Quoting the authors of the Skein hash function:

We recommend that all application designers seriously consider doing this; we have seen many protocols

where a hash that is computed in one part of the protocol can be used in an entirely different part because

two hash computations were done on similar or related data, and the attacker can force the application to

make the hash inputs the same. Personalizing each hash function used in the protocol summarily stops

this type of attack.

(The Skein Hash Function Family, p. 21)

BLAKE2 can be personalized by passing bytes to the person argument:





Personalization together with the keyed mode can also be used to derive different keys from a single one.

The Python Library Reference, Release 3.13.2





Tree mode

Here’s an example of hashing a minimal tree with two leaf nodes:





This example uses 64-byte internal digests, and returns the 32-byte final digest:





Credits

BLAKE2 was designed by Jean-Philippe Aumasson, Samuel Neves, Zooko Wilcox-O’Hearn, and Christian Winnerlein

based on SHA-3 finalist BLAKE created by Jean-Philippe Aumasson, Luca Henzen, Willi Meier, and Raphael C.-W. Phan.

It uses core algorithm from ChaCha cipher designed by Daniel J. Bernstein.

The stdlib implementation is based on pyblake2 module. It was written by Dmitry Chestnykh based on C implemen-

tation written by Samuel Neves. The documentation was copied from pyblake2 and written by Dmitry Chestnykh.

The C code was partly rewritten for Python by Christian Heimes.

The Python Library Reference, Release 3.13.2



The following public domain dedication applies for both C hash function implementation, extension code, and this documentation:

To the extent possible under law, the author(s) have dedicated all copyright and related and neighboring

rights to this software to the public domain worldwide. This software is distributed without any warranty.

You should have received a copy of the CC0 Public Domain Dedication along with this software. If not,

see https://creativecommons.org/publicdomain/zero/1.0/.

The following people have helped with development or contributed their changes to the project and the public domain according to the Creative Commons Public Domain Dedication 1.0 Universal:

• Alexandr Sokolovskiy



µ See also

Module

A module to generate message authentication codes using hashes.

Module

Another way to encode binary hashes for non-binary environments.

https://nvlpubs.nist.gov/nistpubs/fips/nist.fips.180-4.pdf

The FIPS 180-4 publication on Secure Hash Algorithms.

https://csrc.nist.gov/pubs/fips/202/final

The FIPS 202 publication on the SHA-3 Standard.

https://www.blake2.net/

Official BLAKE2 website.

https://en.wikipedia.org/wiki/Cryptographic_hash_function

Wikipedia article with information on which algorithms have known issues and what that means regarding their use.

https://www.ietf.org/rfc/rfc8018.txt

PKCS #5: Password-Based Cryptography Specification Version 2.1

https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-132.pdf

NIST Recommendation for Password-Based Key Derivation.





Source code: Lib/hmac.py



This module implements the HMAC algorithm as described by RFC 2104.

key, msg=None, digestmod

Return a new hmac object. key is a bytes or bytearray object giving the secret key. If msg is present, the method

call is made. digestmod is the digest name, digest constructor or module for the HMAC object

to use. It may be any name suitable to . Despite its argument position, it is required.

Changed in version 3.4: Parameter key can be a bytes or bytearray object. Parameter msg can be of any type

supported by . Parameter digestmod can be the name of a hash algorithm.

Changed in version 3.8: The digestmod argument is now required. Pass it as a keyword argument to avoid

awkwardness when you do not have an initial msg.

key, msg, digest

Return digest of msg for given secret key and digest. The function is equivalent to

, but uses an optimized C or inline implementation, which is faster for messages that

fit into memory. The parameters key, msg, and digest have the same meaning as in .

The Python Library Reference, Release 3.13.2



CPython implementation detail, the optimized C implementation is only used when digest is a string and name

of a digest algorithm, which is supported by OpenSSL.

Added in version 3.7.

An HMAC object has the following methods:

msg

Update the hmac object with msg. Repeated calls are equivalent to a single call with the concatenation of all

the arguments: is equivalent to .

Changed in version 3.4: Parameter msg can be of any type supported by .



Return the digest of the bytes passed to the method so far. This bytes object will be the same length

as the digest_size of the digest given to the constructor. It may contain non-ASCII bytes, including NUL bytes.



Á Warning

When comparing the output of to an externally supplied digest during a verification routine,

it is recommended to use the function instead of the operator to reduce the vulnerability to timing attacks.





Like except the digest is returned as a string twice the length containing only hexadecimal digits.

This may be used to exchange the value safely in email or other non-binary environments.



Á Warning

When comparing the output of to an externally supplied digest during a verification routine,

it is recommended to use the function instead of the operator to reduce the vulnerability to timing attacks.





Return a copy (“clone”) of the hmac object. This can be used to efficiently compute the digests of strings that

share a common initial substring.

A hash object has the following attributes:



The size of the resulting HMAC digest in bytes.



The internal block size of the hash algorithm in bytes.

Added in version 3.4.



The canonical name of this HMAC, always lowercase, e.g. .

Added in version 3.4.

Changed in version 3.10: Removed the undocumented attributes , , and .

This module also provides the following helper function:

a, b

Return . This function uses an approach designed to prevent timing analysis by avoiding content-based

short circuiting behaviour, making it appropriate for cryptography. a and b must both be of the same type:

either (ASCII only, as e.g. returned by ), or a bytes-like object.

The Python Library Reference, Release 3.13.2



® Note

If a and b are of different lengths, or if an error occurs, a timing attack could theoretically reveal information about the types and lengths of a and b—but not their values.



Added in version 3.3.

Changed in version 3.10: The function uses OpenSSL’s internally when available.



µ See also

Module

The Python module providing secure hash functions.





Added in version 3.6.

Source code: Lib/secrets.py



The module is used for generating cryptographically strong random numbers suitable for managing data such as passwords, account authentication, security tokens, and related secrets.

In particular, should be used in preference to the default pseudo-random number generator in the module, which is designed for modelling and simulation, not security or cryptography.



µ See also

PEP 506





The module provides access to the most secure source of randomness that your operating system provides.





A class for generating random numbers using the highest-quality sources provided by the operating system.

See for additional details.

seq

Return a randomly chosen element from a non-empty sequence.

exclusive_upper_bound

Return a random int in the range [0, exclusive_upper_bound).

k

Return a non-negative int with k random bits.





The module provides functions for generating secure tokens, suitable for applications such as password resets, hard-to-guess URLs, and similar.

The Python Library Reference, Release 3.13.2



nbytes=None

Return a random byte string containing nbytes number of bytes. If nbytes is or not supplied, a reasonable

default is used.





nbytes=None

Return a random text string, in hexadecimal. The string has nbytes random bytes, each byte converted to two

hex digits. If nbytes is or not supplied, a reasonable default is used.





nbytes=None

Return a random URL-safe text string, containing nbytes random bytes. The text is Base64 encoded, so on

average each byte results in approximately 1.3 characters. If nbytes is or not supplied, a reasonable

default is used.





How many bytes should tokens use?

To be secure against brute-force attacks, tokens need to have sufficient randomness. Unfortunately, what is considered sufficient will necessarily increase as computers get more powerful and able to make more guesses in a shorter period. As of 2015, it is believed that 32 bytes (256 bits) of randomness is sufficient for the typical use-case expected for the

module.

For those who want to manage their own token length, you can explicitly specify how much randomness is used for

tokens by giving an argument to the various functions. That argument is taken as the number of bytes of randomness to use.

Otherwise, if no argument is provided, or if the argument is , the functions will use a reasonable default instead.



® Note

That default is subject to change at any time, including during maintenance releases.





a, b

Return if strings or bytes-like objects a and b are equal, otherwise , using a “constant-time compare”

to reduce the risk of timing attacks. See for additional details.





This section shows recipes and best practices for using to manage a basic level of security.

Generate an eight-character alphanumeric password:





The Python Library Reference, Release 3.13.2



® Note

Applications should not store passwords in a recoverable format, whether plain text or encrypted. They should

be salted and hashed using a cryptographically strong one-way (irreversible) hash function.



Generate a ten-character alphanumeric password with at least one lowercase character, at least one uppercase char-acter, and at least three digits:





Generate an XKCD-style passphrase:





Generate a hard-to-guess temporary URL containing a security token suitable for password recovery applications:





CHAPTER





The modules described in this chapter provide interfaces to operating system features that are available on (almost) all operating systems, such as files and a clock. The interfaces are generally modeled after the Unix or C interfaces, but they are available on most other systems as well. Here’s an overview:





Source code: Lib/os.py



This module provides a portable way of using operating system dependent functionality. If you just want to read or

write a file see , if you want to manipulate paths, see the module, and if you want to read all the

lines in all the files on the command line see the module. For creating temporary files and directories

see the module, and for high-level file and directory handling see the module.

Notes on the availability of these functions:

• The design of all built-in operating system dependent modules of Python is such that as long as the same

functionality is available, it uses the same interface; for example, the function returns stat

information about path in the same format (which happens to have originated with the POSIX interface).

• Extensions peculiar to a particular operating system are also available through the module, but using them

is of course a threat to portability.

• All functions accepting path or file names accept both bytes and string objects, and result in an object of the

same type, if a path or file name is returned.

• On VxWorks, os.popen, os.fork, os.execv and os.spawn*p* are not supported.

• On WebAssembly platforms, Android and iOS, large parts of the module are not available or behave dif-

ferently. APIs related to processes (e.g. , ) and resources (e.g. ) are not available.

Others like and are emulated or stubs. WebAssembly platforms also lack support for

signals (e.g. , ).



® Note

All functions in this module raise (or subclasses thereof) in the case of invalid or inaccessible file names

and paths, or other arguments that have the correct type, but are not accepted by the operating system.





An alias for the built-in exception.



The name of the operating system dependent module imported. The following names have currently been

registered: , , .



The Python Library Reference, Release 3.13.2



µ See also

has a finer granularity. gives system-dependent version information.

The module provides detailed checks for the system’s identity.





In Python, file names, command line arguments, and environment variables are represented using the string type. On some systems, decoding these strings to and from bytes is necessary before passing them to the op-

erating system. Python uses the filesystem encoding and error handler to perform this conversion (see

).

The filesystem encoding and error handler are configured at Python startup by the function: see and members of .

Changed in version 3.1: On some systems, conversion using the file system encoding may fail. In this case, Python

uses the surrogateescape encoding error handler, which means that undecodable bytes are replaced by a Unicode character U+DCxx on decoding, and these are again translated to the original byte on encoding.

The file system encoding must guarantee to successfully decode all bytes below 128. If the file system encoding fails

to provide this guarantee, API functions can raise .

See also the locale encoding.





Added in version 3.7: See PEP 540 for more details.

The Python UTF-8 Mode ignores the locale encoding and forces the usage of the UTF-8 encoding:

• Use UTF-8 as the filesystem encoding.

• returns .

• returns (the do_setlocale argument has no effect).

• , , and all use UTF-8 as their text encoding, with the

error handler being enabled for and ( contin-

ues to use as it does in the default locale-aware mode)

• On Unix, returns rather than the device encoding.

Note that the standard stream settings in UTF-8 mode can be overridden by (just as they can be in the default locale-aware mode).

As a consequence of the changes in those lower level APIs, other higher level APIs also exhibit different default behaviours:

• Command line arguments, environment variables and filenames are decoded to text using the UTF-8 encoding.

• and use the UTF-8 encoding.

• , , and use the UTF-8 encoding by default. However, they still use the

strict error handler by default so that attempting to open a binary file in text mode is likely to raise an exception

rather than producing nonsense data.

The Python UTF-8 Mode is enabled if the LC_CTYPE locale is or at Python startup (see the function).

It can be enabled or disabled using the command line option and the environment variable.

If the environment variable is not set at all, then the interpreter defaults to using the cur-rent locale settings, unless the current locale is identified as a legacy ASCII-based locale (as described for ), and locale coercion is either disabled or fails. In such legacy locales, the interpreter will default to enabling UTF-8 mode unless explicitly instructed not to do so.

The Python Library Reference, Release 3.13.2



The Python UTF-8 Mode can only be enabled at the Python startup. Its value can be read from

.

See also the UTF-8 mode on Windows and the filesystem encoding and error handler.



µ See also

PEP 686

Python 3.15 will make Python UTF-8 Mode default.





These functions and data items provide information and operate on the current process and user.



Return the filename corresponding to the controlling terminal of the process.

Availability: Unix, not WASI.



A mapping object where keys and values are strings that represent the process environment. For exam-

ple, is the pathname of your home directory (on some platforms), and is equivalent to

in C.

This mapping is captured the first time the module is imported, typically during Python startup as part

of processing . Changes to the environment made after this time are not reflected in ,

except for changes made by modifying directly.

This mapping may be used to modify the environment as well as query the environment. will be

called automatically when the mapping is modified.

On Unix, keys and values use and error handler.

Use if you would like to use a different encoding.

On Windows, the keys are converted to uppercase. This also applies when getting, setting, or deleting an item.

For example, maps the key to the value .



® Note

Calling directly does not change , so it’s better to modify .



® Note

On some platforms, including FreeBSD and macOS, setting may cause memory leaks. Refer to the system documentation for .



You can delete items in this mapping to unset environment variables. will be called automatically

when an item is deleted from , and when one of the or methods is called.

Changed in version 3.9: Updated to support PEP 584’s merge () and update () operators.



Bytes version of : a mapping object where both keys and values are objects representing the

process environment. and are synchronized (modifying updates ,

and vice versa).

is only available if is .

Added in version 3.2.

The Python Library Reference, Release 3.13.2



Changed in version 3.9: Updated to support PEP 584’s merge () and update () operators.

path

fd



These functions are described in Files and Directories.

filename

Encode path-like filename to the filesystem encoding and error handler; return unchanged.

is the reverse function.

Added in version 3.2.

Changed in version 3.6: Support added to accept objects implementing the interface.

filename

Decode the path-like filename from the filesystem encoding and error handler; return unchanged.

is the reverse function.

Added in version 3.2.

Changed in version 3.6: Support added to accept objects implementing the interface.

path

Return the file system representation of the path.

If or is passed in, it is returned unchanged. Otherwise is called and its value is

returned as long as it is a or object. In all other cases, is raised.

Added in version 3.6.



An abstract base class for objects representing a file system path, e.g. .

Added in version 3.6.



Return the file system path representation of the object.

The method should only return a or object, with the preference being for .

key, default=None

Return the value of the environment variable key as a string if it exists, or default if it doesn’t. key is a string.

Note that since uses , the mapping of is similarly also captured on import,

and the function may not reflect future environment changes.

On Unix, keys and values are decoded with and

error handler. Use if you would like to use a different encoding.

Availability: Unix, Windows.

key, default=None

Return the value of the environment variable key as bytes if it exists, or default if it doesn’t. key must be bytes.

Note that since uses , the mapping of is similarly also captured on

import, and the function may not reflect future environment changes.

is only available if is .

Availability: Unix.

Added in version 3.2.



The Python Library Reference, Release 3.13.2



env=None

Returns the list of directories that will be searched for a named executable, similar to a shell, when launching a

process. env, when specified, should be an environment variable dictionary to lookup the PATH in. By default,

when env is , is used.

Added in version 3.2.



Return the effective group id of the current process. This corresponds to the “set id” bit on the file being

executed in the current process.

Availability: Unix, not WASI.



Return the current process’s effective user id.

Availability: Unix, not WASI.



Return the real group id of the current process.

Availability: Unix.

The function is a stub on WASI, see WebAssembly platforms for more information.

user, group, /

Return list of group ids that user belongs to. If group is not in the list, it is included; typically, group is specified

as the group ID field from the password record for user, because that group ID will otherwise be potentially

omitted.

Availability: Unix, not WASI.

Added in version 3.3.



Return list of supplemental group ids associated with the current process.

Availability: Unix, not WASI.



® Note

On macOS, behavior differs somewhat from other Unix platforms. If the Python interpreter

was built with a deployment target of or earlier, returns the list of effective group ids associated with the current user process; this list is limited to a system-defined number of entries, typically

16, and may be modified by calls to if suitably privileged. If built with a deployment target

greater than , returns the current group access list for the user associated with the effective user id of the process; the group access list may change over the lifetime of the process, it is

not affected by calls to , and its length is not limited to 16. The deployment target value,

, can be obtained with .





Return the name of the user logged in on the controlling terminal of the process. For most purposes, it is more

useful to use since the latter checks the environment variables or

to find out who the user is, and falls back to to get the login name of

the current real user id.

Availability: Unix, Windows, not WASI.

pid

Return the process group id of the process with process id pid. If pid is 0, the process group id of the current

process is returned.

Availability: Unix, not WASI.

The Python Library Reference, Release 3.13.2





Return the id of the current process group.

Availability: Unix, not WASI.



Return the current process id.

The function is a stub on WASI, see WebAssembly platforms for more information.



Return the parent’s process id. When the parent process has exited, on Unix the id returned is the one of the

init process (1), on Windows it is still the same id, which may be already reused by another process.

Availability: Unix, Windows, not WASI.

Changed in version 3.2: Added support for Windows.

which, who

Get program scheduling priority. The value which is one of , , or ,

and who is interpreted relative to which (a process identifier for , process group identifier for

, and a user ID for ). A zero value for who denotes (respectively) the calling process,

the process group of the calling process, or the real user ID of the calling process.

Availability: Unix, not WASI.

Added in version 3.3.





Parameters for the and functions.

Availability: Unix, not WASI.

Added in version 3.3.





Parameters for the and functions.

Availability: macOS

Added in version 3.12.



Return a tuple (ruid, euid, suid) denoting the current process’s real, effective, and saved user ids.

Availability: Unix, not WASI.

Added in version 3.2.



Return a tuple (rgid, egid, sgid) denoting the current process’s real, effective, and saved group ids.

Availability: Unix, not WASI.

Added in version 3.2.



Return the current process’s real user id.

Availability: Unix.

The function is a stub on WASI, see WebAssembly platforms for more information.

The Python Library Reference, Release 3.13.2



username, gid, /

Call the system initgroups() to initialize the group access list with all of the groups of which the specified

username is a member, plus the specified group id.

Availability: Unix, not WASI, not Android.

Added in version 3.2.

key, value, /

Set the environment variable named key to the string value. Such changes to the environment affect subpro-

cesses started with , or and .

Assignments to items in are automatically translated into corresponding calls to ;

however, calls to don’t update , so it is actually preferable to assign to items of

. This also applies to and , which respectively use and

in their implementations.



® Note

On some platforms, including FreeBSD and macOS, setting may cause memory leaks. Refer to the system documentation for .



Raises an auditing event with arguments , .

Changed in version 3.9: The function is now always available.

egid, /

Set the current process’s effective group id.

Availability: Unix, not WASI, not Android.

euid, /

Set the current process’s effective user id.

Availability: Unix, not WASI, not Android.

gid, /

Set the current process’ group id.

Availability: Unix, not WASI, not Android.

groups, /

Set the list of supplemental group ids associated with the current process to groups. groups must be a sequence,

and each element must be an integer identifying a group. This operation is typically available only to the

superuser.

Availability: Unix, not WASI.



® Note

On macOS, the length of groups may not exceed the system-defined maximum number of effective group

ids, typically 16. See the documentation for for cases where it may not return the same group list set by calling setgroups().



fd, nstype=0

Reassociate the current thread with a Linux namespace. See the and man pages

for more details.

If fd refers to a link, reassociates the calling thread with the namespace associated

with that link, and nstype may be set to one of the CLONE_NEW* constants to impose constraints on the

operation ( means no constraints).

The Python Library Reference, Release 3.13.2



Since Linux 5.8, fd may refer to a PID file descriptor obtained from . In this case,

reassociates the calling thread into one or more of the same namespaces as the thread referred to by fd. This is

subject to any constraints imposed by nstype, which is a bit mask combining one or more of the CLONE_NEW*

constants, e.g. . The caller’s memberships in un-

specified namespaces are left unchanged.

fd can be any object with a method, or a raw file descriptor.

This example reassociates the thread with the process’s network namespace:





Availability: Linux >= 3.0 with glibc >= 2.14.

Added in version 3.12.



µ See also

The function.





Call the system call or depending on which version is implemented (if any).

See the Unix manual for the semantics.

Availability: Unix, not WASI.

pid, pgrp, /

Call the system call to set the process group id of the process with id pid to the process group

with id pgrp. See the Unix manual for the semantics.

Availability: Unix, not WASI.

which, who, priority

Set program scheduling priority. The value which is one of , , or ,

and who is interpreted relative to which (a process identifier for , process group identifier for

, and a user ID for ). A zero value for who denotes (respectively) the calling process,

the process group of the calling process, or the real user ID of the calling process. priority is a value in the

range -20 to 19. The default priority is 0; lower priorities cause more favorable scheduling.

Availability: Unix, not WASI.

Added in version 3.3.

rgid, egid, /

Set the current process’s real and effective group ids.

Availability: Unix, not WASI, not Android.

rgid, egid, sgid, /

Set the current process’s real, effective, and saved group ids.

Availability: Unix, not WASI, not Android.

Added in version 3.2.

ruid, euid, suid, /

Set the current process’s real, effective, and saved user ids.

Availability: Unix, not WASI, not Android.

Added in version 3.2.

The Python Library Reference, Release 3.13.2



ruid, euid, /

Set the current process’s real and effective user ids.

Availability: Unix, not WASI, not Android.

pid, /

Call the system call . See the Unix manual for the semantics.

Availability: Unix, not WASI.



Call the system call . See the Unix manual for the semantics.

Availability: Unix, not WASI.

uid, /

Set the current process’s user id.

Availability: Unix, not WASI, not Android.

code, /

Return the error message corresponding to the error code in code. On platforms where returns

when given an unknown error number, is raised.



if the native OS type of the environment is bytes (eg. on Windows).

Added in version 3.2.

mask, /

Set the current numeric umask and return the previous umask.

The function is a stub on WASI, see WebAssembly platforms for more information.



Returns information identifying the current operating system. The return value is an object with five attributes:

• - operating system name

• - name of machine on network (implementation-defined)

• - operating system release

• - operating system version

• - hardware identifier

For backwards compatibility, this object is also iterable, behaving like a five-tuple containing ,

, , , and in that order.

Some systems truncate to 8 characters or to the leading component; a better way to get the hostname

is or even .

On macOS, iOS and Android, this returns the kernel name and version (i.e., on macOS and iOS;

on Android). can be used to get the user-facing operating system name and

version on iOS and Android.

Availability: Unix.

Changed in version 3.3: Return type changed from a tuple to a tuple-like object with named attributes.

key, /

Unset (delete) the environment variable named key. Such changes to the environment affect subprocesses

started with , or and .

Deletion of items in is automatically translated into a corresponding call to ; how-

ever, calls to don’t update , so it is actually preferable to delete items of

.

The Python Library Reference, Release 3.13.2



Raises an auditing event with argument .

Changed in version 3.9: The function is now always available and is also available on Windows.

flags

Disassociate parts of the process execution context, and move them into a newly created namespace. See the

man page for more details. The flags argument is a bit mask, combining zero or more of the

CLONE_* constants, that specifies which parts of the execution context should be unshared from their existing

associations and moved to a new namespace. If the flags argument is , no changes are made to the calling

process’s execution context.

Availability: Linux >= 2.6.16.

Added in version 3.12.



µ See also

The function.



Flags to the function, if the implementation supports them. See in the Linux manual for their exact effect and availability.





These functions create new file objects. (See also for opening file descriptors.)

fd, *args, **kwargs

Return an open file object connected to the file descriptor fd. This is an alias of the built-in function

and accepts the same arguments. The only difference is that the first argument of must always be

an integer.





These functions operate on I/O streams referenced using file descriptors.

File descriptors are small integers corresponding to a file that has been opened by the current process. For example, standard input is usually file descriptor 0, standard output is 1, and standard error is 2. Further files opened by a process will then be assigned 3, 4, 5, and so forth. The name “file descriptor” is slightly deceptive; on Unix platforms, sockets and pipes are also referenced by file descriptors.

The method can be used to obtain the file descriptor associated with a file object when required. Note that using the file descriptor directly will bypass the file object methods, ignoring aspects such as internal buffering of data.

The Python Library Reference, Release 3.13.2



fd

Close file descriptor fd.



® Note

This function is intended for low-level I/O and must be applied to a file descriptor as returned by

or . To close a “file object” returned by the built-in function or by or

, use its method.



fd_low, fd_high, /

Close all file descriptors from fd_low (inclusive) to fd_high (exclusive), ignoring errors. Equivalent to (but

much faster than):





src, dst, count, offset_src=None, offset_dst=None

Copy count bytes from file descriptor src, starting from offset offset_src, to file descriptor dst, starting from

offset offset_dst. If offset_src is , then src is read from the current position; respectively for offset_dst.

In Linux kernel older than 5.3, the files pointed to by src and dst must reside in the same filesystem, otherwise

an is raised with set to .

This copy is done without the additional cost of transferring data from the kernel to user space and then back

into the kernel. Additionally, some filesystems could implement extra optimizations, such as the use of reflinks

(i.e., two or more inodes that share pointers to the same copy-on-write disk blocks; supported file systems

include btrfs and XFS) and server-side copy (in the case of NFS).

The function copies bytes between two file descriptors. Text options, like the encoding and the line ending,

are ignored.

The return value is the amount of bytes copied. This could be less than the amount requested.



® Note

On Linux, should not be used for copying a range of a pseudo file from a special filesystem like procfs and sysfs. It will always copy no bytes and return 0 as if the file was empty because of a known Linux kernel issue.



Availability: Linux >= 4.5 with glibc >= 2.27.

Added in version 3.8.

fd

Return a string describing the encoding of the device associated with fd if it is connected to a terminal; else

return .

On Unix, if the Python UTF-8 Mode is enabled, return rather than the device encoding.

Changed in version 3.10: On Unix, the function now implements the Python UTF-8 Mode.

fd, /

Return a duplicate of file descriptor fd. The new file descriptor is non-inheritable.

On Windows, when duplicating a standard stream (0: stdin, 1: stdout, 2: stderr), the new file descriptor is

inheritable.

Availability: not WASI.

The Python Library Reference, Release 3.13.2



Changed in version 3.4: The new file descriptor is now non-inheritable.

fd, fd2, inheritable=True

Duplicate file descriptor fd to fd2, closing the latter first if necessary. Return fd2. The new file descriptor is

inheritable by default or non-inheritable if inheritable is .

Availability: not WASI.

Changed in version 3.4: Add the optional inheritable parameter.

Changed in version 3.7: Return fd2 on success. Previously, was always returned.

fd, mode

Change the mode of the file given by fd to the numeric mode. See the docs for for possible values

of mode. As of Python 3.3, this is equivalent to .

Raises an auditing event with arguments , , .

Availability: Unix, Windows.

The function is limited on WASI, see WebAssembly platforms for more information.

Changed in version 3.13: Added support on Windows.

fd, uid, gid

Change the owner and group id of the file given by fd to the numeric uid and gid. To leave one of the ids

unchanged, set it to -1. See . As of Python 3.3, this is equivalent to .

Raises an auditing event with arguments , , , .

Availability: Unix.

The function is limited on WASI, see WebAssembly platforms for more information.

fd

Force write of file with filedescriptor fd to disk. Does not force update of metadata.

Availability: Unix.



® Note

This function is not available on MacOS.



fd, name, /

Return system configuration information relevant to an open file. name specifies the configuration value to

retrieve; it may be a string which is the name of a defined system value; these names are specified in a number

of standards (POSIX.1, Unix 95, Unix 98, and others). Some platforms define additional names as well. The

names known to the host operating system are given in the dictionary. For configuration

variables not included in that mapping, passing an integer for name is also accepted.

If name is a string and is not known, is raised. If a specific value for name is not supported by

the host system, even if it is included in , an is raised with for

the error number.

As of Python 3.3, this is equivalent to .

Availability: Unix.

fd

Get the status of the file descriptor fd. Return a object.

As of Python 3.3, this is equivalent to .



The Python Library Reference, Release 3.13.2



µ See also

The function.



fd, /

Return information about the filesystem containing the file associated with file descriptor fd, like .

As of Python 3.3, this is equivalent to .

Availability: Unix.

fd

Force write of file with filedescriptor fd to disk. On Unix, this calls the native function; on Windows,

the MS function.

If you’re starting with a buffered Python file object f, first do , and then do

, to ensure that all internal buffers associated with f are written to disk.

Availability: Unix, Windows.

fd, length, /

Truncate the file corresponding to file descriptor fd, so that it is at most length bytes in size. As of Python 3.3,

this is equivalent to .

Raises an auditing event with arguments , .

Availability: Unix, Windows.

Changed in version 3.5: Added support for Windows

fd, /

Get the blocking mode of the file descriptor: if the flag is set, if the flag is cleared.

See also and .

Availability: Unix, Windows.

The function is limited on WASI, see WebAssembly platforms for more information.

On Windows, this function is limited to pipes.

Added in version 3.5.

Changed in version 3.12: Added support for pipes on Windows.

fd, /

Grant access to the slave pseudo-terminal device associated with the master pseudo-terminal device to which

the file descriptor fd refers. The file descriptor fd is not closed upon failure.

Calls the C standard library function .

Availability: Unix, not WASI.

Added in version 3.13.

fd, /

Return if the file descriptor fd is open and connected to a tty(-like) device, else .

fd, cmd, len, /

Apply, test or remove a POSIX lock on an open file descriptor. fd is an open file descriptor. cmd specifies

the command to use - one of , , or . len specifies the section of the file to

lock.

Raises an auditing event with arguments , , .

Availability: Unix.

Added in version 3.3.

The Python Library Reference, Release 3.13.2





Flags that specify what action will take.

Availability: Unix.

Added in version 3.3.

fd, /

Prepare the tty of which fd is a file descriptor for a new login session. Make the calling process a session leader;

make the tty the controlling tty, the stdin, the stdout, and the stderr of the calling process; close fd.

Availability: Unix, not WASI.

Added in version 3.11.

fd, pos, whence, /

Set the current position of file descriptor fd to position pos, modified by whence, and return the new position

in bytes relative to the start of the file. Valid values for whence are:

• or – set pos relative to the beginning of the file

• or – set pos relative to the current file position

• or – set pos relative to the end of the file

• – set pos to the next data location, relative to pos

• – set pos to the next data hole, relative to pos

Changed in version 3.3: Add support for and .





Parameters to the function and the method on file-like objects, for whence to adjust the file

position indicator.



Adjust the file position relative to the beginning of the file.



Adjust the file position relative to the current file position.



Adjust the file position relative to the end of the file.

Their values are 0, 1, and 2, respectively.





Parameters to the function and the method on file-like objects, for seeking file data and holes

on sparsely allocated files.



Adjust the file offset to the next location containing data, relative to the seek position.



Adjust the file offset to the next location containing a hole, relative to the seek position. A hole is defined as a sequence of zeros.



The Python Library Reference, Release 3.13.2



® Note

These operations only make sense for filesystems that support them.



Availability: Linux >= 3.1, macOS, Unix

Added in version 3.3.

path, flags, mode=0o777, *, dir_fd=None

Open the file path and set various flags according to flags and possibly its mode according to mode. When

computing mode, the current umask value is first masked out. Return the file descriptor for the newly opened

file. The new file descriptor is non-inheritable.

For a description of the flag and mode values, see the C run-time documentation; flag constants (like

and ) are defined in the module. In particular, on Windows adding is needed to open

files in binary mode.

This function can support paths relative to directory descriptors with the dir_fd parameter.

Raises an auditing event with arguments , , .

Changed in version 3.4: The new file descriptor is now non-inheritable.



® Note

This function is intended for low-level I/O. For normal usage, use the built-in function , which

returns a file object with and methods (and many more). To wrap a file descriptor in a

file object, use .



Changed in version 3.3: Added the dir_fd parameter.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

function now retries the system call instead of raising an exception (see PEP 475 for

the rationale).

Changed in version 3.6: Accepts a path-like object.

The following constants are options for the flags parameter to the function. They can be combined using the bitwise OR operator . Some of them are not available on all platforms. For descriptions of their availability and

use, consult the manual page on Unix or the MSDN on Windows.





The above constants are available on Unix and Windows.





The Python Library Reference, Release 3.13.2





The above constants are only available on Unix.

Changed in version 3.3: Add constant.





The above constants are only available on Windows.





The above constants are only available on macOS.

Changed in version 3.10: Add , , and constants.





The above constants are extensions and not present if they are not defined by the C library.

Changed in version 3.4: Add on systems that support it. Add , only available on Linux

Kernel 3.11 or newer.



Open a new pseudo-terminal pair. Return a pair of file descriptors for the pty and the

tty, respectively. The new file descriptors are non-inheritable. For a (slightly) more portable approach, use the

module.

Availability: Unix, not WASI.

Changed in version 3.4: The new file descriptors are now non-inheritable.



Create a pipe. Return a pair of file descriptors usable for reading and writing, respectively. The new

file descriptor is non-inheritable.

Availability: Unix, Windows.

Changed in version 3.4: The new file descriptors are now non-inheritable.

flags, /

Create a pipe with flags set atomically. flags can be constructed by ORing together one or more of these

values: , . Return a pair of file descriptors usable for reading and writing,

respectively.

Availability: Unix, not WASI.

Added in version 3.3.

The Python Library Reference, Release 3.13.2



fd, offset, len, /

Ensures that enough disk space is allocated for the file specified by fd starting from offset and continuing for

len bytes.

Availability: Unix.

Added in version 3.3.

fd, offset, len, advice, /

Announces an intention to access data in a specific pattern thus allowing the kernel to make optimizations. The

advice applies to the region of the file specified by fd starting at offset and continuing for len bytes. advice is one

of , , , ,

or .

Availability: Unix.

Added in version 3.3.





Flags that can be used in advice in that specify the access pattern that is likely to be used.

Availability: Unix.

Added in version 3.3.

fd, n, offset, /

Read at most n bytes from file descriptor fd at a position of offset, leaving the file offset unchanged.

Return a bytestring containing the bytes read. If the end of the file referred to by fd has been reached, an

empty bytes object is returned.

Availability: Unix.

Added in version 3.3.

oflag, /

Open and return a file descriptor for a master pseudo-terminal device.

Calls the C standard library function . The oflag argument is used to set file status flags and

file access modes as specified in the manual page of of your system.

The returned file descriptor is non-inheritable. If the value is available on the system, it is added

to oflag.

Availability: Unix, not WASI.

Added in version 3.13.

fd, buffers, offset, flags=0, /

Read from a file descriptor fd at a position of offset into mutable bytes-like objects buffers, leaving the file offset

unchanged. Transfer data into each buffer until it is full and then move on to the next buffer in the sequence to

hold the rest of the data.

The flags argument contains a bitwise OR of zero or more of the following flags:

•

•



The Python Library Reference, Release 3.13.2



Return the total number of bytes actually read which can be less than the total capacity of all the objects.

The operating system may set a limit ( value ) on the number of buffers that can

be used.

Combine the functionality of and .

Availability: Linux >= 2.6.30, FreeBSD >= 6.0, OpenBSD >= 2.7, AIX >= 7.1.

Using flags requires Linux >= 4.6.

Added in version 3.7.



Do not wait for data which is not immediately available. If this flag is specified, the system call will return

instantly if it would have to read data from the backing storage or wait for a lock.

If some data was successfully read, it will return the number of bytes read. If no bytes were read, it will return

and set errno to .

Availability: Linux >= 4.14.

Added in version 3.7.



High priority read/write. Allows block-based filesystems to use polling of the device, which provides lower

latency, but may use additional resources.

Currently, on Linux, this feature is usable only on a file descriptor opened using the flag.

Availability: Linux >= 4.6.

Added in version 3.7.

fd, /

Return the name of the slave pseudo-terminal device associated with the master pseudo-terminal device to

which the file descriptor fd refers. The file descriptor fd is not closed upon failure.

Calls the reentrant C standard library function if it is available; otherwise, the C standard library

function , which is not guaranteed to be thread-safe, is called.

Availability: Unix, not WASI.

Added in version 3.13.

fd, str, offset, /

Write the bytestring in str to file descriptor fd at position of offset, leaving the file offset unchanged.

Return the number of bytes actually written.

Availability: Unix.

Added in version 3.3.

fd, buffers, offset, flags=0, /

Write the buffers contents to file descriptor fd at an offset offset, leaving the file offset unchanged. buffers must

be a sequence of bytes-like objects. Buffers are processed in array order. Entire contents of the first buffer is

written before proceeding to the second, and so on.

The flags argument contains a bitwise OR of zero or more of the following flags:

•

•

•

Return the total number of bytes actually written.

The operating system may set a limit ( value ) on the number of buffers that can

be used.

The Python Library Reference, Release 3.13.2



Combine the functionality of and .

Availability: Linux >= 2.6.30, FreeBSD >= 6.0, OpenBSD >= 2.7, AIX >= 7.1.

Using flags requires Linux >= 4.6.

Added in version 3.7.



Provide a per-write equivalent of the flag. This flag effect applies only to the data range

written by the system call.

Availability: Linux >= 4.7.

Added in version 3.7.



Provide a per-write equivalent of the flag. This flag effect applies only to the data range

written by the system call.

Availability: Linux >= 4.7.

Added in version 3.7.



Provide a per-write equivalent of the flag. This flag is meaningful only for

, and its effect applies only to the data range written by the system call. The offset argument

does not affect the write operation; the data is always appended to the end of the file. However, if the offset

argument is, the current file offset is updated.

Availability: Linux >= 4.16.

Added in version 3.10.

fd, n, /

Read at most n bytes from file descriptor fd.

Return a bytestring containing the bytes read. If the end of the file referred to by fd has been reached, an

empty bytes object is returned.



® Note

This function is intended for low-level I/O and must be applied to a file descriptor as returned by

or . To read a “file object” returned by the built-in function or by or

, or , use its or methods.



Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

function now retries the system call instead of raising an exception (see PEP 475 for

the rationale).

out_fd, in_fd, offset, count

out_fd, in_fd, offset, count, headers=(), trailers=(), flags=0

Copy count bytes from file descriptor in_fd to file descriptor out_fd starting at offset. Return the number of

bytes sent. When EOF is reached return .

The first function notation is supported by all platforms that define .

On Linux, if offset is given as , the bytes are read from the current position of in_fd and the position of

in_fd is updated.

The second case may be used on macOS and FreeBSD where headers and trailers are arbitrary sequences of

buffers that are written before and after the data from in_fd is written. It returns the same as the first case.

On macOS and FreeBSD, a value of for count specifies to send until the end of in_fd is reached.

The Python Library Reference, Release 3.13.2



All platforms support sockets as out_fd file descriptor, and some platforms allow other types (e.g. regular file,

pipe) as well.

Cross-platform applications should not use headers, trailers and flags arguments.

Availability: Unix, not WASI.



® Note

For a higher-level wrapper of , see .



Added in version 3.3.

Changed in version 3.9: Parameters out and in was renamed to out_fd and in_fd.





Parameters to the function, if the implementation supports them.

Availability: Unix, not WASI.

Added in version 3.3.



Parameter to the function, if the implementation supports it. The data won’t be cached in the

virtual memory and will be freed afterwards.

Availability: Unix, not WASI.

Added in version 3.11.

fd, blocking, /

Set the blocking mode of the specified file descriptor. Set the flag if blocking is , clear

the flag otherwise.

See also and .

Availability: Unix, Windows.

The function is limited on WASI, see WebAssembly platforms for more information.

On Windows, this function is limited to pipes.

Added in version 3.5.

Changed in version 3.12: Added support for pipes on Windows.

src, dst, count, offset_src=None, offset_dst=None

Transfer count bytes from file descriptor src, starting from offset offset_src, to file descriptor dst, starting from

offset offset_dst. At least one of the file descriptors must refer to a pipe. If offset_src is , then src is read

from the current position; respectively for offset_dst. The offset associated to the file descriptor that refers to

a pipe must be . The files pointed to by src and dst must reside in the same filesystem, otherwise an

is raised with set to .

This copy is done without the additional cost of transferring data from the kernel to user space and then back

into the kernel. Additionally, some filesystems could implement extra optimizations. The copy is done as if

both files are opened as binary.

Upon successful completion, returns the number of bytes spliced to or from the pipe. A return value of 0

means end of input. If src refers to a pipe, then this means that there was no data to transfer, and it would not

make sense to block because there are no writers connected to the write end of the pipe.

Availability: Linux >= 2.6.17 with glibc >= 2.5

Added in version 3.10.

The Python Library Reference, Release 3.13.2





Added in version 3.10.

fd, buffers, /

Read from a file descriptor fd into a number of mutable bytes-like objects buffers. Transfer data into each buffer

until it is full and then move on to the next buffer in the sequence to hold the rest of the data.

Return the total number of bytes actually read which can be less than the total capacity of all the objects.

The operating system may set a limit ( value ) on the number of buffers that can

be used.

Availability: Unix.

Added in version 3.3.

fd, /

Return the process group associated with the terminal given by fd (an open file descriptor as returned by

).

Availability: Unix, not WASI.

fd, pg, /

Set the process group associated with the terminal given by fd (an open file descriptor as returned by

) to pg.

Availability: Unix, not WASI.

fd, /

Return a string which specifies the terminal device associated with file descriptor fd. If fd is not associated

with a terminal device, an exception is raised.

Availability: Unix.

fd, /

Unlock the slave pseudo-terminal device associated with the master pseudo-terminal device to which the file

descriptor fd refers. The file descriptor fd is not closed upon failure.

Calls the C standard library function .

Availability: Unix, not WASI.

Added in version 3.13.

fd, str, /

Write the bytestring in str to file descriptor fd.

Return the number of bytes actually written.



® Note

This function is intended for low-level I/O and must be applied to a file descriptor as returned by

or . To write a “file object” returned by the built-in function or by or

, or or , use its method.



Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

function now retries the system call instead of raising an exception (see PEP 475 for

the rationale).



The Python Library Reference, Release 3.13.2



fd, buffers, /

Write the contents of buffers to file descriptor fd. buffers must be a sequence of bytes-like objects. Buffers are

processed in array order. Entire contents of the first buffer is written before proceeding to the second, and so

on.

Returns the total number of bytes actually written.

The operating system may set a limit ( value ) on the number of buffers that can

be used.

Availability: Unix.

Added in version 3.3.



Querying the size of a terminal

Added in version 3.3.

fd=STDOUT_FILENO, /

Return the size of the terminal window as , tuple of type .

The optional argument (default , or standard output) specifies which file descriptor should

be queried.

If the file descriptor is not connected to a terminal, an is raised.

is the high-level function which should normally be used,

is the low-level implementation.

Availability: Unix, Windows.



A subclass of tuple, holding of the terminal window size.



Width of the terminal window in characters.



Height of the terminal window in characters.



Inheritance of File Descriptors

Added in version 3.4.

A file descriptor has an “inheritable” flag which indicates if the file descriptor can be inherited by child processes. Since Python 3.4, file descriptors created by Python are non-inheritable by default.

On UNIX, non-inheritable file descriptors are closed in child processes at the execution of a new program, other file descriptors are inherited.

On Windows, non-inheritable handles and file descriptors are closed in child processes, except for standard streams

(file descriptors 0, 1 and 2: stdin, stdout and stderr), which are always inherited. Using functions, all inher-

itable handles and all inheritable file descriptors are inherited. Using the module, all file descriptors except standard streams are closed, and inheritable handles are only inherited if the close_fds parameter is .

On WebAssembly platforms, the file descriptor cannot be modified.

fd, /

Get the “inheritable” flag of the specified file descriptor (a boolean).

fd, inheritable, /

Set the “inheritable” flag of the specified file descriptor.



The Python Library Reference, Release 3.13.2



handle, /

Get the “inheritable” flag of the specified handle (a boolean).

Availability: Windows.

handle, inheritable, /

Set the “inheritable” flag of the specified handle.

Availability: Windows.





On some Unix platforms, many of these functions support one or more of these features:

• specifying a file descriptor: Normally the path argument provided to functions in the module must be a

string specifying a file path. However, some functions now alternatively accept an open file descriptor for their

path argument. The function will then operate on the file referred to by the descriptor. (For POSIX systems,

Python will call the variant of the function prefixed with (e.g. call instead of ).)

You can check whether or not path can be specified as a file descriptor for a particular function on your platform

using . If this functionality is unavailable, using it will raise a .

If the function also supports dir_fd or follow_symlinks arguments, it’s an error to specify one of those when

supplying path as a file descriptor.

• paths relative to directory descriptors: If dir_fd is not , it should be a file descriptor referring to a

directory, and the path to operate on should be relative; path will then be relative to that directory. If the path

is absolute, dir_fd is ignored. (For POSIX systems, Python will call the variant of the function with an

suffix and possibly prefixed with (e.g. call instead of ).

You can check whether or not dir_fd is supported for a particular function on your platform using

. If it’s unavailable, using it will raise a .

• not following symlinks: If follow_symlinks is , and the last element of the path to operate on is a

symbolic link, the function will operate on the symbolic link itself rather than the file pointed to by the link.

(For POSIX systems, Python will call the variant of the function.)

You can check whether or not follow_symlinks is supported for a particular function on your platform using

. If it’s unavailable, using it will raise a .

path, mode, *, dir_fd=None, effective_ids=False, follow_symlinks=True

Use the real uid/gid to test for access to path. Note that most operations will use the effective uid/gid, therefore

this routine can be used in a suid/sgid environment to test if the invoking user has the specified access to path.

mode should be to test the existence of path, or it can be the inclusive OR of one or more of ,

, and to test permissions. Return if access is allowed, if not. See the Unix man page

for more information.

This function can support specifying paths relative to directory descriptors and not following symlinks.

If effective_ids is , will perform its access checks using the effective uid/gid instead of the real

uid/gid. effective_ids may not be supported on your platform; you can check whether or not it is available using

. If it is unavailable, using it will raise a .



® Note

Using to check if a user is authorized to e.g. open a file before actually doing so using creates a security hole, because the user might exploit the short time interval between checking and opening

the file to manipulate it. It’s preferable to use EAFP techniques. For example:





The Python Library Reference, Release 3.13.2



is better written as:





® Note

I/O operations may fail even when indicates that they would succeed, particularly for operations on network filesystems which may have permissions semantics beyond the usual POSIX permission-bit model.



Changed in version 3.3: Added the dir_fd, effective_ids, and follow_symlinks parameters.

Changed in version 3.6: Accepts a path-like object.





Values to pass as the mode parameter of to test the existence, readability, writability and exe-

cutability of path, respectively.

path

Change the current working directory to path.

This function can support specifying a file descriptor. The descriptor must refer to an opened directory, not an

open file.

This function can raise and subclasses such as , , and

.

Raises an auditing event with argument .

Changed in version 3.3: Added support for specifying path as a file descriptor on some platforms.

Changed in version 3.6: Accepts a path-like object.

path, flags, *, follow_symlinks=True

Set the flags of path to the numeric flags. flags may take a combination (bitwise OR) of the following values

(as defined in the module):

•

•

•

•

•

•

•

•

•

The Python Library Reference, Release 3.13.2



•

•

•

This function can support not following symlinks.

Raises an auditing event with arguments , .

Availability: Unix, not WASI.

Changed in version 3.3: Added the follow_symlinks parameter.

Changed in version 3.6: Accepts a path-like object.

path, mode, *, dir_fd=None, follow_symlinks=True

Change the mode of path to the numeric mode. mode may take one of the following values (as defined in the

module) or bitwise ORed combinations of them:

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

This function can support specifying a file descriptor, paths relative to directory descriptors and not following

symlinks.



® Note

Although Windows supports , you can only set the file’s read-only flag with it (via the and constants or a corresponding integer value). All other bits are ignored. The default value of follow_symlinks is on Windows.

The function is limited on WASI, see WebAssembly platforms for more information.



Raises an auditing event with arguments , , .

The Python Library Reference, Release 3.13.2



Changed in version 3.3: Added support for specifying path as an open file descriptor, and the dir_fd and

follow_symlinks arguments.

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.13: Added support for a file descriptor and the follow_symlinks argument on Windows.

path, uid, gid, *, dir_fd=None, follow_symlinks=True

Change the owner and group id of path to the numeric uid and gid. To leave one of the ids unchanged, set it

to -1.

This function can support specifying a file descriptor, paths relative to directory descriptors and not following

symlinks.

See for a higher-level function that accepts names in addition to numeric ids.

Raises an auditing event with arguments , , , .

Availability: Unix.

The function is limited on WASI, see WebAssembly platforms for more information.

Changed in version 3.3: Added support for specifying path as an open file descriptor, and the dir_fd and

follow_symlinks arguments.

Changed in version 3.6: Supports a path-like object.

path

Change the root directory of the current process to path.

Availability: Unix, not WASI, not Android.

Changed in version 3.6: Accepts a path-like object.

fd

Change the current working directory to the directory represented by the file descriptor fd. The descriptor

must refer to an opened directory, not an open file. As of Python 3.3, this is equivalent to .

Raises an auditing event with argument .

Availability: Unix.



Return a string representing the current working directory.



Return a bytestring representing the current working directory.

Changed in version 3.8: The function now uses the UTF-8 encoding on Windows, rather than the ANSI code

page: see PEP 529 for the rationale. The function is no longer deprecated on Windows.

path, flags

Set the flags of path to the numeric flags, like , but do not follow symbolic links. As of Python

3.3, this is equivalent to .

Raises an auditing event with arguments , .

Availability: Unix, not WASI.

Changed in version 3.6: Accepts a path-like object.

path, mode

Change the mode of path to the numeric mode. If path is a symlink, this affects the symlink rather than

the target. See the docs for for possible values of mode. As of Python 3.3, this is equivalent to

.

is not part of POSIX, but Unix implementations may have it if changing the mode of symbolic

links is supported.

The Python Library Reference, Release 3.13.2



Raises an auditing event with arguments , , .

Availability: Unix, Windows, not Linux, FreeBSD >= 1.3, NetBSD >= 1.3, not OpenBSD

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.13: Added support on Windows.

path, uid, gid

Change the owner and group id of path to the numeric uid and gid. This function will not follow symbolic links.

As of Python 3.3, this is equivalent to .

Raises an auditing event with arguments , , , .

Availability: Unix.

Changed in version 3.6: Accepts a path-like object.

src, dst, *, src_dir_fd=None, dst_dir_fd=None, follow_symlinks=True

Create a hard link pointing to src named dst.

This function can support specifying src_dir_fd and/or dst_dir_fd to supply paths relative to directory descrip-

tors, and not following symlinks.

Raises an auditing event with arguments , , , .

Availability: Unix, Windows.

Changed in version 3.2: Added Windows support.

Changed in version 3.3: Added the src_dir_fd, dst_dir_fd, and follow_symlinks parameters.

Changed in version 3.6: Accepts a path-like object for src and dst.

path=’.’

Return a list containing the names of the entries in the directory given by path. The list is in arbitrary order, and

does not include the special entries and even if they are present in the directory. If a file is removed

from or added to the directory during the call of this function, whether a name for that file be included is

unspecified.

path may be a path-like object. If path is of type (directly or indirectly through the interface),

the filenames returned will also be of type ; in all other circumstances, they will be of type .

This function can also support specifying a file descriptor; the file descriptor must refer to a directory.

Raises an auditing event with argument .



® Note

To encode filenames to , use .



µ See also

The function returns directory entries along with file attribute information, giving better per-formance for many common use cases.



Changed in version 3.2: The path parameter became optional.

Changed in version 3.3: Added support for specifying path as an open file descriptor.

Changed in version 3.6: Accepts a path-like object.



The Python Library Reference, Release 3.13.2





Return a list containing the names of drives on a Windows system.

A drive name typically looks like . Not every drive name will be associated with a volume, and some

may be inaccessible for a variety of reasons, including permissions, network connectivity or missing media.

This function does not test for access.

May raise if an error occurs collecting the drive names.

Raises an auditing event with no arguments.

Availability: Windows

Added in version 3.12.

volume

Return a list containing the mount points for a volume on a Windows system.

volume must be represented as a GUID path, like those returned by . Volumes may be

mounted in multiple locations or not at all. In the latter case, the list will be empty. Mount points that are not

associated with a volume will not be returned by this function.

The mount points return by this function will be absolute paths, and may be longer than the drive name.

Raises if the volume is not recognized or if an error occurs collecting the paths.

Raises an auditing event with argument .

Availability: Windows

Added in version 3.12.



Return a list containing the volumes in the system.

Volumes are typically represented as a GUID path that looks like

.

GUID path, permissions allowing.

recommended use of this function is to retrieve mount points using .

May raise if an error occurs collecting the volumes.

Raises an auditing event with no arguments.

Availability: Windows

Added in version 3.12.

path, *, dir_fd=None

Perform the equivalent of an system call on the given path. Similar to , but does not follow

symbolic links. Return a object.

On platforms that do not support symbolic links, this is an alias for .

As of Python 3.3, this is equivalent to .

This function can also support paths relative to directory descriptors.



µ See also

The function.



Changed in version 3.2: Added support for Windows 6.0 (Vista) symbolic links.

Changed in version 3.3: Added the dir_fd parameter.

Changed in version 3.6: Accepts a path-like object.

The Python Library Reference, Release 3.13.2



Changed in version 3.8: On Windows, now opens reparse points that represent another path (name surrogates),

including symbolic links and directory junctions. Other kinds of reparse points are resolved by the operating

system as for .

path, mode=0o777, *, dir_fd=None

Create a directory named path with numeric mode mode.

If the directory already exists, is raised. If a parent directory in the path does not exist,

is raised.

On some systems, mode is ignored. Where it is used, the current umask value is first masked out. If bits

other than the last 9 (i.e. the last 3 digits of the octal representation of the mode) are set, their meaning is

platform-dependent. On some platforms, they are ignored and you should call explicitly to set them.

On Windows, a mode of is specifically handled to apply access control to the new directory such that

only the current user and administrators have access. Other values of mode are ignored.

This function can also support paths relative to directory descriptors.

It is also possible to create temporary directories; see the module’s func-

tion.

Raises an auditing event with arguments , , .

Changed in version 3.3: Added the dir_fd parameter.

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.13: Windows now handles a mode of .

name, mode=0o777, exist_ok=False

Recursive directory creation function. Like , but makes all intermediate-level directories needed to

contain the leaf directory.

The mode parameter is passed to for creating the leaf directory; see the mkdir() description for how

it is interpreted. To set the file permission bits of any newly created parent directories you can set the umask

before invoking . The file permission bits of existing parent directories are not changed.

If exist_ok is (the default), a is raised if the target directory already exists.



® Note

will become confused if the path elements to create include (eg. “..” on UNIX systems).



This function handles UNC paths correctly.

Raises an auditing event with arguments , , .

Changed in version 3.2: Added the exist_ok parameter.

Changed in version 3.4.1: Before Python 3.4.1, if exist_ok was and the directory existed,

would still raise an error if mode did not match the mode of the existing directory. Since this behavior was

impossible to implement safely, it was removed in Python 3.4.1. See bpo-21082.

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.7: The mode argument no longer affects the file permission bits of newly created

intermediate-level directories.

path, mode=0o666, *, dir_fd=None

Create a FIFO (a named pipe) named path with numeric mode mode. The current umask value is first masked

out from the mode.

This function can also support paths relative to directory descriptors.

The Python Library Reference, Release 3.13.2



FIFOs are pipes that can be accessed like regular files. FIFOs exist until they are deleted (for example with

). Generally, FIFOs are used as rendezvous between “client” and “server” type processes: the

server opens the FIFO for reading, and the client opens it for writing. Note that doesn’t open the

FIFO — it just creates the rendezvous point.

Availability: Unix, not WASI.

Changed in version 3.3: Added the dir_fd parameter.

Changed in version 3.6: Accepts a path-like object.

path, mode=0o600, device=0, *, dir_fd=None

Create a filesystem node (file, device special file or named pipe) named path. mode specifies both the

permissions to use and the type of node to be created, being combined (bitwise OR) with one of

, , , and (those constants are available in ).

For and , device defines the newly created device special file (probably using

), otherwise it is ignored.

This function can also support paths relative to directory descriptors.

Availability: Unix, not WASI.

Changed in version 3.3: Added the dir_fd parameter.

Changed in version 3.6: Accepts a path-like object.

device, /

Extract the device major number from a raw device number (usually the or field from ).

device, /

Extract the device minor number from a raw device number (usually the or field from

).

major, minor, /

Compose a raw device number from the major and minor device numbers.

path, name

Return system configuration information relevant to a named file. name specifies the configuration value to

retrieve; it may be a string which is the name of a defined system value; these names are specified in a number

of standards (POSIX.1, Unix 95, Unix 98, and others). Some platforms define additional names as well. The

names known to the host operating system are given in the dictionary. For configuration

variables not included in that mapping, passing an integer for name is also accepted.

If name is a string and is not known, is raised. If a specific value for name is not supported by

the host system, even if it is included in , an is raised with for

the error number.

This function can support specifying a file descriptor.

Availability: Unix.

Changed in version 3.6: Accepts a path-like object.



Dictionary mapping names accepted by and to the integer values defined for

those names by the host operating system. This can be used to determine the set of names known to the

system.

Availability: Unix.

path, *, dir_fd=None

Return a string representing the path to which the symbolic link points. The result may be either an absolute

or relative pathname; if it is relative, it may be converted to an absolute pathname using

.

The Python Library Reference, Release 3.13.2



If the path is a string object (directly or indirectly through a interface), the result will also be a

string object, and the call may raise a UnicodeDecodeError. If the path is a bytes object (direct or indirectly),

the result will be a bytes object.

This function can also support paths relative to directory descriptors.

When trying to resolve a path that may contain links, use to properly handle recursion and

platform differences.

Availability: Unix, Windows.

Changed in version 3.2: Added support for Windows 6.0 (Vista) symbolic links.

Changed in version 3.3: Added the dir_fd parameter.

Changed in version 3.6: Accepts a path-like object on Unix.

Changed in version 3.8: Accepts a path-like object and a bytes object on Windows.

Added support for directory junctions, and changed to return the substitution path (which typically includes

prefix) rather than the optional “print name” field that was previously returned.

path, *, dir_fd=None

Remove (delete) the file path. If path is a directory, an is raised. Use to remove directories.

If the file does not exist, a is raised.

This function can support paths relative to directory descriptors.

On Windows, attempting to remove a file that is in use causes an exception to be raised; on Unix, the directory

entry is removed but the storage allocated to the file is not made available until the original file is no longer in

use.

This function is semantically identical to .

Raises an auditing event with arguments , .

Changed in version 3.3: Added the dir_fd parameter.

Changed in version 3.6: Accepts a path-like object.

name

Remove directories recursively. Works like except that, if the leaf directory is successfully re-

moved, tries to successively remove every parent directory mentioned in path until an error

is raised (which is ignored, because it generally means that a parent directory is not empty). For example,

will first remove the directory , and then remove

and if they are empty. Raises if the leaf directory could not be successfully removed.

Raises an auditing event with arguments , .

Changed in version 3.6: Accepts a path-like object.

src, dst, *, src_dir_fd=None, dst_dir_fd=None

Rename the file or directory src to dst. If dst exists, the operation will fail with an subclass in a

number of cases:

On Windows, if dst exists a is always raised. The operation may fail if src and dst are on

different filesystems. Use to support moves to a different filesystem.

On Unix, if src is a file and dst is a directory or vice-versa, an or a

will be raised respectively. If both are directories and dst is empty, dst will be silently

replaced. If dst is a non-empty directory, an is raised. If both are files, dst will be replaced silently if

the user has permission. The operation may fail on some Unix flavors if src and dst are on different filesystems.

If successful, the renaming will be an atomic operation (this is a POSIX requirement).

This function can support specifying src_dir_fd and/or dst_dir_fd to supply paths relative to directory descrip-

tors.

If you want cross-platform overwriting of the destination, use .

The Python Library Reference, Release 3.13.2



Raises an auditing event with arguments , , , .

Changed in version 3.3: Added the src_dir_fd and dst_dir_fd parameters.

Changed in version 3.6: Accepts a path-like object for src and dst.

old, new

Recursive directory or file renaming function. Works like , except creation of any intermediate

directories needed to make the new pathname good is attempted first. After the rename, directories corre-

sponding to rightmost path segments of the old name will be pruned away using .



® Note

This function can fail with the new directory structure made if you lack permissions needed to remove the leaf directory or file.



Raises an auditing event with arguments , , , .

Changed in version 3.6: Accepts a path-like object for old and new.

src, dst, *, src_dir_fd=None, dst_dir_fd=None

Rename the file or directory src to dst. If dst is a non-empty directory, will be raised. If dst exists

and is a file, it will be replaced silently if the user has permission. The operation may fail if src and dst are on

different filesystems. If successful, the renaming will be an atomic operation (this is a POSIX requirement).

This function can support specifying src_dir_fd and/or dst_dir_fd to supply paths relative to directory descrip-

tors.

Raises an auditing event with arguments , , , .

Added in version 3.3.

Changed in version 3.6: Accepts a path-like object for src and dst.

path, *, dir_fd=None

Remove (delete) the directory path. If the directory does not exist or is not empty, a

or an is raised respectively. In order to remove whole directory trees, can be

used.

This function can support paths relative to directory descriptors.

Raises an auditing event with arguments , .

Changed in version 3.3: Added the dir_fd parameter.

Changed in version 3.6: Accepts a path-like object.

path=’.’

Return an iterator of objects corresponding to the entries in the directory given by path. The

entries are yielded in arbitrary order, and the special entries and are not included. If a file is removed

from or added to the directory after creating the iterator, whether an entry for that file be included is unspecified.

Using instead of can significantly increase the performance of code that also needs

file type or file attribute information, because objects expose this information if the operating

system provides it when scanning a directory. All methods may perform a system call, but

and usually only require a system call for symbolic links;

always requires a system call on Unix but only requires one for symbolic links on Windows.

path may be a path-like object. If path is of type (directly or indirectly through the interface),

the type of the and attributes of each will be ; in all other circumstances,

they will be of type .

This function can also support specifying a file descriptor; the file descriptor must refer to a directory.

Raises an auditing event with argument .

The Python Library Reference, Release 3.13.2



The iterator supports the context manager protocol and has the following method:



Close the iterator and free acquired resources.

This is called automatically when the iterator is exhausted or garbage collected, or when an error happens during iterating. However it is advisable to call it explicitly or use the statement.

Added in version 3.6.

The following example shows a simple use of to display all the files (excluding directories) in the

given path that don’t start with . The call will generally not make an additional system

call:





® Note

On Unix-based systems, uses the system’s opendir() and readdir() functions. On Windows, it

uses the Win32 FindFirstFileW and FindNextFileW functions.



Added in version 3.5.

Changed in version 3.6: Added support for the context manager protocol and the method. If a

iterator is neither exhausted nor explicitly closed a will be emitted in its

destructor.

The function accepts a path-like object.

Changed in version 3.7: Added support for file descriptors on Unix.



Object yielded by to expose the file path and other file attributes of a directory entry.

will provide as much of this information as possible without making additional system calls. When

a or system call is made, the object will cache the result.

instances are not intended to be stored in long-lived data structures; if you know the file meta-

data has changed or if a long time has elapsed since calling , call to

fetch up-to-date information.

Because the methods can make operating system calls, they may also raise . If you

need very fine-grained control over errors, you can catch when calling one of the

methods and handle as appropriate.

To be directly usable as a path-like object, implements the interface.

Attributes and methods on a instance are as follows:



The entry’s base filename, relative to the path argument.

The attribute will be if the path argument is of type and otherwise.

Use to decode byte filenames.



The entry’s full path name: equivalent to where

scandir_path is the path argument. The path is only absolute if the path ar-

gument was absolute. If the path argument was a file descriptor, the attribute is the

same as the attribute.

The Python Library Reference, Release 3.13.2



The attribute will be if the path argument is of type and otherwise.

Use to decode byte filenames.



Return the inode number of the entry.

The result is cached on the object. Use to fetch up-to-date information.

On the first, uncached call, a system call is required on Windows but not on Unix.

*, follow_symlinks=True

Return if this entry is a directory or a symbolic link pointing to a directory; return if the entry is or points to any other kind of file, or if it doesn’t exist anymore.

If follow_symlinks is , return only if this entry is a directory (without following symlinks); return if the entry is any other kind of file or if it doesn’t exist anymore.

The result is cached on the object, with a separate cache for follow_symlinks and

. Call along with to fetch up-to-date information.

On the first, uncached call, no system call is required in most cases. Specifically, for non-symlinks, neither Windows or Unix require a system call, except on certain Unix file systems, such as network file systems, that return . If the entry is a symlink, a system call will be required to follow the symlink unless follow_symlinks is .

This method can raise , such as , but is caught and not raised.

*, follow_symlinks=True

Return if this entry is a file or a symbolic link pointing to a file; return if the entry is or points to a directory or other non-file entry, or if it doesn’t exist anymore.

If follow_symlinks is , return only if this entry is a file (without following symlinks); return if the entry is a directory or other non-file entry, or if it doesn’t exist anymore.

The result is cached on the object. Caching, system calls made, and exceptions raised are

as per .



Return if this entry is a symbolic link (even if broken); return if the entry points to a directory or any kind of file, or if it doesn’t exist anymore.

The result is cached on the object. Call to fetch up-to-date infor-mation.

On the first, uncached call, no system call is required in most cases. Specifically, neither Windows or Unix require a system call, except on certain Unix file systems, such as network file systems, that return .

This method can raise , such as , but is caught and not raised.



Return if this entry is a junction (even if broken); return if the entry points to a regular directory, any kind of file, a symlink, or if it doesn’t exist anymore.

The result is cached on the object. Call to fetch up-to-date information.

Added in version 3.12.

*, follow_symlinks=True

Return a object for this entry. This method follows symbolic links by default; to stat a symbolic link add the argument.

The Python Library Reference, Release 3.13.2



On Unix, this method always requires a system call. On Windows, it only requires a system call if fol-low_symlinks is and the entry is a reparse point (for example, a symbolic link or directory junction).

On Windows, the , and attributes of the are always set to

zero. Call to get these attributes.

The result is cached on the object, with a separate cache for follow_symlinks and

. Call to fetch up-to-date information.

Note that there is a nice correspondence between several attributes and methods of and of

. In particular, the attribute has the same meaning, as do the , ,

, , and methods.

Added in version 3.5.

Changed in version 3.6: Added support for the interface. Added support for paths on

Windows.

Changed in version 3.12: The attribute of a stat result is deprecated on Windows. The file creation

time is properly available as , and in the future may be changed to return zero or

the metadata change time, if available.

path, *, dir_fd=None, follow_symlinks=True

Get the status of a file or a file descriptor. Perform the equivalent of a system call on the given path.

path may be specified as either a string or bytes – directly or indirectly through the interface – or

as an open file descriptor. Return a object.

This function normally follows symlinks; to stat a symlink add the argument , or

use .

This function can support specifying a file descriptor and not following symlinks.

On Windows, passing will disable following all name-surrogate reparse points,

which includes symlinks and directory junctions. Other types of reparse points that do not resemble links or

that the operating system is unable to follow will be opened directly. When following a chain of multiple links,

this may result in the original link being returned instead of the non-link that prevented full traversal. To obtain

stat results for the final path in this case, use the function to resolve the path name as

far as possible and call on the result. This does not apply to dangling symlinks or junction points,

which will raise the usual exceptions.

Example:





µ See also

and functions.



Changed in version 3.3: Added the dir_fd and follow_symlinks parameters, specifying a file descriptor instead

of a path.

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.8: On Windows, all reparse points that can be resolved by the operating system are now

followed, and passing disables following all name surrogate reparse points. If the The Python Library Reference, Release 3.13.2



operating system reaches a reparse point that it is not able to follow, stat now returns the information for the

original path as if had been specified instead of raising an error.



Object whose attributes correspond roughly to the members of the structure. It is used for the result of

, and .

Attributes:



File mode: file type and file mode bits (permissions).



Platform dependent, but if non-zero, uniquely identifies the file for a given value of . Typically:

• the inode number on Unix,

• the file index on Windows



Identifier of the device on which this file resides.



Number of hard links.



User identifier of the file owner.



Group identifier of the file owner.



Size of the file in bytes, if it is a regular file or a symbolic link. The size of a symbolic link is the length of the pathname it contains, without a terminating null byte.

Timestamps:



Time of most recent access expressed in seconds.



Time of most recent content modification expressed in seconds.



Time of most recent metadata change expressed in seconds.

Changed in version 3.12: is deprecated on Windows. Use for the file creation time. In the future, will contain the time of the most recent metadata change, as for other platforms.



Time of most recent access expressed in nanoseconds as an integer.

Added in version 3.3.



Time of most recent content modification expressed in nanoseconds as an integer.

Added in version 3.3.



Time of most recent metadata change expressed in nanoseconds as an integer.

Added in version 3.3.

The Python Library Reference, Release 3.13.2



Changed in version 3.12: is deprecated on Windows. Use for the file creation time. In the future, will contain the time of the most recent metadata change, as for other platforms.



Time of file creation expressed in seconds. This attribute is not always available, and may raise

.

Changed in version 3.12: is now available on Windows.



Time of file creation expressed in nanoseconds as an integer. This attribute is not always available, and

may raise .

Added in version 3.12.



® Note

The exact meaning and resolution of the , , and at-tributes depend on the operating system and the file system. For example, on Windows systems using

the FAT32 file systems, has 2-second resolution, and has only 1-day resolution. See your operating system documentation for details.

Similarly, although , , and are always expressed in nanoseconds, many systems do not provide nanosecond precision. On systems that do pro-

vide nanosecond precision, the floating-point object used to store , , and

cannot preserve all of it, and as such will be slightly inexact. If you need the exact times-

tamps you should always use , , and .



On some Unix systems (such as Linux), the following attributes may also be available:



Number of 512-byte blocks allocated for file. This may be smaller than /512 when the file has holes.



“Preferred” blocksize for efficient file system I/O. Writing to a file in smaller chunks may cause an inef-ficient read-modify-rewrite.



Type of device if an inode device.



User defined flags for file.

On other Unix systems (such as FreeBSD), the following attributes may be available (but may be only filled

out if root tries to use them):



File generation number.

On Solaris and derivatives, the following attributes may also be available:



String that uniquely identifies the type of the filesystem that contains the file.

On macOS systems, the following attributes may also be available:



Real size of the file.



Creator of the file.

The Python Library Reference, Release 3.13.2





File type.

On Windows systems, the following attributes are also available:



Windows file attributes: member of the structure returned by . See the

constants in the module.

Added in version 3.5.



When has the set, this field contains the

tag identifying the type of reparse point. See the constants in the module.

The standard module defines functions and constants that are useful for extracting information from a

structure. (On Windows, some items are filled with dummy values.)

For backward compatibility, a instance is also accessible as a tuple of at least 10 integers giving

the most important (and portable) members of the structure, in the order , , ,

, , , , , , . More items may be added at

the end by some implementations. For compatibility with older Python versions, accessing as

a tuple always returns integers.

Changed in version 3.5: Windows now returns the file index as when available.

Changed in version 3.7: Added the member to Solaris/derivatives.

Changed in version 3.8: Added the member on Windows.

Changed in version 3.8: On Windows, the member now identifies special files as ,

or as appropriate.

Changed in version 3.12: On Windows, is deprecated. Eventually, it will contain the last metadata

change time, for consistency with other platforms, but for now still contains creation time. Use

for the creation time.

On Windows, may now be up to 128 bits, depending on the file system. Previously it would not be

above 64 bits, and larger file identifiers would be arbitrarily packed.

On Windows, no longer returns a value. Previously it would contain the same as , which

was incorrect.

Added the member on Windows.

path

Perform a system call on the given path. The return value is an object whose attributes describe

the filesystem on the given path, and correspond to the members of the structure, namely: ,

, , , , , , , , ,

.

Two module-level constants are defined for the attribute’s bit-flags: if is set, the filesystem

is mounted read-only, and if is set, the semantics of setuid/setgid bits are disabled or not supported.

Additional module-level constants are defined for GNU/glibc based systems. These are

(disallow access to device special files), (disallow program execution),

(writes are synced at once), (allow mandatory locks on an FS), (write on

file/directory/symlink), (append-only file), (immutable file), (do

not update access times), (do not update directory access times), (update

atime relative to mtime/ctime).

This function can support specifying a file descriptor.

Availability: Unix.

Changed in version 3.2: The and constants were added.

The Python Library Reference, Release 3.13.2



Changed in version 3.3: Added support for specifying path as an open file descriptor.

Changed in version 3.4: The , , , , ,

, , , , and constants were added.

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.7: Added the attribute.



A object indicating which functions in the module accept an open file descriptor for their dir_fd

parameter. Different platforms provide different features, and the underlying functionality Python uses to

implement the dir_fd parameter is not available on all platforms Python supports. For consistency’s sake,

functions that may support dir_fd always allow specifying the parameter, but will throw an exception if the

functionality is used when it’s not locally available. (Specifying for dir_fd is always supported on all

platforms.)

To check whether a particular function accepts an open file descriptor for its dir_fd parameter, use the

operator on . As an example, this expression evaluates to if accepts

open file descriptors for dir_fd on the local platform:





Currently dir_fd parameters only work on Unix platforms; none of them work on Windows.

Added in version 3.3.



A object indicating whether permits specifying for its effective_ids parameter on the

local platform. (Specifying for effective_ids is always supported on all platforms.) If the local platform

supports it, the collection will contain ; otherwise it will be empty.

This expression evaluates to if supports on the local platform:





Currently effective_ids is only supported on Unix platforms; it does not work on Windows.

Added in version 3.3.



A object indicating which functions in the module permit specifying their path parameter as an open file

descriptor on the local platform. Different platforms provide different features, and the underlying functionality

Python uses to accept open file descriptors as path arguments is not available on all platforms Python supports.

To determine whether a particular function permits specifying an open file descriptor for its path parameter,

use the operator on . As an example, this expression evaluates to if

accepts open file descriptors for path on your local platform:





Added in version 3.3.



A object indicating which functions in the module accept for their follow_symlinks parameter

on the local platform. Different platforms provide different features, and the underlying functionality Python

uses to implement follow_symlinks is not available on all platforms Python supports. For consistency’s sake,

functions that may support follow_symlinks always allow specifying the parameter, but will throw an exception

if the functionality is used when it’s not locally available. (Specifying for follow_symlinks is always

supported on all platforms.)

To check whether a particular function accepts for its follow_symlinks parameter, use the operator

on . As an example, this expression evaluates to if you may specify

when calling on the local platform:

The Python Library Reference, Release 3.13.2





Added in version 3.3.

src, dst, target_is_directory=False, *, dir_fd=None

Create a symbolic link pointing to src named dst.

On Windows, a symlink represents either a file or a directory, and does not morph to the target dynamically. If

the target is present, the type of the symlink will be created to match. Otherwise, the symlink will be created as

a directory if target_is_directory is or a file symlink (the default) otherwise. On non-Windows platforms,

target_is_directory is ignored.

This function can support paths relative to directory descriptors.



® Note

On newer versions of Windows 10, unprivileged accounts can create symlinks if Developer Mode is en-abled. When Developer Mode is not available/enabled, the SeCreateSymbolicLinkPrivilege privilege is re-quired, or the process must be run as an administrator.

is raised when the function is called by an unprivileged user.



Raises an auditing event with arguments , , .

Availability: Unix, Windows.

The function is limited on WASI, see WebAssembly platforms for more information.

Changed in version 3.2: Added support for Windows 6.0 (Vista) symbolic links.

Changed in version 3.3: Added the dir_fd parameter, and now allow target_is_directory on non-Windows

platforms.

Changed in version 3.6: Accepts a path-like object for src and dst.

Changed in version 3.8: Added support for unelevated symlinks on Windows with Developer Mode.



Force write of everything to disk.

Availability: Unix.

Added in version 3.3.

path, length

Truncate the file corresponding to path, so that it is at most length bytes in size.

This function can support specifying a file descriptor.

Raises an auditing event with arguments , .

Availability: Unix, Windows.

Added in version 3.3.

Changed in version 3.5: Added support for Windows

Changed in version 3.6: Accepts a path-like object.

path, *, dir_fd=None

Remove (delete) the file path. This function is semantically identical to ; the name is its

traditional Unix name. Please see the documentation for for further information.

Raises an auditing event with arguments , .

Changed in version 3.3: Added the dir_fd parameter.

Changed in version 3.6: Accepts a path-like object.

The Python Library Reference, Release 3.13.2



path, times=None, *, ns, dir_fd=None, follow_symlinks=True

Set the access and modified times of the file specified by path.

takes two optional parameters, times and ns. These specify the times set on path and are used as

follows:

• If ns is specified, it must be a 2-tuple of the form where each member is an

int expressing nanoseconds.

• If times is not , it must be a 2-tuple of the form where each member is an int or

float expressing seconds.

• If times is and ns is unspecified, this is equivalent to specifying

where both times are the current time.

It is an error to specify tuples for both times and ns.

Note that the exact times you set here may not be returned by a subsequent call, depending on the

resolution with which your operating system records access and modification times; see . The best

way to preserve exact times is to use the st_atime_ns and st_mtime_ns fields from the result object

with the ns parameter to .

This function can support specifying a file descriptor, paths relative to directory descriptors and not following

symlinks.

Raises an auditing event with arguments , , , .

Changed in version 3.3: Added support for specifying path as an open file descriptor, and the dir_fd, fol-

low_symlinks, and ns parameters.

Changed in version 3.6: Accepts a path-like object.

top, topdown=True, onerror=None, followlinks=False

Generate the file names in a directory tree by walking the tree either top-down or bottom-up. For each di-

rectory in the tree rooted at directory top (including top itself), it yields a 3-tuple

.

dirpath is a string, the path to the directory. dirnames is a list of the names of the subdirectories in dirpath

(including symlinks to directories, and excluding and ). filenames is a list of the names of the non-

directory files in dirpath. Note that the names in the lists contain no path components. To get a full path (which

begins with top) to a file or directory in dirpath, do . Whether or not the

lists are sorted depends on the file system. If a file is removed from or added to the dirpath directory during

generating the lists, whether a name for that file be included is unspecified.

If optional argument topdown is or not specified, the triple for a directory is generated before the triples

for any of its subdirectories (directories are generated top-down). If topdown is , the triple for a directory

is generated after the triples for all of its subdirectories (directories are generated bottom-up). No matter the

value of topdown, the list of subdirectories is retrieved before the tuples for the directory and its subdirectories

are generated.

When topdown is , the caller can modify the dirnames list in-place (perhaps using or slice assign-

ment), and will only recurse into the subdirectories whose names remain in dirnames; this can be

used to prune the search, impose a specific order of visiting, or even to inform about directories the

caller creates or renames before it resumes again. Modifying dirnames when topdown is has

no effect on the behavior of the walk, because in bottom-up mode the directories in dirnames are generated

before dirpath itself is generated.

By default, errors from the call are ignored. If optional argument onerror is specified, it should

be a function; it will be called with one argument, an instance. It can report the error to continue

with the walk, or raise the exception to abort the walk. Note that the filename is available as the

attribute of the exception object.

By default, will not walk down into symbolic links that resolve to directories. Set followlinks to

to visit directories pointed to by symlinks, on systems that support them.

The Python Library Reference, Release 3.13.2



® Note

Be aware that setting followlinks to can lead to infinite recursion if a link points to a parent directory

of itself. does not keep track of the directories it visited already.



® Note

If you pass a relative pathname, don’t change the current working directory between resumptions of

. never changes the current directory, and assumes that its caller doesn’t either.



This example displays the number of bytes taken by non-directory files in each directory under the starting

directory, except that it doesn’t look under any CVS subdirectory:





In the next example (simple implementation of ), walking the tree bottom-up is essential,

doesn’t allow deleting a directory before the directory is empty:





Raises an auditing event with arguments , , , .

Changed in version 3.5: This function now calls instead of , making it faster

by reducing the number of calls to .

Changed in version 3.6: Accepts a path-like object.

top=’.’, topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=None

This behaves exactly like , except that it yields a 4-tuple

, and it supports .

dirpath, dirnames and filenames are identical to output, and dirfd is a file descriptor referring to the

directory dirpath.

This function always supports paths relative to directory descriptors and not following symlinks. Note however

that, unlike other functions, the default value for follow_symlinks is .



® Note



The Python Library Reference, Release 3.13.2



Since yields file descriptors, those are only valid until the next iteration step, so you should

duplicate them (e.g. with ) if you want to keep them longer.



This example displays the number of bytes taken by non-directory files in each directory under the starting

directory, except that it doesn’t look under any CVS subdirectory:





In the next example, walking the tree bottom-up is essential: doesn’t allow deleting a directory before

the directory is empty:





Raises an auditing event with arguments , , , , .

Availability: Unix.

Added in version 3.3.

Changed in version 3.6: Accepts a path-like object.

Changed in version 3.7: Added support for paths.

name, flags=os.MFD_CLOEXEC

Create an anonymous file and return a file descriptor that refers to it. flags must be one of the

constants available on the system (or a bitwise ORed combination of them). By default, the new file descriptor

is non-inheritable.

The name supplied in name is used as a filename and will be displayed as the target of the corresponding

symbolic link in the directory . The displayed name is always prefixed with and

serves only for debugging purposes. Names do not affect the behavior of the file descriptor, and as such multiple

files can have the same name without any side effects.

Availability: Linux >= 3.17 with glibc >= 2.27.

Added in version 3.8.





The Python Library Reference, Release 3.13.2





These flags can be passed to .

Availability: Linux >= 3.17 with glibc >= 2.27

The flags are only available since Linux 4.14.

Added in version 3.8.

initval, flags=os.EFD_CLOEXEC

Create and return an event file descriptor. The file descriptors supports raw and with a buffer

size of 8, , and similar. See man page for more information. By default, the

new file descriptor is non-inheritable.

initval is the initial value of the event counter. The initial value must be a 32 bit unsigned integer. Please note

that the initial value is limited to a 32 bit unsigned int although the event counter is an unsigned 64 bit integer

with a maximum value of 2-2.

flags can be constructed from , , and .

If is specified and the event counter is non-zero, returns 1 and decre-

ments the counter by one.

If is not specified and the event counter is non-zero, returns the current

event counter value and resets the counter to zero.

If the event counter is zero and is not specified, blocks.

increments the event counter. Write blocks if the write operation would increment the

counter to a value larger than 2 -2.

Example:





Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.10.

The Python Library Reference, Release 3.13.2



fd

Read value from an file descriptor and return a 64 bit unsigned int. The function does not verify

that fd is an .

Availability: Linux >= 2.6.27

Added in version 3.10.

fd, value

Add value to an file descriptor. value must be a 64 bit unsigned int. The function does not verify

that fd is an .

Availability: Linux >= 2.6.27

Added in version 3.10.



Set close-on-exec flag for new file descriptor.

Availability: Linux >= 2.6.27

Added in version 3.10.



Set status flag for new file descriptor.

Availability: Linux >= 2.6.27

Added in version 3.10.



Provide semaphore-like semantics for reads from an file descriptor. On read the internal counter

is decremented by one.

Availability: Linux >= 2.6.30

Added in version 3.10.



Timer File Descriptors

Added in version 3.13.

These functions provide support for Linux’s timer file descriptor API. Naturally, they are all only available on Linux.

clockid, / , *, flags=0

Create and return a timer file descriptor (timerfd).

The file descriptor returned by supports:

•

•

•

The file descriptor’s method can be called with a buffer size of 8. If the timer has already expired one

or more times, returns the number of expirations with the host’s endianness, which may be converted

to an by .

and can be used to wait until timer expires and the file descriptor is readable.

clockid must be a valid clock ID, as defined in the module:

•

•

• (Since Linux 3.15 for timerfd_create)

The Python Library Reference, Release 3.13.2



If clockid is , a settable system-wide real-time clock is used. If system clock

is changed, timer setting need to be updated.

.

If clockid is , a non-settable monotonically increasing clock is used. Even if the

system clock is changed, the timer setting will not be affected.

If clockid is , same as except it includes any time that

the system is suspended.

The file descriptor’s behaviour can be modified by specifying a flags value. Any of the following variables may

used, combined using bitwise OR (the operator):

•

•

If is not set as a flag, blocks until the timer expires. If it is set as a flag,

doesn’t block, but If there hasn’t been an expiration since the last call to read, raises with

is set to .

is always set by Python automatically.

The file descriptor must be closed with when it is no longer needed, or else the file descriptor

will be leaked.



µ See also

The man page.



Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.13.

fd, / , *, flags=flags, initial=0.0, interval=0.0

Alter a timer file descriptor’s internal timer.

.

fd must be a valid timer file descriptor.

The timer’s behaviour can be modified by specifying a flags value. Any of the following variables may used,

combined using bitwise OR (the operator):

•

•

The timer is disabled by setting initial to zero (). If initial is equal to or greater than zero, the timer is enabled.

If initial is less than zero, it raises an exception with set to

By default the timer will fire when initial seconds have elapsed. (If initial is zero, timer will fire immediately.)

However, if the flag is set, the timer will fire when the timer’s clock (set by clockid in

) reaches initial seconds.

The timer’s interval is set by the interval . If interval is zero, the timer only fires once, on the initial

expiration. If interval is greater than zero, the timer fires every time interval seconds have elapsed since the

previous expiration. If interval is less than zero, it raises with set to

If the flag is set along with and the clock for this timer

is , the timer is marked as cancelable if the real-time clock is changed discontinu-

ously. Reading the descriptor is aborted with the error ECANCELED.

Linux manages system clock as UTC. A daylight-savings time transition is done by changing time offset only

and doesn’t cause discontinuous system clock change.

Discontinuous system clock change will be caused by the following events:

The Python Library Reference, Release 3.13.2



•

•

• set the system date and time by command

Return a two-item tuple of (, ) from the previous timer state, before this func-

tion executed.



µ See also

, , , , and

.



Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.13.

fd, / , *, flags=0, initial=0, interval=0

Similar to , but use time as nanoseconds. This function operates the same interval timer

as .

Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.13.

fd, /

Return a two-item tuple of floats (, ).

denotes the relative time until next the timer next fires, regardless of if the

flag is set.

denotes the timer’s interval. If zero, the timer will only fire once, after seconds

have elapsed.



µ See also





Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.13.

fd, /

Similar to , but return time as nanoseconds.

Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.13.



A flag for the function, which sets the status flag for the new timer file

descriptor. If is not set as a flag, blocks.

Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.13.



A flag for the function, If is set as a flag, set close-on-exec flag for new

file descriptor.

Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.13.

The Python Library Reference, Release 3.13.2





A flag for the and functions. If this flag is set, initial is

interpreted as an absolute value on the timer’s clock (in UTC seconds or nanoseconds since the Unix Epoch).

Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.13.



A flag for the and functions along with

. The timer is cancelled when the time of the underlying clock changes discon-

tinuously.

Availability: Linux >= 2.6.27 with glibc >= 2.8

Added in version 3.13.



Linux extended attributes

Added in version 3.3.

These functions are all available on Linux only.

path, attribute, *, follow_symlinks=True

Return the value of the extended filesystem attribute attribute for path. attribute can be bytes or str (directly or

indirectly through the interface). If it is str, it is encoded with the filesystem encoding.

This function can support specifying a file descriptor and not following symlinks.

Raises an auditing event with arguments , .

Changed in version 3.6: Accepts a path-like object for path and attribute.

path=None, *, follow_symlinks=True

Return a list of the extended filesystem attributes on path. The attributes in the list are represented as strings

decoded with the filesystem encoding. If path is , will examine the current directory.

This function can support specifying a file descriptor and not following symlinks.

Raises an auditing event with argument .

Changed in version 3.6: Accepts a path-like object.

path, attribute, *, follow_symlinks=True

Removes the extended filesystem attribute attribute from path. attribute should be bytes or str (directly or

indirectly through the interface). If it is a string, it is encoded with the filesystem encoding and

error handler.

This function can support specifying a file descriptor and not following symlinks.

Raises an auditing event with arguments , .

Changed in version 3.6: Accepts a path-like object for path and attribute.

path, attribute, value, flags=0, *, follow_symlinks=True

Set the extended filesystem attribute attribute on path to value. attribute must be a bytes or str with no embedded

NULs (directly or indirectly through the interface). If it is a str, it is encoded with the filesystem

encoding and error handler. flags may be or . If is given

and the attribute does not exist, will be raised. If is given and the attribute already

exists, the attribute will not be created and will be raised.

This function can support specifying a file descriptor and not following symlinks.



® Note

A bug in Linux kernel versions less than 2.6.39 caused the flags argument to be ignored on some filesystems.

The Python Library Reference, Release 3.13.2



Raises an auditing event with arguments , , , .

Changed in version 3.6: Accepts a path-like object for path and attribute.



The maximum size the value of an extended attribute can be. Currently, this is 64 KiB on Linux.



This is a possible value for the flags argument in . It indicates the operation must create an

attribute.



This is a possible value for the flags argument in . It indicates the operation must replace an

existing attribute.





These functions may be used to create and manage processes.

The various functions take a list of arguments for the new program loaded into the process. In each case, the first of these arguments is passed to the new program as its own name rather than as an argument a user may have typed on a command line. For the C programmer, this is the passed to a program’s . For example, will only print on standard output; will seem to be ignored.



Generate a signal to the current process. On Unix, the default behavior is to produce a core dump;

on Windows, the process immediately returns an exit code of . Be aware that calling this function will not

call the Python signal handler registered for with .

path

Add a path to the DLL search path.

This search path is used when resolving dependencies for imported extension modules (the module itself is

resolved through ), and also by .

Remove the directory by calling close() on the returned object or using it in a statement.

See the Microsoft documentation for more information about how DLLs are loaded.

Raises an auditing event with argument .

Availability: Windows.

Added in version 3.8: Previous versions of CPython would resolve DLLs using the default behavior for the

current process. This led to inconsistencies, such as only sometimes searching or the current working

directory, and OS functions such as having no effect.

In 3.8, the two primary ways DLLs are loaded now explicitly override the process-wide behavior to ensure

consistency. See the porting notes for information on updating libraries.

path, arg0, arg1, ...

path, arg0, arg1, ..., env

file, arg0, arg1, ...

file, arg0, arg1, ..., env

path, args

path, args, env

file, args

file, args, env

These functions all execute a new program, replacing the current process; they do not return. On Unix, the

new executable is loaded into the current process, and will have the same process id as the caller. Errors will

be reported as exceptions.

The Python Library Reference, Release 3.13.2



The current process is replaced immediately. Open file objects and descriptors are not flushed, so if there may

be data buffered on these open files, you should flush them using or

before calling an function.

The “l” and “v” variants of the functions differ in how command-line arguments are passed. The “l”

variants are perhaps the easiest to work with if the number of parameters is fixed when the code is written;

the individual parameters simply become additional parameters to the functions. The “v” variants

are good when the number of parameters is variable, with the arguments being passed in a list or tuple as the

args parameter. In either case, the arguments to the child process should start with the name of the command

being run, but this is not enforced.

The variants which include a “p” near the end (, , , and ) will

use the environment variable to locate the program file. When the environment is being replaced (using

one of the variants, discussed in the next paragraph), the new environment is used as the source of the

variable. The other variants, , , , and , will not use the

variable to locate the executable; path must contain an appropriate absolute or relative path. Relative paths

must include at least one slash, even on Windows, as plain names will not be resolved.

For , , , and (note that these all end in “e”), the env parameter

must be a mapping which is used to define the environment variables for the new process (these are used instead

of the current process’ environment); the functions , , , and all cause

the new process to inherit the environment of the current process.

For on some platforms, path may also be specified as an open file descriptor. This functionality

may not be supported on your platform; you can check whether or not it is available using .

If it is unavailable, using it will raise a .

Raises an auditing event with arguments , , .

Availability: Unix, Windows, not WASI, not Android, not iOS.

Changed in version 3.3: Added support for specifying path as an open file descriptor for .

Changed in version 3.6: Accepts a path-like object.

n

Exit the process with status n, without calling cleanup handlers, flushing stdio buffers, etc.



® Note

The standard way to exit is . should normally only be used in the child process

after a .



The following exit codes are defined and can be used with , although they are not required. These are typically used for system programs written in Python, such as a mail server’s external command delivery program.



® Note

Some of these may not be available on all Unix platforms, since there is some variation. These constants are

defined where they are defined by the underlying platform.





Exit code that means no error occurred. May be taken from the defined value of on some

platforms. Generally has a value of zero.

Availability: Unix, Windows.



Exit code that means the command was used incorrectly, such as when the wrong number of arguments are

given.

Availability: Unix, not WASI.

The Python Library Reference, Release 3.13.2





Exit code that means the input data was incorrect.

Availability: Unix, not WASI.



Exit code that means an input file did not exist or was not readable.

Availability: Unix, not WASI.



Exit code that means a specified user did not exist.

Availability: Unix, not WASI.



Exit code that means a specified host did not exist.

Availability: Unix, not WASI.



Exit code that means that a required service is unavailable.

Availability: Unix, not WASI.



Exit code that means an internal software error was detected.

Availability: Unix, not WASI.



Exit code that means an operating system error was detected, such as the inability to fork or create a pipe.

Availability: Unix, not WASI.



Exit code that means some system file did not exist, could not be opened, or had some other kind of error.

Availability: Unix, not WASI.



Exit code that means a user specified output file could not be created.

Availability: Unix, not WASI.



Exit code that means that an error occurred while doing I/O on some file.

Availability: Unix, not WASI.



Exit code that means a temporary failure occurred. This indicates something that may not really be an error,

such as a network connection that couldn’t be made during a retryable operation.

Availability: Unix, not WASI.



Exit code that means that a protocol exchange was illegal, invalid, or not understood.

Availability: Unix, not WASI.



Exit code that means that there were insufficient permissions to perform the operation (but not intended for

file system problems).

Availability: Unix, not WASI.

The Python Library Reference, Release 3.13.2





Exit code that means that some kind of configuration error occurred.

Availability: Unix, not WASI.



Exit code that means something like “an entry was not found”.

Availability: Unix, not WASI.



Fork a child process. Return in the child and the child’s process id in the parent. If an error occurs

is raised.

Note that some platforms including FreeBSD <= 6.3 and Cygwin have known issues when using from

a thread.

Raises an auditing event with no arguments.



Á Warning

If you use TLS sockets in an application calling , see the warning in the documentation.



Á Warning

On macOS the use of this function is unsafe when mixed with using higher-level system APIs, and that

includes using .



Changed in version 3.8: Calling in a subinterpreter is no longer supported ( is raised).

Changed in version 3.12: If Python is able to detect that your process has multiple threads, now

raises a .

We chose to surface this as a warning, when detectable, to better inform developers of a design problem that

the POSIX platform specifically notes as not supported. Even in code that appears to work, it has never been

safe to mix threading with on POSIX platforms. The CPython runtime itself has always made

API calls that are not safe for use in the child process when threads existed in the parent (such as and

).

Users of macOS or users of libc or malloc implementations other than those typically found in glibc to date

are among those already more likely to experience deadlocks running such code.

See this discussion on fork being incompatible with threads for technical details of why we’re surfacing this

longstanding platform compatibility problem to developers.

Availability: POSIX, not WASI, not Android, not iOS.



Fork a child process, using a new pseudo-terminal as the child’s controlling terminal. Return a pair of

, where pid is in the child, the new child’s process id in the parent, and fd is the file descriptor of the

master end of the pseudo-terminal. For a more portable approach, use the module. If an error occurs

is raised.

Raises an auditing event with no arguments.



Á Warning

On macOS the use of this function is unsafe when mixed with using higher-level system APIs, and that

includes using .

The Python Library Reference, Release 3.13.2



Changed in version 3.8: Calling in a subinterpreter is no longer supported ( is

raised).

Changed in version 3.12: If Python is able to detect that your process has multiple threads, this now raises a

. See the longer explanation on .

Availability: Unix, not WASI, not Android, not iOS.

pid, sig, /

Send signal sig to the process pid. Constants for the specific signals available on the host platform are defined

in the module.

Windows: The and signals are special signals which

can only be sent to console processes which share a common console window, e.g., some subprocesses. Any

other value for sig will cause the process to be unconditionally killed by the TerminateProcess API, and the

exit code will be set to sig.

See also .

Raises an auditing event with arguments , .

Availability: Unix, Windows, not WASI, not iOS.

Changed in version 3.2: Added Windows support.

pgid, sig, /

Send the signal sig to the process group pgid.

Raises an auditing event with arguments , .

Availability: Unix, not WASI, not iOS.

increment, /

Add increment to the process’s “niceness”. Return the new niceness.

Availability: Unix, not WASI.

pid, flags=0

Return a file descriptor referring to the process pid with flags set. This descriptor can be used to perform

process management without races and signals.

See the man page for more details.

Availability: Linux >= 5.3, Android >= API level 31

Added in version 3.9.



This flag indicates that the file descriptor will be non-blocking. If the process referred to by the file

descriptor has not yet terminated, then an attempt to wait on the file descriptor using will

immediately return the error rather than blocking.

Availability: Linux >= 5.10

Added in version 3.12.

op, /

Lock program segments into memory. The value of op (defined in ) determines which seg-

ments are locked.

Availability: Unix, not WASI, not iOS.

cmd, mode=’r’, buffering=-1

Open a pipe to or from command cmd. The return value is an open file object connected to the pipe, which

can be read or written depending on whether mode is (default) or . The buffering argument have the

same meaning as the corresponding argument to the built-in function. The returned file object reads

or writes text strings rather than bytes.

The Python Library Reference, Release 3.13.2



The method returns if the subprocess exited successfully, or the subprocess’s return code if there

was an error. On POSIX systems, if the return code is positive it represents the return value of the process left-

shifted by one byte. If the return code is negative, the process was terminated by the signal given by the negated

value of the return code. (For example, the return value might be if the subprocess was

killed.) On Windows systems, the return value contains the signed integer return code from the child process.

On Unix, can be used to convert the method result (exit status) into

an exit code if it is not . On Windows, the method result is directly the exit code (or ).

This is implemented using ; see that class’s documentation for more powerful ways to

manage and communicate with subprocesses.

Availability: not WASI, not Android, not iOS.



® Note

The Python UTF-8 Mode affects encodings used for cmd and pipe contents.

is a simple wrapper around . Use or

to control options like encodings.



path, argv, env, *, file_actions=None, setpgroup=None, resetids=False, setsid=False,

setsigmask=(), setsigdef=(), scheduler=None

Wraps the C library API for use from Python.

Most users should use instead of .

The positional-only arguments path, args, and env are similar to . env is allowed to be , in

which case current process’ environment is used.

The path parameter is the path to the executable file. The path should contain a directory. Use

to pass an executable file without directory.

The file_actions argument may be a sequence of tuples describing actions to take on specific file descriptors

in the child process between the C library implementation’s and steps. The first item in each

tuple must be one of the three type indicator listed below describing the remaining tuple elements:



(, fd, path, flags, mode)

Performs .



(, fd)

Performs .



(, fd, new_fd)

Performs .



(, fd)

Performs .

These tuples correspond to the C library ,

, , and

API calls used to prepare for the

call itself.

The setpgroup argument will set the process group of the child to the value specified. If the value speci-

fied is 0, the child’s process group ID will be made the same as its process ID. If the value of setpgroup

The Python Library Reference, Release 3.13.2



is not set, the child will inherit the parent’s process group ID. This argument corresponds to the C library

flag.

If the resetids argument is it will reset the effective UID and GID of the child to the real UID and GID

of the parent process. If the argument is , then the child retains the effective UID and GID of the

parent. In either case, if the set-user-ID and set-group-ID permission bits are enabled on the executable file,

their effect will override the setting of the effective UID and GID. This argument corresponds to the C library

flag.

If the setsid argument is , it will create a new session ID for . setsid requires

or flag. Otherwise, is raised.

The setsigmask argument will set the signal mask to the signal set specified.

used, then the child inherits the parent’s signal mask.

flag.

The sigdef argument will reset the disposition of all signals in the set specified. This argument corresponds to

the C library flag.

The scheduler argument must be a tuple containing the (optional) scheduler policy and an instance of

with the scheduler parameters. A value of in the place of the scheduler policy indicates

that is not being provided. This argument is a combination of the C library

and flags.

Raises an auditing event with arguments , , .

Added in version 3.8.

Changed in version 3.13: env parameter accepts . is available on plat-

forms where exists.

Availability: Unix, not WASI, not Android, not iOS.

path, argv, env, *, file_actions=None, setpgroup=None, resetids=False, setsid=False,

setsigmask=(), setsigdef=(), scheduler=None

Wraps the C library API for use from Python.

Similar to except that the system searches for the executable file in the list of directories

specified by the environment variable (in the same way as for ).

Raises an auditing event with arguments , , .

Added in version 3.8.

Availability: POSIX, not WASI, not Android, not iOS.

See documentation.

*, before=None, after_in_parent=None, after_in_child=None

Register callables to be executed when a new child process is forked using or similar process

cloning APIs. The parameters are optional and keyword-only. Each specifies a different call point.

• before is a function called before forking a child process.

• after_in_parent is a function called from the parent process after forking a child process.

• after_in_child is a function called from the child process.

These calls are only made if control is expected to return to the Python interpreter. A typical

launch will not trigger them as the child is not going to re-enter the interpreter.

Functions registered for execution before forking are called in reverse registration order. Functions registered

for execution after forking (either in the parent or in the child) are called in registration order.

Note that calls made by third-party C code may not call those functions, unless it explicitly calls

, and .

There is no way to unregister a function.

Availability: Unix, not WASI, not Android, not iOS.

The Python Library Reference, Release 3.13.2



Added in version 3.7.

mode, path, ...

mode, path, ..., env

mode, file, ...

mode, file, ..., env

mode, path, args

mode, path, args, env

mode, file, args

mode, file, args, env

Execute the program path in a new process.

(Note that the module provides more powerful facilities for spawning new processes and retriev-

ing their results; using that module is preferable to using these functions. Check especially the Replacing Older

Functions with the subprocess Module section.)

If mode is , this function returns the process id of the new process; if mode is , returns

the process’s exit code if it exits normally, or, where signal is the signal that killed the process. On

Windows, the process id will actually be the process handle, so can be used with the function.

Note on VxWorks, this function doesn’t return when the new process is killed. Instead it raises

OSError exception.

The “l” and “v” variants of the functions differ in how command-line arguments are passed. The “l”

variants are perhaps the easiest to work with if the number of parameters is fixed when the code is written; the

individual parameters simply become additional parameters to the functions. The “v” variants are

good when the number of parameters is variable, with the arguments being passed in a list or tuple as the args

parameter. In either case, the arguments to the child process must start with the name of the command being

run.

The variants which include a second “p” near the end (, , , and

) will use the environment variable to locate the program file. When the environment

is being replaced (using one of the variants, discussed in the next paragraph), the new environ-

ment is used as the source of the variable. The other variants, , , ,

and , will not use the variable to locate the executable; path must contain an appropriate

absolute or relative path.

For , , , and (note that these all end in “e”), the env pa-

rameter must be a mapping which is used to define the environment variables for the new process (they are

used instead of the current process’ environment); the functions , , , and

all cause the new process to inherit the environment of the current process. Note that keys and

values in the env dictionary must be strings; invalid keys or values will cause the function to fail, with a return

value of .

As an example, the following calls to and are equivalent:





Raises an auditing event with arguments , , , .

Availability: Unix, Windows, not WASI, not Android, not iOS.

, , and are not available on Windows. and

are not thread-safe on Windows; we advise you to use the module instead.

Changed in version 3.6: Accepts a path-like object.



The Python Library Reference, Release 3.13.2





Possible values for the mode parameter to the family of functions. If either of these values is given,

the functions will return as soon as the new process has been created, with the process id as the return

value.

Availability: Unix, Windows.



Possible value for the mode parameter to the family of functions. If this is given as mode, the

functions will not return until the new process has run to completion and will return the exit code of the process

the run is successful, or if a signal kills the process.

Availability: Unix, Windows.





Possible values for the mode parameter to the family of functions. These are less portable than those

listed above. is similar to , but the new process is detached from the console of the

calling process. If is used, the current process will be replaced; the function will not

return.

Availability: Windows.

path , operation , arguments , cwd , show_cmd

Start a file with its associated application.

When operation is not specified, this acts like double-clicking the file in Windows Explorer, or giving the file

name as an argument to the command from the interactive command shell: the file is opened with

whatever application (if any) its extension is associated.

When another operation is given, it must be a “command verb” that specifies what should be done with the file.

Common verbs documented by Microsoft are , and (to be used on files) as well as

and (to be used on directories).

When launching an application, specify arguments to be passed as a single string. This argument may have no

effect when using this function to launch a document.

The default working directory is inherited, but may be overridden by the cwd argument. This should be an

absolute path. A relative path will be resolved against this argument.

Use show_cmd to override the default window style. Whether this has any effect will depend on the application

being launched. Values are integers as supported by the Win32 function.

returns as soon as the associated application is launched. There is no option to wait for the

application to close, and no way to retrieve the application’s exit status. The path parameter is relative to the

current directory or cwd. If you want to use an absolute path, make sure the first character is not a slash ()

Use or the function to ensure that paths are properly encoded for Win32.

To reduce interpreter startup overhead, the Win32 function is not resolved until this func-

tion is first called. If the function cannot be resolved, will be raised.

Raises an auditing event with arguments , .

Raises an auditing event with arguments , , , ,

.

Availability: Windows.

Changed in version 3.10: Added the arguments, cwd and show_cmd arguments, and the

audit event.

command

Execute the command (a string) in a subshell. This is implemented by calling the Standard C function

, and has the same limitations. Changes to , etc. are not reflected in the environ-

ment of the executed command. If command generates any output, it will be sent to the interpreter standard The Python Library Reference, Release 3.13.2



output stream. The C standard does not specify the meaning of the return value of the C function, so the return

value of the Python function is system-dependent.

On Unix, the return value is the exit status of the process encoded in the format specified for .

On Windows, the return value is that returned by the system shell after running command. The shell is given

by the Windows environment variable : it is usually , which returns the exit status of the

command run; on systems using a non-native shell, consult your shell documentation.

The module provides more powerful facilities for spawning new processes and retrieving their

results; using that module is preferable to using this function. See the Replacing Older Functions with the

subprocess Module section in the documentation for some helpful recipes.

On Unix, can be used to convert the result (exit status) into an exit code. On

Windows, the result is directly the exit code.

Raises an auditing event with argument .

Availability: Unix, Windows, not WASI, not Android, not iOS.



Returns the current global process times. The return value is an object with five attributes:

• - user time

• - system time

• - user time of all child processes

• - system time of all child processes

• - elapsed real time since a fixed point in the past

For backwards compatibility, this object also behaves like a five-tuple containing , ,

, , and in that order.

See the Unix manual page and times(3) manual page on Unix or the GetProcessTimes MSDN on

Windows. On Windows, only and are known; the other attributes are zero.

Availability: Unix, Windows.

Changed in version 3.3: Return type changed from a tuple to a tuple-like object with named attributes.



Wait for completion of a child process, and return a tuple containing its pid and exit status indication: a 16-bit

number, whose low byte is the signal number that killed the process, and whose high byte is the exit status (if

the signal number is zero); the high bit of the low byte is set if a core file was produced.

If there are no children that could be waited for, is raised.

can be used to convert the exit status into an exit code.

Availability: Unix, not WASI, not Android, not iOS.



µ See also

The other functions documented below can be used to wait for the completion of a specific child

process and have more options. is the only one also available on Windows.



idtype, id, options, /

Wait for the completion of a child process.

idtype can be , , , or (on Linux) . The interpretation of id depends on it; see

their individual descriptions.

options is an OR combination of flags. At least one of , or is required;

and are additional optional flags.

The Python Library Reference, Release 3.13.2



The return value is an object representing the data contained in the structure with the following

attributes:

• (process ID)

• (real user ID of the child)

• (always )

• (the exit status or signal number, depending on )

• (see for possible values)

If is specified and there are no matching children in the requested state, is returned. Otherwise,

if there are no matching children that could be waited for, is raised.

Availability: Unix, not WASI, not Android, not iOS.

Added in version 3.3.

Changed in version 3.13: This function is now available on macOS as well.

pid, options, /

The details of this function differ on Unix and Windows.

On Unix: Wait for completion of a child process given by process id pid, and return a tuple containing its

process id and exit status indication (encoded as for ). The semantics of the call are affected by the

value of the integer options, which should be for normal operation.

If pid is greater than , requests status information for that specific process. If pid is , the request

is for the status of any child in the process group of the current process. If pid is, the request pertains to

any child of the current process. If pid is less than, status is requested for any process in the process group

(the absolute value of pid).

options is an OR combination of flags. If it contains and there are no matching children in the

requested state, is returned. Otherwise, if there are no matching children that could be waited for,

is raised. Other options that can be used are and .

On Windows: Wait for completion of a process given by process handle pid, and return a tuple containing pid,

and its exit status shifted left by 8 bits (shifting makes cross-platform use of the function easier). A pid less

than or equal to has no special meaning on Windows, and raises an exception. The value of integer options

has no effect. pid can refer to any process whose id is known, not necessarily a child process. The

functions called with return suitable process handles.

can be used to convert the exit status into an exit code.

Availability: Unix, Windows, not WASI, not Android, not iOS.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

function now retries the system call instead of raising an exception (see PEP 475 for

the rationale).

options

Similar to , except no process id argument is given and a 3-element tuple containing the child’s pro-

cess id, exit status indication, and resource usage information is returned. Refer to

for details on resource usage information. The options argument is the same as that provided to

and .

can be used to convert the exit status into an exitcode.

Availability: Unix, not WASI, not Android, not iOS.

pid, options

Similar to , except a 3-element tuple, containing the child’s process id, exit status indication, and

resource usage information is returned. Refer to for details on resource usage

information. The arguments to are the same as those provided to .

can be used to convert the exit status into an exitcode.

The Python Library Reference, Release 3.13.2



Availability: Unix, not WASI, not Android, not iOS.





These are the possible values for idtype in . They affect how id is interpreted:

• - wait for the child whose PID is id.

• - wait for any child whose progress group ID is id.

• - wait for any child; id is ignored.

• - wait for the child identified by the file descriptor id (a process file descriptor created with

).

Availability: Unix, not WASI, not Android, not iOS.



® Note

is only available on Linux >= 5.4.



Added in version 3.3.

Added in version 3.9: The constant.



This options flag for , , , and causes child processes to be reported

if they have been continued from a job control stop since they were last reported.

Availability: Unix, not WASI, not Android, not iOS.



This options flag for causes child processes that have terminated to be reported.

The other functions always report children that have terminated, so this option is not available for them.

Availability: Unix, not WASI, not Android, not iOS.

Added in version 3.3.



This options flag for causes child processes that have been stopped by the delivery of a signal to be

reported.

This option is not available for the other functions.

Availability: Unix, not WASI, not Android, not iOS.

Added in version 3.3.



This options flag for , , and causes child processes to also be reported if they

have been stopped but their current state has not been reported since they were stopped.

This option is not available for .

Availability: Unix, not WASI, not Android, not iOS.



This options flag causes , , , and to return right away if no child

process status is available immediately.

Availability: Unix, not WASI, not Android, not iOS.

The Python Library Reference, Release 3.13.2





This options flag causes to leave the child in a waitable state, so that a later call can be

used to retrieve the child status information again.

This option is not available for the other functions.

Availability: Unix, not WASI, not Android, not iOS.





These are the possible values for in the result returned by .

Availability: Unix, not WASI, not Android, not iOS.

Added in version 3.3.

Changed in version 3.9: Added and values.

status

Convert a wait status to an exit code.

On Unix:

• If the process exited normally (if is true), return the process exit status (return

): result greater than or equal to 0.

• If the process was terminated by a signal (if is true), return where

signum is the number of the signal that caused the process to terminate (return): result less than 0.

• Otherwise, raise a .

On Windows, return status shifted right by 8 bits.

On Unix, if the process is being traced or if was called with option, the caller must

first check if is true. This function must not be called if is

true.



µ See also

, , , , , functions.



Availability: Unix, Windows, not WASI, not Android, not iOS.

Added in version 3.9.

The following functions take a process status code as returned by , , or as a parameter. They may be used to determine the disposition of a process.

status, /

Return if a core dump was generated for the process, otherwise return .

This function should be employed only if is true.

Availability: Unix, not WASI, not Android, not iOS.



The Python Library Reference, Release 3.13.2



status

Return if a stopped child has been resumed by delivery of (if the process has been continued

from a job control stop), otherwise return .

See option.

Availability: Unix, not WASI, not Android, not iOS.

status

Return if the process was stopped by delivery of a signal, otherwise return .

only returns if the call was done using option or when the

process is being traced (see ).

Availability: Unix, not WASI, not Android, not iOS.

status

Return if the process was terminated by a signal, otherwise return .

Availability: Unix, not WASI, not Android, not iOS.

status

Return if the process exited terminated normally, that is, by calling or , or by returning

from ; otherwise return .

Availability: Unix, not WASI, not Android, not iOS.

status

Return the process exit status.

This function should be employed only if is true.

Availability: Unix, not WASI, not Android, not iOS.

status

Return the signal which caused the process to stop.

This function should be employed only if is true.

Availability: Unix, not WASI, not Android, not iOS.

status

Return the number of the signal that caused the process to terminate.

This function should be employed only if is true.

Availability: Unix, not WASI, not Android, not iOS.





These functions control how a process is allocated CPU time by the operating system. They are only available on some Unix platforms. For more detailed information, consult your Unix manpages.

Added in version 3.3.

The following scheduling policies are exposed if they are supported by the operating system.



The default scheduling policy.



Scheduling policy for CPU-intensive processes that tries to preserve interactivity on the rest of the computer.



Scheduling policy for extremely low priority background tasks.



The Python Library Reference, Release 3.13.2





Scheduling policy for sporadic server programs.



A First In First Out scheduling policy.



A round-robin scheduling policy.



This flag can be OR’ed with any other scheduling policy. When a process with this flag set forks, its child’s

scheduling policy and priority are reset to the default.

sched_priority

This class represents tunable scheduling parameters used in ,

, and . It is immutable.

At the moment, there is only one possible parameter:



The scheduling priority for a scheduling policy.

policy

Get the minimum priority value for policy. policy is one of the scheduling policy constants above.

policy

Get the maximum priority value for policy. policy is one of the scheduling policy constants above.

pid, policy, param, /

Set the scheduling policy for the process with PID pid. A pid of 0 means the calling process. policy is one of

the scheduling policy constants above. param is a instance.

pid, /

Return the scheduling policy for the process with PID pid. A pid of 0 means the calling process. The result is

one of the scheduling policy constants above.

pid, param, /

Set the scheduling parameters for the process with PID pid. A pid of 0 means the calling process. param is a

instance.

pid, /

Return the scheduling parameters as a instance for the process with PID pid. A pid of 0 means

the calling process.

pid, /

Return the round-robin quantum in seconds for the process with PID pid. A pid of 0 means the calling process.



Voluntarily relinquish the CPU. See for details.

pid, mask, /

Restrict the process with PID pid (or the current process if zero) to a set of CPUs. mask is an iterable of

integers representing the set of CPUs to which the process should be restricted.

pid, /

Return the set of CPUs the process with PID pid is restricted to.

If pid is zero, return the set of CPUs the calling thread of the current process is restricted to.

See also the function.



The Python Library Reference, Release 3.13.2





name, /

Return string-valued system configuration values. name specifies the configuration value to retrieve; it may

be a string which is the name of a defined system value; these names are specified in a number of standards

(POSIX, Unix 95, Unix 98, and others). Some platforms define additional names as well. The names known to

the host operating system are given as the keys of the dictionary. For configuration variables

not included in that mapping, passing an integer for name is also accepted.

If the configuration value specified by name isn’t defined, is returned.

If name is a string and is not known, is raised. If a specific value for name is not supported by

the host system, even if it is included in , an is raised with for the

error number.

Availability: Unix.



Dictionary mapping names accepted by to the integer values defined for those names by the host

operating system. This can be used to determine the set of names known to the system.

Availability: Unix.



Return the number of logical CPUs in the system. Returns if undetermined.

The function can be used to get the number of logical CPUs usable by the calling

thread of the current process.

Added in version 3.4.

Changed in version 3.13: If is given or is set, returns

the overridden value n.



Return the number of processes in the system run queue averaged over the last 1, 5, and 15 minutes or raises

if the load average was unobtainable.

Availability: Unix.



Get the number of logical CPUs usable by the calling thread of the current process. Returns if unde-

termined. It can be less than depending on the CPU affinity.

The function can be used to get the number of logical CPUs in the system.

If is given or is set, returns the overridden

value n.

See also the function.

Added in version 3.13.

name, /

Return integer-valued system configuration values. If the configuration value specified by name isn’t defined,

is returned. The comments regarding the name parameter for apply here as well; the dictionary

that provides information on the known names is given by .

Availability: Unix.



Dictionary mapping names accepted by to the integer values defined for those names by the host

operating system. This can be used to determine the set of names known to the system.

Availability: Unix.

Changed in version 3.11: Add name.

The Python Library Reference, Release 3.13.2



The following data values are used to support path manipulation operations. These are defined for all platforms.

Higher-level operations on pathnames are defined in the module.



The constant string used by the operating system to refer to the current directory. This is for Windows

and POSIX. Also available via .



The constant string used by the operating system to refer to the parent directory. This is for Windows

and POSIX. Also available via .



The character used by the operating system to separate pathname components. This is for POSIX and

for Windows. Note that knowing this is not sufficient to be able to parse or concatenate pathnames —

use and — but it is occasionally useful. Also available via .



An alternative character used by the operating system to separate pathname components, or if only one

separator character exists. This is set to on Windows systems where is a backslash. Also available

via .



The character which separates the base filename from the extension; for example, the in . Also

available via .



The character conventionally used by the operating system to separate search path components (as in ),

such as for POSIX or for Windows. Also available via .



The default search path used by and if the environment doesn’t have a key. Also

available via .



The string used to separate (or, rather, terminate) lines on the current platform. This may be a single character,

such as for POSIX, or multiple characters, for example, for Windows. Do not use os.linesep as a

line terminator when writing files opened in text mode (the default); use a single instead, on all platforms.



The file path of the null device. For example: for POSIX, for Windows. Also available

via .





Flags for use with the and functions. See the Unix manual page

for what the different flags mean.

Added in version 3.3.





The Python Library Reference, Release 3.13.2



size, flags=0

Get up to size random bytes. The function can return less bytes than requested.

These bytes can be used to seed user-space random number generators or for cryptographic purposes.

relies on entropy gathered from device drivers and other sources of environmental noise. Un-

necessarily reading large quantities of data will have a negative impact on other users of the

and devices.

The flags argument is a bit mask that can contain zero or more of the following values ORed together:

and .

See also the Linux getrandom() manual page.

Availability: Linux >= 3.17.

Added in version 3.6.

size, /

Return a bytestring of size random bytes suitable for cryptographic use.

This function returns random bytes from an OS-specific randomness source. The returned data should be un-

predictable enough for cryptographic applications, though its exact quality depends on the OS implementation.

On Linux, if the syscall is available, it is used in blocking mode: block until the system urandom

entropy pool is initialized (128 bits of entropy are collected by the kernel). See the PEP 524 for the rationale.

On Linux, the function can be used to get random bytes in non-blocking mode (using the

flag) or to poll until the system urandom entropy pool is initialized.

On a Unix-like system, random bytes are read from the device. If the device

is not available or not readable, the exception is raised.

On Windows, it will use .



µ See also

The module provides higher level functions. For an easy-to-use interface to the random number

generator provided by your platform, please see .



Changed in version 3.5: On Linux 3.17 and newer, the syscall is now used when available. On

OpenBSD 5.6 and newer, the C function is now used. These functions avoid the usage of an

internal file descriptor.

Changed in version 3.5.2: On Linux, if the syscall blocks (the urandom entropy pool is not

initialized yet), fall back on reading .

Changed in version 3.6: On Linux, is now used in blocking mode to increase the security.

Changed in version 3.11: On Windows, is used instead of which

is deprecated.



By default, when reading from , blocks if no random bytes are available, and

when reading from , it blocks if the entropy pool has not yet been initialized.

If the flag is set, then does not block in these cases, but instead immediately

raises .

Added in version 3.6.



If this bit is set, then random bytes are drawn from the pool instead of the

pool.

Added in version 3.6.

The Python Library Reference, Release 3.13.2





Source code: Lib/io.py





The module provides Python’s main facilities for dealing with various types of I/O. There are three main types of I/O: text I/O, binary I/O and raw I/O. These are generic categories, and various backing stores can be used for each of

them. A concrete object belonging to any of these categories is called a file object. Other common terms are stream and file-like object.

Independent of its category, each concrete stream object will also have various capabilities: it can be read-only, write-only, or read-write. It can also allow arbitrary random access (seeking forwards or backwards to any location), or only sequential access (for example in the case of a socket or pipe).

All streams are careful about the type of data you give to them. For example giving a object to the

method of a binary stream will raise a . So will giving a object to the method of a text stream.

Changed in version 3.3: Operations that used to raise now raise , since is now an alias

of .



Text I/O

Text I/O expects and produces objects. This means that whenever the backing store is natively made of bytes (such as in the case of a file), encoding and decoding of data is made transparently as well as optional translation of platform-specific newline characters.

The easiest way to create a text stream is with , optionally specifying an encoding:





In-memory text streams are also available as objects:





The text stream API is described in detail in the documentation of .



Binary I/O

Binary I/O (also called buffered I/O) expects bytes-like objects and produces objects. No encoding, decoding, or newline translation is performed. This category of streams can be used for all kinds of non-text data, and also when manual control over the handling of text data is desired.

The easiest way to create a binary stream is with with in the mode string:





In-memory binary streams are also available as objects:





The binary stream API is described in detail in the docs of .

Other library modules may provide additional ways to create text or binary streams. See

for example.



The Python Library Reference, Release 3.13.2



Raw I/O

Raw I/O (also called unbuffered I/O) is generally used as a low-level building-block for binary and text streams; it is rarely useful to directly manipulate a raw stream from user code. Nevertheless, you can create a raw stream by opening a file in binary mode with buffering disabled:





The raw stream API is described in detail in the docs of .





The default encoding of and is locale-specific ().

However, many developers forget to specify the encoding when opening text files encoded in UTF-8 (e.g. JSON, TOML, Markdown, etc…) since most Unix platforms use UTF-8 locale by default. This causes bugs because the locale encoding is not UTF-8 for most Windows users. For example:





Accordingly, it is highly recommended that you specify the encoding explicitly when opening text files. If you want to use UTF-8, pass . To use the current locale encoding, is supported since Python 3.10.



µ See also

Python UTF-8 Mode

Python UTF-8 Mode can be used to change the default encoding to UTF-8 from locale-specific encoding.

PEP 686

Python 3.15 will make Python UTF-8 Mode default.



Opt-in EncodingWarning

Added in version 3.10: See PEP 597 for more details.

To find where the default locale encoding is used, you can enable the command line

option or set the environment variable, which will emit an when the default encoding is used.

If you are providing an API that uses or and passes as a parameter,

you can use so that callers of the API will emit an if they don’t pass an . However, please consider using UTF-8 by default (i.e. ) for new APIs.





An int containing the default buffer size used by the module’s buffered I/O classes. uses the file’s

blksize (as obtained by ) if possible.

file, mode=’r’ , buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None

This is an alias for the builtin function.



This function raises an auditing event with arguments path, mode and flags. The mode and flags arguments

may have been modified or inferred from the original call.

The Python Library Reference, Release 3.13.2



path

Opens the provided file with mode . This function should be used when the intent is to treat the contents

as executable code.

path should be a and an absolute path.

The behavior of this function may be overridden by an earlier call to the .

However, assuming that path is a and an absolute path, should always behave the

same as . Overriding the behavior is intended for additional validation or preprocessing

of the file.

Added in version 3.8.

encoding, stacklevel=2, /

This is a helper function for callables that use or and have an

parameter.

This function returns encoding if it is not . Otherwise, it returns or depending on

UTF-8 Mode.

This function emits an if is true and encoding

is . stacklevel specifies where the warning is emitted. For example:





In this example, an is emitted for the caller of .

See Text Encoding for more information.

Added in version 3.10.

Changed in version 3.11: returns “utf-8” when UTF-8 mode is enabled and encoding is

.



This is a compatibility alias for the builtin exception.



An exception inheriting and that is raised when an unsupported operation is called on

a stream.



µ See also



contains the standard IO streams: , , and .





The implementation of I/O streams is organized as a hierarchy of classes. First abstract base classes (ABCs), which are used to specify the various categories of streams, then concrete classes providing the standard stream implemen-tations.



® Note

The abstract base classes also provide default implementations of some methods in order to help implemen-

tation of concrete stream classes. For example, provides unoptimized implementations of

and .

The Python Library Reference, Release 3.13.2



At the top of the I/O hierarchy is the abstract base class . It defines the basic interface to a stream. Note, however, that there is no separation between reading and writing to streams; implementations are allowed to raise

if they do not support a given operation.

The ABC extends . It deals with the reading and writing of bytes to a stream. subclasses

to provide an interface to files in the machine’s file system.

The ABC extends . It deals with buffering on a raw binary stream (). Its sub-

classes, , , and buffer raw binary streams that are writable,

readable, and both readable and writable, respectively. provides a buffered interface to seekable

streams. Another subclass, , is a stream of in-memory bytes.

The ABC extends . It deals with streams whose bytes represent text, and handles encoding

and decoding to and from strings. , which extends , is a buffered text interface to a

buffered raw stream (). Finally, is an in-memory stream for text.

Argument names are not part of the specification, and only the arguments of are intended to be used as keyword arguments.

The following table summarizes the ABCs provided by the module:



ABC Inherits Stub Mixin Methods and Properties

Methods

, , , , , ,

, and , , , , ,

, , , , and



Inherited methods, , and

and

, Inherited methods, , and

,

, and



, Inherited methods, , , and

,

,

and



I/O Base Classes



The abstract base class for all I/O classes.

This class provides empty abstract implementations for many methods that derived classes can override selec-

tively; the default implementations represent a file that cannot be read, written or seeked.

Even though does not declare or because their signatures will vary, implemen-

tations and clients should consider those methods part of the interface. Also, implementations may raise a

(or ) when operations they do not support are called.

The basic type used for binary data read from or written to a file is . Other bytes-like objects are accepted

as method arguments too. Text I/O classes work with data.

Note that calling any method (even inquiries) on a closed stream is undefined. Implementations may raise

in this case.

(and its subclasses) supports the iterator protocol, meaning that an object can be iterated over

yielding the lines in a stream. Lines are defined slightly differently depending on whether the stream is a binary

stream (yielding bytes), or a text stream (yielding character strings). See below.

is also a context manager and therefore supports the statement. In this example, file is closed

after the statement’s suite is finished—even if an exception occurs:

The Python Library Reference, Release 3.13.2





provides these data attributes and methods:



Flush and close this stream. This method has no effect if the file is already closed. Once the file is closed,

any operation on the file (e.g. reading or writing) will raise a .

As a convenience, it is allowed to call this method more than once; only the first call, however, will have an effect.



if the stream is closed.



Return the underlying file descriptor (an integer) of the stream if it exists. An is raised if the IO object does not use a file descriptor.



Flush the write buffers of the stream if applicable. This does nothing for read-only and non-blocking streams.



Return if the stream is interactive (i.e., connected to a terminal/tty device).



Return if the stream can be read from. If , will raise .

size=-1, /

Read and return one line from the stream. If size is specified, at most size bytes will be read.

The line terminator is always for binary files; for text files, the newline argument to can be used to select the line terminator(s) recognized.

hint=-1, /

Read and return a list of lines from the stream. hint can be specified to control the number of lines read: no more lines will be read if the total size (in bytes/characters) of all lines so far exceeds hint.

hint values of or less, as well as , are treated as no hint.

Note that it’s already possible to iterate on file objects using without calling .

offset, whence=os.SEEK_SET, /

Change the stream position to the given byte offset, interpreted relative to the position indicated by whence, and return the new absolute position. Values for whence are:

• or – start of the stream (the default); offset should be zero or positive

• or – current stream position; offset may be negative

• or – end of the stream; offset is usually negative

Added in version 3.1: The constants.

Added in version 3.3: Some operating systems could support additional values, like or

. The valid values for a file could depend on it being open in text or binary mode.



Return if the stream supports random access. If , , and will

raise .



Return the current stream position.

The Python Library Reference, Release 3.13.2



size=None, /

Resize the stream to the given size in bytes (or the current position if size is not specified). The current stream position isn’t changed. This resizing can extend or reduce the current file size. In case of extension, the contents of the new file area depend on the platform (on most systems, additional bytes are zero-filled). The new file size is returned.

Changed in version 3.5: Windows will now zero-fill files when extending.



Return if the stream supports writing. If , and will raise .

lines, /

Write a list of lines to the stream. Line separators are not added, so it is usual for each of the lines provided to have a line separator at the end.



Prepare for object destruction. provides a default implementation of this method that calls the

instance’s method.



Base class for raw binary streams. It inherits from .

Raw binary streams typically provide low-level access to an underlying OS device or API, and do not try to

encapsulate it in high-level primitives (this functionality is done at a higher-level in buffered binary streams

and text streams, described later in this page).

provides these methods in addition to those from :

size=-1, /

Read up to size bytes from the object and return them. As a convenience, if size is unspecified or -1, all bytes until EOF are returned. Otherwise, only one system call is ever made. Fewer than size bytes may be returned if the operating system call returns fewer than size bytes.

If 0 bytes are returned, and size was not 0, this indicates end of file. If the object is in non-blocking mode and no bytes are available, is returned.

The default implementation defers to and .



Read and return all the bytes from the stream until EOF, using multiple calls to the stream if necessary.

b, /

Read bytes into a pre-allocated, writable bytes-like object b, and return the number of bytes read. For

example, b might be a . If the object is in non-blocking mode and no bytes are available, is returned.

b, /

Write the given bytes-like object, b, to the underlying raw stream, and return the number of bytes written. This can be less than the length of b in bytes, depending on specifics of the underlying raw stream, and especially if it is in non-blocking mode. is returned if the raw stream is set not to block and no single byte could be readily written to it. The caller may release or mutate b after this method returns, so the implementation should only access b during the method call.



Base class for binary streams that support some kind of buffering. It inherits from .

The main difference with is that methods , and will try (respec-

tively) to read as much input as requested or to consume all given output, at the expense of making perhaps

more than one system call.

In addition, those methods can raise if the underlying raw stream is in non-blocking mode

and cannot take or give enough data; unlike their counterparts, they will never return .

Besides, the method does not have a default implementation that defers to .

The Python Library Reference, Release 3.13.2



A typical implementation should not inherit from a implementation, but wrap

one, like and do.

provides or overrides these data attributes and methods in addition to those from :





The underlying raw stream (a instance) that deals with. This is not part

of the API and may not exist on some implementations.



Separate the underlying raw stream from the buffer and return it.

After the raw stream has been detached, the buffer is in an unusable state.

Some buffers, like , do not have the concept of a single raw stream to return from this method.

They raise .

Added in version 3.1.

size=-1, /

Read and return up to size bytes. If the argument is omitted, , or negative, data is read and returned

until EOF is reached. An empty object is returned if the stream is already at EOF.

If the argument is positive, and the underlying raw stream is not interactive, multiple raw reads may be issued to satisfy the byte count (unless EOF is reached first). But for interactive raw streams, at most one raw read will be issued, and a short result does not imply that EOF is imminent.

A is raised if the underlying raw stream is in non blocking-mode, and has no data available at the moment.

size=-1, /

Read and return up to size bytes, with at most one call to the underlying raw stream’s (or

) method. This can be useful if you are implementing your own buffering on top of a

object.

If size is (the default), an arbitrary number of bytes are returned (more than zero unless EOF is reached).

b, /

Read bytes into a pre-allocated, writable bytes-like object b and return the number of bytes read. For

example, b might be a .

Like , multiple reads may be issued to the underlying raw stream, unless the latter is interactive.

A is raised if the underlying raw stream is in non blocking-mode, and has no data available at the moment.

b, /

Read bytes into a pre-allocated, writable bytes-like object b, using at most one call to the underlying raw

stream’s (or ) method. Return the number of bytes read.

A is raised if the underlying raw stream is in non blocking-mode, and has no data available at the moment.

Added in version 3.5.

b, /

Write the given bytes-like object, b, and return the number of bytes written (always equal to the length of

b in bytes, since if the write fails an will be raised). Depending on the actual implementation, these bytes may be readily written to the underlying stream, or held in a buffer for performance and latency reasons.

When in non-blocking mode, a is raised if the data needed to be written to the raw stream but it couldn’t accept all the data without blocking.

The Python Library Reference, Release 3.13.2



The caller may release or mutate b after this method returns, so the implementation should only access b during the method call.



Raw File I/O

name, mode=’r’ , closefd=True, opener=None

A raw binary stream representing an OS-level file containing bytes data. It inherits from .

The name can be one of two things:

• a character string or object representing the path to the file which will be opened. In this case

closefd must be (the default) otherwise an error will be raised.

• an integer representing the number of an existing OS-level file descriptor to which the resulting

object will give access. When the FileIO object is closed this fd will be closed as well, unless closefd is set to .

The mode can be , , or for reading (default), writing, exclusive creation or appending. The

file will be created if it doesn’t exist when opened for writing or appending; it will be truncated when opened

for writing. will be raised if it already exists when opened for creating. Opening a file

for creating implies writing, so this mode behaves in a similar way to . Add a to the mode to allow

simultaneous reading and writing.

The (when called with a positive argument), and methods on this class will

only make one system call.

A custom opener can be used by passing a callable as opener. The underlying file descriptor for the file object

is then obtained by calling opener with (name, flags). opener must return an open file descriptor (passing

as opener results in functionality similar to passing ).

The newly created file is non-inheritable.

See the built-in function for examples on using the opener parameter.

Changed in version 3.3: The opener parameter was added. The mode was added.

Changed in version 3.4: The file is now non-inheritable.

provides these data attributes in addition to those from and :



The mode as given in the constructor.



The file name. This is the file descriptor of the file when no name is given in the constructor.



Buffered Streams

Buffered I/O streams provide a higher-level interface to an I/O device than raw I/O does.

initial_bytes=b”

A binary stream using an in-memory bytes buffer. It inherits from . The buffer is discarded

when the method is called.

The optional argument initial_bytes is a bytes-like object that contains initial data.

provides or overrides these methods in addition to those from and :



Return a readable and writable view over the contents of the buffer without copying them. Also, mutating the view will transparently update the contents of the buffer:





The Python Library Reference, Release 3.13.2





® Note

As long as the view exists, the object cannot be resized or closed.



Added in version 3.2.



Return containing the entire contents of the buffer.

size=-1, /

In , this is the same as .

Changed in version 3.7: The size argument is now optional.

b, /

In , this is the same as .

Added in version 3.5.

raw, buffer_size=DEFAULT_BUFFER_SIZE

A buffered binary stream providing higher-level access to a readable, non seekable raw binary

stream. It inherits from .

When reading data from this object, a larger amount of data may be requested from the underlying raw stream,

and kept in an internal buffer. The buffered data can then be returned directly on subsequent reads.

The constructor creates a for the given readable raw stream and buffer_size. If buffer_size

is omitted, is used.

provides or overrides these methods in addition to those from and

:

size=0, /

Return bytes from the stream without advancing the position. At most one single read on the raw stream is done to satisfy the call. The number of bytes returned may be less or more than requested.

size=-1, /

Read and return size bytes, or if size is not given or negative, until EOF or if the read call would block in non-blocking mode.

size=-1, /

Read and return up to size bytes with only one call on the raw stream. If at least one byte is buffered, only buffered bytes are returned. Otherwise, one raw stream read call is made.

Changed in version 3.7: The size argument is now optional.

raw, buffer_size=DEFAULT_BUFFER_SIZE

A buffered binary stream providing higher-level access to a writeable, non seekable raw binary

stream. It inherits from .

When writing to this object, data is normally placed into an internal buffer. The buffer will be written out to

the underlying object under various conditions, including:

• when the buffer gets too small for all pending data;

• when is called;

• when a is requested (for objects);

• when the object is closed or destroyed.

The Python Library Reference, Release 3.13.2



The constructor creates a for the given writeable raw stream. If the buffer_size is not given,

it defaults to .

provides or overrides these methods in addition to those from and

:



Force bytes held in the buffer into the raw stream. A should be raised if the raw stream blocks.

b, /

Write the bytes-like object, b, and return the number of bytes written. When in non-blocking mode, a

is raised if the buffer needs to be written out but the raw stream blocks.

raw, buffer_size=DEFAULT_BUFFER_SIZE

A buffered binary stream providing higher-level access to a seekable raw binary stream. It inherits

from and .

The constructor creates a reader and writer for a seekable raw stream, given in the first argument. If the

buffer_size is omitted it defaults to .

is capable of anything or can do. In addition,

and are guaranteed to be implemented.

reader, writer, buffer_size=DEFAULT_BUFFER_SIZE, /

A buffered binary stream providing higher-level access to two non seekable raw binary streams—

one readable, the other writeable. It inherits from .

reader and writer are objects that are readable and writeable respectively. If the buffer_size is

omitted it defaults to .

implements all of ’s methods except for , which raises

.



Á Warning

does not attempt to synchronize accesses to its underlying raw streams. You should

not pass it the same object as reader and writer; use instead.



Text I/O



Base class for text streams. This class provides a character and line based interface to stream I/O. It inherits

from .

provides or overrides these data attributes and methods in addition to those from :



The name of the encoding used to decode the stream’s bytes into strings, and to encode strings into bytes.



The error setting of the decoder or encoder.



A string, a tuple of strings, or , indicating the newlines translated so far. Depending on the imple-mentation and the initial constructor flags, this may not be available.



The underlying binary buffer (a instance) that deals with. This is not

part of the API and may not exist in some implementations.

The Python Library Reference, Release 3.13.2





Separate the underlying binary buffer from the and return it.

After the underlying buffer has been detached, the is in an unusable state.

Some implementations, like , may not have the concept of an underlying buffer

and calling this method will raise .

Added in version 3.1.

size=-1, /

Read and return at most size characters from the stream as a single . If size is negative or , reads until EOF.

size=-1, /

Read until newline or EOF and return a single . If the stream is already at EOF, an empty string is returned.

If size is specified, at most size characters will be read.

offset, whence=SEEK_SET, /

Change the stream position to the given offset. Behaviour depends on the whence parameter. The default value for whence is .

• or : seek from the start of the stream (the default); offset must either be a number

returned by , or zero. Any other offset value produces undefined behaviour.

• or : “seek” to the current position; offset must be zero, which is a no-operation (all other

values are unsupported).

• or : seek to the end of the stream; offset must be zero (all other values are unsupported).

Return the new absolute position as an opaque number.

Added in version 3.1: The constants.



Return the current stream position as an opaque number. The number does not usually represent a number of bytes in the underlying binary storage.

s, /

Write the string s to the stream and return the number of characters written.

buffer, encoding=None, errors=None, newline=None, line_buffering=False,

write_through=False

A buffered text stream providing higher-level access to a buffered binary stream. It inherits

from .

encoding gives the name of the encoding that the stream will be decoded or encoded with. It defaults to

. can be used to specify the current locale’s encoding ex-

plicitly. See Text Encoding for more information.

errors is an optional string that specifies how encoding and decoding errors are to be handled. Pass

to raise a exception if there is an encoding error (the default of has the same effect), or pass

to ignore errors. (Note that ignoring encoding errors can lead to data loss.) causes a re-

placement marker (such as ) to be inserted where there is malformed data. causes

malformed data to be replaced by a backslashed escape sequence. When writing,

(replace with the appropriate XML character reference) or (replace with es-

cape sequences) can be used. Any other error handling name that has been registered with

is also valid.

newline controls how line endings are handled. It can be , , , , and . It works as

follows:



The Python Library Reference, Release 3.13.2



• When reading input from the stream, if newline is , universal newlines mode is enabled. Lines in

the input can end in , , or , and these are translated into before being returned to the caller. If newline is , universal newlines mode is enabled, but line endings are returned to the caller untranslated. If newline has any of the other legal values, input lines are only terminated by the given string, and the line ending is returned to the caller untranslated.

• When writing output to the stream, if newline is , any characters written are translated to

the system default line separator, . If newline is or , no translation takes place. If newline is any of the other legal values, any characters written are translated to the given string.

If line_buffering is , is implied when a call to write contains a newline character or a carriage

return.

If write_through is , calls to are guaranteed not to be buffered: any data written on the

object is immediately handled to its underlying binary buffer.

Changed in version 3.3: The write_through argument has been added.

Changed in version 3.3: The default encoding is now instead

of . Don’t change temporary the locale encoding using

, use the current locale encoding instead of the user preferred encoding.

Changed in version 3.10: The encoding argument now supports the dummy encoding name.

provides these data attributes and methods in addition to those from and

:



Whether line buffering is enabled.



Whether writes are passed immediately to the underlying binary buffer.

Added in version 3.7.

*, encoding=None, errors=None, newline=None, line_buffering=None, write_through=None

Reconfigure this text stream using new settings for encoding, errors, newline, line_buffering and write_through.

Parameters not specified keep current settings, except is used when encoding is specified but errors is not specified.

It is not possible to change the encoding or newline if some data has already been read from the stream. On the other hand, changing encoding after write is possible.

This method does an implicit stream flush before setting the new parameters.

Added in version 3.7.

Changed in version 3.11: The method supports option.

cookie, whence=os.SEEK_SET, /

Set the stream position. Return the new stream position as an .

Four operations are supported, given by the following argument combinations:

• : Rewind to the start of the stream.

• : Restore a previous position; cookie must be a number returned by

.

• : Fast-forward to the end of the stream.

• : Leave the current stream position unchanged.

Any other argument combinations are invalid, and may raise exceptions.



The Python Library Reference, Release 3.13.2



µ See also

, , and .





Return the stream position as an opaque number. The return value of can be given as input to

, to restore a previous stream position.

initial_value=” , newline=’\n’

A text stream using an in-memory text buffer. It inherits from .

The text buffer is discarded when the method is called.

The initial value of the buffer can be set by providing initial_value. If newline translation is enabled, newlines

will be encoded as if by . The stream is positioned at the start of the buffer which emulates opening an

existing file in a mode, making it ready for an immediate write from the beginning or for a write that would

overwrite the initial value. To emulate opening a file in an mode ready for appending, use

to reposition the stream at the end of the buffer.

The newline argument works like that of , except that when writing output to the stream, if

newline is , newlines are written as on all platforms.

provides this method in addition to those from and :



Return a containing the entire contents of the buffer. Newlines are decoded as if by , al-though the stream position is not changed.

Example usage:





A helper codec that decodes newlines for universal newlines mode. It inherits from

.





This section discusses the performance of the provided concrete I/O implementations.



Binary I/O

By reading and writing only large chunks of data even when the user asks for a single byte, buffered I/O hides any inefficiency in calling and executing the operating system’s unbuffered I/O routines. The gain depends on the OS and the kind of I/O which is performed. For example, on some modern OSes such as Linux, unbuffered disk I/O can be as fast as buffered I/O. The bottom line, however, is that buffered I/O offers predictable performance regardless of the platform and the backing device. Therefore, it is almost always preferable to use buffered I/O rather than unbuffered I/O for binary data.

The Python Library Reference, Release 3.13.2



Text I/O

Text I/O over a binary storage (such as a file) is significantly slower than binary I/O over the same storage, because it requires conversions between unicode and binary data using a character codec. This can become noticeable handling

huge amounts of text data like large log files. Also, and are both quite slow due to the reconstruction algorithm used.

, however, is a native in-memory unicode container and will exhibit similar speed to .



Multi-threading

objects are thread-safe to the extent that the operating system calls (such as under Unix) they wrap are thread-safe too.

Binary buffered objects (instances of , , and

) protect their internal structures using a lock; it is therefore safe to call them from multi-ple threads at once.

objects are not thread-safe.



Reentrancy

Binary buffered objects (instances of , , and

) are not reentrant.

arise from doing I/O in a handler. If a thread tries to re-enter a buffered object which it is already accessing,

a is raised. Note this doesn’t prohibit a different thread from entering the buffered object.

The above implicitly extends to text files, since the function will wrap a buffered object inside a

. This includes standard streams and therefore affects the built-in function as well.





This module provides various time-related functions. For related functionality, see also the and modules.

Although this module is always available, not all functions are available on all platforms. Most of the functions defined in this module call platform C library functions with the same name. It may sometimes be helpful to consult the platform documentation, because the semantics of these functions varies among platforms.

An explanation of some terminology and conventions is in order.

• The epoch is the point where the time starts, the return value of . It is January 1, 1970,

00:00:00 (UTC) on all platforms.

• The term seconds since the epoch refers to the total number of elapsed seconds since the epoch, typically

excluding leap seconds. Leap seconds are excluded from this total on all POSIX-compliant platforms.

• The functions in this module may not handle dates and times before the epoch or far in the future. The cut-off

point in the future is determined by the C library; for 32-bit systems, it is typically in 2038.

• Function can parse 2-digit years when given format code. When 2-digit years are parsed,

they are converted according to the POSIX and ISO C standards: values 69–99 are mapped to 1969–1999,

and values 0–68 are mapped to 2000–2068.

• UTC is Coordinated Universal Time (formerly known as Greenwich Mean Time, or GMT). The acronym UTC

is not a mistake but a compromise between English and French.

• DST is Daylight Saving Time, an adjustment of the timezone by (usually) one hour during part of the year.

DST rules are magic (determined by local law) and can change from year to year. The C library has a table

containing the local rules (often it is read from a system file for flexibility) and is the only source of True

Wisdom in this respect.

The Python Library Reference, Release 3.13.2



• The precision of the various real-time functions may be less than suggested by the units in which their value

or argument is expressed. E.g. on most Unix systems, the clock “ticks” only 50 or 100 times a second.

• On the other hand, the precision of and is better than their Unix equivalents: times

are expressed as floating-point numbers, returns the most accurate time available (using Unix

where available), and will accept a time with a nonzero fraction (Unix

is used to implement this, where available).

• The time value as returned by , , and , and accepted by ,

and , is a sequence of 9 integers. The return values of , ,

and also offer attribute names for individual fields.

See for a description of these objects.

Changed in version 3.3: The type was extended to provide the and

attributes when platform supports corresponding members.

Changed in version 3.6: The attributes and are now available on all

platforms.

• Use the following functions to convert between time representations:



From To Use

seconds since the epoch in UTC

seconds since the epoch in local time

in UTC seconds since the epoch

in local time seconds since the epoch





t

Convert a tuple or representing a time as returned by or to a string

of the following form: . The day field is two characters long and is space

padded if the day is a single digit, e.g.: .

If t is not provided, the current time as returned by is used. Locale information is not used by

.



® Note

Unlike the C function of the same name, does not add a trailing newline.



thread_id

Return the clk_id of the thread-specific CPU-time clock for the specified thread_id.

Use or the attribute of objects to get a suitable

value for thread_id.



Á Warning

Passing an invalid or expired thread_id may result in undefined behavior, such as segmentation fault.



Availability: Unix

See the man page for for further information.

Added in version 3.7.

The Python Library Reference, Release 3.13.2



clk_id

Return the resolution (precision) of the specified clock clk_id. Refer to Clock ID Constants for a list of accepted

values for clk_id.

Availability: Unix.

Added in version 3.3.

clk_id → float

Return the time of the specified clock clk_id. Refer to Clock ID Constants for a list of accepted values for

clk_id.

Use to avoid the precision loss caused by the type.

Availability: Unix.

Added in version 3.3.

clk_id → int

Similar to but return time as nanoseconds.

Availability: Unix.

Added in version 3.7.

clk_id, time: float

Set the time of the specified clock clk_id. Currently, is the only accepted value for clk_id.

Use to avoid the precision loss caused by the type.

Availability: Unix, not Android, not iOS.

Added in version 3.3.

clk_id, time: int

Similar to but set time with nanoseconds.

Availability: Unix, not Android, not iOS.

Added in version 3.7.

secs

Convert a time expressed in seconds since the epoch to a string of a form:

representing local time. The day field is two characters long and is space padded if the day is a single digit,

e.g.: .

If secs is not provided or , the current time as returned by is used. is equivalent

to . Locale information is not used by .

name

Get information on the specified clock as a namespace object. Supported clock names and the corresponding

functions to read their value are:

• :

• :

• :

• :

• :

The result has the following attributes:

• adjustable: if the clock can be changed automatically (e.g. by a NTP daemon) or manually by the

system administrator, otherwise

• implementation: The name of the underlying C function used to get the clock value. Refer to Clock ID

Constants for possible values.

The Python Library Reference, Release 3.13.2



• monotonic: if the clock cannot go backward, otherwise

• resolution: The resolution of the clock in seconds ()

Added in version 3.3.

secs

Convert a time expressed in seconds since the epoch to a in UTC in which the dst flag is always

zero. If secs is not provided or , the current time as returned by is used. Fractions of a second are

ignored. See above for a description of the object. See for the inverse

of this function.

secs

Like but converts to local time. If secs is not provided or , the current time as returned by

is used. The dst flag is set to when DST applies to the given time.

may raise , if the timestamp is outside the range of values supported by the

platform C or functions, and on or failure.

It’s common for this to be restricted to years between 1970 and 2038.

t

This is the inverse function of . Its argument is the or full 9-tuple (since the

dst flag is needed; use as the dst flag if it is unknown) which expresses the time in local time, not UTC. It

returns a floating-point number, for compatibility with . If the input value cannot be represented as

a valid time, either or will be raised (which depends on whether the invalid

value is caught by Python or the underlying C libraries). The earliest date for which it can generate a time is

platform-dependent.

→ float

Return the value (in fractional seconds) of a monotonic clock, i.e. a clock that cannot go backwards. The clock

is not affected by system clock updates. The reference point of the returned value is undefined, so that only

the difference between the results of two calls is valid.

Clock:

• On Windows, call and .

• On macOS, call and .

• On HP-UX, call .

• Call if available.

• Otherwise, call .

Use to avoid the precision loss caused by the type.

Added in version 3.3.

Changed in version 3.5: The function is now always available and always system-wide.

Changed in version 3.10: On macOS, the function is now system-wide.

→ int

Similar to , but return time as nanoseconds.

Added in version 3.7.

→ float

Return the value (in fractional seconds) of a performance counter, i.e. a clock with the highest available

resolution to measure a short duration. It does include time elapsed during sleep and is system-wide. The

reference point of the returned value is undefined, so that only the difference between the results of two calls

is valid.

CPython implementation detail: On CPython, use the same clock as and is a mono-

tonic clock, i.e. a clock that cannot go backwards.

Use to avoid the precision loss caused by the type.

The Python Library Reference, Release 3.13.2



Added in version 3.3.

Changed in version 3.10: On Windows, the function is now system-wide.

Changed in version 3.13: Use the same clock as .

→ int

Similar to , but return time as nanoseconds.

Added in version 3.7.

→ float

Return the value (in fractional seconds) of the sum of the system and user CPU time of the current process. It

does not include time elapsed during sleep. It is process-wide by definition. The reference point of the returned

value is undefined, so that only the difference between the results of two calls is valid.

Use to avoid the precision loss caused by the type.

Added in version 3.3.

→ int

Similar to but return time as nanoseconds.

Added in version 3.7.

secs

Suspend execution of the calling thread for the given number of seconds. The argument may be a floating-point

number to indicate a more precise sleep time.

If the sleep is interrupted by a signal and no exception is raised by the signal handler, the sleep is restarted with

a recomputed timeout.

The suspension time may be longer than requested by an arbitrary amount, because of the scheduling of other

activity in the system.



Windows implementation

On Windows, if secs is zero, the thread relinquishes the remainder of its time slice to any other thread that is

ready to run. If there are no other threads ready to run, the function returns immediately, and the thread con-

tinues execution. On Windows 8.1 and newer the implementation uses a high-resolution timer which provides

resolution of 100 nanoseconds. If secs is zero, is used.



Unix implementation

• Use if available (resolution: 1 nanosecond);

• Or use if available (resolution: 1 nanosecond);

• Or use (resolution: 1 microsecond).



® Note

To emulate a “no-op”, use instead of .

To voluntarily relinquish the CPU, specify a real-time scheduling policy and use instead.



Raises an auditing event with argument .

Changed in version 3.5: The function now sleeps at least secs even if the sleep is interrupted by a signal, except

if the signal handler raises an exception (see PEP 475 for the rationale).

Changed in version 3.11: On Unix, the and functions are now used if

available. On Windows, a waitable timer is now used.

Changed in version 3.13: Raises an auditing event.

The Python Library Reference, Release 3.13.2



format, t

Convert a tuple or representing a time as returned by or to a string

as specified by the format argument. If t is not provided, the current time as returned by is

used. format must be a string. is raised if any field in t is outside of the allowed range.

0 is a legal argument for any position in the time tuple; if it is normally illegal the value is forced to a correct

one.

The following directives can be embedded in the format string. They are shown without the optional field

width and precision specification, and are replaced by the indicated characters in the result:



The Python Library Reference, Release 3.13.2



Directive Meaning Notes

Locale’s abbreviated weekday

name.

Locale’s full weekday name.

Locale’s abbreviated month

name.

Locale’s full month name.

Locale’s appropriate date and

time representation.

Day of the month as a decimal

number [01,31].

(1)

Microseconds as a decimal

number

[000000,999999].

Hour (24-hour clock) as a deci-

mal number [00,23].

Hour (12-hour clock) as a deci-

mal number [01,12].

Day of the year as a decimal num-

ber [001,366].

Month as a decimal number

[01,12].

Minute as a decimal number

[00,59].

Locale’s equivalent of either AM (2)

or PM.

Second as a decimal number (3)

[00,61].

Week number of the year (Sun- (4)

day as the first day of the week)

as a decimal number [00,53]. All

days in a new year preceding the

first Sunday are considered to be

in week 0.

Day of the week (Monday is 1;

Sunday is 7) as a decimal number

[1, 7].

Weekday as a decimal number

[0(Sunday),6].

Week number of the year (Mon- (4)

day as the first day of the week)

as a decimal number [00,53]. All

days in a new year preceding the

first Monday are considered to be

in week 0.

Locale’s appropriate date repre-

sentation.

Locale’s appropriate time repre-

sentation.

Year without century as a decimal

number [00,99].

Year with century as a decimal

number.

Time zone offset indicating a

positive or negative time differ-

ence from UTC/GMT of the form

+HHMM or -HHMM, where H

The Python Library Reference, Release 3.13.2



Notes:

(1) The format directive only applies to , not to .

and where the format

directive applies to microseconds.

(2) When used with the function, the directive only affects the output hour field if the

directive is used to parse the hour.

(3) The range really is to ; value is valid in timestamps representing leap seconds and value is

supported for historical reasons.

(4) When used with the function, and are only used in calculations when the day of the

week and the year are specified.

Here is an example, a format for dates compatible with that specified in the RFC 2822 Internet email standard.





Additional directives may be supported on certain platforms, but only the ones listed here have a meaning stan-

dardized by ANSI C. To see the full set of format codes supported on your platform, consult the

documentation.

On some platforms, an optional field width and precision specification can immediately follow the initial

of a directive in the following order; this is also not portable. The field width is normally 2 except for where

it is 3.

string, format

Parse a string representing a time according to a format. The return value is a as returned by

or .

The format parameter uses the same directives as those used by ; it defaults to

which matches the formatting returned by . If string cannot be parsed according

to format, or if it has excess data after parsing, is raised. The default values used to fill in any

missing data when more accurate values cannot be inferred are .

Both string and format must be strings.

For example:





Support for the directive is based on the values contained in and whether is true.

Because of this, it is platform-specific except for recognizing UTC and GMT which are always known (and

are considered to be non-daylight savings timezones).

Only the directives specified in the documentation are supported. Because is implemented per

platform it can sometimes offer more directives than those listed. But is independent of any

platform and thus does not necessarily support all directives available that are not documented as supported.



The type of the time value sequence returned by , , and . It is an object

with a named tuple interface: values can be accessed by index and by attribute name. The following values are

present:





The Python Library Reference, Release 3.13.2



Index Attribute Values

0 (for example, 1993)





1 range [1, 12]





2 range [1, 31]





3 range [0, 23]





4 range [0, 59]





5 range [0, 61]; see Note (2) in



6 range [0, 6]; Monday is 0





7 range [1, 366]





8 0, 1 or -1; see below





N/A





N/A





Note that unlike the C structure, the month value is a range of [1, 12], not [0, 11].

In calls to , may be set to 1 when daylight savings time is in effect, and 0 when it is not.

A value of -1 indicates that this is not known, and will usually result in the correct state being filled in.

When a tuple with an incorrect length is passed to a function expecting a , or having elements

of the wrong type, a is raised.

→ float

Return the time in seconds since the epoch as a floating-point number. The handling of leap seconds is platform

dependent. On Windows and most Unix systems, the leap seconds are not counted towards the time in seconds

since the epoch. This is commonly referred to as Unix time.

Note that even though the time is always returned as a floating-point number, not all systems provide time with

a better precision than 1 second. While this function normally returns non-decreasing values, it can return a

lower value than a previous call if the system clock has been set back between the two calls.

The number returned by may be converted into a more common time format (i.e. year, month, day,

hour, etc…) in UTC by passing it to function or in local time by passing it to the

function. In both cases a object is returned, from which the components of the calendar date

may be accessed as attributes.

Clock:

• On Windows, call .

The Python Library Reference, Release 3.13.2



• Call if available.

• Otherwise, call .

Use to avoid the precision loss caused by the type.

→ int

Similar to but returns time as an integer number of nanoseconds since the epoch.

Added in version 3.7.

→ float

Return the value (in fractional seconds) of the sum of the system and user CPU time of the current thread.

It does not include time elapsed during sleep. It is thread-specific by definition. The reference point of the

returned value is undefined, so that only the difference between the results of two calls in the same thread is

valid.

Use to avoid the precision loss caused by the type.

Availability: Linux, Unix, Windows.

Unix systems supporting .

Added in version 3.7.

→ int

Similar to but return time as nanoseconds.

Added in version 3.7.



Reset the time conversion rules used by the library routines. The environment variable specifies how this is

done. It will also set the variables (from the environment variable), (non-DST seconds

West of UTC), (DST seconds west of UTC) and (to 0 if this timezone does not have any

daylight saving time rules, or to nonzero if there is a time, past, present or future when daylight saving time

applies).

Availability: Unix.



® Note

Although in many cases, changing the environment variable may affect the output of functions like

without calling , this behavior should not be relied on.

The environment variable should contain no whitespace.



The standard format of the environment variable is (whitespace added for clarity):





Where the components are:

and

Three or more alphanumerics giving the timezone abbreviations.

time.tzname



The offset has the form: . This indicates the value added the local time to arrive at UTC. If preceded by a ‘-’, the timezone is east of the Prime Meridian; otherwise, it is west. If no offset follows dst, summer time is assumed to be one hour ahead of standard time.



Indicates when to change to and back from DST. The format of the start and end dates are one of the following:

The Python Library Reference, Release 3.13.2





The Julian day n (1 <= n <= 365). Leap days are not counted, so in all years February 28 is day 59 and March 1 is day 60.



The zero-based Julian day (0 <= n <= 365). Leap days are counted, and it is possible to refer to February 29.



The d’th day (0 <= d <= 6) of week n of month m of the year (1 <= n <= 5, 1 <= m <= 12, where week 5 means “the last d day in month m” which may occur in either the fourth or the fifth week). Week 1 is the first week in which the d’th day occurs. Day zero is a Sunday.

has the same format as except that no leading sign (‘-’ or ‘+’) is allowed. The default, if time is not given, is 02:00:00.





On many Unix systems (including *BSD, Linux, Solaris, and Darwin), it is more convenient to use the system’s

zoneinfo () database to specify the timezone rules. To do this, set the environment variable to

the path of the required timezone datafile, relative to the root of the systems ‘zoneinfo’ timezone database,

usually located at . For example, , ,

or .





These constants are used as parameters for and .



Identical to , except it also includes any time that the system is suspended.

This allows applications to get a suspend-aware monotonic clock without having to deal with the complications

of , which may have discontinuities if the time is changed using or

similar.

Availability: Linux >= 2.6.39.

Added in version 3.7.



The Solaris OS has a timer that attempts to use an optimal hardware source, and may give

close to nanosecond resolution. is the nonadjustable, high-resolution clock.

Availability: Solaris.

Added in version 3.3.

The Python Library Reference, Release 3.13.2





Clock that cannot be set and represents monotonic time since some unspecified starting point.

Availability: Unix.

Added in version 3.3.



Similar to , but provides access to a raw hardware-based time that is not subject to NTP

adjustments.

Availability: Linux >= 2.6.28, macOS >= 10.12.

Added in version 3.3.



Similar to , but reads a value cached by the system at context switch and hence has

less accuracy.

Availability: macOS >= 10.12.

Added in version 3.13.



High-resolution per-process timer from the CPU.

Availability: Unix.

Added in version 3.3.



High-resolution per-process timer from the CPU.

Availability: FreeBSD, NetBSD >= 7, OpenBSD.

Added in version 3.7.



International Atomic Time

The system must have a current leap second table in order for this to give the correct answer. PTP or NTP

software can maintain a leap second table.

Availability: Linux.

Added in version 3.9.



Thread-specific CPU-time clock.

Availability: Unix.

Added in version 3.3.



Time whose absolute value is the time the system has been running and not suspended, providing accurate

uptime measurement, both absolute and interval.

Availability: FreeBSD, OpenBSD >= 5.5.

Added in version 3.7.



Clock that increments monotonically, tracking the time since an arbitrary point, unaffected by frequency or

time adjustments and not incremented while the system is asleep.

Availability: macOS >= 10.12.

Added in version 3.8.

The Python Library Reference, Release 3.13.2





Like , but the value is cached by the system at context switches and therefore has less

accuracy.

Availability: macOS >= 10.12.

Added in version 3.13.

The following constant is the only parameter that can be sent to .



System-wide real-time clock. Setting this clock requires appropriate privileges.

Availability: Unix.

Added in version 3.3.





The offset of the local DST timezone, in seconds west of UTC, if one is defined. This is negative if the local

DST timezone is east of UTC (as in Western Europe, including the UK). Only use this if is nonzero.

See note below.



Nonzero if a DST timezone is defined. See note below.



The offset of the local (non-DST) timezone, in seconds west of UTC (negative in most of Western Europe,

positive in the US, zero in the UK). See note below.



A tuple of two strings: the first is the name of the local non-DST timezone, the second is the name of the local

DST timezone. If no DST timezone is defined, the second string should not be used. See note below.



® Note

For the above Timezone constants (, , , and ), the value is determined

by the timezone rules in effect at module load time or the last time is called and may be incorrect for

times in the past. It is recommended to use the and results from to obtain

timezone information.



µ See also

Module

More object-oriented interface to dates and times.

Module

Internationalization services. The locale setting affects the interpretation of many format specifiers in

and .

Module

General calendar-related functions. is the inverse of from this module.





Source code: Lib/logging/__init__.py

The Python Library Reference, Release 3.13.2



Important

This page contains the API reference information. For tutorial information and discussion of more advanced

topics, see

• Basic Tutorial

• Advanced Tutorial

• Logging Cookbook



This module defines functions and classes which implement a flexible event logging system for applications and libraries.

The key benefit of having the logging API provided by a standard library module is that all Python modules can participate in logging, so your application log can include your own messages integrated with messages from third-party modules.

Here’s a simple example of idiomatic usage:





If you run myapp.py, you should see this in myapp.log:





The key feature of this idiomatic usage is that the majority of code is simply creating a module level logger with , and using that logger to do any needed logging. This is concise, while allowing down-stream code fine-grained control if needed. Logged messages to the module-level logger get forwarded to handlers of loggers in higher-level modules, all the way up to the highest-level logger known as the root logger; this approach is known as hierarchical logging.

For logging to be useful, it needs to be configured: setting the levels and destinations for each logger, potentially changing how specific modules log, often based on command-line arguments or application configuration. In most cases, like the one above, only the root logger needs to be so configured, since all the lower level loggers at module

level eventually forward their messages to its handlers. provides a quick way to configure the root logger that handles many use cases.

The Python Library Reference, Release 3.13.2



The module provides a lot of functionality and flexibility. If you are unfamiliar with logging, the best way to get to grips with it is to view the tutorials (see the links above and on the right).

The basic classes defined by the module, together with their attributes and methods, are listed in the sections below.

• Loggers expose the interface that application code directly uses.

• Handlers send the log records (created by loggers) to the appropriate destination.

• Filters provide a finer grained facility for determining which log records to output.

• Formatters specify the layout of log records in the final output.





Loggers have the following attributes and methods. Note that Loggers should NEVER be instantiated directly, but

always through the module-level function . Multiple calls to with the same name will always return a reference to the same Logger object.

The is potentially a period-separated hierarchical value, like (though it could also be just plain , for example). Loggers that are further down in the hierarchical list are children of loggers higher up in the list. For example, given a logger with a name of , loggers with names of , , and are all descendants of . In addition, all loggers are descendants of the root logger. The logger name hierarchy is analogous to the Python package hierarchy, and identical to it if you organise your loggers on a per-module basis using the recommended construction . That’s because in a module, is the module’s name in the Python package namespace.





This is the logger’s name, and is the value that was passed to to obtain the logger.



® Note

This attribute should be treated as read-only.





The threshold of this logger, as set by the method.



® Note

Do not set this attribute directly - always use , which has checks for the level passed to it.





The parent logger of this logger. It may change based on later instantiation of loggers which are higher up in the namespace hierarchy.



® Note

This value should be treated as read-only.





If this attribute evaluates to true, events logged to this logger will be passed to the handlers of higher level (ancestor) loggers, in addition to any handlers attached to this logger. Messages are passed directly to the ancestor loggers’ handlers - neither the level nor filters of the ancestor loggers in question are considered.

If this evaluates to false, logging messages are not passed to the handlers of ancestor loggers.

The Python Library Reference, Release 3.13.2



Spelling it out with an example: If the propagate attribute of the logger named evaluates to true, any event logged to via a method call such as will [subject to passing that logger’s level and filter settings] be passed in turn to any handlers attached to loggers named , and the root logger, after first being passed to any handlers attached to . If any logger in the chain , , has its attribute set to false, then that is the last logger whose handlers are offered the event to handle, and propagation stops at that point.

The constructor sets this attribute to .



® Note

If you attach a handler to a logger and one or more of its ancestors, it may emit the same record multiple times. In general, you should not need to attach a handler to more than one logger - if you just attach it to the appropriate logger which is highest in the logger hierarchy, then it will see all events logged by all descendant loggers, provided that their propagate setting is left set to . A common scenario is to attach handlers only to the root logger, and to let propagation take care of the rest.





The list of handlers directly attached to this logger instance.



® Note

This attribute should be treated as read-only; it is normally changed via the and

methods, which use locks to ensure thread-safe operation.





This attribute disables handling of any events. It is set to in the initializer, and only changed by logging configuration code.



® Note

This attribute should be treated as read-only.



level

Sets the threshold for this logger to level. Logging messages which are less severe than level will be ignored; logging messages which have severity level or higher will be emitted by whichever handler or handlers service this logger, unless a handler’s level has been set to a higher severity level than level.

When a logger is created, the level is set to (which causes all messages to be processed when the logger is the root logger, or delegation to the parent when the logger is a non-root logger). Note that

the root logger is created with level .

The term ‘delegation to the parent’ means that if a logger has a level of NOTSET, its chain of ancestor loggers is traversed until either an ancestor with a level other than NOTSET is found, or the root is reached.

If an ancestor is found with a level other than NOTSET, then that ancestor’s level is treated as the effective level of the logger where the ancestor search began, and is used to determine how a logging event is handled.

If the root is reached, and it has a level of NOTSET, then all messages will be processed. Otherwise, the root’s level will be used as the effective level.

See Logging Levels for a list of levels.

Changed in version 3.2: The level parameter now accepts a string representation of the level such as

‘INFO’ as an alternative to the integer constants such as . Note, however, that levels are internally The Python Library Reference, Release 3.13.2



stored as integers, and methods such as e.g. and will re-turn/expect to be passed integers.

level

Indicates if a message of severity level would be processed by this logger. This method checks first the module-level level set by and then the logger’s effective level as determined

by .



Indicates the effective level for this logger. If a value other than has been set using ,

it is returned. Otherwise, the hierarchy is traversed towards the root until a value other than is

found, and that value is returned. The value returned is an integer, typically one of ,

etc.

suffix

Returns a logger which is a descendant to this logger, as determined by the suffix. Thus, would return the same logger as would be returned by . This is a convenience method, useful when the parent logger is named using e.g. rather than a literal string.

Added in version 3.2.



Returns a set of loggers which are immediate children of this logger. So for example might return a set containing loggers named and , but a logger named wouldn’t be included in the set. Likewise, might return a set including a logger named , but it wouldn’t include one named .

Added in version 3.12.

msg, *args, **kwargs

Logs a message with level on this logger. The msg is the message format string, and the args are the arguments which are merged into msg using the string formatting operator. (Note that this means that you can use keywords in the format string, together with a single dictionary argument.) No % formatting operation is performed on msg when no args are supplied.

There are four keyword arguments in kwargs which are inspected: exc_info, stack_info, stacklevel and extra.

If exc_info does not evaluate as false, it causes exception information to be added to the logging message.

If an exception tuple (in the format returned by ) or an exception instance is provided,

it is used; otherwise, is called to get the exception information.

The second optional keyword argument is stack_info, which defaults to . If true, stack information is added to the logging message, including the actual logging call. Note that this is not the same stack information as that displayed through specifying exc_info: The former is stack frames from the bottom of the stack up to the logging call in the current thread, whereas the latter is information about stack frames which have been unwound, following an exception, while searching for exception handlers.

You can specify stack_info independently of exc_info, e.g. to just show how you got to a certain point in your code, even when no exceptions were raised. The stack frames are printed following a header line which says:





This mimics the which is used when displaying exception frames.

The third optional keyword argument is stacklevel, which defaults to . If greater than 1, the correspond-ing number of stack frames are skipped when computing the line number and function name set in the

created for the logging event. This can be used in logging helpers so that the function name,

The Python Library Reference, Release 3.13.2



filename and line number recorded are not the information for the helper function/method, but rather its

caller. The name of this parameter mirrors the equivalent one in the module.

The fourth keyword argument is extra which can be used to pass a dictionary which is used to populate the

of the created for the logging event with user-defined attributes. These custom attributes can then be used as you like. For example, they could be incorporated into logged messages. For example:





would print something like





The keys in the dictionary passed in extra should not clash with the keys used by the logging system. (See

the section on LogRecord attributes for more information on which keys are used by the logging system.)

If you choose to use these attributes in logged messages, you need to exercise some care. In the above

example, for instance, the has been set up with a format string which expects ‘clientip’ and

‘user’ in the attribute dictionary of the . If these are missing, the message will not be logged because a string formatting exception will occur. So in this case, you always need to pass the extra dictionary with these keys.

While this might be annoying, this feature is intended for use in specialized circumstances, such as multi-threaded servers where the same code executes in many contexts, and interesting conditions which arise are dependent on this context (such as remote client IP address and authenticated user name, in the above

example). In such circumstances, it is likely that specialized s would be used with particular

s.

If no handler is attached to this logger (or any of its ancestors, taking into account the relevant

attributes), the message will be sent to the handler set on .

Changed in version 3.2: The stack_info parameter was added.

Changed in version 3.5: The exc_info parameter can now accept exception instances.

Changed in version 3.8: The stacklevel parameter was added.

msg, *args, **kwargs

Logs a message with level on this logger. The arguments are interpreted as for .

msg, *args, **kwargs

Logs a message with level on this logger. The arguments are interpreted as for .



® Note

There is an obsolete method which is functionally identical to . As is deprecated, please do not use it - use instead.



msg, *args, **kwargs

Logs a message with level on this logger. The arguments are interpreted as for .

msg, *args, **kwargs

Logs a message with level on this logger. The arguments are interpreted as for .



The Python Library Reference, Release 3.13.2



level, msg, *args, **kwargs

Logs a message with integer level level on this logger. The other arguments are interpreted as for

.

msg, *args, **kwargs

Logs a message with level on this logger. The arguments are interpreted as for . Ex-ception info is added to the logging message. This method should only be called from an exception handler.

filter

Adds the specified filter filter to this logger.

filter

Removes the specified filter filter from this logger.

record

Apply this logger’s filters to the record and return if the record is to be processed. The filters are consulted in turn, until one of them returns a false value. If none of them return a false value, the record will be processed (passed to handlers). If one returns a false value, no further processing of the record occurs.

hdlr

Adds the specified handler hdlr to this logger.

hdlr

Removes the specified handler hdlr from this logger.

stack_info=False, stacklevel=1

Finds the caller’s source filename and line number. Returns the filename, line number, function name and stack information as a 4-element tuple. The stack information is returned as unless stack_info is .

The stacklevel parameter is passed from code calling the and other APIs. If greater than 1, the excess is used to skip stack frames before determining the values to be returned. This will generally be useful when calling logging APIs from helper/wrapper code, so that the information in the event log refers not to the helper/wrapper code, but to the code that calls it.

record

Handles a record by passing it to all handlers associated with this logger and its ancestors (until a false value of propagate is found). This method is used for unpickled records received from a socket, as well

as those created locally. Logger-level filtering is applied using .

name, level, fn, lno, msg, args, exc_info, func=None, extra=None, sinfo=None

This is a factory method which can be overridden in subclasses to create specialized in-stances.



Checks to see if this logger has any handlers configured. This is done by looking for handlers in this logger and its parents in the logger hierarchy. Returns if a handler was found, else . The method stops searching up the hierarchy whenever a logger with the ‘propagate’ attribute set to false is found - that will be the last logger which is checked for the existence of handlers.

Added in version 3.2.

Changed in version 3.7: Loggers can now be pickled and unpickled.





The numeric values of logging levels are given in the following table. These are primarily of interest if you want to define your own levels, and need them to have specific values relative to the predefined levels. If you define a level with the same numeric value, it overwrites the predefined value; the predefined name is lost.

The Python Library Reference, Release 3.13.2



Level Numeric value What it means / When to use it

0



to determine the effective level. If

that still resolves to , then

all events are logged. When set on

a handler, all events are handled.

10



diagnose a problem.

20

ing as expected.

30



might occur in the near future (e.g.

‘disk space low’). The software is

still working as expected.

40



form some function.

50



continue running.





Handlers have the following attributes and methods. Note that is never instantiated directly; this class

acts as a base for more useful subclasses. However, the method in subclasses needs to call

.



level=NOTSET

Initializes the instance by setting its level, setting the list of filters to the empty list and creating

a lock (using ) for serializing access to an I/O mechanism.



Initializes a thread lock which can be used to serialize access to underlying I/O functionality which may not be threadsafe.



Acquires the thread lock created with .



Releases the thread lock acquired with .

level

Sets the threshold for this handler to level. Logging messages which are less severe than level will be ig-

nored. When a handler is created, the level is set to (which causes all messages to be processed).

See Logging Levels for a list of levels.

Changed in version 3.2: The level parameter now accepts a string representation of the level such as

‘INFO’ as an alternative to the integer constants such as .

fmt

Sets the for this handler to fmt.

The Python Library Reference, Release 3.13.2



filter

Adds the specified filter filter to this handler.

filter

Removes the specified filter filter from this handler.

record

Apply this handler’s filters to the record and return if the record is to be processed. The filters are consulted in turn, until one of them returns a false value. If none of them return a false value, the record will be emitted. If one returns a false value, the handler will not emit the record.



Ensure all logging output has been flushed. This version does nothing and is intended to be implemented by subclasses.



Tidy up any resources used by the handler. This version does no output but removes the handler from an internal map of handlers, which is used for handler lookup by name.

Subclasses should ensure that this gets called from overridden methods.

record

Conditionally emits the specified logging record, depending on filters which may have been added to the handler. Wraps the actual emission of the record with acquisition/release of the I/O thread lock.

record

This method should be called from handlers when an exception is encountered during an call.

If the module-level attribute is , exceptions get silently ignored. This is what is mostly wanted for a logging system - most users will not care about errors in the logging system, they are more interested in application errors. You could, however, replace this with a custom handler if you wish. The specified record is the one which was being processed when the exception occurred. (The

default value of is , as that is more useful during development).

record

Do formatting for a record - if a formatter is set, use it. Otherwise, use the default formatter for the module.

record

Do whatever it takes to actually log the specified logging record. This version is intended to be imple-

mented by subclasses and so raises a .



Á Warning

This method is called after a handler-level lock is acquired, which is released after this method returns. When you override this method, note that you should be careful when calling anything that invokes other parts of the logging API which might do locking, because that might result in a deadlock. Specifically:

• Logging configuration APIs acquire the module-level lock, and then individual handler-level

locks as those handlers are configured.

• Many logging APIs lock the module-level lock. If such an API is called from this method, it

could cause a deadlock if a configuration call is made on another thread, because that thread will try to acquire the module-level lock before the handler-level lock, whereas this thread tries to acquire the module-level lock after the handler-level lock (because in this method, the handler-level lock has already been acquired).



For a list of handlers included as standard, see .



The Python Library Reference, Release 3.13.2





fmt=None, datefmt=None, style=’%’, validate=True, *, defaults=None

Responsible for converting a to an output string to be interpreted by a human or external system.

Parameters

• () – A format string in the given style for the logged output as a whole. The

possible mapping keys are drawn from the object’s LogRecord attributes. If not specified, is used, which is just the logged message.

• () – A format string in the given style for the date/time portion of the logged

output. If not specified, the default described in is used.

• () – Can be one of , or and determines how the format string

will be merged with its data: using one of printf-style String Formatting (),

() or (). This only applies to fmt and datefmt (e.g. versus ), not to the actual log messages passed to the logging methods. However, there are other ways to use - and -formatting for log mes-sages.

• () – If (the default), incorrect or mismatched fmt and style

will raise a ; for example, .

• () – A dictionary with default values to use in

custom fields. For example,

Changed in version 3.2: Added the style parameter.

Changed in version 3.8: Added the validate parameter.

Changed in version 3.10: Added the defaults parameter.

record

The record’s attribute dictionary is used as the operand to a string formatting operation. Returns the resulting string. Before formatting the dictionary, a couple of preparatory steps are carried out. The message attribute of the record is computed using msg % args. If the formatting string contains

, is called to format the event time. If there is exception information,

it is formatted using and appended to the message. Note that the formatted ex-ception information is cached in attribute exc_text. This is useful because the exception information can

be pickled and sent across the wire, but you should be careful if you have more than one subclass which customizes the formatting of exception information. In this case, you will have to clear the cached value (by setting the exc_text attribute to ) after a formatter has done its formatting, so that the next formatter to handle the event doesn’t use the cached value, but recalculates it afresh.

If stack information is available, it’s appended after the exception information, using to transform it if necessary.

record, datefmt=None

This method should be called from by a formatter which wants to make use of a formatted time. This method can be overridden in formatters to provide for any specific requirement, but the basic

behavior is as follows: if datefmt (a string) is specified, it is used with to format the creation time of the record. Otherwise, the format ‘%Y-%m-%d %H:%M:%S,uuu’ is used, where the

uuu part is a millisecond value and the other letters are as per the documentation. An example time in this format is . The resulting string is returned.

This function uses a user-configurable function to convert the creation time to a tuple. By default,

is used; to change this for a particular formatter instance, set the attribute

to a function with the same signature as or . To change it for all formatters, for example if you want all logging times to be shown in GMT, set the attribute in the class.

The Python Library Reference, Release 3.13.2



Changed in version 3.3: Previously, the default format was hard-coded as in this example: where the part before the comma is handled by a strptime format string ( ), and the part after the comma is a millisecond value. Because strptime does not have a format placeholder for milliseconds, the millisecond value is appended using another format string, — and both of these format strings have been hardcoded into this method. With the change, these strings are defined as class-level attributes which can be overridden at the instance level when desired. The names of the attributes are (for the strptime format string) and (for appending the millisecond value).

Changed in version 3.9: The can be .

exc_info

Formats the specified exception information (a standard exception tuple as returned by

) as a string. This default implementation just uses . The resulting string is returned.

stack_info

Formats the specified stack information (a string as returned by , but with the last newline removed) as a string. This default implementation just returns the input value.

linefmt=None

A base formatter class suitable for subclassing when you want to format a number of records. You can pass a

instance which you want to use to format each line (that corresponds to a single record). If not

specified, the default formatter (which just outputs the event message) is used as the line formatter.

records

Return a header for a list of records. The base implementation just returns the empty string. You will need to override this method if you want specific behaviour, e.g. to show the count of records, a title or a separator line.

records

Return a footer for a list of records. The base implementation just returns the empty string. You will need to override this method if you want specific behaviour, e.g. to show the count of records or a separator line.

records

Return formatted text for a list of records. The base implementation just returns the empty string if there are no records; otherwise, it returns the concatenation of the header, each record formatted with the line formatter, and the footer.





can be used by and for more sophisticated filtering than is provided by levels. The base filter class only allows events which are below a certain point in the logger hierarchy. For example, a filter initialized with ‘A.B’ will allow events logged by loggers ‘A.B’, ‘A.B.C’, ‘A.B.C.D’, ‘A.B.D’ etc. but not ‘A.BB’, ‘B.A.B’ etc. If initialized with the empty string, all events are passed.

name=”

Returns an instance of the class. If name is specified, it names a logger which, together with its

children, will have its events allowed through the filter. If name is the empty string, allows every event.

record

Is the specified record to be logged? Returns false for no, true for yes. Filters can either modify log records in-place or return a completely different record instance which will replace the original log record in any future processing of the event.

Note that filters attached to handlers are consulted before an event is emitted by the handler, whereas filters attached

to loggers are consulted whenever an event is logged (using , , etc.), before sending an event to handlers. This means that events which have been generated by descendant loggers will not be filtered by a logger’s filter setting, unless the filter has also been applied to those descendant loggers.

The Python Library Reference, Release 3.13.2



You don’t actually need to subclass : you can pass any instance which has a method with the same semantics.

Changed in version 3.2: You don’t need to create specialized classes, or use other classes with a method: you can use a function (or other callable) as a filter. The filtering logic will check to see if the filter object

has a attribute: if it does, it’s assumed to be a and its method is called. Otherwise, it’s assumed to be a callable and called with the record as the single parameter. The returned value should conform to

that returned by .

Changed in version 3.12: You can now return a instance from filters to replace the log record rather

than modifying it in place. This allows filters attached to a to modify the log record before it is emitted, without having side effects on other handlers.

Although filters are used primarily to filter records based on more sophisticated criteria than levels, they get to see every record which is processed by the handler or logger they’re attached to: this can be useful if you want to do things like counting how many records were processed by a particular logger or handler, or adding, changing or removing

attributes in the being processed. Obviously changing the LogRecord needs to be done with some care, but it does allow the injection of contextual information into logs (see filters-contextual).





instances are created automatically by the every time something is logged, and can be created

manually via (for example, from a pickled event received over the wire).

name, level, pathname, lineno, msg, args, exc_info, func=None, sinfo=None

Contains all the information pertinent to the event being logged.

The primary information is passed in msg and args, which are combined using to create the

attribute of the record.

Parameters

• () – The name of the logger used to log the event represented by this

. Note that the logger name in the will always have this value, even though it may be emitted by a handler attached to a different (ancestor) logger.

• () – The numeric level of the logging event (such as for , for

, etc). Note that this is converted to two attributes of the LogRecord: for the numeric value and for the corresponding level name.

• () – The full string path of the source file where the logging call was made.

• () – The line number in the source file where the logging call was made.

• () – The event description message, which can be a %-format string with place-

holders for variable data, or an arbitrary object (see arbitrary-object-messages).

• ( ) – Variable data to merge into the msg argument to

obtain the event description.

• (

) – An exception tuple with the current exception in-

formation, as returned by , or if no exception information is available.

• ( ) – The name of the function or method from which the logging call

was invoked.

• ( ) – A text string representing stack information from the base of the

stack in the current thread, up to the logging call.



Returns the message for this instance after merging any user-supplied arguments with the

message. If the user-supplied message argument to the logging call is not a string, is called on it to convert it to a string. This allows use of user-defined classes as messages, whose method can return the actual format string to be used.

The Python Library Reference, Release 3.13.2



Changed in version 3.2: The creation of a has been made more configurable by providing a

factory which is used to create the record. The factory can be set using and

(see this for the factory’s signature).

This functionality can be used to inject your own values into a at creation time. You can use the

following pattern:





With this pattern, multiple factories could be chained, and as long as they don’t overwrite each other’s attributes

or unintentionally overwrite the standard attributes listed above, there should be no surprises.





The LogRecord has a number of attributes, most of which are derived from the parameters to the constructor. (Note that the names do not always correspond exactly between the LogRecord constructor parameters and the LogRecord attributes.) These attributes can be used to merge data from the record into the format string. The following table lists (in alphabetical order) the attribute names, their meanings and the corresponding placeholder in a %-style format string.

If you are using {}-formatting (), you can use as the placeholder in the format string.

If you are using $-formatting (), use the form . In both cases, of course, replace with the actual attribute name you want to use.

In the case of {}-formatting, you can specify formatting flags by placing them after the attribute name, separated from it with a colon. For example: a placeholder of would format a millisecond value of as . Refer

to the documentation for full details on the options available to you.



The Python Library Reference, Release 3.13.2



At- Format Description

tribute

name

args You shouldn’t The tuple of arguments merged into to produce , or a dict whose

need to format

this yourself. nary).

asc- Human-readable time when the was created. By default this is of the

time

portion of the time).

cre- Time when the was created (as returned by / 1e9).

ated

exc_info You shouldn’t Exception tuple (à la ) or, if no exception has occurred, .

need to format

this yourself.

file- Filename portion of .

name

func- Name of function containing the logging call.

Name

level- Text logging level for the message (, , , ,

name ).

lev- Numeric logging level for the message (, , , ,

elno ).

lineno Source line number where the logging call was issued (if available).

mes- The logged message, computed as . This is set when

sage is invoked.

mod- Module (name portion of ).

ule

msecs Millisecond portion of the time when the was created.

msg You shouldn’t The format string passed in the original logging call. Merged with to produce

need to format , or an arbitrary object (see arbitrary-object-messages). this yourself.

name Name of the logger used to log the call.

path- Full pathname of the source file where the logging call was issued (if available).

name

pro- Process ID (if available).

cess

pro- Process name (if available).

cess-

Name

rela- Time in milliseconds when the LogRecord was created, relative to the time the

tive- logging module was loaded.

Cre-

ated

stack_infoYou shouldn’t Stack frame information (where available) from the bottom of the stack in the cur-

need to format

this yourself. in the creation of this record.

thread Thread ID (if available).

thread- Thread name (if available).

Name

taskName name (if available).



Changed in version 3.1: processName was added.

Changed in version 3.12: taskName was added.



The Python Library Reference, Release 3.13.2





instances are used to conveniently pass contextual information into logging calls. For a usage example, see the section on adding contextual information to your logging output.

logger, extra, merge_extra=False

Returns an instance of initialized with an underlying instance, a dict-like object

(extra), and a boolean (merge_extra) indicating whether or not the extra argument of individual log calls should

be merged with the extra. The default behavior is to ignore the extra argument of individual

log calls and only use the one of the instance

msg, kwargs

Modifies the message and/or keyword arguments passed to a logging call in order to insert contextual information. This implementation takes the object passed as extra to the constructor and adds it to kwargs using key ‘extra’. The return value is a (msg, kwargs) tuple which has the (possibly modified) versions of the arguments passed in.



Delegates to the underlying on logger.



Delegates to the underlying method on logger.

In addition to the above, supports the following methods of : ,

, , , , , , ,

, and .

tures as their counterparts in , so you can use the two types of instances interchangeably.

Changed in version 3.2: The , , and

methods were added to . These methods delegate to the underly-

ing logger.

Changed in version 3.6: Attribute and method were added, which delegate to the underlying

logger and allow adapters to be nested.

Changed in version 3.13: The merge_extra argument was added.





The logging module is intended to be thread-safe without any special work needing to be done by its clients. It achieves this though using threading locks; there is one lock to serialize access to the module’s shared data, and each handler also creates a lock to serialize access to its underlying I/O.

If you are implementing asynchronous signal handlers using the module, you may not be able to use logging

from within such handlers. This is because lock implementations in the module are not always re-entrant, and so cannot be invoked from such signal handlers.





In addition to the classes described above, there are a number of module-level functions.

name=None

Return a logger with the specified name or, if name is , return the root logger of the hierarchy. If

specified, the name is typically a dot-separated hierarchical name like ‘a’, ‘a.b’ or ‘a.b.c.d’. Choice of these

names is entirely up to the developer who is using logging, though it is recommended that be used

unless you have a specific reason for not doing that, as mentioned in Logger Objects.

All calls to this function with a given name return the same logger instance. This means that logger instances

never need to be passed between different parts of an application.



Return either the standard class, or the last class passed to . This function may

be called from within a new class definition, to ensure that installing a customized class will not undo

customizations already applied by other code. For example:

The Python Library Reference, Release 3.13.2





Return a callable which is used to create a .

Added in version 3.2: This function has been provided, along with , to allow

developers more control over how the representing a logging event is constructed.

See for more information about the how the factory is called.

msg, *args, **kwargs

This is a convenience function that calls , on the root logger. The handling of the arguments

is in every way identical to what is described in that method.

The only difference is that if the root logger has no handlers, then is called, prior to calling

on the root logger.

For very short scripts or quick demonstrations of facilities, and the other module-level func-

tions may be convenient. However, most programs will want to carefully and explicitly control the logging

configuration, and should therefore prefer creating a module-level logger and calling (or

other level-specific methods) on it, as described at the beginnning of this documentation.

msg, *args, **kwargs

Logs a message with level on the root logger. The arguments and behavior are otherwise the same as for

.

msg, *args, **kwargs

Logs a message with level on the root logger. The arguments and behavior are otherwise the same

as for .



® Note

There is an obsolete function which is functionally identical to . As is deprecated, please do not use it - use instead.



msg, *args, **kwargs

Logs a message with level on the root logger. The arguments and behavior are otherwise the same as

for .

msg, *args, **kwargs

Logs a message with level on the root logger. The arguments and behavior are otherwise the same

as for .

msg, *args, **kwargs

Logs a message with level on the root logger. The arguments and behavior are otherwise the same as

for . Exception info is added to the logging message. This function should only be called from an

exception handler.

level, msg, *args, **kwargs

Logs a message with level level on the root logger. The arguments and behavior are otherwise the same as for

.

level=CRITICAL

Provides an overriding level level for all loggers which takes precedence over the logger’s own level. When

the need arises to temporarily throttle logging output down across the whole application, this function can be

useful. Its effect is to disable all logging calls of severity level and below, so that if you call it with a value of

INFO, then all INFO and DEBUG events would be discarded, whereas those of severity WARNING and above

would be processed according to the logger’s effective level. If is The Python Library Reference, Release 3.13.2



called, it effectively removes this overriding level, so that logging output again depends on the effective levels

of individual loggers.

Note that if you have defined any custom logging level higher than (this is not recommended), you

won’t be able to rely on the default value for the level parameter, but will have to explicitly supply a suitable

value.

Changed in version 3.7: The level parameter was defaulted to level . See bpo-28524 for more

information about this change.

level, levelName

Associates level level with text levelName in an internal dictionary, which is used to map numeric levels to a

textual representation, for example when a formats a message. This function can also be used

to define your own levels. The only constraints are that all levels used must be registered using this function,

levels should be positive integers and they should increase in increasing order of severity.



® Note

If you are thinking of defining your own levels, please see the section on custom-levels.





Returns a mapping from level names to their corresponding logging levels. For example, the string “CRIT-

ICAL” maps to . The returned mapping is copied from an internal mapping on each call to this

function.

Added in version 3.11.

level

Returns the textual or numeric representation of logging level level.

If level is one of the predefined levels , , , or then you get the corre-

sponding string. If you have associated levels with names using then the name you have

associated with level is returned. If a numeric value corresponding to one of the defined levels is passed in,

the corresponding string representation is returned.

The level parameter also accepts a string representation of the level such as ‘INFO’. In such cases, this functions

returns the corresponding numeric value of the level.

If no matching numeric or string value is passed in, the string ‘Level %s’ % level is returned.



® Note

Levels are internally integers (as they need to be compared in the logging logic). This function is used to convert between an integer level and the level name displayed in the formatted log output by means of the

format specifier (see LogRecord attributes), and vice versa.



Changed in version 3.4: In Python versions earlier than 3.4, this function could also be passed a text level, and

would return the corresponding numeric value of the level. This undocumented behaviour was considered a

mistake, and was removed in Python 3.4, but reinstated in 3.4.2 due to retain backward compatibility.

name

Returns a handler with the specified name, or if there is no handler with that name.

Added in version 3.12.



Returns an immutable set of all known handler names.

Added in version 3.12.

The Python Library Reference, Release 3.13.2



attrdict

Creates and returns a new instance whose attributes are defined by attrdict. This function is useful

for taking a pickled attribute dictionary, sent over a socket, and reconstituting it as a

instance at the receiving end.

**kwargs

Does basic configuration for the logging system by creating a with a default

and adding it to the root logger. The functions , , , and

will call automatically if no handlers are defined for the root logger.

This function does nothing if the root logger already has handlers configured, unless the keyword argument

force is set to .



® Note

This function should be called from the main thread before other threads are started. In versions of Python prior to 2.7.1 and 3.2, if this function is called from multiple threads, it is possible (in rare circumstances) that a handler will be added to the root logger more than once, leading to unexpected results such as messages being duplicated in the log.



The following keyword arguments are supported.



Format Description

filename Specifies that a be created, using the specified filename, rather than a

.

filemode If filename is specified, open the file in this mode. Defaults to . format Use the specified format string for the handler. Defaults to attributes , and

separated by colons.

datefmt Use the specified date/time format, as accepted by . style If format is specified, use this style for the format string. One of , or for

printf-style, or respectively. Defaults to .

level Set the root logger level to the specified level.

stream Use the specified stream to initialize the . Note that this argument is

incompatible with filename- if both are present, a is raised.

handlers

Any handlers which don’t already have a formatter set will be assigned the default formatter created in this function. Note that this argument is incompatible with filename or stream- if both are present, a is raised.

force If this keyword argument is specified as true, any existing handlers attached to the root

logger are removed and closed, before carrying out the configuration as specified by the other arguments.

encoding If this keyword argument is specified along with filename, its value is used when the

is created, and thus used when opening the output file.

errors If this keyword argument is specified along with filename, its value is used when the

is created, and thus used when opening the output file. If not specified, the value ‘backslashreplace’ is used. Note that if is specified, it will be passed as such to

, which means that it will be treated the same as passing ‘errors’.



Changed in version 3.2: The style argument was added.

Changed in version 3.3: The handlers argument was added. Additional checks were added to catch situations

where incompatible arguments are specified (e.g. handlers together with stream or filename, or stream together

with filename).

Changed in version 3.8: The force argument was added.

Changed in version 3.9: The encoding and errors arguments were added.

The Python Library Reference, Release 3.13.2





Informs the logging system to perform an orderly shutdown by flushing and closing all handlers. This should

be called at application exit and no further use of the logging system should be made after this call.

When the logging module is imported, it registers this function as an exit handler (see ), so normally

there’s no need to do that manually.

klass

Tells the logging system to use the class klass when instantiating a logger. The class should define

such that only a name argument is required, and the should call . This

function is typically called before any loggers are instantiated by applications which need to use custom logger

behavior. After this call, as at any other time, do not instantiate loggers directly using the subclass: continue

to use the API to get your loggers.

factory

Set a callable which is used to create a .

Parameters

– The factory callable to be used to instantiate a log record.

Added in version 3.2: This function has been provided, along with , to allow

developers more control over how the representing a logging event is constructed.

The factory has the following signature:





name

The logger name.

level

The logging level (numeric).

fn

The full pathname of the file where the logging call was made.

lno

The line number in the file where the logging call was made.

msg

The logging message.

args

The arguments for the logging message.

exc_info

An exception tuple, or .

func

The name of the function or method which invoked the logging call.

sinfo

A stack traceback such as is provided by , showing the call hierarchy.

kwargs

Additional keyword arguments.





A “handler of last resort” is available through this attribute. This is a writing to

with a level of , and is used to handle logging events in the absence of any logging configuration. The

end result is to just print the message to . This replaces the earlier error message saying that “no

The Python Library Reference, Release 3.13.2



handlers could be found for logger XYZ”. If you need the earlier behaviour for some reason,

can be set to .

Added in version 3.2.



Used to see if exceptions during handling should be propagated.

Default: .

If is , exceptions get silently ignored. This is what is mostly wanted for a logging

system - most users will not care about errors in the logging system, they are more interested in application

errors.





The function can be used to integrate with the module.

capture

This function is used to turn the capture of warnings by logging on and off.

If capture is , warnings issued by the module will be redirected to the logging system. Specif-

ically, a warning will be formatted using and the resulting string logged to a

logger named with a severity of .

If capture is , the redirection of warnings to the logging system will stop, and warnings will be redirected

to their original destinations (i.e. those in effect before was called).



µ See also

Module

Configuration API for the logging module.

Module

Useful handlers included with the logging module.

PEP 282- A Logging System

The proposal which described this feature for inclusion in the Python standard library.

Original Python logging package

This is the original source for the package. The version of the package available from this site

is suitable for use with Python 1.5.2, 2.1.x and 2.2.x, which do not include the package in the standard library.





Source code: Lib/logging/config.py



Important

This page contains only reference information. For tutorials, please see

• Basic Tutorial

• Advanced Tutorial

• Logging Cookbook



This section describes the API for configuring the logging module.

The Python Library Reference, Release 3.13.2





The following functions configure the logging module. They are located in the module. Their use is optional — you can configure the logging module using these functions or by making calls to the main API

(defined in itself) and defining handlers which are declared either in or .

config

Takes the logging configuration from a dictionary. The contents of this dictionary are described in Configuration

dictionary schema below.

If an error is encountered during configuration, this function will raise a , ,

or with a suitably descriptive message. The following is a (possibly in-

complete) list of conditions which will raise an error:

• A which is not a string or which is a string not corresponding to an actual logging level.

• A value which is not a boolean.

• An id which does not have a corresponding destination.

• A non-existent handler id found during an incremental call.

• An invalid logger name.

• Inability to resolve to an internal or external object.

Parsing is performed by the class, whose constructor is passed the dictionary used

for configuration, and has a method. The module has a callable at-

tribute which is initially set to . You can replace the value of

with a suitable implementation of your own.

calls passing the specified dictionary, and then calls the

method on the returned object to put the configuration into effect:





For example, a subclass of could call in its own

, then set up custom prefixes which would be usable in the subsequent call.

would be bound to this new subclass, and then could be called exactly

as in the default, uncustomized state.

Added in version 3.2.

fname, defaults=None, disable_existing_loggers=True, encoding=None

Reads the logging configuration from a -format file. The format of the file should be as de-

scribed in Configuration file format. This function can be called several times from an application, allowing an

end user to select from various pre-canned configurations (if the developer provides a mechanism to present

the choices and load the chosen configuration).

It will raise if the file doesn’t exist and if the file is invalid or empty.

Parameters

• – A filename, or a file-like object, or an instance derived from

. If a -derived instance is passed, it is

used as is. Otherwise, a is instantiated, and the configuration read by it

from the object passed in . If that has a method, it is assumed to be

a file-like object and read using ; otherwise, it is assumed to be a filename

and passed to .

• – Defaults to be passed to the can be specified in this argu-

ment.

• – If specified as , loggers which exist when this

call is made are left enabled. The default is because this enables old behaviour in

The Python Library Reference, Release 3.13.2



a backward-compatible way. This behaviour is to disable any existing non-root loggers unless they or their ancestors are explicitly named in the logging configuration.

• – The encoding used to open file when fname is filename.

Changed in version 3.4: An instance of a subclass of is now accepted as a value for

. This facilitates:

• Use of a configuration file where logging configuration is just part of the overall application configuration.

• Use of a configuration read from a file, and then modified by the using application (e.g. based

on command-line parameters or other aspects of the runtime environment) before being passed to .

Changed in version 3.10: Added the encoding parameter.

Changed in version 3.12: An exception will be thrown if the provided file doesn’t exist or is invalid or empty.

port=DEFAULT_LOGGING_CONFIG_PORT, verify=None

Starts up a socket server on the specified port, and listens for new configurations. If no port is specified, the

module’s default is used. Logging configurations will be sent as a file

suitable for processing by or . Returns a instance on which you

can call to start the server, and which you can when appropriate. To stop the server, call

.

The argument, if specified, should be a callable which should verify whether bytes received across the

socket are valid and should be processed. This could be done by encrypting and/or signing what is sent across

the socket, such that the callable can perform signature verification and/or decryption. The

callable is called with a single argument - the bytes received across the socket - and should return the bytes to

be processed, or to indicate that the bytes should be discarded. The returned bytes could be the same

as the passed in bytes (e.g. when only verification is done), or they could be completely different (perhaps if

decryption were performed).

To send a configuration to the socket, read in the configuration file and send it to the socket as a sequence of

bytes preceded by a four-byte length string packed in binary using .



® Note

Because portions of the configuration are passed through , use of this function may open its users to a security risk. While the function only binds to a socket on , and so does not accept con-nections from remote machines, there are scenarios where untrusted code could be run under the account

of the process which calls . Specifically, if the process calling runs on a multi-user machine where users cannot trust each other, then a malicious user could arrange to run essentially arbi-

trary code in a victim user’s process, simply by connecting to the victim’s socket and sending a configuration which runs whatever code the attacker wants to have executed in the victim’s process. This is especially easy to do if the default port is used, but not hard even if a different port is used. To avoid

the risk of this happening, use the argument to to prevent unrecognised configurations from being applied.



Changed in version 3.4: The argument was added.



® Note

If you want to send configurations to the listener which don’t disable existing loggers, you will need to use a

JSON format for the configuration, which will use for configuration. This method allows you to specify as in the configuration you send.





Stops the listening server which was created with a call to . This is typically called before calling

on the return value from .

The Python Library Reference, Release 3.13.2





The logging configuration functionality tries to offer convenience, and in part this is done by offering the ability to convert text in configuration files into Python objects used in logging configuration - for example, as described in

User-defined objects. However, these same mechanisms (importing callables from user-defined modules and calling them with parameters from the configuration) could be used to invoke any code you like, and for this reason you should treat configuration files from untrusted sources with extreme caution and satisfy yourself that nothing bad can happen if you load them, before actually loading them.





Describing a logging configuration requires listing the various objects to create and the connections between them; for example, you may create a handler named ‘console’ and then say that the logger named ‘startup’ will send its messages

to the ‘console’ handler. These objects aren’t limited to those provided by the module because you might write your own formatter or handler class. The parameters to these classes may also need to include external objects

such as . The syntax for describing these objects and connections is defined in Object connections below.



Dictionary Schema Details

The dictionary passed to must contain the following keys:

• version- to be set to an integer value representing the schema version. The only valid value at present is 1, but

having this key allows the schema to evolve while still preserving backwards compatibility.

All other keys are optional, but if present they will be interpreted as described below. In all cases below where a ‘configuring dict’ is mentioned, it will be checked for the special key to see if a custom instantiation is required.

If so, the mechanism described in User-defined objects below is used to create an instance; otherwise, the context is used to determine what to instantiate.

• formatters- the corresponding value will be a dict in which each key is a formatter id and each value is a dict

describing how to configure the corresponding instance.

The configuring dict is searched for the following optional keys which correspond to the arguments passed to

create a object:

–

–

–

– (since version >=3.8)

– (since version >=3.12)

An optional key indicates the name of the formatter’s class (as a dotted module and class name). The

instantiation arguments are as for , thus this key is most useful for instantiating a customised

subclass of . For example, the alternative class might present exception tracebacks in an expanded

or condensed format. If your formatter requires different or extra configuration keys, you should use User-

defined objects.

• filters- the corresponding value will be a dict in which each key is a filter id and each value is a dict describing

how to configure the corresponding Filter instance.

The configuring dict is searched for the key (defaulting to the empty string) and this is used to construct

a instance.

• handlers- the corresponding value will be a dict in which each key is a handler id and each value is a dict

describing how to configure the corresponding Handler instance.

The configuring dict is searched for the following keys:

– (mandatory). This is the fully qualified name of the handler class.

– (optional). The level of the handler.

– (optional). The id of the formatter for this handler.

The Python Library Reference, Release 3.13.2



– (optional). A list of ids of the filters for this handler.

Changed in version 3.11: can take filter instances in addition to ids.

All other keys are passed through as keyword arguments to the handler’s constructor. For example, given the

snippet:





the handler with id is instantiated as a , using

as the underlying stream. The handler with id is instantiated as a

with the keyword arguments

.

• loggers- the corresponding value will be a dict in which each key is a logger name and each value is a dict

describing how to configure the corresponding Logger instance.

The configuring dict is searched for the following keys:

– (optional). The level of the logger.

– (optional). The propagation setting of the logger.

– (optional). A list of ids of the filters for this logger.

Changed in version 3.11: can take filter instances in addition to ids.

– (optional). A list of ids of the handlers for this logger.

The specified loggers will be configured according to the level, propagation, filters and handlers specified.

• root- this will be the configuration for the root logger. Processing of the configuration will be as for any logger,

except that the setting will not be applicable.

• incremental- whether the configuration is to be interpreted as incremental to the existing configuration. This

value defaults to , which means that the specified configuration replaces the existing configuration with

the same semantics as used by the existing API.

If the specified value is , the configuration is processed as described in the section on Incremental Con-

figuration.

• disable_existing_loggers- whether any existing non-root loggers are to be disabled. This setting mirrors the

parameter of the same name in . If absent, this parameter defaults to . This value is

ignored if incremental is .



Incremental Configuration

It is difficult to provide complete flexibility for incremental configuration. For example, because objects such as filters and formatters are anonymous, once a configuration is set up, it is not possible to refer to such anonymous objects when augmenting a configuration.

Furthermore, there is not a compelling case for arbitrarily altering the object graph of loggers, handlers, filters, formatters at run-time, once a configuration is set up; the verbosity of loggers and handlers can be controlled just by setting levels (and, in the case of loggers, propagation flags). Changing the object graph arbitrarily in a safe way is The Python Library Reference, Release 3.13.2



problematic in a multi-threaded environment; while not impossible, the benefits are not worth the complexity it adds to the implementation.

Thus, when the key of a configuration dict is present and is , the system will completely ignore any and entries, and process only the settings in the entries, and the and settings in the and entries.

Using a value in the configuration dict lets configurations to be sent over the wire as pickled dicts to a socket listener. Thus, the logging verbosity of a long-running application can be altered over time with no need to stop and restart the application.



Object connections

The schema describes a set of logging objects - loggers, handlers, formatters, filters - which are connected to each other in an object graph. Thus, the schema needs to represent connections between the objects. For example, say that, once configured, a particular logger has attached to it a particular handler. For the purposes of this discussion, we can say that the logger represents the source, and the handler the destination, of a connection between the two. Of course in the configured objects this is represented by the logger holding a reference to the handler. In the configuration dict, this is done by giving each destination object an id which identifies it unambiguously, and then using the id in the source object’s configuration to indicate that a connection exists between the source and the destination object with that id.

So, for example, consider the following YAML snippet:





(Note: YAML used here because it’s a little more readable than the equivalent Python source form for the dictionary.)

The ids for loggers are the logger names which would be used programmatically to obtain a reference to those loggers, e.g. . The ids for Formatters and Filters can be any string value (such as , above) and they are transient, in that they are only meaningful for processing the configuration dictionary and used to determine connections between objects, and are not persisted anywhere when the configuration call is complete.

The above snippet indicates that logger named should have two handlers attached to it, which are described by the handler ids and . The formatter for is that described by id , and the formatter for is that described by id .



User-defined objects

The schema supports user-defined objects for handlers, filters and formatters. (Loggers do not need to have different types for different instances, so there is no support in this configuration schema for user-defined logger classes.)

Objects to be configured are described by dictionaries which detail their configuration. In some places, the logging system will be able to infer from the context how an object is to be instantiated, but when a user-defined object is to be instantiated, the system will not know how to do this. In order to provide complete flexibility for user-defined object instantiation, the user needs to provide a ‘factory’ - a callable which is called with a configuration dictionary

The Python Library Reference, Release 3.13.2



and which returns the instantiated object. This is signalled by an absolute import path to the factory being made available under the special key . Here’s a concrete example:





The above YAML snippet defines three formatters. The first, with id , is a standard instance with the specified format string. The second, with id , has a longer format and also defines the

time format explicitly, and will result in a initialized with those two format strings. Shown in Python source form, the and formatters have configuration sub-dictionaries:





and:





respectively, and as these dictionaries do not contain the special key , the instantiation is inferred from the

context: as a result, standard instances are created. The configuration sub-dictionary for the third formatter, with id , is:





and this contains the special key , which means that user-defined instantiation is wanted. In this case, the specified factory callable will be used. If it is an actual callable it will be used directly - otherwise, if you specify a string (as in the example) the actual callable will be located using normal import mechanisms. The callable will be called with the remaining items in the configuration sub-dictionary as keyword arguments. In the above example, the formatter with id will be assumed to be returned by the call:





Á Warning

The values for keys such as , and in the above example should not be configuration dictionar-

ies or references such as or , because they will not be processed by the configuration

machinery, but passed to the callable as-is.



The key has been used as the special key because it is not a valid keyword parameter name, and so will not clash with the names of the keyword arguments used in the call. The also serves as a mnemonic that the The Python Library Reference, Release 3.13.2



corresponding value is a callable.

Changed in version 3.11: The member of and can take filter instances in addition to ids.

You can also specify a special key whose value is a dictionary is a mapping of attribute names to values. If found, the specified attributes will be set on the user-defined object before it is returned. Thus, with the following configuration:





the returned formatter will have attribute set to and attribute set to .



Á Warning

The values for attributes such as and in the above example should not be configuration dictionaries or ref-

erences such as or , because they will not be processed by the configuration machinery,

but set as attribute values as-is.



Handler configuration order

Handlers are configured in alphabetical order of their keys, and a configured handler replaces the configuration dictionary in (a working copy of) the dictionary in the schema. If you use a construct such as , then initially points to the configuration dictionary for the handler named , and later (once that handler has been configured) it points to the configured handler instance. Thus, could resolve to either a dictionary or a handler instance. In general, it is wise to name handlers in a way such that dependent handlers are configured _after_ any handlers they depend on; that allows something like to be used in configuring a handler that depends on handler . If that dependent handler were named , problems would result, because the configuration of would be attempted before that of , and would not yet have been configured. However, if the dependent handler were named , it would be configured after , with the result that would resolve to configured handler , and not its configuration dictionary.



Access to external objects

There are times where a configuration needs to refer to objects external to the configuration, for example . If the configuration dict is constructed using Python code, this is straightforward, but a problem arises when the configuration is provided via a text file (e.g. JSON, YAML). In a text file, there is no standard way to distinguish from the literal string . To facilitate this distinction, the configuration system looks for certain special prefixes in string values and treat them specially. For example, if the literal string is provided as a value in the configuration, then the will be stripped off and the remainder of the value processed using normal import mechanisms.

The handling of such prefixes is done in a way analogous to protocol handling: there is a generic mechanism to look for prefixes which match the regular expression whereby, if the is recognised, the is processed in a prefix-dependent manner and the result of the processing replaces the string value. If the prefix is not recognised, then the string value will be left as-is.



The Python Library Reference, Release 3.13.2



Access to internal objects

As well as external objects, there is sometimes also a need to refer to objects in the configuration. This will be done implicitly by the configuration system for things that it knows about. For example, the string value for a in a logger or handler will automatically be converted to the value , and the , and entries will take an object id and resolve to the appropriate destination object.

However, a more generic mechanism is needed for user-defined objects which are not known to the module.

For example, consider , which takes a argument which is another handler to delegate to. Since the system already knows about this class, then in the configuration, the given just needs to be the object id of the relevant target handler, and the system will resolve to the handler from the id. If, however, a user defines a which has an handler, the configuration system would not know that the referred to a handler. To cater for this, a generic resolution system allows the user to specify:





The literal string will be resolved in an analogous way to strings with the prefix, but looking in the configuration itself rather than the import namespace. The mechanism allows access by dot or by index, in a similar way to that provided by . Thus, given the following snippet:





in the configuration, the string would resolve to the dict with key , the string would resolve to the dict with key in the dict, and so on. The string would resolve to and the string would resolve to the value . The value could be accessed using either or, equivalently, . The latter form only needs to be used if the key contains spaces or non-alphanumeric characters. Please note that the characters and are not allowed in the keys. If an index value consists only of decimal digits, access will be attempted using the corresponding integer value, falling back to the string value if needed.

Given a string , this will resolve to . If the string is speci-fied as , the system will attempt to retrieve the value from , and fall back to if that fails.



Import resolution and custom importers

Import resolution, by default, uses the builtin function to do its importing. You may want to replace this with your own importing mechanism: if so, you can replace the attribute of the or its superclass, the class. However, you need to be careful because of the way functions are accessed from classes via descriptors. If you are using a Python callable to do your imports, and you want to define

it at class level rather than instance level, you need to wrap it with . For example:

The Python Library Reference, Release 3.13.2





You don’t need to wrap with if you’re setting the import callable on a configurator instance.



Configuring QueueHandler and QueueListener

If you want to configure a , noting that this is normally used in conjunction with a , you can configure both together. After the configuration, the instance will be available as the

attribute of the created handler, and that in turn will be available to you using and passing the name you have used for the in your configuration. The dictionary schema for configuring the pair is shown in the example YAML snippet below.





The and keys are optional.

If the key is present, the corresponding value can be one of the following:

• An object implementing the and public API. For instance, this may be

an actual instance of or a subclass thereof, or a proxy obtained by

.

This is of course only possible if you are constructing or modifying the configuration dictionary in code.

• A string that resolves to a callable which, when called with no arguments, returns the queue instance to use.

That callable could be a subclass or a function which returns a suitable queue instance, such as

.

• A dict with a key which is constructed in the usual way as discussed in User-defined objects. The result

of this construction should be a instance.

If the key is absent, a standard unbounded instance is created and used.

If the key is present, the corresponding value can be one of the following:

• A subclass of . This is of course only possible if you are constructing

or modifying the configuration dictionary in code.

• A string which resolves to a class which is a subclass of , such as

.

• A dict with a key which is constructed in the usual way as discussed in User-defined objects. The result

of this construction should be a callable with the same signature as the initializer.

If the key is absent, is used.

The values under the key are the names of other handlers in the configuration (not shown in the above snippet) which will be passed to the queue listener.

Any custom queue handler and listener classes will need to be defined with the same initialization signatures as

and .

Added in version 3.12.

The Python Library Reference, Release 3.13.2





The configuration file format understood by is based on functionality. The file must contain sections called , and which identify by name the entities of each type which are defined in the file. For each such entity, there is a separate section which identifies how that entity is configured. Thus, for a logger named in the section, the relevant configuration details are held in a section . Similarly, a handler called in the section will have its configuration held in a section called , while a formatter called in the section will have its configuration specified in a section called . The root logger configuration must be specified in a section called .



® Note

The API is older than the API and does not provide functionality to cover

certain aspects of logging. For example, you cannot configure objects, which provide for filtering of

messages beyond simple integer levels, using . If you need to have instances of in your

logging configuration, you will need to use . Note that future enhancements to configuration

functionality will be added to , so it’s worth considering transitioning to this newer API when it’s

convenient to do so.



Examples of these sections in the file are given below.





The root logger must specify a level and a list of handlers. An example of a root logger section is given below.





The entry can be one of or . For the root logger

only, means that all messages will be logged. Level values are evaluated in the context of the package’s namespace.

The entry is a comma-separated list of handler names, which must appear in the section. These names must appear in the section and have corresponding sections in the configuration file.

For loggers other than the root logger, some additional information is required. This is illustrated by the following example.





The and entries are interpreted as for the root logger, except that if a non-root logger’s level is specified as , the system consults loggers higher up the hierarchy to determine the effective level of the logger. The entry is set to 1 to indicate that messages must propagate to handlers higher up the logger hierarchy from this logger, or 0 to indicate that messages are not propagated to handlers up the hierarchy. The entry is the hierarchical channel name of the logger, that is to say the name used by the application to get the logger.

Sections which specify handler configuration are exemplified by the following.

The Python Library Reference, Release 3.13.2





The entry indicates the handler’s class (as determined by in the package’s namespace). The is interpreted as for loggers, and is taken to mean ‘log everything’.

The entry indicates the key name of the formatter for this handler. If blank, a default formatter () is used. If a name is specified, it must appear in the section and have a corresponding section in the configuration file.

The entry, when evaluated in the context of the package’s namespace, is the list of arguments to the constructor for the handler class. Refer to the constructors for the relevant handlers, or to the examples below, to see how typical entries are constructed. If not provided, it defaults to .

The optional entry, when evaluated in the context of the package’s namespace, is the keyword argument dict to the constructor for the handler class. If not provided, it defaults to .





The Python Library Reference, Release 3.13.2





Sections which specify formatter configuration are typified by the following.





The arguments for the formatter configuration are the same as the keys in the dictionary schema formatters section.

The entry, when evaluated in the context of the package’s namespace, is a dictionary of default values for custom formatting fields. If not provided, it defaults to .



® Note

Due to the use of as described above, there are potential security risks which result from using the

to send and receive configurations via sockets. The risks are limited to where multiple users with no

mutual trust run code on the same machine; see the documentation for more information.



µ See also

Module

API reference for the logging module.

Module

Useful handlers included with the logging module.





Source code: Lib/logging/handlers.py



Important

This page contains only reference information. For tutorials, please see

• Basic Tutorial

• Advanced Tutorial

• Logging Cookbook

The Python Library Reference, Release 3.13.2



The following useful handlers are provided in the package. Note that three of the handlers (,

and ) are actually defined in the module itself, but have been documented here along with the other handlers.





The class, located in the core package, sends logging output to streams such as sys.stdout, sys.stderr or any file-like object (or, more precisely, any object which supports and methods).

stream=None

Returns a new instance of the class. If stream is specified, the instance will use it for logging

output; otherwise, sys.stderr will be used.

record

If a formatter is specified, it is used to format the record. The record is then written to the stream

followed by . If exception information is present, it is formatted using

and appended to the stream.



Flushes the stream by calling its method. Note that the method is inherited from

and so does no output, so an explicit call may be needed at times.

stream

Sets the instance’s stream to the specified value, if it is different. The old stream is flushed before the new stream is set.

Parameters

– The stream that the handler should use.

Returns

the old stream, if the stream was changed, or if it wasn’t.

Added in version 3.7.



String used as the terminator when writing a formatted record to a stream. Default value is .

If you don’t want a newline termination, you can set the handler instance’s attribute to the empty string.

In earlier versions, the terminator was hardcoded as .

Added in version 3.2.





The class, located in the core package, sends logging output to a disk file. It inherits the

output functionality from .

filename, mode=’a’ , encoding=None, delay=False, errors=None

Returns a new instance of the class. The specified file is opened and used as the stream for

logging. If mode is not specified, is used. If encoding is not , it is used to open the file with that

encoding. If delay is true, then file opening is deferred until the first call to . By default, the file grows

indefinitely. If errors is specified, it’s used to determine how encoding errors are handled.

Changed in version 3.6: As well as string values, objects are also accepted for the filename argument.

Changed in version 3.9: The errors parameter was added.



Closes the file.

The Python Library Reference, Release 3.13.2



record

Outputs the record to the file.

Note that if the file was closed due to logging shutdown at exit and the file mode is ‘w’, the record will

not be emitted (see bpo-42378).





Added in version 3.1.

The class, located in the core package, does not do any formatting or output. It is essentially a ‘no-op’ handler for use by library developers.



Returns a new instance of the class.

record

This method does nothing.

record

This method does nothing.



This method returns for the lock, since there is no underlying I/O to which access needs to be serialized.

See library-config for more information on how to use .





The class, located in the module, is a which watches the file it is logging to. If the file changes, it is closed and reopened using the file name.

A file change can happen because of usage of programs such as newsyslog and logrotate which perform log file rotation. This handler, intended for use under Unix/Linux, watches the file to see if it has changed since the last emit. (A file is deemed to have changed if its device or inode have changed.) If the file has changed, the old file stream is closed, and the file opened to get a new stream.

This handler is not appropriate for use under Windows, because under Windows open log files cannot be moved or renamed - logging opens the files with exclusive locks - and so there is no need for such a handler. Furthermore,

ST_INO is not supported under Windows; always returns zero for this value.

filename, mode=’a’ , encoding=None, delay=False,

errors=None

Returns a new instance of the class. The specified file is opened and used as the

stream for logging. If mode is not specified, is used. If encoding is not , it is used to open the file

with that encoding. If delay is true, then file opening is deferred until the first call to . By default, the

file grows indefinitely. If errors is provided, it determines how encoding errors are handled.

Changed in version 3.6: As well as string values, objects are also accepted for the filename argument.

Changed in version 3.9: The errors parameter was added.



Checks to see if the file has changed. If it has, the existing stream is flushed and closed and the file opened again, typically as a precursor to outputting the record to the file.

Added in version 3.6.

record

Outputs the record to the file, but first calls to reopen the file if it has changed.



The Python Library Reference, Release 3.13.2





The class, located in the module, is the base class for the rotating

file handlers, and . You should not need to instantiate this class, but it has attributes and methods you may need to override.

filename, mode, encoding=None, delay=False,

errors=None

The parameters are as for . The attributes are:



If this attribute is set to a callable, the method delegates to this callable. The

parameters passed to the callable are those passed to .



® Note

The namer function is called quite a few times during rollover, so it should be as simple and as fast as possible. It should also return the same output every time for a given input, otherwise the rollover behaviour may not work as expected.

It’s also worth noting that care should be taken when using a namer to preserve certain attributes

in the filename which are used during rotation. For example, expects to have a set of log files whose names contain successive integers, so that rotation works as expected,

and deletes old log files (based on the parameter passed to the handler’s initializer) by determining the oldest files to delete. For this to happen, the filenames should be sortable using the date/time portion of the filename, and a namer needs to respect this. (If a namer is wanted that doesn’t respect this scheme, it will need to be used in a subclass of

which overrides the method to fit in with the custom naming scheme.)



Added in version 3.3.



If this attribute is set to a callable, the method delegates to this callable. The parameters

passed to the callable are those passed to .

Added in version 3.3.

default_name

Modify the filename of a log file when rotating.

This is provided so that a custom filename can be provided.

The default implementation calls the ‘namer’ attribute of the handler, if it’s callable, passing the default name to it. If the attribute isn’t callable (the default is ), the name is returned unchanged.

Parameters

– The default name for the log file.

Added in version 3.3.

source, dest

When rotating, rotate the current log.

The default implementation calls the ‘rotator’ attribute of the handler, if it’s callable, passing the source and dest arguments to it. If the attribute isn’t callable (the default is ), the source is simply renamed to the destination.

Parameters

• – The source filename. This is normally the base filename, e.g. ‘test.log’.

• – The destination filename. This is normally what the source is rotated to, e.g.

‘test.log.1’.

The Python Library Reference, Release 3.13.2



Added in version 3.3.

The reason the attributes exist is to save you having to subclass - you can use the same callables for instances

of and . If either the namer or rotator callable raises an exception, this will be handled in the same way as any other exception during an call, i.e. via the method of the handler.

If you need to make more significant changes to rotation processing, you can override the methods.

For an example, see cookbook-rotator-namer.





The class, located in the module, supports rotation of disk log files.



filename, mode=’a’, maxBytes=0, backupCount=0,

encoding=None, delay=False, errors=None

Returns a new instance of the class. The specified file is opened and used as the

stream for logging. If mode is not specified, is used. If encoding is not , it is used to open the file

with that encoding. If delay is true, then file opening is deferred until the first call to . By default, the

file grows indefinitely. If errors is provided, it determines how encoding errors are handled.

You can use the maxBytes and backupCount values to allow the file to rollover at a predetermined size. When

the size is about to be exceeded, the file is closed and a new file is silently opened for output. Rollover occurs

whenever the current log file is nearly maxBytes in length; but if either of maxBytes or backupCount is zero,

rollover never occurs, so you generally want to set backupCount to at least 1, and have a non-zero maxBytes.

When backupCount is non-zero, the system will save old log files by appending the extensions ‘.1’, ‘.2’ etc., to

the filename. For example, with a backupCount of 5 and a base file name of , you would get

, , , up to . The file being written to is always . When this

file is filled, it is closed and renamed to , and if files , , etc. exist, then

they are renamed to , etc. respectively.

Changed in version 3.6: As well as string values, objects are also accepted for the filename argument.

Changed in version 3.9: The errors parameter was added.



Does a rollover, as described above.

record

Outputs the record to the file, catering for rollover as described previously.





The class, located in the module, supports rotation of disk log files at certain timed intervals.

filename, when=’h’, interval=1, backupCount=0,

encoding=None, delay=False, utc=False,

atTime=None, errors=None

Returns a new instance of the class. The specified file is opened and used as

the stream for logging. On rotating it also sets the filename suffix. Rotating happens based on the product of

when and interval.

You can use the when to specify the type of interval. The list of possible values is below. Note that they are

not case sensitive.



The Python Library Reference, Release 3.13.2



Value Type of interval If/how atTime is used

Seconds Ignored

Minutes Ignored

Hours Ignored

Days Ignored

Weekday (0=Monday)

time

Roll over at midnight, if atTime not specified, else at time

atTime time



When using weekday-based rotation, specify ‘W0’ for Monday, ‘W1’ for Tuesday, and so on up to ‘W6’ for

Sunday. In this case, the value passed for interval isn’t used.

The system will save old log files by appending extensions to the filename. The extensions are date-and-time

based, using the strftime format or a leading portion thereof, depending on the rollover

interval.

When computing the next rollover time for the first time (when the handler is created), the last modification

time of an existing log file, or else the current time, is used to compute when the next rotation will occur.

If the utc argument is true, times in UTC will be used; otherwise local time is used.

If backupCount is nonzero, at most backupCount files will be kept, and if more would be created when rollover

occurs, the oldest one is deleted. The deletion logic uses the interval to determine which files to delete, so

changing the interval may leave old files lying around.

If delay is true, then file opening is deferred until the first call to .

If atTime is not , it must be a instance which specifies the time of day when rollover

occurs, for the cases where rollover is set to happen “at midnight” or “on a particular weekday”. Note that in

these cases, the atTime value is effectively used to compute the initial rollover, and subsequent rollovers would

be calculated via the normal interval calculation.

If errors is specified, it’s used to determine how encoding errors are handled.



® Note

Calculation of the initial rollover time is done when the handler is initialised. Calculation of subsequent rollover times is done only when rollover occurs, and rollover occurs only when emitting output. If this is not kept in mind, it might lead to some confusion. For example, if an interval of “every minute” is set, that does not mean you will always see log files with times (in the filename) separated by a minute; if, during application execution, logging output is generated more frequently than once a minute, then you can expect to see log files with times separated by a minute. If, on the other hand, logging messages are only output once every five minutes (say), then there will be gaps in the file times corresponding to the minutes where no output (and hence no rollover) occurred.



Changed in version 3.4: atTime parameter was added.

Changed in version 3.6: As well as string values, objects are also accepted for the filename argument.

Changed in version 3.9: The errors parameter was added.



Does a rollover, as described above.

record

Outputs the record to the file, catering for rollover as described above.



Returns a list of filenames which should be deleted as part of rollover. These are the absolute paths of the oldest backup log files written by the handler.

The Python Library Reference, Release 3.13.2





The class, located in the module, sends logging output to a network socket. The base class uses a TCP socket.

host, port

Returns a new instance of the class intended to communicate with a remote machine whose

address is given by host and port.

Changed in version 3.4: If is specified as , a Unix domain socket is created using the value in

- otherwise, a TCP socket is created.



Closes the socket.



Pickles the record’s attribute dictionary and writes it to the socket in binary format. If there is an error with the socket, silently drops the packet. If the connection was previously lost, re-establishes the connection.

To unpickle the record at the receiving end into a , use the function.



Handles an error which has occurred during . The most likely cause is a lost connection. Closes the socket so that we can retry on the next event.



This is a factory method which allows subclasses to define the precise type of socket they want. The

default implementation creates a TCP socket ( ).

record

Pickles the record’s attribute dictionary in binary format with a length prefix, and returns it ready for transmission across the socket. The details of this operation are equivalent to:





Note that pickles aren’t completely secure. If you are concerned about security, you may want to override this method to implement a more secure mechanism. For example, you can sign pickles using HMAC and then verify them on the receiving end, or alternatively you can disable unpickling of global objects on the receiving end.

packet

Send a pickled byte-string packet to the socket. The format of the sent byte-string is as described in the

documentation for .

This function allows for partial sends, which can happen when the network is busy.



Tries to create a socket; on failure, uses an exponential back-off algorithm. On initial failure, the handler will drop the message it was trying to send. When subsequent messages are handled by the same instance, it will not try connecting until some time has passed. The default parameters are such that the initial delay is one second, and if after that delay the connection still can’t be made, the handler will double the delay each time up to a maximum of 30 seconds.

This behaviour is controlled by the following handler attributes:

• (initial delay, defaulting to 1.0 seconds).

• (multiplier, defaulting to 2.0).

• (maximum delay, defaulting to 30.0 seconds).

This means that if the remote listener starts up after the handler has been used, you could lose messages (since the handler won’t even attempt a connection until the delay has elapsed, but just silently drop messages during the delay period).

The Python Library Reference, Release 3.13.2





The class, located in the module, inherits from to sup-port sending logging messages over UDP sockets.

host, port

Returns a new instance of the class intended to communicate with a remote machine

whose address is given by host and port.



® Note

As UDP is not a streaming protocol, there is no persistent connection between an instance of this handler and host. For this reason, when using a network socket, a DNS lookup might have to be made each time an event is logged, which can introduce some latency into the system. If this affects you, you can do a lookup yourself and initialize this handler using the looked-up IP address rather than the hostname.



Changed in version 3.4: If is specified as , a Unix domain socket is created using the value in

- otherwise, a UDP socket is created.



Pickles the record’s attribute dictionary and writes it to the socket in binary format. If there is an error

with the socket, silently drops the packet. To unpickle the record at the receiving end into a ,

use the function.



The factory method of is here overridden to create a UDP socket (

).

s

Send a pickled byte-string to a socket. The format of the sent byte-string is as described in the documen-

tation for .





The class, located in the module, supports sending logging messages to a remote or local Unix syslog.

address=(’localhost’, SYSLOG_UDP_PORT),

facility=LOG_USER, socktype=socket.SOCK_DGRAM

Returns a new instance of the class intended to communicate with a remote Unix ma-

chine whose address is given by address in the form of a tuple. If address is not specified,

is used. The address is used to open a socket. An alternative to providing a

tuple is providing an address as a string, for example ‘/dev/log’. In this case, a Unix domain socket

is used to send the message to the syslog. If facility is not specified, is used. The type of socket

opened depends on the socktype argument, which defaults to and thus opens a UDP

socket. To open a TCP socket (for use with the newer syslog daemons such as rsyslog), specify a value of

.

Note that if your server is not listening on UDP port 514, may appear not to work. In that

case, check what address you should be using for a domain socket - it’s system dependent. For example, on

Linux it’s usually ‘/dev/log’ but on OS/X it’s ‘/var/run/syslog’. You’ll need to check your platform and use the

appropriate address (you may need to do this check at runtime if your application needs to run on several

platforms). On Windows, you pretty much have to use the UDP option.



® Note

On macOS 12.x (Monterey), Apple has changed the behaviour of their syslog daemon - it no longer listens

on a domain socket. Therefore, you cannot expect to work on this system.

The Python Library Reference, Release 3.13.2



See gh-91070 for more information.



Changed in version 3.2: socktype was added.



Closes the socket to the remote host.



Tries to create a socket and, if it’s not a datagram socket, connect it to the other end. This method is called during handler initialization, but it’s not regarded as an error if the other end isn’t listening at this point - the method will be called again when emitting an event, if there is no socket at that point.

Added in version 3.11.

record

The record is formatted, and then sent to the syslog server. If exception information is present, it is not sent to the server.

Changed in version 3.2.1: (See: bpo-12168.) In earlier versions, the message sent to the syslog daemons was always terminated with a NUL byte, because early versions of these daemons expected a NUL

terminated message - even though it’s not in the relevant specification (RFC 5424). More recent versions of these daemons don’t expect the NUL byte but strip it off if it’s there, and even more recent daemons (which adhere more closely to RFC 5424) pass the NUL byte on as part of the message.

To enable easier handling of syslog messages in the face of all these differing daemon behaviours, the appending of the NUL byte has been made configurable, through the use of a class-level attribute, . This defaults to (preserving the existing behaviour) but can be set to on a instance in order for that instance to not append the NUL terminator.

Changed in version 3.3: (See: bpo-12419.) In earlier versions, there was no facility for an “ident” or “tag” prefix to identify the source of the message. This can now be specified using a class-level attribute, defaulting to to preserve existing behaviour, but which can be overridden on a instance in order for that instance to prepend the ident to every message handled. Note that the provided ident must be text, not bytes, and is prepended to the message exactly as is.

facility, priority

Encodes the facility and priority into an integer. You can pass in strings or integers - if strings are passed, internal mapping dictionaries are used to convert them to integers.

The symbolic values are defined in and mirror the values defined in the header file.

Priorities



Name (string) Symbolic value

LOG_ALERT

or LOG_CRIT

LOG_DEBUG

or LOG_EMERG

or LOG_ERR

LOG_INFO

LOG_NOTICE

or LOG_WARNING



Facilities



The Python Library Reference, Release 3.13.2



Name (string) Symbolic value

LOG_AUTH

LOG_AUTHPRIV

LOG_CRON

LOG_DAEMON

LOG_FTP

LOG_KERN

LOG_LPR

LOG_MAIL

LOG_NEWS

LOG_SYSLOG

LOG_USER

LOG_UUCP

LOG_LOCAL0

LOG_LOCAL1

LOG_LOCAL2

LOG_LOCAL3

LOG_LOCAL4

LOG_LOCAL5

LOG_LOCAL6

LOG_LOCAL7



levelname

Maps a logging level name to a syslog priority name. You may need to override this if you are using custom levels, or if the default algorithm is not suitable for your needs. The default algorithm maps , , , and to the equivalent syslog names, and all other level names to ‘warning’.





The class, located in the module, supports sending logging messages to a local Windows NT, Windows 2000 or Windows XP event log. Before you can use it, you need Mark Hammond’s Win32 extensions for Python installed.

appname, dllname=None, logtype=’Application’

Returns a new instance of the class. The appname is used to define the application

name as it appears in the event log. An appropriate registry entry is created using this name. The dllname

should give the fully qualified pathname of a .dll or .exe which contains message definitions to hold in the log

(if not specified, is used - this is installed with the Win32 extensions and contains

some basic placeholder message definitions. Note that use of these placeholders will make your event logs big,

as the entire message source is held in the log. If you want slimmer logs, you have to pass in the name of your

own .dll or .exe which contains the message definitions you want to use in the event log). The logtype is one of

, or , and defaults to .



At this point, you can remove the application name from the registry as a source of event log entries. However, if you do this, you will not be able to see the events as you intended in the Event Log Viewer -it needs to be able to access the registry to get the .dll name. The current version does not do this.

record

Determines the message ID, event category and event type, and then logs the message in the NT event log.

record

Returns the event category for the record. Override this if you want to specify your own categories. This version returns 0.

The Python Library Reference, Release 3.13.2



record

Returns the event type for the record. Override this if you want to specify your own types. This version does a mapping using the handler’s typemap attribute, which is set up in to a dictionary which contains mappings for , , , and . If you are using your own levels, you will either need to override this method or place a suitable dictionary in the handler’s typemap attribute.

record

Returns the message ID for the record. If you are using your own messages, you could do this by having the msg passed to the logger being an ID rather than a format string. Then, in here, you could use a dictionary lookup to get the message ID. This version returns 1, which is the base message ID in .





The class, located in the module, supports sending logging messages to an email address via SMTP.

mailhost, fromaddr, toaddrs, subject, credentials=None,

secure=None, timeout=1.0

Returns a new instance of the class. The instance is initialized with the from and to addresses

and subject line of the email. The toaddrs should be a list of strings. To specify a non-standard SMTP port,

use the (host, port) tuple format for the mailhost argument. If you use a string, the standard SMTP port is used.

If your SMTP server requires authentication, you can specify a (username, password) tuple for the credentials

argument.

To specify the use of a secure protocol (TLS), pass in a tuple to the secure argument. This will only be used

when authentication credentials are supplied. The tuple should be either an empty tuple, or a single-value tuple

with the name of a keyfile, or a 2-value tuple with the names of the keyfile and certificate file. (This tuple is

passed to the method.)

A timeout can be specified for communication with the SMTP server using the timeout argument.

Changed in version 3.3: Added the timeout parameter.

record

Formats the record and sends it to the specified addressees.

record

If you want to specify a subject line which is record-dependent, override this method.





The class, located in the module, supports buffering of logging records in memory, periodically flushing them to a target handler. Flushing occurs whenever the buffer is full, or when an event of a certain severity or greater is seen.

is a subclass of the more general , which is an abstract class. This buffers logging records in memory. Whenever each record is added to the buffer, a check is made by calling to see if the buffer should be flushed. If it should, then is expected to do the flushing.

capacity

Initializes the handler with a buffer of the specified capacity. Here, capacity means the number of logging

records buffered.

record

Append the record to the buffer. If returns true, call to process the buffer.



For a instance, flushing means that it sets the buffer to an empty list. This method can be overwritten to implement more useful flushing behavior.

The Python Library Reference, Release 3.13.2



record

Return if the buffer is up to capacity. This method can be overridden to implement custom flushing strategies.

capacity, flushLevel=ERROR, target=None, flushOnClose=True

Returns a new instance of the class. The instance is initialized with a buffer size of capacity

(number of records buffered). If flushLevel is not specified, is used. If no target is specified, the target

will need to be set using before this handler does anything useful. If flushOnClose is specified

as , then the buffer is not flushed when the handler is closed. If not specified or specified as , the

previous behaviour of flushing the buffer will occur when the handler is closed.

Changed in version 3.6: The flushOnClose parameter was added.



Calls , sets the target to and clears the buffer.



For a instance, flushing means just sending the buffered records to the target, if there is one. The buffer is also cleared when buffered records are sent to the target. Override if you want different behavior.

target

Sets the target handler for this handler.

record

Checks for buffer full or a record at the flushLevel or higher.





The class, located in the module, supports sending logging messages to a web server, using either or semantics.

host, url, method=’GET’, secure=False, credentials=None,

context=None

Returns a new instance of the class. The host can be of the form , should you need

to use a specific port number. If no method is specified, is used. If secure is true, a HTTPS connection will

be used. The context parameter may be set to a instance to configure the SSL settings used

for the HTTPS connection. If credentials is specified, it should be a 2-tuple consisting of userid and password,

which will be placed in a HTTP ‘Authorization’ header using Basic authentication. If you specify credentials,

you should also specify secure=True so that your userid and password are not passed in cleartext across the

wire.

Changed in version 3.5: The context parameter was added.

record

Provides a dictionary, based on , which is to be URL-encoded and sent to the web server. The default implementation just returns . This method can be overridden if e.g. only a

subset of is to be sent to the web server, or if more specific customization of what’s sent to the server is required.

record

Sends the record to the web server as a URL-encoded dictionary. The method is used to convert the record to the dictionary to be sent.



® Note

Since preparing a record for sending it to a web server is not the same as a generic formatting operation,

using to specify a for a has no effect. Instead of calling

, this handler calls and then to encode the dictionary in a form suitable for sending to a web server.

The Python Library Reference, Release 3.13.2





Added in version 3.2.

The class, located in the module, supports sending logging messages to a

queue, such as those implemented in the or modules.

Along with the class, can be used to let handlers do their work on a separate thread from the one which does the logging. This is important in web applications and also other service applications where threads servicing clients need to respond as quickly as possible, while any potentially slow operations (such as

sending an email via ) are done on a separate thread.

queue

Returns a new instance of the class. The instance is initialized with the queue to send messages

to. The queue can be any queue-like object; it’s used as-is by the method, which needs to know

how to send messages to it. The queue is not required to have the task tracking API, which means that you can

use instances for queue.



® Note

If you are using , you should avoid using and instead use

.



record

Enqueues the result of preparing the LogRecord. Should an exception occur (e.g. because a bounded

queue has filled up), the method is called to handle the error. This can result in the

record silently being dropped (if is ) or a message printed to

(if is ).

record

Prepares a record for queuing. The object returned by this method is enqueued.

The base implementation formats the record to merge the message, arguments, exception and stack information, if present. It also removes unpickleable items from the record in-place. Specifically, it overwrites the record’s and attributes with the merged message (obtained by calling the

handler’s method), and sets the , and attributes to .

You might want to override this method if you want to convert the record to a dict or JSON string, or send a modified copy of the record while leaving the original intact.



® Note

The base implementation formats the message with arguments, sets the and attributes to the formatted message and sets the and attributes to to allow pickling and

to prevent further attempts at formatting. This means that a handler on the side won’t have the information to do custom formatting, e.g. of exceptions. You may wish to subclass and override this method to e.g. avoid setting to . Note that the / / changes are related to ensuring the record is pickleable, and you might or might not be able to avoid doing that depending on whether your are pickleable. (Note that you may have to consider not only your own code but also code in any libraries that you use.)



record

Enqueues the record on the queue using ; you may want to override this if you want to use blocking behaviour, or a timeout, or a customized queue implementation.



When created via configuration using , this attribute will contain a instance for use with this handler. Otherwise, it will be .

Added in version 3.12.

The Python Library Reference, Release 3.13.2





Added in version 3.2.

The class, located in the module, supports receiving logging messages from

a queue, such as those implemented in the or modules. The messages are received from a queue in an internal thread and passed, on the same thread, to one or more handlers for processing. While

is not itself a handler, it is documented here because it works hand-in-hand with .

Along with the class, can be used to let handlers do their work on a separate thread from the one which does the logging. This is important in web applications and also other service applications where threads servicing clients need to respond as quickly as possible, while any potentially slow operations (such as

sending an email via ) are done on a separate thread.

queue, *handlers, respect_handler_level=False

Returns a new instance of the class. The instance is initialized with the queue to send

messages to and a list of handlers which will handle entries placed on the queue. The queue can be any queue-

like object; it’s passed as-is to the method, which needs to know how to get messages from it. The

queue is not required to have the task tracking API (though it’s used if available), which means that you can

use instances for queue.



® Note

If you are using , you should avoid using and instead use

.



If is , a handler’s level is respected (compared with the level for the message)

when deciding whether to pass messages to that handler; otherwise, the behaviour is as in previous Python

versions - to always pass each message to each handler.

Changed in version 3.5: The argument was added.

block

Dequeues a record and return it, optionally blocking.

The base implementation uses . You may want to override this method if you want to use timeouts or work with custom queue implementations.

record

Prepare a record for handling.

This implementation just returns the passed-in record. You may want to override this method if you need to do any custom marshalling or manipulation of the record before passing it to the handlers.

record

Handle a record.

This just loops through the handlers offering them the record to handle. The actual object passed to the

handlers is that which is returned from .



Starts the listener.

This starts up a background thread to monitor the queue for LogRecords to process.



Stops the listener.

This asks the thread to terminate, and then waits for it to do so. Note that if you don’t call this before your application exits, there may be some records still left on the queue, which won’t be processed.



The Python Library Reference, Release 3.13.2





Writes a sentinel to the queue to tell the listener to quit. This implementation uses . You may want to override this method if you want to use timeouts or work with custom queue implementa-tions.

Added in version 3.3.



µ See also

Module

API reference for the logging module.

Module

Configuration API for the logging module.





Source code: Lib/platform.py



® Note

Specific platforms listed alphabetically, with Linux included in the Unix section.





executable=sys.executable, bits=”, linkage=”

Queries the given executable (defaults to the Python interpreter binary) for various architecture information.

Returns a tuple which contain information about the bit architecture and the linkage

format used for the executable. Both values are returned as strings.

Values that cannot be determined are returned as given by the parameter presets. If bits is given as , the

(or on Python version < 1.5.2) is used as indicator for the supported

pointer size.

The function relies on the system’s command to do the actual work. This is available on most if not all

Unix platforms and some non-Unix platforms and then only if the executable points to the Python interpreter.

Reasonable defaults are used when the above needs are not met.



® Note

On macOS (and perhaps other platforms), executable files may be universal files containing multiple ar-chitectures.

To get at the “64-bitness” of the current interpreter, it is more reliable to query the attribute:





Returns the machine type, e.g. . An empty string is returned if the value cannot be determined.



Returns the computer’s network name (may not be fully qualified!). An empty string is returned if the value

cannot be determined.

The Python Library Reference, Release 3.13.2



aliased=False, terse=False

Returns a single string identifying the underlying platform with as much useful information as possible.

The output is intended to be human readable rather than machine parseable. It may look different on different

platforms and this is intended.

If aliased is true, the function will use aliases for various platforms that report system names which differ from

their common names, for example SunOS will be reported as Solaris. The function is used

to implement this.

Setting terse to true causes the function to return only the absolute minimum information needed to identify

the platform.

Changed in version 3.8: On macOS, the function now uses , if it returns a non-empty release

string, to get the macOS version rather than the darwin version.



Returns the (real) processor name, e.g. .

An empty string is returned if the value cannot be determined. Note that many platforms do not provide this

information or simply return the same value as for . NetBSD does this.



Returns a tuple stating the Python build number and date as strings.



Returns a string identifying the compiler used for compiling Python.



Returns a string identifying the Python implementation SCM branch.



Returns a string identifying the Python implementation. Possible return values are: ‘CPython’, ‘IronPython’,

‘Jython’, ‘PyPy’.



Returns a string identifying the Python implementation SCM revision.



Returns the Python version as string .

Note that unlike the Python , the returned value will always include the patchlevel (it defaults

to 0).



Returns the Python version as tuple of strings.

Note that unlike the Python , the returned value will always include the patchlevel (it defaults

to ).



Returns the system’s release, e.g. or . An empty string is returned if the value cannot be

determined.



Returns the system/OS name, such as , , , . An empty string is re-

turned if the value cannot be determined.

On iOS and Android, this returns the user-facing OS name (i.e, , or ). To obtain

the kernel name ( or ), use .

system, release, version

Returns aliased to common marketing names used for some systems. It

also does some reordering of the information in some cases where it would otherwise cause confusion.

The Python Library Reference, Release 3.13.2





Returns the system’s release version, e.g. . An empty string is returned if the value cannot

be determined.

On iOS and Android, this is the user-facing OS version. To obtain the Darwin or Linux kernel version, use

.



Fairly portable uname interface. Returns a containing six attributes: , ,

, , , and .

is resolved late, on demand.

Note: the first two attribute names differ from the names presented by , where they are named

and .

Entries which cannot be determined are set to .

Changed in version 3.3: Result changed from a tuple to a .

Changed in version 3.9: is resolved late instead of immediately.





release=”, vendor=”, vminfo=(”, ”, ”), osinfo=(”, ”, ”)

Version interface for Jython.

Returns a tuple with vminfo being a tuple

and osinfo being a tuple . Values

which cannot be determined are set to the defaults given as parameters (which all default to ).

Deprecated since version 3.13, will be removed in version 3.15: It was largely untested, had a confusing API,

and was only useful for Jython support.





release=”, version=”, csd=” , ptype=”

Get additional version information from the Windows Registry and return a tuple

referring to OS release, version number, CSD level (service pack) and OS type (multi/single

processor). Values which cannot be determined are set to the defaults given as parameters (which all default

to an empty string).

As a hint: ptype is on single processor NT machines and

on multi processor machines. The refers to the OS version being free of debugging code.

It could also state which means the OS version uses debugging code, i.e. code that checks argu-

ments, ranges, etc.



Returns a string representing the current Windows edition, or if the value cannot be determined.

Possible values include but are not limited to , , , and

.

Added in version 3.8.



Return if the Windows edition returned by is recognized as an IoT edition.

Added in version 3.8.



The Python Library Reference, Release 3.13.2





release=”, versioninfo=(”, ”, ”), machine=”

Get macOS version information and return it as tuple with version-

info being a tuple .

Entries which cannot be determined are set to . All tuple entries are strings.





system=”, release=”, model=”, is_simulator=False

Get iOS version information and return it as a with the following attributes:

• is the OS name; either or .

• is the iOS version number as a string (e.g., ).

• is the device model identifier; this will be a string like for a physical device, or

on a simulator.

• is a boolean describing if the app is running on a simulator or a physical device.

Entries which cannot be determined are set to the defaults given as parameters.





executable=sys.executable, lib=”, version=”, chunksize=16384

Tries to determine the libc version against which the file executable (defaults to the Python interpreter) is

linked. Returns a tuple of strings which default to the given parameters in case the lookup

fails.

Note that this function has intimate knowledge of how different libc versions add symbols to the executable is

probably only usable for executables compiled using .

The file is read and scanned in chunks of chunksize bytes.





Get operating system identification from file and return it as a dict. The file is a

freedesktop.org standard and is available in most Linux distributions. A noticeable exception is Android and

Android-based distributions.

Raises or subclass when neither nor can be read.

On success, the function returns a dictionary where keys and values are strings. Values have their special

characters like and unquoted. The fields , , and are always defined according to

the standard. All other fields are optional. Vendors may include additional fields.

Note that fields like , , and are strings suitable for presentation to users. Programs

should use fields like , , , or to identify Linux distributions.

Example:





Added in version 3.10.

The Python Library Reference, Release 3.13.2





release=” , api_level=0, manufacturer=”, model=”, device=”, is_emulator=False

Get Android device information. Returns a with the following attributes. Values which cannot

be determined are set to the defaults given as parameters.

• - Android version, as a string (e.g. ).

• - API level of the running device, as an integer (e.g. for Android 14). To get the API

level which Python was built against, see .

• -Manufacturer name.

• -Model name – typically the marketing name or model number.

• -Device name – typically the model number or a codename.

• - if the device is an emulator; if it’s a physical device.

Google maintains a list of known model and device names.

Added in version 3.13.





This module makes available standard system symbols. The value of each symbol is the corresponding integer value. The names and descriptions are borrowed from , which should be all-inclusive.



Dictionary providing a mapping from the errno value to the string name in the underlying system. For instance,

maps to .

To translate a numeric error code to an error message, use .

Of the following list, symbols that are not used on the current platform are not defined by the module. The specific list of defined symbols is available as . Symbols available can include:



Operation not permitted. This error is mapped to the exception .



No such file or directory. This error is mapped to the exception .



No such process. This error is mapped to the exception .



Interrupted system call. This error is mapped to the exception .



I/O error



No such device or address



Arg list too long



Exec format error



Bad file number

The Python Library Reference, Release 3.13.2





No child processes. This error is mapped to the exception .



Try again. This error is mapped to the exception .



Out of memory



Permission denied. This error is mapped to the exception .



Bad address



Block device required



Device or resource busy



File exists. This error is mapped to the exception .



Cross-device link



No such device



Not a directory. This error is mapped to the exception .



Is a directory. This error is mapped to the exception .



Invalid argument



File table overflow



Too many open files



Not a typewriter



Text file busy



File too large



No space left on device



Illegal seek



Read-only file system

The Python Library Reference, Release 3.13.2





Too many links



Broken pipe. This error is mapped to the exception .



Math argument out of domain of func



Math result not representable



Resource deadlock would occur



File name too long



No record locks available



Function not implemented



Directory not empty



Too many symbolic links encountered



Operation would block. This error is mapped to the exception .



No message of desired type



Identifier removed



Channel number out of range



Level 2 not synchronized



Level 3 halted



Level 3 reset



Link number out of range



Protocol driver not attached



No CSI structure available



Level 2 halted

The Python Library Reference, Release 3.13.2





Invalid exchange



Invalid request descriptor



Exchange full



No anode



Invalid request code



Invalid slot



File locking deadlock error



Bad font file format



Device not a stream



No data available



Timer expired



Out of streams resources



Machine is not on the network



Package not installed



Object is remote



Link has been severed



Advertise error



Srmount error



Communication error on send



Protocol error



Multihop attempted

The Python Library Reference, Release 3.13.2





RFS specific error



Not a data message



Value too large for defined data type



Name not unique on network



File descriptor in bad state



Remote address changed



Can not access a needed shared library



Accessing a corrupted shared library



.lib section in a.out corrupted



Attempting to link in too many shared libraries



Cannot exec a shared library directly



Illegal byte sequence



Interrupted system call should be restarted



Streams pipe error



Too many users



Socket operation on non-socket



Destination address required



Message too long



Protocol wrong type for socket



Protocol not available



Protocol not supported

The Python Library Reference, Release 3.13.2





Socket type not supported



Operation not supported on transport endpoint



Operation not supported

Added in version 3.2.



Protocol family not supported



Address family not supported by protocol



Address already in use



Cannot assign requested address



Network is down



Network is unreachable



Network dropped connection because of reset



Software caused connection abort. This error is mapped to the exception .



Connection reset by peer. This error is mapped to the exception .



No buffer space available



Transport endpoint is already connected



Transport endpoint is not connected



Cannot send after transport endpoint shutdown. This error is mapped to the exception .



Too many references: cannot splice



Connection timed out. This error is mapped to the exception .



Connection refused. This error is mapped to the exception .



Host is down



The Python Library Reference, Release 3.13.2





No route to host



Operation already in progress. This error is mapped to the exception .



Operation now in progress. This error is mapped to the exception .



Stale NFS file handle



Structure needs cleaning



Not a XENIX named type file



No XENIX semaphores available



Is a named type file



Remote I/O error



Quota exceeded



Interface output queue is full

Added in version 3.11.



No medium found



Wrong medium type



Required key not available



Key has expired



Key has been revoked



Key was rejected by service



Operation not possible due to RF-kill



Locked lock was unmapped



Facility is not active



The Python Library Reference, Release 3.13.2





Authentication error

Added in version 3.2.



Bad CPU type in executable

Added in version 3.2.



Bad executable (or shared library)

Added in version 3.2.



Malformed Mach-o file

Added in version 3.2.



Device error

Added in version 3.2.



Inappropriate file type or format

Added in version 3.2.



Need authenticator

Added in version 3.2.



Attribute not found

Added in version 3.2.



Policy not found

Added in version 3.2.



Too many processes

Added in version 3.2.



Bad procedure for program

Added in version 3.2.



Program version wrong

Added in version 3.2.



RPC prog. not avail

Added in version 3.2.



The Python Library Reference, Release 3.13.2





Device power is off

Added in version 3.2.



RPC struct is bad

Added in version 3.2.



RPC version wrong

Added in version 3.2.



Shared library version mismatch

Added in version 3.2.



Capabilities insufficient. This error is mapped to the exception .

Availability: WASI, FreeBSD

Added in version 3.11.1.



Operation canceled

Added in version 3.2.



Owner died

Added in version 3.2.



State not recoverable

Added in version 3.2.





Source code: Lib/ctypes



is a foreign function library for Python. It provides C compatible data types, and allows calling functions in DLLs or shared libraries. It can be used to wrap these libraries in pure Python.





Note: The code samples in this tutorial use to make sure that they actually work. Since some code samples behave differently under Linux, Windows, or macOS, they contain doctest directives in comments.

Note: Some code samples reference the ctypes type. On platforms where

it is an alias to . So, you should not be confused if is printed if you would ex-

pect — they are actually the same type.



The Python Library Reference, Release 3.13.2



Loading dynamic link libraries

exports the cdll, and on Windows windll and oledll objects, for loading dynamic link libraries.

You load libraries by accessing them as attributes of these objects. cdll loads libraries which export functions using the standard calling convention, while windll libraries call functions using the calling convention. oledll also uses the calling convention, and assumes the functions return a Windows error code.

The error code is used to automatically raise an exception when the function call fails.

Changed in version 3.3: Windows errors used to raise , which is now an alias of .

Here are some examples for Windows. Note that is the MS standard C library containing most standard C functions, and uses the calling convention:





Windows appends the usual file suffix automatically.



® Note

Accessing the standard C library through will use an outdated version of the library that may be

incompatible with the one being used by Python. Where possible, use native Python functionality, or else import

and use the module.



On Linux, it is required to specify the filename including the extension to load a library, so attribute access can not

be used to load libraries. Either the method of the dll loaders should be used, or you should load the library by creating an instance of CDLL by calling the constructor:





Accessing functions from loaded dlls

Functions are accessed as attributes of dll objects:





Note that win32 system dlls like and often export ANSI as well as UNICODE versions of a function. The UNICODE version is exported with a appended to the name, while the ANSI version is exported with an appended to the name. The win32 function, which returns a module handle for a given

The Python Library Reference, Release 3.13.2



module name, has the following C prototype, and a macro is used to expose one of them as depending on whether UNICODE is defined or not:





windll does not try to select one of them by magic, you must access the version you need by specifying or explicitly, and then call it with bytes or string objects respectively.

Sometimes, dlls export functions with names which aren’t valid Python identifiers, like . In this

case you have to use to retrieve the function:





On Windows, some dlls export functions not by name but by ordinal. These functions can be accessed by indexing the dll object with the ordinal number:





Calling functions

You can call these functions like any other Python callable. This example uses the function, which takes no arguments and returns a pseudo-random integer:





On Windows, you can call the function, which returns a win32 module handle (passing as single argument to call it with a pointer):





is raised when you call an function with the calling convention, or vice versa:





The Python Library Reference, Release 3.13.2



To find out the correct calling convention you have to look into the C header file or the documentation for the function you want to call.

On Windows, uses win32 structured exception handling to prevent crashes from general protection faults when functions are called with invalid argument values:





There are, however, enough ways to crash Python with , so you should be careful anyway.

module can be helpful in debugging crashes (e.g. from segmentation faults produced by erroneous C library calls).

, integers, bytes objects and (unicode) strings are the only native Python objects that can directly be used as parameters in these function calls. is passed as a C pointer, bytes objects and strings are passed as pointer to the memory block that contains their data ( or ). Python integers are passed as the platform’s default C type, their value is masked to fit into the C type.

Before we move on calling functions with other parameter types, we have to learn more about data types.



Fundamental data types

defines a number of primitive C compatible data types:



ctypes type C type Python type

bool (1)

1-character bytes object

1-character string

int

int

int

int

int

int

int

int

or int

or int

int

or int

int

float

float

float

(NUL terminated) bytes object or

(NUL terminated) string or

int or

(1) The constructor accepts any object with a truth value.

All these types can be created by calling them with an optional initializer of the correct type and value:





The Python Library Reference, Release 3.13.2





Since these types are mutable, their value can also be changed afterwards:





Assigning a new value to instances of the pointer types , , and changes the mem-ory location they point to, not the contents of the memory block (of course not, because Python bytes objects are immutable):





You should be careful, however, not to pass them to functions expecting pointers to mutable memory. If you need

mutable memory blocks, ctypes has a function which creates these in various ways. The current memory block contents can be accessed (or changed) with the property; if you want to access it as NUL terminated string, use the property:





The Python Library Reference, Release 3.13.2





The function replaces the old function (which is still available as an alias). To create a mutable memory block containing unicode characters of the C type , use the

function.



Calling functions, continued

Note that printf prints to the real standard output channel, not to , so these examples will only work at the console prompt, not from within IDLE or PythonWin:





As has been mentioned before, all Python types except integers, strings, and bytes objects have to be wrapped in their

corresponding type, so that they can be converted to the required C data type:





Calling variadic functions

On a lot of platforms calling variadic functions through ctypes is exactly the same as calling functions with a fixed number of parameters. On some platforms, and in particular ARM64 for Apple Platforms, the calling convention for variadic functions is different than that for regular functions.

On those platforms it is required to specify the attribute for the regular, non-variadic, function arguments:





Because specifying the attribute does not inhibit portability it is advised to always specify for all variadic functions.



Calling functions with your own custom data types

You can also customize argument conversion to allow instances of your own classes be used as function

arguments. looks for an attribute and uses this as the function argument. The attribute

must be an integer, string, bytes, a instance, or an object with an attribute:





The Python Library Reference, Release 3.13.2





If you don’t want to store the instance’s data in the instance variable, you could define a which makes the attribute available on request.



Specifying the required argument types (function prototypes)

It is possible to specify the required argument types of functions exported from DLLs by setting the attribute.

must be a sequence of C data types (the function is probably not a good example here, because it takes a variable number and different types of parameters depending on the format string, on the other hand this is quite handy to experiment with this feature):





Specifying a format protects against incompatible argument types (just as a prototype for a C function), and tries to convert the arguments to valid types:





If you have defined your own classes which you pass to function calls, you have to implement a class

method for them to be able to use them in the sequence. The class method receives the Python object passed to the function call, it should do a typecheck or whatever is needed to make sure this object is acceptable, and then return the object itself, its attribute, or whatever you want to pass as the C

function argument in this case. Again, the result should be an integer, string, bytes, a instance, or an object with an attribute.



Return types

By default functions are assumed to return the C type. Other return types can be specified by setting the attribute of the function object.

The C prototype of is . Because might be of a different type than the default return type , you should specify the attribute:





The argument types can be specified using :





To call the function with a pointer as first argument, use :

The Python Library Reference, Release 3.13.2





Here is a more advanced example, it uses the function, which expects a string pointer and a char, and returns a pointer to a string:





If you want to avoid the calls above, you can set the attribute, and the second argument will be converted from a single character Python bytes object into a C char:





You can also use a callable Python object (a function or a class for example) as the attribute, if the foreign function returns an integer. The callable will be called with the integer the C function returns, and the result of this call will be used as the result of your function call. This is useful to check for error return values and automatically raise an exception:





is a function which will call Windows api to get the string representation of an error code, and returns an exception. takes an optional error code parameter, if no one is used, it calls

to retrieve it.

The Python Library Reference, Release 3.13.2



Please note that a much more powerful error checking mechanism is available through the attribute; see the reference manual for details.



Passing pointers (or: passing parameters by reference)

Sometimes a C api function expects a pointer to a data type as parameter, probably to write into the corresponding location, or if the data is too large to be passed by value. This is also known as passing parameters by reference.

exports the function which is used to pass parameters by reference. The same effect can be

achieved with the function, although does a lot more work since it constructs a real pointer

object, so it is faster to use if you don’t need the pointer object in Python itself:





Structures and unions

Structures and unions must derive from the and base classes which are defined in the

module. Each subclass must define a attribute. must be a list of 2-tuples, containing a field name and a field type.

The field type must be a type like , or any other derived type: structure, union, array, pointer.

Here is a simple example of a POINT structure, which contains two integers named x and y, and also shows how to initialize a structure in the constructor:





You can, however, build much more complicated structures. A structure can itself contain other structures by using a structure as a field type.

Here is a RECT structure which contains two POINTs named upperleft and lowerright:





The Python Library Reference, Release 3.13.2





Nested structures can also be initialized in the constructor in several ways:





Field descriptors can be retrieved from the class, they are useful for debugging because they can provide useful information:





Á Warning

does not support passing unions or structures with bit-fields to functions by value. While this may work

on 32-bit x86, it’s not guaranteed by the library to work in the general case. Unions and structures with bit-fields

should always be passed to functions by pointer.



Structure/union alignment and byte order

By default, Structure and Union fields are aligned in the same way the C compiler does it. It is possible to override

this behavior by specifying a class attribute in the subclass definition. This must be set to a positive integer and specifies the maximum alignment for the fields. This is what also does in MSVC. It is also possible to set a minimum alignment for how the subclass itself is packed in the same way

works in MSVC. This can be achieved by specifying a : class attribute in the subclass definition.

uses the native byte order for Structures and Unions. To build structures with non-native byte or-

der, you can use one of the , , , and

base classes. These classes cannot contain pointer fields.



Bit fields in structures and unions

It is possible to create structures and unions containing bit fields. Bit fields are only possible for integer fields, the bit

width is specified as the third item in the tuples:





The Python Library Reference, Release 3.13.2



Arrays

Arrays are sequences, containing a fixed number of instances of the same type.

The recommended way to create array types is by multiplying a data type with a positive integer:





Here is an example of a somewhat artificial data type, a structure containing 4 POINTs among other stuff:





Instances are created in the usual way, by calling the class:





The above code print a series of lines, because the array contents is initialized to zeros.

Initializers of the correct type can also be specified:





Pointers

Pointer instances are created by calling the function on a type:





Pointer instances have a attribute which returns the object to which the pointer points, the object above:





Note that does not have OOR (original object return), it constructs a new, equivalent object each time you retrieve an attribute:

The Python Library Reference, Release 3.13.2





Assigning another instance to the pointer’s contents attribute would cause the pointer to point to the memory location where this is stored:





Pointer instances can also be indexed with integers:





Assigning to an integer index changes the pointed to value:





It is also possible to use indexes different from 0, but you must know what you’re doing, just as in C: You can access or change arbitrary memory locations. Generally you only use this feature if you receive a pointer from a C function, and you know that the pointer actually points to an array instead of a single item.

Behind the scenes, the function does more than simply create pointer instances, it has to create pointer

types first. This is done with the function, which accepts any type, and returns a new type:





Calling the pointer type without an argument creates a pointer. pointers have a boolean value:





checks for when dereferencing pointers (but dereferencing invalid non- pointers would crash Python):

The Python Library Reference, Release 3.13.2





Type conversions

Usually, ctypes does strict type checking. This means, if you have in the list of a function or as the type of a member field in a structure definition, only instances of exactly the same type are accepted. There are some exceptions to this rule, where ctypes accepts other objects. For example, you can pass compatible array instances instead of pointer types. So, for , ctypes accepts an array of c_int:





In addition, if a function argument is explicitly declared to be a pointer type (such as ) in

, an object of the pointed type ( in this case) can be passed to the function. ctypes will apply

the required conversion in this case automatically.

To set a POINTER type field to , you can assign :





Sometimes you have instances of incompatible types. In C, you can cast one type into another type. provides

a function which can be used in the same way. The structure defined above accepts

pointers or arrays for its field, but not instances of other types:





For these cases, the function is handy.

The function can be used to cast a ctypes instance into a pointer to a different ctypes data type. takes two parameters, a ctypes object that is or can be converted to a pointer of some kind, and a ctypes pointer type. It returns an instance of the second argument, which references the same memory block as the first argument:

The Python Library Reference, Release 3.13.2





So, can be used to assign to the field of the structure:





Incomplete Types

Incomplete Types are structures, unions or arrays whose members are not yet specified. In C, they are specified by forward declarations, which are defined later:





The straightforward translation into ctypes code would be this, but it does not work:





because the new is not available in the class statement itself. In , we can define the class

and set the attribute later, after the class statement:





Let’s try it. We create two instances of , and let them point to each other, and finally follow the pointer chain a few times:





The Python Library Reference, Release 3.13.2





Callback functions

allows creating C callable function pointers from Python callables. These are sometimes called callback functions.

First, you must create a class for the callback function. The class knows the calling convention, the return type, and the number and types of arguments this function will receive.

The factory function creates types for callback functions using the calling convention. On

Windows, the factory function creates types for callback functions using the calling convention.

Both of these factory functions are called with the result type as first argument, and the callback functions expected argument types as the remaining arguments.

I will present an example here which uses the standard C library’s function, that is used to sort items with the help of a callback function. will be used to sort an array of integers:





must be called with a pointer to the data to sort, the number of items in the data array, the size of one item, and a pointer to the comparison function, the callback. The callback will then be called with two pointers to items, and it must return a negative integer if the first item is smaller than the second, a zero if they are equal, and a positive integer otherwise.

So our callback function receives pointers to integers, and must return an integer. First we create the for the callback function:





To get started, here is a simple callback that shows the values it gets passed:





The result:





The Python Library Reference, Release 3.13.2



Now we can actually compare the two items and return a useful result:





As we can easily check, our array is sorted now:





The function factories can be used as decorator factories, so we may as well write:





® Note

Make sure you keep references to objects as long as they are used from C code. doesn’t,

and if you don’t, they may be garbage collected, crashing your program when a callback is made.

Also, note that if the callback function is called in a thread created outside of Python’s control (e.g. by the foreign

code that calls the callback), ctypes creates a new dummy Python thread on every invocation. This behavior

is correct for most purposes, but it means that values stored with will not survive across

different callbacks, even when those calls are made from the same C thread.



Accessing values exported from dlls

Some shared libraries not only export functions, they also export variables. An example in the Python library itself is the , Python runtime version number encoded in a single constant integer.

can access values like this with the class methods of the type. pythonapi is a predefined symbol giving access to the Python C api:





The Python Library Reference, Release 3.13.2



An extended example which also demonstrates the use of pointers accesses the pointer exported by Python.

Quoting the docs for that value:

This pointer is initialized to point to an array of records, terminated by one whose members

are all or zero. When a frozen module is imported, it is searched in this table. Third-party code

could play tricks with this to provide a dynamically created collection of frozen modules.

So manipulating this pointer could even prove useful. To restrict the example size, we show only how this table can

be read with :





We have defined the data type, so we can get the pointer to the table:





Since is a to the array of records, we can iterate over it, but we just have to make sure that our loop terminates, because pointers have no size. Sooner or later it would probably crash with an access violation or whatever, so it’s better to break out of the loop when we hit the entry:





The fact that standard Python has a frozen module and a frozen package (indicated by the negative member) is not well known, it is only used for testing. Try it out with for example.



Surprises

There are some edges in where you might expect something other than what actually happens.

Consider the following example:





The Python Library Reference, Release 3.13.2





Hm. We certainly expected the last statement to print . What happened? Here are the steps of the line above:





Note that and are objects still using the internal buffer of the object above. So executing copies the buffer contents of into ‘s buffer. This, in turn, changes the contents of . So, the last assignment , doesn’t have the expected effect.

Keep in mind that retrieving sub-objects from Structure, Unions, and Arrays doesn’t copy the sub-object, instead it retrieves a wrapper object accessing the root-object’s underlying buffer.

Another example that may behave differently from what one would expect is this:





® Note

Objects instantiated from can only have their value set to bytes or integers.



Why is it printing ? ctypes instances are objects containing a memory block plus some descriptors accessing the contents of the memory. Storing a Python object in the memory block does not store the object itself, instead the of the object is stored. Accessing the contents again constructs a new Python object each time!



Variable-sized data types

provides some support for variable-sized arrays and structures.

The function can be used to resize the memory buffer of an existing ctypes object. The function takes the object as first argument, and the requested size in bytes as the second argument. The memory block cannot be made

smaller than the natural memory block specified by the objects type, a is raised if this is tried:





The Python Library Reference, Release 3.13.2





This is nice and fine, but how would one access the additional elements contained in this array? Since the type still only knows about 4 elements, we get errors accessing other elements:





Another way to use variable-sized data types with is to use the dynamic nature of Python, and (re-)define the data type after the required size is already known, on a case by case basis.





Finding shared libraries

When programming in a compiled language, shared libraries are accessed when compiling/linking a program, and when the program is run.

The purpose of the function is to locate a library in a way similar to what the compiler or runtime loader does (on platforms with several versions of a shared library the most recent should be loaded), while the ctypes library loaders act like when a program is run, and call the runtime loader directly.

The module provides a function which can help to determine the library to load.

name

Try to find a library and return a pathname. name is the library name without any prefix like lib, suffix like

, or version number (this is the form used for the posix linker option). If no library can be

found, returns .

The exact functionality is system dependent.

On Linux, tries to run external programs (, , and ) to find the library file. It returns the filename of the library file.

Changed in version 3.6: On Linux, the value of the environment variable is used when searching for libraries, if a library cannot be found by any other means.

Here are some examples:





On macOS and Android, uses the system’s standard naming schemes and paths to locate the library, and returns a full pathname if successful:

The Python Library Reference, Release 3.13.2





On Windows, searches along the system search path, and returns the full pathname, but since there is no predefined naming scheme a call like will fail and return .

If wrapping a shared library with , it may be better to determine the shared library name at development

time, and hardcode that into the wrapper module instead of using to locate the library at runtime.



Loading shared libraries

There are several ways to load shared libraries into the Python process. One way is to instantiate one of the following classes:

name, mode=DEFAULT_MODE , handle=None, use_errno=False, use_last_error=False,

winmode=None

Instances of this class represent loaded shared libraries. Functions in these libraries use the standard C calling

convention, and are assumed to return .

On Windows creating a instance may fail even if the DLL name exists. When a dependent DLL of the

loaded DLL is not found, a error is raised with the message “[WinError 126] The specified module

could not be found”. This error message does not contain the name of the missing DLL because the Windows

API does not return this information making this error hard to diagnose. To resolve this error and determine

which DLL is not found, you need to find the list of dependent DLLs and determine which one is not found

using Windows debugging and tracing tools.

Changed in version 3.12: The name parameter can now be a path-like object.



µ See also

Microsoft DUMPBIN tool – A tool to find DLL dependents.



name, mode=DEFAULT_MODE, handle=None, use_errno=False, use_last_error=False,

winmode=None

Instances of this class represent loaded shared libraries, functions in these libraries use the calling

convention, and are assumed to return the windows specific code. values contain infor-

mation specifying whether the function call failed or succeeded, together with additional error code. If the

return value signals a failure, an is automatically raised.

Availability: Windows

Changed in version 3.3: used to be raised, which is now an alias of .

Changed in version 3.12: The name parameter can now be a path-like object.

name, mode=DEFAULT_MODE, handle=None, use_errno=False, use_last_error=False,

winmode=None

Instances of this class represent loaded shared libraries, functions in these libraries use the calling

convention, and are assumed to return by default.

Availability: Windows

Changed in version 3.12: The name parameter can now be a path-like object.

The Python Library Reference, Release 3.13.2



The Python global interpreter lock is released before calling any function exported by these libraries, and reacquired afterwards.

name, mode=DEFAULT_MODE, handle=None

Instances of this class behave like instances, except that the Python GIL is not released during the function

call, and after the function execution the Python error flag is checked. If the error flag is set, a Python exception

is raised.

Thus, this is only useful to call Python C api functions directly.

Changed in version 3.12: The name parameter can now be a path-like object.

All these classes can be instantiated by calling them with at least one argument, the pathname of the shared library. If you have an existing handle to an already loaded shared library, it can be passed as the named parameter, otherwise the underlying platform’s or function is used to load the library into the process, and to get a handle to it.

The mode parameter can be used to specify how the library is loaded. For details, consult the manpage. On Windows, mode is ignored. On posix systems, RTLD_NOW is always added, and is not configurable.

The use_errno parameter, when set to true, enables a ctypes mechanism that allows accessing the system

error number in a safe way. maintains a thread-local copy of the system’s variable; if you call foreign

functions created with then the value before the function call is swapped with the ctypes private copy, the same happens immediately after the function call.

The function returns the value of the ctypes private copy, and the function

changes the ctypes private copy to a new value and returns the former value.

The use_last_error parameter, when set to true, enables the same mechanism for the Windows error code

which is managed by the and Windows API functions;

and are used to request and change the ctypes private copy of the windows error code.

The winmode parameter is used on Windows to specify how the library is loaded (since mode is ignored). It takes any value that is valid for the Win32 API flags parameter. When omitted, the default is to use the flags that result in the most secure DLL load, which avoids issues such as DLL hijacking. Passing the full path to the DLL is the safest way to ensure the correct library and dependencies are loaded.

Changed in version 3.8: Added winmode parameter.



Flag to use as mode parameter. On platforms where this flag is not available, it is defined as the integer zero.



Flag to use as mode parameter. On platforms where this is not available, it is the same as RTLD_GLOBAL.



The default mode which is used to load shared libraries. On OSX 10.3, this is RTLD_GLOBAL, otherwise it

is the same as RTLD_LOCAL.

Instances of these classes have no public methods. Functions exported by the shared library can be accessed as attributes or by index. Please note that accessing the function through an attribute caches the result and therefore accessing it repeatedly returns the same object each time. On the other hand, accessing it through an index returns a new object each time:





The following public attributes are available, their name starts with an underscore to not clash with exported function names:

The Python Library Reference, Release 3.13.2





The system handle used to access the library.



The name of the library passed in the constructor.

Shared libraries can also be loaded by using one of the prefabricated objects, which are instances of the

class, either by calling the method, or by retrieving the library as attribute of the loader instance.

dlltype

Class which loads shared libraries. dlltype should be one of the , , , or types.

has special behavior: It allows loading a shared library by accessing it as attribute of a library

loader instance. The result is cached, so repeated attribute accesses return the same library each time.

name

Load a shared library into the process and return it. This method always returns a new instance of the library.

These prefabricated library loaders are available:



Creates instances.



Creates instances.

Availability: Windows



Creates instances.

Availability: Windows



Creates instances.

For accessing the C Python api directly, a ready-to-use Python shared library object is available:



An instance of that exposes Python C API functions as attributes. Note that all these functions are

assumed to return C , which is of course not always the truth, so you have to assign the correct

attribute to use these functions.



Loading a library through any of these objects raises an auditing event with string argument , the name used to load the library.



Accessing a function on a loaded library raises an auditing event with arguments (the library object) and (the symbol’s name as a string or integer).



In cases when only the library handle is available rather than the object, accessing a function raises an auditing event with arguments (the raw library handle) and .



Foreign functions

As explained in the previous section, foreign functions can be accessed as attributes of loaded shared libraries. The function objects created in this way by default accept any number of arguments, accept any ctypes data instances as arguments, and return the default result type specified by the library loader.

The Python Library Reference, Release 3.13.2



They are instances of a private local class (not exposed in ) which inherits from the private

class:





Base class for C callable foreign functions.

Instances of foreign functions are also C compatible data types; they represent C function pointers.

This behavior can be customized by assigning to special attributes of the foreign function object.



Assign a ctypes type to specify the result type of the foreign function. Use for , a function not returning anything.

It is possible to assign a callable Python object that is not a ctypes type, in this case the function is assumed to return a C , and the callable will be called with this integer, allowing further processing or error checking. Using this is deprecated, for more flexible post processing or error checking use a ctypes data

type as and assign a callable to the attribute.



Assign a tuple of ctypes types to specify the argument types that the function accepts. Functions using the calling convention can only be called with the same number of arguments as the length of this tuple; functions using the C calling convention accept additional, unspecified arguments as well.

When a foreign function is called, each actual argument is passed to the class method

of the items in the tuple, this method allows adapting the actual argument to an object that

the foreign function accepts. For example, a item in the tuple will convert a string passed as argument into a bytes object using ctypes conversion rules.

New: It is now possible to put items in argtypes which are not ctypes types, but each item must have a

method which returns a value usable as argument (integer, string, ctypes instance). This allows defining adapters that can adapt custom objects as function parameters.



Assign a Python function or another callable to this attribute. The callable will be called with three or more arguments:

result, func, arguments

result is what the foreign function returns, as specified by the attribute.

func is the foreign function object itself, this allows reusing the same callable object to check or post process the results of several functions.

arguments is a tuple containing the parameters originally passed to the function call, this allows specializing the behavior on the arguments used.

The object that this function returns will be returned from the foreign function call, but it can also check the result value and raise an exception if the foreign function call failed.



This exception is raised when a foreign function call cannot convert one of the passed arguments.



On Windows, when a foreign function call raises a system exception (for example, due to an access violation), it will be captured and replaced with a suitable Python exception. Further, an auditing event with argument will be raised, allowing an audit hook to replace the exception with its own.

The Python Library Reference, Release 3.13.2



Some ways to invoke foreign function calls may raise an auditing event with arguments and .



Function prototypes

Foreign functions can also be created by instantiating function prototypes. Function prototypes are similar to func-tion prototypes in C; they describe a function (return type, argument types, calling convention) without defining an implementation. The factory functions must be called with the desired result type and the argument types of the function, and can be used as decorator factories, and as such, be applied to functions through the syntax.

See Callback functions for examples.

restype, *argtypes, use_errno=False, use_last_error=False

The returned function prototype creates functions that use the standard C calling convention. The function

will release the GIL during the call. If use_errno is set to true, the ctypes private copy of the system

variable is exchanged with the real value before and after the call; use_last_error does the same for the

Windows error code.

restype, *argtypes, use_errno=False, use_last_error=False

The returned function prototype creates functions that use the calling convention. The function will

release the GIL during the call. use_errno and use_last_error have the same meaning as above.

Availability: Windows

restype, *argtypes

The returned function prototype creates functions that use the Python calling convention. The function will

not release the GIL during the call.

Function prototypes created by these factory functions can be instantiated in different ways, depending on the type and number of the parameters in the call:

address

Returns a foreign function at the specified address which must be an integer.

callable

Create a C callable function (a callback function) from a Python callable.

func_spec, paramflags

Returns a foreign function exported by a shared library. func_spec must be a 2-tuple

. The first item is the name of the exported function as string, or the ordinal of the exported function

as small integer. The second item is the shared library instance.

vtbl_index, name, paramflags, iid

Returns a foreign function that will call a COM method. vtbl_index is the index into the virtual function table,

a small non-negative integer. name is name of the COM method. iid is an optional pointer to the interface

identifier which is used in extended error reporting.

COM methods use a special calling convention: They require a pointer to the COM interface as first argument,

in addition to those parameters that are specified in the tuple.

The optional paramflags parameter creates foreign function wrappers with much more functionality than the features described above.

paramflags must be a tuple of the same length as .

Each item in this tuple contains further information about a parameter, it must be a tuple containing one, two, or three items.

The first item is an integer containing a combination of direction flags for the parameter:

1

Specifies an input parameter to the function.

The Python Library Reference, Release 3.13.2



2

Output parameter. The foreign function fills in a value.

4

Input parameter which defaults to the integer zero.

The optional second item is the parameter name as string. If this is specified, the foreign function can be called with named parameters.

The optional third item is the default value for this parameter.

The following example demonstrates how to wrap the Windows function so that it supports default parameters and named arguments. The C declaration from the windows header file is this:





Here is the wrapping with :





The foreign function can now be called in these ways:





A second example demonstrates output parameters. The win32 function retrieves the dimensions of a specified window by copying them into structure that the caller has to supply. Here is the C declaration:





Here is the wrapping with :





Functions with output parameters will automatically return the output parameter value if there is a single one, or a tuple containing the output parameter values when there are more than one, so the GetWindowRect function now returns a RECT instance, when called.

Output parameters can be combined with the protocol to do further output processing and error checking. The win32 api function returns a to signal success or failure, so this function could do the error checking, and raises an exception when the api call failed:

The Python Library Reference, Release 3.13.2





If the function returns the argument tuple it receives unchanged, continues the normal processing it does on the output parameters. If you want to return a tuple of window coordinates instead of a instance, you can retrieve the fields in the function and return them instead, the normal processing will no longer take place:





Utility functions

obj

Returns the address of the memory buffer as integer. obj must be an instance of a ctypes type.

Raises an auditing event with argument .

obj_or_type

Returns the alignment requirements of a ctypes type. obj_or_type must be a ctypes type or instance.

obj, offset

Returns a light-weight pointer to obj, which must be an instance of a ctypes type. offset defaults to zero, and

must be an integer that will be added to the internal pointer value.

corresponds to this C code:





The returned object can only be used as a foreign function call parameter. It behaves similar to ,

but the construction is a lot faster.

obj, type

This function is similar to the cast operator in C. It returns a new instance of type which points to the same

memory block as obj. type must be a pointer type, and obj must be an object that can be interpreted as a pointer.

init_or_size, size=None

This function creates a mutable character buffer. The returned object is a ctypes array of .

init_or_size must be an integer which specifies the size of the array, or a bytes object which will be used to

initialize the array items.

If a bytes object is specified as first argument, the buffer is made one item larger than its length so that the

last element in the array is a NUL termination character. An integer can be passed as second argument which

allows specifying the size of the array if the length of the bytes should not be used.

Raises an auditing event with arguments , .

init_or_size, size=None

This function creates a mutable unicode character buffer. The returned object is a ctypes array of .

The Python Library Reference, Release 3.13.2



init_or_size must be an integer which specifies the size of the array, or a string which will be used to initialize

the array items.

If a string is specified as first argument, the buffer is made one item larger than the length of the string so that

the last element in the array is a NUL termination character. An integer can be passed as second argument

which allows specifying the size of the array if the length of the string should not be used.

Raises an auditing event with arguments , .



This function is a hook which allows implementing in-process COM servers with ctypes. It is called from the

DllCanUnloadNow function that the _ctypes extension dll exports.

Availability: Windows



This function is a hook which allows implementing in-process COM servers with ctypes. It is called from the

DllGetClassObject function that the extension dll exports.

Availability: Windows

name

Try to find a library and return a pathname. name is the library name without any prefix like , suffix like

, or version number (this is the form used for the posix linker option). If no library can be

found, returns .

The exact functionality is system dependent.



Returns the filename of the VC runtime library used by Python, and by the extension modules. If the name of

the library cannot be determined, is returned.

If you need to free memory, for example, allocated by an extension module with a call to the ,

it is important that you use the function in the same library that allocated the memory.

Availability: Windows

code

Returns a textual description of the error code code. If no error code is specified, the last error code is used

by calling the Windows api function GetLastError.

Availability: Windows



Returns the last error code set by Windows in the calling thread.

function directly, it does not return the ctypes-private copy of the error code.

Availability: Windows



Returns the current value of the ctypes-private copy of the system variable in the calling thread.

Raises an auditing event with no arguments.



Returns the current value of the ctypes-private copy of the system variable in the calling thread.

Availability: Windows

Raises an auditing event with no arguments.

dst, src, count

Same as the standard C memmove library function: copies count bytes from src to dst. dst and src must be

integers or ctypes instances that can be converted to pointers.



The Python Library Reference, Release 3.13.2



dst, c, count

Same as the standard C memset library function: fills the memory block at address dst with count bytes of

value c. dst must be an integer specifying an address, or a ctypes instance.

type, /

Create and return a new ctypes pointer type. Pointer types are cached and reused internally, so calling this

function repeatedly is cheap. type must be a ctypes type.

obj, /

Create a new pointer instance, pointing to obj. The returned object is of the type .

Note: If you just want to pass a pointer to an object to a foreign function call, you should use

which is much faster.

obj, size

This function resizes the internal memory buffer of obj, which must be an instance of a ctypes type. It is not

possible to make the buffer smaller than the native size of the objects type, as given by ,

but it is possible to enlarge the buffer.

value

Set the current value of the ctypes-private copy of the system variable in the calling thread to value and

return the previous value.

Raises an auditing event with argument .

value

Sets the current value of the ctypes-private copy of the system variable in the calling thread to

value and return the previous value.

Availability: Windows

Raises an auditing event with argument .

obj_or_type

Returns the size in bytes of a ctypes type or instance memory buffer. Does the same as the C operator.

ptr, size=-1

Return the byte string at void *ptr. If size is specified, it is used as size, otherwise the string is assumed to be

zero-terminated.

Raises an auditing event with arguments , .

code=None, descr=None

This function is probably the worst-named thing in ctypes. It creates an instance of . If code is not

specified, is called to determine the error code. If descr is not specified, is

called to get a textual description of the error.

Availability: Windows

Changed in version 3.3: An instance of used to be created, which is now an alias of .

ptr, size=-1

Return the wide-character string at void *ptr. If size is specified, it is used as the number of characters of the

string, otherwise the string is assumed to be zero-terminated.

Raises an auditing event with arguments , .



Data types



This non-public class is the common base class of all ctypes data types. Among other things, all ctypes type

instances contain a memory block that hold C compatible data; the address of the memory block is returned

by the helper function. Another instance variable is exposed as ; this contains other

Python objects that need to be kept alive in case the memory block contains pointers.

The Python Library Reference, Release 3.13.2



Common methods of ctypes data types, these are all class methods (to be exact, they are methods of the

metaclass):

source, offset

This method returns a ctypes instance that shares the buffer of the source object. The source object must support the writeable buffer interface. The optional offset parameter specifies an offset into the source

buffer in bytes; the default is zero. If the source buffer is not large enough a is raised.

Raises an auditing event with arguments , , .

source , offset

This method creates a ctypes instance, copying the buffer from the source object buffer which must be readable. The optional offset parameter specifies an offset into the source buffer in bytes; the default is

zero. If the source buffer is not large enough a is raised.

Raises an auditing event with arguments , , .

address

This method returns a ctypes type instance using the memory specified by address which must be an integer.



This method, and others that indirectly call this method, raises an auditing event with argument .

obj

This method adapts obj to a ctypes type. It is called with the actual object used in a foreign function call

when the type is present in the foreign function’s tuple; it must return an object that can be used as a function call parameter.

All ctypes data types have a default implementation of this classmethod that normally returns obj if that is an instance of the type. Some types accept other objects as well.

library, name

This method returns a ctypes type instance exported by a shared library. name is the name of the symbol that exports the data, library is the loaded shared library.

Common instance variables of ctypes data types:



Sometimes ctypes data instances do not own the memory block they contain, instead they share part of

the memory block of a base object. The read-only member is the root ctypes object that owns the memory block.



This read-only variable is true when the ctypes data instance has allocated the memory block itself, false otherwise.



This member is either or a dictionary containing Python objects that need to be kept alive so that the memory block contents is kept valid. This object is only exposed for debugging; never modify the contents of this dictionary.



Fundamental data types



This non-public class is the base class of all fundamental ctypes data types. It is mentioned here because it

contains the common attributes of the fundamental ctypes data types. is a subclass of ,

so it inherits their methods and attributes. ctypes data types that are not and do not contain pointers can now

be pickled.

Instances have a single attribute:

The Python Library Reference, Release 3.13.2





This attribute contains the actual value of the instance. For integer and pointer types, it is an integer, for character types, it is a single character bytes object or string, for character pointer types it is a Python bytes object or string.

When the attribute is retrieved from a ctypes instance, usually a new object is returned each time.

does not implement original object return, always a new object is constructed. The same is true for all other ctypes object instances.

Fundamental data types, when returned as foreign function call results, or, for example, by retrieving structure field members or array items, are transparently converted to native Python types. In other words, if a foreign function has

a of , you will always receive a Python bytes object, not a instance.

Subclasses of fundamental data types do not inherit this behavior. So, if a foreign functions is a subclass

of , you will receive an instance of this subclass from the function call. Of course, you can get the value of the pointer by accessing the attribute.

These are the fundamental ctypes data types:



Represents the C datatype, and interprets the value as small integer. The constructor accepts

an optional integer initializer; no overflow checking is done.



Represents the C datatype, and interprets the value as a single character. The constructor accepts an

optional string initializer, the length of the string must be exactly one character.



Represents the C datatype when it points to a zero-terminated string. For a general character pointer

that may also point to binary data, must be used. The constructor accepts an integer

address, or a bytes object.



Represents the C datatype. The constructor accepts an optional float initializer.



Represents the C datatype. The constructor accepts an optional float initializer. On platforms

where it is an alias to .



Represents the C datatype. The constructor accepts an optional float initializer.



Represents the C datatype. The constructor accepts an optional integer initializer; no overflow

checking is done. On platforms where it is an alias to .



Represents the C 8-bit datatype. Usually an alias for .



Represents the C 16-bit datatype. Usually an alias for .



Represents the C 32-bit datatype. Usually an alias for .



Represents the C 64-bit datatype. Usually an alias for .



Represents the C datatype. The constructor accepts an optional integer initializer; no overflow

checking is done.

The Python Library Reference, Release 3.13.2





Represents the C datatype. The constructor accepts an optional integer initializer; no

overflow checking is done.



Represents the C datatype. The constructor accepts an optional integer initializer; no overflow

checking is done.



Represents the C datatype.



Represents the C datatype.

Added in version 3.2.



Represents the C datatype.

Added in version 3.12.



Represents the C datatype, it interprets the value as small integer. The constructor accepts

an optional integer initializer; no overflow checking is done.



Represents the C datatype. The constructor accepts an optional integer initializer; no overflow

checking is done. On platforms where it is an alias for .



Represents the C 8-bit datatype. Usually an alias for .



Represents the C 16-bit datatype. Usually an alias for .



Represents the C 32-bit datatype. Usually an alias for .



Represents the C 64-bit datatype. Usually an alias for .



Represents the C datatype. The constructor accepts an optional integer initializer; no over-

flow checking is done.



Represents the C datatype. The constructor accepts an optional integer initializer; no

overflow checking is done.



Represents the C datatype. The constructor accepts an optional integer initializer; no

overflow checking is done.



Represents the C type. The value is represented as integer. The constructor accepts an optional integer

initializer.



Represents the C datatype, and interprets the value as a single character unicode string. The con-

structor accepts an optional string initializer, the length of the string must be exactly one character.



The Python Library Reference, Release 3.13.2





Represents the C datatype, which must be a pointer to a zero-terminated wide character string.

The constructor accepts an integer address, or a string.



Represent the C datatype (more accurately, from C99). Its value can be or , and the

constructor accepts any object that has a truth value.



Represents a value, which contains success or error information for a function or method call.

Availability: Windows



Represents the C datatype. Calling this without an argument creates a pointer.

The module provides quite some other Windows specific data types, for example , , or . Some useful structures like or are also defined.



Structured data types

*args, **kw

Abstract base class for unions in native byte order.

*args, **kw

Abstract base class for unions in big endian byte order.

Added in version 3.11.

*args, **kw

Abstract base class for unions in little endian byte order.

Added in version 3.11.

*args, **kw

Abstract base class for structures in big endian byte order.

*args, **kw

Abstract base class for structures in little endian byte order.

Structures and unions with non-native byte order cannot contain pointer type fields, or any other data types containing pointer type fields.

*args, **kw

Abstract base class for structures in native byte order.

Concrete structure and union types must be created by subclassing one of these types, and at least define a

class variable. will create descriptors which allow reading and writing the fields by direct

attribute accesses. These are the



A sequence defining the structure fields. The items must be 2-tuples or 3-tuples. The first item is the name of the field, the second item specifies the type of the field; it can be any ctypes data type.

For integer type fields like , a third optional item can be given. It must be a small positive integer defining the bit width of the field.

Field names must be unique within one structure or union. This is not checked, only one field can be accessed when names are repeated.

It is possible to define the class variable after the class statement that defines the Structure subclass, this allows creating data types that directly or indirectly reference themselves:



The Python Library Reference, Release 3.13.2





The class variable must, however, be defined before the type is first used (an instance is

created, is called on it, and so on). Later assignments to the class variable will raise an AttributeError.

It is possible to define sub-subclasses of structure types, they inherit the fields of the base class plus the

defined in the sub-subclass, if any.



An optional small integer that allows overriding the alignment of structure fields in the instance.

must already be defined when is assigned, otherwise it will have no effect. Setting this attribute to 0 is the same as not setting it at all.



An optional small integer that allows overriding the alignment of the structure when being packed or unpacked to/from memory. Setting this attribute to 0 is the same as not setting it at all.

Added in version 3.13.



An optional sequence that lists the names of unnamed (anonymous) fields. must be al-

ready defined when is assigned, otherwise it will have no effect.

The fields listed in this variable must be structure or union type fields. will create descriptors in the structure type that allows accessing the nested fields directly, without the need to create the structure or union field.

Here is an example type (Windows):





The structure describes a COM data type, the field specifies which one of the union fields is valid. Since the field is defined as anonymous field, it is now possible to access the members directly off the TYPEDESC instance. and are equivalent, but the former is faster since it does not need to create a temporary union instance:





It is possible to define sub-subclasses of structures, they inherit the fields of the base class. If the subclass

definition has a separate variable, the fields specified in this are appended to the fields of the base

class.

Structure and union constructors accept both positional and keyword arguments. Positional arguments are

used to initialize member fields in the same order as they are appear in . Keyword arguments in the The Python Library Reference, Release 3.13.2



constructor are interpreted as attribute assignments, so they will initialize with the same name, or

create new attributes for names not present in .



Arrays and pointers

*args

Abstract base class for arrays.

The recommended way to create concrete array types is by multiplying any data type with a non-

negative integer. Alternatively, you can subclass this type and define and class variables.

Array elements can be read and written using standard subscript and slice accesses; for slice reads, the resulting

object is not itself an .



A positive integer specifying the number of elements in the array. Out-of-range subscripts result in an

. Will be returned by .



Specifies the type of each element in the array.

Array subclass constructors accept positional arguments, used to initialize the elements in order.

type, length

Create an array. Equivalent to , where type is a data type and length an integer.

This function is soft deprecated in favor of multiplication. There are no plans to remove it.



Private, abstract base class for pointers.

Concrete pointer types are created by calling with the type that will be pointed to; this is done

automatically by .

If a pointer points to an array, its elements can be read and written using standard subscript and slice accesses.

Pointer objects have no size, so will raise . Negative subscripts will read from the memory

before the pointer (as in C), and out-of-range subscripts will probably crash with an access violation (if you’re

lucky).



Specifies the type pointed to.





Returns the object to which to pointer points. Assigning to this attribute changes the pointer to point to the assigned object.





CHAPTER





The modules described in this chapter assist with implementing command line and terminal interfaces for applica-tions.

Here’s an overview:





Added in version 3.2.

Source code: Lib/argparse.py



® Note

While is the default recommended standard library module for implementing basic command line

applications, authors with more exacting requirements for exactly how their command line applications behave

may find it doesn’t provide the necessary level of control. Refer to Choosing an argument parsing library for

alternatives to consider when doesn’t support behaviors that the application requires (such as entirely

disabling support for interspersed options and positional arguments, or accepting option parameter values that

start witheven when they correspond to another defined option).



Tutorial

This page contains the API reference information. For a more gentle introduction to Python command-line

parsing, have a look at the argparse tutorial.



The module makes it easy to write user-friendly command-line interfaces. The program defines what

arguments it requires, and will figure out how to parse those out of . The module also automatically generates help and usage messages. The module will also issue errors when users give the program invalid arguments.

The module’s support for command-line interfaces is built around an instance of

. It is a container for argument specifications and has options that apply to the parser as whole:





The method attaches individual argument specifications to the parser. It supports positional arguments, options that accept values, and on/off flags:

The Python Library Reference, Release 3.13.2





The method runs the parser and places the extracted data in a

object:





® Note

If you’re looking for a guide about how to upgrade code to , see Upgrading Optparse Code.





prog=None, usage=None, description=None, epilog=None, parents=[],

formatter_class=argparse.HelpFormatter, prefix_chars=’-’ ,

fromfile_prefix_chars=None, argument_default=None,

conflict_handler=’error’, add_help=True, allow_abbrev=True,

exit_on_error=True

Create a new object. All parameters should be passed as keyword arguments. Each pa-

rameter has its own more detailed description below, but in short they are:

• prog- The name of the program (default: )

• usage- The string describing the program usage (default: generated from arguments added to parser)

• description- Text to display before the argument help (by default, no text)

• epilog- Text to display after the argument help (by default, no text)

• parents- A list of objects whose arguments should also be included

• formatter_class- A class for customizing the help output

• prefix_chars- The set of characters that prefix optional arguments (default: ‘-‘)

• fromfile_prefix_chars- The set of characters that prefix files from which additional arguments should be

read (default: )

• argument_default- The global default value for arguments (default: )

• conflict_handler- The strategy for resolving conflicting optionals (usually unnecessary)

• add_help- Add a option to the parser (default: )

• allow_abbrev- Allows long options to be abbreviated if the abbreviation is unambiguous. (default: )

• exit_on_error- Determines whether or not exits with error info when an error occurs.

(default: )

Changed in version 3.5: allow_abbrev parameter was added.

Changed in version 3.8: In previous versions, allow_abbrev also disabled grouping of short flags such as

to mean.

Changed in version 3.9: exit_on_error parameter was added.

The following sections describe how each of these are used.



The Python Library Reference, Release 3.13.2



prog

By default, calculates the name of the program to display in help messages depending on the way the Python interpreter was run:

• The of if a file was passed as argument.

• The Python interpreter name followed by if a directory or a zipfile was passed as argument.

• The Python interpreter name followed by followed by the module or package name if the option was

used.

This default is almost always desirable because it will make the help messages match the string that was used to invoke the program on the command line. However, to change this default behavior, another value can be supplied

using the argument to :





Note that the program name, whether determined from or from the argument, is available to help messages using the format specifier.





usage

By default, calculates the usage message from the arguments it contains. The default message can be overridden with the keyword argument:





The format specifier is available to fill in the program name in your usage messages.



description

Most calls to the constructor will use the keyword argument. This argument gives a brief description of what the program does and how it works. In help messages, the description is displayed between the command-line usage string and the help messages for the various arguments.

The Python Library Reference, Release 3.13.2



By default, the description will be line-wrapped so that it fits within the given space. To change this behavior, see the

formatter_class argument.



epilog

Some programs like to display additional description of the program after the description of the arguments. Such

text can be specified using the argument to :





As with the description argument, the text is by default line-wrapped, but this behavior can be adjusted

with the formatter_class argument to .



parents

Sometimes, several parsers share a common set of arguments. Rather than repeating the definitions of these argu-

ments, a single parser with all the shared arguments and passed to argument to can

be used. The argument takes a list of objects, collects all the positional and optional

actions from them, and adds these actions to the object being constructed:





Note that most parent parsers will specify . Otherwise, the will see two options (one in the parent and one in the child) and raise an error.



® Note

You must fully initialize the parsers before passing them via . If you change the parent parsers after

the child parser, those changes will not be reflected in the child.



formatter_class

objects allow the help formatting to be customized by specifying an alternate formatting class. Currently, there are four such classes:



The Python Library Reference, Release 3.13.2





and give more control over how textual descrip-

tions are displayed. By default, objects line-wrap the description and epilog texts in command-line help messages:





Passing as indicates that description and epilog are al-ready correctly formatted and should not be line-wrapped:





maintains whitespace for all sorts of help text, including argument descriptions. However, multiple newlines are replaced with one. If you wish to preserve multiple blank lines, add spaces between the newlines.

automatically adds information about default values to each of the argument help messages:

The Python Library Reference, Release 3.13.2





uses the name of the type argument for each argument as the display name for its

values (rather than using the dest as the regular formatter does):





prefix_chars

Most command-line options will useas the prefix, e.g.. Parsers that need to support different or additional prefix characters, e.g. for options like or , may specify them using the argument

to the constructor:





The argument defaults to . Supplying a set of characters that does not includewill cause options to be disallowed.



fromfile_prefix_chars

Sometimes, when dealing with a particularly long argument list, it may make sense to keep the list of arguments in a file rather than typing it out at the command line. If the argument is given to the

constructor, then arguments that start with any of the specified characters will be treated as files, and will be replaced by the arguments they contain. For example:





The Python Library Reference, Release 3.13.2





Arguments read from a file must by default be one per line (but see also ) and are treated as if they were in the same place as the original file referencing argument on the command line. So in the example above, the expression is considered equivalent to the expression .

uses filesystem encoding and error handler to read the file containing arguments.

The argument defaults to , meaning that arguments will never be treated as file references.

Changed in version 3.12: changed encoding and errors to read arguments files from default

(e.g. and ) to the filesystem encoding and error handler. Arguments file should be encoded in UTF-8 instead of ANSI Codepage on Windows.



argument_default

Generally, argument defaults are specified either by passing a default to or by calling the

methods with a specific set of name-value pairs. Sometimes however, it may be useful to specify a single parser-wide default for arguments. This can be accomplished by passing the keyword

argument to . For example, to globally suppress attribute creation on calls, we supply :





allow_abbrev

Normally, when you pass an argument list to the method of an , it recognizes

abbreviations of long options.

This feature can be disabled by setting to :





Added in version 3.5.



conflict_handler

objects do not allow two actions with the same option string. By default, objects raise an exception if an attempt is made to create an argument with an option string that is already in use:





The Python Library Reference, Release 3.13.2





Sometimes (e.g. when using parents) it may be useful to simply override any older arguments with the same op-tion string. To get this behavior, the value can be supplied to the argument of

:





Note that objects only remove an action if all of its option strings are overridden. So, in the example above, the old action is retained as the action, because only the option string was overridden.



add_help

By default, objects add an option which simply displays the parser’s help message. If or is supplied at the command line, the help will be printed.

Occasionally, it may be useful to disable the addition of this help option. This can be achieved by passing as

the argument to :





The help option is typically. The exception to this is if the is specified and does not include, in which case and are not valid options. In this case, the first character in is used to prefix the help options:





exit_on_error

Normally, when you pass an invalid argument list to the method of an , it will

print a message to and exit with a status code of 2.

If the user would like to catch errors manually, the feature can be enabled by setting to :

The Python Library Reference, Release 3.13.2





Added in version 3.9.





name or flags..., *, action , nargs , const , default , type , choices

, required , help , metavar , dest , deprecated

Define how a single command-line argument should be parsed. Each parameter has its own more detailed

description below, but in short they are:

• name or flags- Either a name or a list of option strings, e.g. or .

• action- The basic type of action to be taken when this argument is encountered at the command line.

• nargs- The number of command-line arguments that should be consumed.

• const- A constant value required by some action and nargs selections.

• default- The value produced if the argument is absent from the command line and if it is absent from

the namespace object.

• type- The type to which the command-line argument should be converted.

• choices- A sequence of the allowable values for the argument.

• required- Whether or not the command-line option may be omitted (optionals only).

• help- A brief description of what the argument does.

• metavar- A name for the argument in usage messages.

• dest- The name of the attribute to be added to the object returned by .

• deprecated- Whether or not use of the argument is deprecated.

The following sections describe how each of these are used.



name or flags

The method must know whether an optional argument, like or, or a positional argu-

ment, like a list of filenames, is expected. The first arguments passed to must therefore be either a series of flags, or a simple argument name.

For example, an optional argument could be created like:





while a positional argument could be created like:





When is called, optional arguments will be identified by theprefix, and the remaining arguments will be assumed to be positional:

The Python Library Reference, Release 3.13.2





action

objects associate command-line arguments with actions. These actions can do just about anything with the command-line arguments associated with them, though most actions simply add an attribute to the object

returned by . The keyword argument specifies how the command-line arguments should be handled. The supplied actions are:

• - This just stores the argument’s value. This is the default action.

• - This stores the value specified by the const keyword argument; note that the const keyword

argument defaults to . The action is most commonly used with optional arguments that

specify some sort of flag. For example:





• and - These are special cases of used for storing the

values and respectively. In addition, they create default values of and respectively:





• - This stores a list, and appends each argument value to the list. It is useful to allow an option to be

specified multiple times. If the default value is non-empty, the default elements will be present in the parsed

value for the option, with any values from the command line appended after those default values. Example

usage:





• - This stores a list, and appends the value specified by the const keyword argument to the

list; note that the const keyword argument defaults to . The action is typically useful

when multiple arguments need to store constants to the same list. For example:





The Python Library Reference, Release 3.13.2





• - This stores a list and appends each item from the multi-value argument list to it. The

action is typically used with the nargs keyword argument value or . Note that when nargs is

(the default) or , each character of the argument string will be appended to the list. Example usage:





Added in version 3.8.

• - This counts the number of times a keyword argument occurs. For example, this is useful for

increasing verbosity levels:





Note, the default will be unless explicitly set to 0.

• - This prints a complete help message for all the options in the current parser and then exits. By

default a help action is automatically added to the parser. See for details of how the output

is created.

• - This expects a keyword argument in the call, and prints version

information and exits when invoked:





Only actions that consume command-line arguments (e.g. , or ) can be used with positional arguments.



You may also specify an arbitrary action by passing an subclass or other object that implements the

same interface. The is available in and adds support for boolean

actions such as and:





Added in version 3.9.

The recommended way to create a custom action is to extend , overriding the method and optionally the and methods. You can also register custom actions using the

method and reference them by their registered name.

An example of a custom action:



The Python Library Reference, Release 3.13.2





For more details, see .



nargs

objects usually associate a single command-line argument with a single action to be taken. The keyword argument associates a different number of command-line arguments with a single action. See also

Specifying ambiguous arguments. The supported values are:

• (an integer). arguments from the command line will be gathered together into a list. For example:





Note that produces a list of one item. This is different from the default, in which the item is produced

by itself.

• . One argument will be consumed from the command line if possible, and produced as a single item. If no

command-line argument is present, the value from default will be produced. Note that for optional arguments,

there is an additional case - the option string is present but not followed by a command-line argument. In this

case the value from const will be produced. Some examples to illustrate this:





One of the more common uses of is to allow optional input and output files:





The Python Library Reference, Release 3.13.2





• . All command-line arguments present are gathered into a list. Note that it generally doesn’t make much

sense to have more than one positional argument with , but multiple optional arguments with

is possible. For example:





• . Just like , all command-line args present are gathered into a list. Additionally, an error message will

be generated if there wasn’t at least one command-line argument present. For example:





If the keyword argument is not provided, the number of arguments consumed is determined by the action. Generally this means a single command-line argument will be consumed and a single item (not a list) will be produced. Actions that do not consume command-line arguments (e.g. ) set .



const

The argument of is used to hold constant values that are not read from the command line

but are required for the various actions. The two most common uses of it are:

• When is called with or . These

actions add the value to one of the attributes of the object returned by . See the action

description for examples. If is not provided to , it will receive a default value of

.

• When is called with option strings (like or) and . This creates an

optional argument that can be followed by zero or one command-line arguments. When parsing the command

line, if the option string is encountered with no command-line argument following it, the value of will

be assumed to be instead. See the nargs description for examples.

Changed in version 3.11: by default, including when or .



default

All optional arguments and some positional arguments may be omitted at the command line. The keyword

argument of , whose value defaults to , specifies what value should be used if the command-line argument is not present. For optional arguments, the value is used when the option string was not present at the command line:



The Python Library Reference, Release 3.13.2





If the target namespace already has an attribute set, the action default will not overwrite it:





If the value is a string, the parser parses the value as if it were a command-line argument. In particular,

the parser applies any type conversion argument, if provided, before setting the attribute on the return value. Otherwise, the parser uses the value as is:





For positional arguments with nargs equal to or , the value is used when no command-line argument was present:





For required arguments, the value is ignored. For example, this applies to positional arguments with nargs values other than or , or optional arguments marked as .

Providing causes no attribute to be added if the command-line argument was not present:





type

By default, the parser reads command-line arguments in as simple strings. However, quite often the command-

line string should instead be interpreted as another type, such as a or . The keyword for

allows any necessary type-checking and type conversions to be performed.

If the type keyword is used with the default keyword, the type converter is only applied if the default is a string.

The argument to can be a callable that accepts a single string or the name of a registered type (see )

If the function raises , , or , the exception is caught and a nicely formatted error message is displayed. Other exception types are not handled.

Common built-in types and functions can be used as type converters:

The Python Library Reference, Release 3.13.2





User defined functions can be used as well:





The function is not recommended as a type converter. All it does is convert empty strings to and non-empty strings to . This is usually not what is desired.

In general, the keyword is a convenience that should only be used for simple conversions that can only raise one of the three supported exceptions. Anything with more interesting error-handling or resource management should be done downstream after the arguments are parsed.

For example, JSON or YAML conversions have complex error cases that require better reporting than can be given

by the keyword. A would not be well formatted and a exception would not be handled at all.

Even has its limitations for use with the keyword. If one argument uses and then a subsequent argument fails, an error is reported but the file is not automatically closed. In this case, it would be better to wait until after the parser has run and then use the -statement to manage the files.

For type checkers that simply check against a fixed set of values, consider using the choices keyword instead.



choices

Some command-line arguments should be selected from a restricted set of values. These can be handled by passing a

sequence object as the choices keyword argument to . When the command line is parsed, argument values will be checked, and an error message will be displayed if the argument was not one of the acceptable values:





Note that inclusion in the choices sequence is checked after any type conversions have been performed, so the type

of the objects in the choices sequence should match the type specified.

Any sequence can be passed as the choices value, so objects, objects, and custom sequences are all supported.

Use of is not recommended because it is difficult to control its appearance in usage, help, and error messages.

The Python Library Reference, Release 3.13.2



Formatted choices override the default metavar which is normally derived from dest. This is usually what you want because the user never sees the dest parameter. If this display isn’t desirable (perhaps because there are many choices),

just specify an explicit metavar.



required

In general, the module assumes that flags like and indicate optional arguments, which can always be omitted at the command line. To make an option required, can be specified for the

keyword argument to :





As the example shows, if an option is marked as , will report an error if that option is not present at the command line.



® Note

Required options are generally considered bad form because users expect options to be optional, and thus they

should be avoided when possible.



help

The value is a string containing a brief description of the argument. When a user requests help (usually by using or at the command line), these descriptions will be displayed with each argument.

The strings can include various format specifiers to avoid repetition of things like the program name or the

argument default. The available specifiers include the program name, and most keyword arguments to

, e.g. , , etc.:





As the help string supports %-formatting, if you want a literal to appear in the help string, you must escape it as .

supports silencing the help entry for certain options, by setting the value to :





The Python Library Reference, Release 3.13.2



metavar

When generates help messages, it needs some way to refer to each expected argument. By default,

objects use the dest value as the “name” of each object. By default, for positional argument actions,

the dest value is used directly, and for optional argument actions, the dest value is uppercased. So, a single positional argument with will be referred to as . A single optional argument that should be followed by a single command-line argument will be referred to as . An example:





An alternative name can be specified with :





Note that only changes the displayed name - the name of the attribute on the object is still

determined by the dest value.

Different values of may cause the metavar to be used multiple times. Providing a tuple to specifies a different display for each of the arguments:





The Python Library Reference, Release 3.13.2



dest

Most actions add some value as an attribute of the object returned by . The

name of this attribute is determined by the keyword argument of . For positional argument

actions, is normally supplied as the first argument to :





For optional argument actions, the value of is normally inferred from the option strings. generates the value of by taking the first long option string and stripping away the initialstring. If no long option strings were supplied, will be derived from the first short option string by stripping the initialcharacter. Any internalcharacters will be converted to characters to make sure the string is a valid attribute name. The examples below illustrate this behavior:





allows a custom attribute name to be provided:





deprecated

During a project’s lifetime, some arguments may need to be removed from the command line. Before removing them, you should inform your users that the arguments are deprecated and will be removed. The

keyword argument of , which defaults to , specifies if the argument is deprecated and will

be removed in the future. For arguments, if is , then a warning will be printed to when the argument is used:





Added in version 3.13.



Action classes

classes implement the Action API, a callable which returns a callable which processes arguments from the

command-line. Any object which follows this API may be passed as the parameter to .

option_strings, dest, nargs=None, const=None, default=None, type=None,

choices=None, required=False, help=None, metavar=None

objects are used by an to represent the information needed to parse a single argu-

ment from one or more strings from the command line. The class must accept the two positional argu-

The Python Library Reference, Release 3.13.2



ments plus any keyword arguments passed to except for the

itself.

Instances of (or return value of any callable to the parameter) should have attributes ,

, , , , , etc. defined. The easiest way to ensure these at-

tributes are defined is to call .

parser, namespace, values, option_string=None

instances should be callable, so subclasses must override the method, which should accept four parameters:

• parser- The object which contains this action.

• namespace- The object that will be returned by . Most actions add an

attribute to this object using .

• values- The associated command-line arguments, with any type conversions applied. Type conver-

sions are specified with the type keyword argument to .

• option_string- The option string that was used to invoke this action. The argument

is optional, and will be absent if the action is associated with a positional argument.

The method may perform arbitrary actions, but will typically set attributes on the based on and .



subclasses can define a method that takes no argument and return a string which will be used when printing the usage of the program. If such method is not provided, a sensible default will be used.





args=None, namespace=None

Convert argument strings to objects and assign them as attributes of the namespace. Return the populated

namespace.

Previous calls to determine exactly what objects are created and how they are assigned.

See the documentation for for details.

• args- List of strings to parse. The default is taken from .

• namespace- An object to take the attributes. The default is a new empty object.



Option value syntax

The method supports several ways of specifying the value of an option (if it takes one). In the simplest case, the option and its value are passed as two separate arguments:





For long options (options with names longer than a single character), the option and value can also be passed as a single command-line argument, using to separate them:





For short options (options only one character long), the option and its value can be concatenated:

The Python Library Reference, Release 3.13.2





Several short options can be joined together, using only a singleprefix, as long as only the last option (or none of them) requires a value:





Invalid arguments

While parsing the command line, checks for a variety of errors, including ambiguous options, invalid types, invalid options, wrong number of positional arguments, etc. When it encounters such an error, it exits and prints the error along with a usage message:





Arguments containing

The method attempts to give errors whenever the user has clearly made a mistake, but some situations are inherently ambiguous. For example, the command-line argument could either be an attempt to specify an

option or an attempt to provide a positional argument. The method is cautious here: positional arguments may only begin withif they look like negative numbers and there are no options in the parser that look like negative numbers:





The Python Library Reference, Release 3.13.2





If you have positional arguments that must begin withand don’t look like negative numbers, you can insert the

pseudo-argument which tells that everything after that is a positional argument:





See also the argparse howto on ambiguous arguments for more details.



Argument abbreviations (prefix matching)

The method by default allows long options to be abbreviated to a prefix, if the abbreviation is unambiguous (the prefix matches a unique option):





An error is produced for arguments that could produce more than one options. This feature can be disabled by setting

allow_abbrev to .



Beyond

Sometimes it may be useful to have an parse arguments other than those of . This can

be accomplished by passing a list of strings to . This is useful for testing at the interactive prompt:





The Python Library Reference, Release 3.13.2





The Namespace object



Simple class used by default by to create an object holding attributes and return it.

This class is deliberately simple, just an subclass with a readable string representation. If you prefer

to have dict-like view of the attributes, you can use the standard Python idiom, :





It may also be useful to have an assign attributes to an already existing object, rather than

a new object. This can be achieved by specifying the keyword argument:





Sub-commands

* , title , description , prog , parser_class , action , dest ,

, help , metavar

Many programs split up their functionality into a number of subcommands, for example, the program can

invoke subcommands like , , and . Splitting up functionality this

way can be a particularly good idea when a program performs several different functions which require different

kinds of command-line arguments. supports the creation of such subcommands with the

method. The method is normally called with no arguments and

returns a special action object. This object has a single method, , which takes a command

name and any constructor arguments, and returns an object that can be

modified as usual.

Description of parameters:

• title- title for the sub-parser group in help output; by default “subcommands” if description is provided,

otherwise uses title for positional arguments

• description- description for the sub-parser group in help output, by default

• prog- usage information that will be displayed with sub-command help, by default the name of the

program and any positional arguments before the subparser argument

The Python Library Reference, Release 3.13.2



• parser_class- class which will be used to create sub-parser instances, by default the class of the current

parser (e.g. )

• action- the basic type of action to be taken when this argument is encountered at the command line

• dest- name of the attribute under which sub-command name will be stored; by default and no value

is stored

• required- Whether or not a subcommand must be provided, by default (added in 3.7)

• help- help for sub-parser group in help output, by default

• metavar- string presenting available subcommands in help; by default it is and presents subcom-

mands in form {cmd1, cmd2, ..}

Some example usage:





Note that the object returned by will only contain attributes for the main parser and the

subparser that was selected by the command line (and not any other subparsers). So in the example above,

when the command is specified, only the and attributes are present, and when the command is

specified, only the and attributes are present.

Similarly, when a help message is requested from a subparser, only the help for that particular parser will be

printed. The help message will not include parent parser or sibling parser messages. (A help message for each

subparser command, however, can be given by supplying the argument to as above.)





The Python Library Reference, Release 3.13.2





The method also supports and keyword arguments. When either

is present, the subparser’s commands will appear in their own group in the help output. For example:





Furthermore, supports an additional aliases argument, which allows multiple strings to refer

to the same subparser. This example, like , aliases as a shorthand for :





supports also an additional deprecated argument, which allows to deprecate the subparser.





Added in version 3.13.

One particularly effective way of handling subcommands is to combine the use of the

method with calls to so that each subparser knows which Python function it should execute.

For example:

The Python Library Reference, Release 3.13.2





This way, you can let do the job of calling the appropriate function after argument parsing is

complete. Associating functions with actions like this is typically the easiest way to handle the different actions

for each of your subparsers. However, if it is necessary to check the name of the subparser that was invoked,

the keyword argument to the call will work:





Changed in version 3.7: New required keyword-only parameter.



FileType objects

mode=’r’, bufsize=-1, encoding=None, errors=None

The factory creates objects that can be passed to the type argument of

. Arguments that have objects as their type will open command-line arguments

as files with the requested modes, buffer sizes, encodings and error handling (see the function for

more details):



The Python Library Reference, Release 3.13.2





FileType objects understand the pseudo-argument and automatically convert this into for

readable objects and for writable objects:





Changed in version 3.4: Added the encodings and errors parameters.



Argument groups

title=None, description=None, *, argument_default ,



By default, groups command-line arguments into “positional arguments” and “options”

when displaying help messages. When there is a better conceptual grouping of arguments than this default

one, appropriate groups can be created using the method:





The method returns an argument group object which has an

method just like a regular . When an argument is added to the group, the parser treats

it just like a normal argument, but displays the argument in a separate group for help messages. The

method accepts title and description arguments which can be used to customize

this display:





The Python Library Reference, Release 3.13.2





The optional, keyword-only parameters argument_default and conflict_handler allow for finer-grained control

of the behavior of the argument group. These parameters have the same meaning as in the

constructor, but apply specifically to the argument group rather than the entire parser.

Note that any arguments not in your user-defined groups will end up back in the usual “positional arguments”

and “optional arguments” sections.

Changed in version 3.11: Calling on an argument group is deprecated. This feature

was never supported and does not always work correctly. The function exists on the API by accident through

inheritance and will be removed in the future.



Mutual exclusion

required=False

Create a mutually exclusive group. will make sure that only one of the arguments in the mutually

exclusive group was present on the command line:





The method also accepts a required argument, to indicate that at least

one of the mutually exclusive arguments is required:





Note that currently mutually exclusive argument groups do not support the title and description arguments of

. However, a mutually exclusive group can be added to an argument group that has

a title and description. For example:





The Python Library Reference, Release 3.13.2





Changed in version 3.11: Calling or on a

mutually exclusive group is deprecated. These features were never supported and do not always work correctly.

The functions exist on the API by accident through inheritance and will be removed in the future.



Parser defaults

**kwargs

Most of the time, the attributes of the object returned by will be fully determined by inspecting

the command-line arguments and the argument actions. allows some additional attributes

that are determined without any inspection of the command line to be added:





Note that parser-level defaults always override argument-level defaults:





Parser-level defaults can be particularly useful when working with multiple parsers.

method for an example of this type.

dest

Get the default value for a namespace attribute, as set by either or by :





Printing help

In most typical applications, will take care of formatting and printing any usage or error messages. However, several formatting methods are available:

file=None

Print a brief description of how the should be invoked on the command line. If file is

, is assumed.

file=None

Print a help message, including the program usage and information about the arguments registered with the

. If file is , is assumed.

There are also variants of these methods that simply return a string instead of printing it:



The Python Library Reference, Release 3.13.2





Return a string containing a brief description of how the should be invoked on the command

line.



Return a string containing a help message, including the program usage and information about the arguments

registered with the .



Partial parsing

args=None, namespace=None

Sometimes a script may only parse a few of the command-line arguments, passing the remaining arguments

on to another script or program. In these cases, the method can be useful. It works

much like except that it does not produce an error when extra arguments are present. Instead,

it returns a two item tuple containing the populated namespace and the list of remaining argument strings.





Á Warning

Prefix matching rules apply to . The parser may consume an option even if it’s just a

prefix of one of its known options, instead of leaving it in the remaining arguments list.



Customizing file parsing

arg_line

Arguments that are read from a file (see the fromfile_prefix_chars keyword argument to the

constructor) are read one argument per line. can be overridden for fancier

reading.

This method takes a single argument arg_line which is a string read from the argument file. It returns a list of

arguments parsed from this string. The method is called once per line read from the argument file, in order.

A useful override of this method is one that treats each space-separated word as an argument. The following

example demonstrates how to do this:





Exiting methods

status=0, message=None

This method terminates the program, exiting with the specified status and, if given, it prints a message to

before that. The user can override this method to handle these steps differently:





The Python Library Reference, Release 3.13.2



message

This method prints a usage message, including the message, to and terminates the program with

a status code of 2.



Intermixed parsing

args=None, namespace=None

args=None, namespace=None

A number of Unix commands allow the user to intermix optional arguments with positional arguments.

The and methods support this pars-

ing style.

These parsers do not support all the features, and will raise exceptions if unsupported features are

used. In particular, subparsers, and mutually exclusive groups that include both optionals and positionals are

not supported.

The following example shows the difference between and

: the former returns as unparsed arguments, while the

latter collects all the positionals into .





returns a two item tuple containing the populated namespace and the

list of remaining argument strings. raises an error if there are any remaining

unparsed argument strings.

Added in version 3.7.



Registering custom types or actions

registry_name, value, object

Sometimes it’s desirable to use a custom string in error messages to provide more user-friendly output. In these

cases, can be used to register custom actions or types with a parser and allow you to reference

the type by their registered name instead of their callable name.

The method accepts three arguments - a registry_name, specifying the internal registry where the

object will be stored (e.g., , ), value, which is the key under which the object will be registered,

and object, the callable to be registered.

The following example shows how to register a custom type with a parser:





The Python Library Reference, Release 3.13.2





An error from creating or using an argument (optional or positional).

The string value of this exception is the message, augmented with information about the argument that caused

it.



Raised when something goes wrong converting a command line string to a type.



Guides and Tutorials

Argparse Tutorial

author

Tshepang Mbambo

This tutorial is intended to be a gentle introduction to , the recommended command-line parsing module in the Python standard library.



® Note

The standard library includes two other libraries directly related to command-line parameter processing: the

lower level module (which may require more code to configure for a given application, but also al-

lows an application to request behaviors that doesn’t support), and the very low level (which

specifically serves as an equivalent to the family of functions available to C programmers). While

neither of those modules is covered directly in this guide, many of the core concepts in first originated

in , so some aspects of this tutorial will also be relevant to users.



Concepts

Let’s show the sort of functionality that we are going to explore in this introductory tutorial by making use of the command:





A few concepts we can learn from the four commands:

• The command is useful when run without any options at all. It defaults to displaying the contents of the

current directory.

• If we want beyond what it provides by default, we tell it a bit more. In this case, we want it to display a different

directory, . What we did is specify what is known as a positional argument. It’s named so because the

program should know what to do with the value, solely based on where it appears on the command line. This The Python Library Reference, Release 3.13.2



concept is more relevant to a command like , whose most basic usage is . The first position

is what you want copied, and the second position is where you want it copied to.

• Now, say we want to change behaviour of the program. In our example, we display more info for each file

instead of just showing the file names. The in that case is known as an optional argument.

• That’s a snippet of the help text. It’s very useful in that you can come across a program you have never used

before, and can figure out how it works simply by reading its help text.



The basics

Let us start with a very simple example which does (almost) nothing:





Following is a result of running the code:





Here is what is happening:

• Running the script without any options results in nothing displayed to stdout. Not so useful.

• The second one starts to display the usefulness of the module. We have done almost nothing, but

already we get a nice help message.

• The option, which can also be shortened to, is the only option we get for free (i.e. no need to

specify it). Specifying anything else results in an error. But even then, we do get a useful usage message, also

for free.



Introducing Positional arguments

An example:





And running the code:





The Python Library Reference, Release 3.13.2





Here is what’s happening:

• We’ve added the method, which is what we use to specify which command-line options

the program is willing to accept. In this case, I’ve named it so that it’s in line with its function.

• Calling our program now requires us to specify an option.

• The method actually returns some data from the options specified, in this case, .

• The variable is some form of ‘magic’ that performs for free (i.e. no need to specify which variable

that value is stored in). You will also notice that its name matches the string argument given to the method,

.

Note however that, although the help display looks nice and all, it currently is not as helpful as it can be. For example we see that we got as a positional argument, but we don’t know what it does, other than by guessing or by reading the source code. So, let’s make it a bit more useful:





And we get:





Now, how about doing something even more useful:





Following is a result of running the code:





That didn’t go so well. That’s because treats the options we give it as strings, unless we tell it otherwise.

So, let’s tell to treat that input as an integer:

The Python Library Reference, Release 3.13.2





Following is a result of running the code:





That went well. The program now even helpfully quits on bad illegal input before proceeding.



Introducing Optional arguments

So far we have been playing with positional arguments. Let us have a look on how to add optional ones:





And the output:





Here is what is happening:

• The program is written so as to display something when is specified and display nothing when

not.

• To show that the option is actually optional, there is no error when running the program without it. Note that

by default, if an optional argument isn’t used, the relevant variable, in this case , is given

as a value, which is the reason it fails the truth test of the statement.

• The help message is a bit different.

• When using the option, one must also specify some value, any value.

The above example accepts arbitrary integer values for, but for our simple program, only two values are actually useful, or . Let’s modify the code accordingly:

The Python Library Reference, Release 3.13.2





And the output:





Here is what is happening:

• The option is now more of a flag than something that requires a value. We even changed the name of the option

to match that idea. Note that we now specify a new keyword, , and give it the value .

This means that, if the option is specified, assign the value to . Not specifying it implies

.

• It complains when you specify a value, in true spirit of what flags actually are.

• Notice the different help text.



Short options

If you are familiar with command line usage, you will notice that I haven’t yet touched on the topic of short versions of the options. It’s quite simple:





And here goes:





Note that the new ability is also reflected in the help text.

The Python Library Reference, Release 3.13.2



Combining Positional and Optional arguments

Our program keeps growing in complexity:





And now the output:





• We’ve brought back a positional argument, hence the complaint.

• Note that the order does not matter.

How about we give this program of ours back the ability to have multiple verbosity values, and actually get to use them:





And the output:





The Python Library Reference, Release 3.13.2





These all look good except the last one, which exposes a bug in our program. Let’s fix it by restricting the values the option can accept:





And the output:





Note that the change also reflects both in the error message as well as the help string.

Now, let’s use a different approach of playing with verbosity, which is pretty common. It also matches the way the CPython executable handles its own verbosity argument (check the output of ):





The Python Library Reference, Release 3.13.2





We have introduced another action, “count”, to count the number of occurrences of specific options.





• Yes, it’s now more of a flag (similar to ) in the previous version of our script. That

should explain the complaint.

• It also behaves similar to “store_true” action.

• Now here’s a demonstration of what the “count” action gives. You’ve probably seen this sort of usage before.

• And if you don’t specify the flag, that flag is considered to have value.

• As should be expected, specifying the long form of the flag, we should get the same output.

• Sadly, our help output isn’t very informative on the new ability our script has acquired, but that can always be

fixed by improving the documentation for our script (e.g. via the keyword argument).

• That last output exposes a bug in our program.

Let’s fix:





The Python Library Reference, Release 3.13.2





And this is what it gives:





• First output went well, and fixes the bug we had before. That is, we want any value >= 2 to be as verbose as

possible.

• Third output not so good.

Let’s fix that bug:





We’ve just introduced yet another keyword, . We’ve set it to in order to make it comparable to the other int values. Remember that by default, if an optional argument isn’t specified, it gets the value, and that cannot

be compared to an int value (hence the exception).

And:





You can go quite far just with what we’ve learned so far, and we have only scratched the surface. The module is very powerful, and we’ll explore a bit more of it before we end this tutorial.



Getting a little more advanced

What if we wanted to expand our tiny program to perform other powers, not just squares:





The Python Library Reference, Release 3.13.2





Output:





Notice that so far we’ve been using verbosity level to change the text that gets displayed. The following example instead uses verbosity level to display more text instead:





Output:





The Python Library Reference, Release 3.13.2



Specifying ambiguous arguments

When there is ambiguity in deciding whether an argument is positional or for an argument,can be used to tell

that everything after that is a positional argument:





Conflicting options

So far, we have been working with two methods of an instance. Let’s introduce a

third one, . It allows for us to specify options that conflict with each other. Let’s also change the rest of the program so that the new functionality makes more sense: we’ll introduce the option, which will be the opposite of the one:





Our program is now simpler, and we’ve lost some functionality for the sake of demonstration. Anyways, here’s the output:





The Python Library Reference, Release 3.13.2





That should be easy to follow. I’ve added that last output so you can see the sort of flexibility you get, i.e. mixing long form options with short form ones.

Before we conclude, you probably want to tell your users the main purpose of your program, just in case they don’t know:





Note that slight difference in the usage text. Note the , which tells us that we can either use or, but not both at the same time:





How to translate the argparse output

The output of the module such as its help text and error messages are all made translatable using the

module. This allows applications to easily localize messages produced by . See also Interna-

tionalizing your programs and modules.

For instance, in this output:



The Python Library Reference, Release 3.13.2





The strings , , and are all translatable.

In order to translate these strings, they must first be extracted into a file. For example, using Babel, run this command:





This command will extract all translatable strings from the module and output them into a file named . This command assumes that your Python installation is in .

You can find out the location of the module on your system using this script:





Once the messages in the file are translated and the translations are installed using , will be able to display the translated messages.

To translate your own strings in the output, use .



Custom type converters

The module allows you to specify custom type converters for your command-line arguments. This allows

you to modify user input before it’s stored in the . This can be useful when you need to pre-process the input before it is used in your program.

When using a custom type converter, you can use any callable that takes a single string argument (the argument value) and returns the converted value. However, if you need to handle more complex scenarios, you can use a custom action class with the action parameter instead.

For example, let’s say you want to handle arguments with different prefixes and process them accordingly:





Output:

The Python Library Reference, Release 3.13.2





In this example, we:

• Created a parser with custom prefix characters using the parameter.

• Defined two arguments, and , which used the parameter to create custom type converters to store

the value in a tuple with the prefix.

Without the custom type converters, the arguments would have treated the and as the same argument, which would have been undesirable. By using custom type converters, we were able to differentiate between the two argu-ments.



Conclusion

The module offers a lot more than shown here. Its docs are quite detailed and thorough, and full of examples. Having gone through this tutorial, you should easily digest them without feeling overwhelmed.



Migrating code to

The module offers several higher level features not natively provided by the module, including:

• Handling positional arguments.

• Supporting subcommands.

• Allowing alternative option prefixes like and .

• Handling zero-or-more and one-or-more style arguments.

• Producing more informative usage messages.

• Providing a much simpler interface for custom and .

Originally, the module attempted to maintain compatibility with . However, the fundamental design differences between supporting declarative command line option processing (while leaving positional argument processing to application code), and supporting both named options and positional arguments in the declarative interface mean that the API has diverged from that of over time.

As described in Choosing an argument parsing library, applications that are currently using and are happy with the way it works can just continue to use .

Application developers that are considering migrating should also review the list of intrinsic behavioural differences described in that section before deciding whether or not migration is desirable.

For applications that do choose to migrate from to , the following suggestions should be helpful:

• Replace all calls with

calls.

• Replace with and add

additional calls for the positional arguments. Keep in mind that what

was previously called , now in the context is called .

• Replace by using

instead of .

• Replace callback actions and the keyword arguments with or arguments.

• Replace string names for keyword arguments with the corresponding type objects (e.g. int, float, complex,

etc).

• Replace with and and

with .

• Replace strings with implicit arguments such as or with the standard Python syntax to use

dictionaries to format strings, that is, and .

The Python Library Reference, Release 3.13.2



• Replace the OptionParser constructor argument with a call to

.





Source code: Lib/optparse.py





The standard library includes three argument parsing libraries:

• : a module that closely mirrors the procedural C API. Included in the standard library since

before the initial Python 1.0 release.

• : a declarative replacement for that provides equivalent functionality without requiring

each application to implement its own procedural option parsing logic. Included in the standard library since

the Python 2.3 release.

• : a more opinionated alternative to that provides more functionality by default, at the

expense of reduced application flexibility in controlling exactly how arguments are processed. Included in the

standard library since the Python 2.7 and Python 3.2 releases.

In the absence of more specific argument parsing design constraints, is the recommended choice for im-plementing command line applications, as it offers the highest level of baseline functionality with the least application level code.

is retained almost entirely for backwards compatibility reasons. However, it also serves a niche use case as a tool for prototyping and testing command line argument handling in -based C applications.

should be considered as an alternative to in the following cases:

• an application is already using and doesn’t want to risk the subtle behavioural changes that may

arise when migrating to

• the application requires additional control over the way options and positional parameters are interleaved on

the command line (including the ability to disable the interleaving feature completely)

• the application requires additional control over the incremental parsing of command line elements (while

does support this, the exact way it works in practice is undesirable for some use cases)

• the application requires additional control over the handling of options which accept parameter values that may

start with(such as delegated options to be passed to invoked subprocesses)

• the application requires some other command line parameter processing behavior which does not

support, but which can be implemented in terms of the lower level interface offered by

These considerations also mean that is likely to provide a better foundation for library authors writing third party command line argument processing libraries.

As a concrete example, consider the following two command line argument parsing configurations, the first using , and the second using :





The Python Library Reference, Release 3.13.2





The most obvious difference is that in the version, the non-option arguments are processed separately by the application after the option processing is complete. In the version, positional arguments are declared and processed in the same way as the named options.

However, the version will also handle some parameter combination differently from the way the version would handle them. For example (amongst other differences):

• supplying gives and when using , but a usage error with

(complaining that no value has been supplied for, since is interpreted as meaning

the verbosity flag)

• similarly, supplyinggives and when using , but a usage error with

(also complaining that no value has been supplied for, sinceis interpreted as

terminating the option processing and treating all remaining values as positional arguments)

• supplying gives when using , but gives with

(since is special cased as an alternative separator for option parameter values)

Whether these differing behaviors in the version are considered desirable or a problem will depend on the specific command line application use case.



µ See also

click is a third party argument processing library (originally based on ), which allows command line

applications to be developed as a set of decorated command implementation functions.

Other third party libraries, such as typer or msgspec-click, allow command line interfaces to be specified in ways

that more effectively integrate with static checking of Python type annotations.





is a more convenient, flexible, and powerful library for parsing command-line options than the minimalist

module. uses a more declarative style of command-line parsing: you create an instance of

, populate it with options, and parse the command line. allows users to specify options in the conventional GNU/POSIX syntax, and additionally generates usage and help messages for you.

Here’s an example of using in a simple script:





With these few lines of code, users of your script can now do the “usual thing” on the command-line, for example:

The Python Library Reference, Release 3.13.2





As it parses the command line, sets attributes of the object returned by based

on user-supplied command-line values. When returns from parsing this command line,

will be and will be . supports both long and short options, allows short options to be merged together, and allows options to be associated with their arguments in a variety of ways. Thus, the following command lines are all equivalent to the above example:





Additionally, users can run one of the following





and will print out a brief summary of your script’s options:





where the value of yourscript is determined at runtime (normally from ).





was explicitly designed to encourage the creation of programs with straightforward command-line inter-faces that follow the conventions established by the family of functions available to C developers. To that end, it supports only the most common command-line syntax and semantics conventionally used under Unix. If you are unfamiliar with these conventions, reading this section will allow you to acquaint yourself with them.



Terminology

argument

a string entered on the command-line, and passed by the shell to or . In Python, arguments

are elements of ( is the name of the program being executed). Unix shells also

use the term “word”.

It is occasionally desirable to substitute an argument list other than , so you should read “argu-

ment” as “an element of , or of some other list provided as a substitute for ”.

option

an argument used to supply extra information to guide or customize the execution of a program. There are

many different syntaxes for options; the traditional Unix syntax is a hyphen (“-”) followed by a single letter,

e.g. or. Also, traditional Unix syntax allows multiple options to be merged into a single argument, e.g.

is equivalent to. The GNU project introducedfollowed by a series of hyphen-separated words,

e.g. or. These are the only two option syntaxes provided by .

Some other option syntaxes that the world has seen include:

• a hyphen followed by a few letters, e.g. (this is not the same as multiple options merged into a single

argument)

• a hyphen followed by a whole word, e.g. (this is technically equivalent to the previous syntax, but

they aren’t usually seen in the same program)

The Python Library Reference, Release 3.13.2



• a plus sign followed by a single letter, or a few letters, or a word, e.g. ,

• a slash followed by a letter, or a few letters, or a word, e.g. ,

These option syntaxes are not supported by , and they never will be. This is deliberate: the first three

are non-standard on any environment, and the last only makes sense if you’re exclusively targeting Windows

or certain legacy platforms (e.g. VMS, MS-DOS).

option argument

an argument that follows an option, is closely associated with that option, and is consumed from the argument

list when that option is. With , option arguments may either be in a separate argument from their

option:





or included in the same argument:





Typically, a given option either takes an argument or it doesn’t. Lots of people want an “optional option

arguments” feature, meaning that some options will take an argument if they see it, and won’t if they don’t.

This is somewhat controversial, because it makes parsing ambiguous: if takes an optional argument and

is another option entirely, how do we interpret? Because of this ambiguity, does not support

this feature.

positional argument

something leftover in the argument list after options have been parsed, i.e. after options and their arguments

have been parsed and removed from the argument list.

required option

an option that must be supplied on the command-line; note that the phrase “required option” is self-

contradictory in English. doesn’t prevent you from implementing required options, but doesn’t

give you much help at it either.

For example, consider this hypothetical command-line:





and are both options. Assuming that takes one argument, is an option argument. and are positional arguments.



What are options for?

Options are used to provide extra information to tune or customize the execution of a program. In case it wasn’t clear, options are usually optional. A program should be able to run just fine with no options whatsoever. (Pick a random program from the Unix or GNU toolsets. Can it run without any options at all and still make sense? The main exceptions are , , and —all of which are mutant oddballs that have been rightly criticized for their non-standard syntax and confusing interfaces.)

Lots of people want their programs to have “required options”. Think about it. If it’s required, then it’s not optional! If there is a piece of information that your program absolutely requires in order to run successfully, that’s what positional arguments are for.

As an example of good command-line interface design, consider the humble utility, for copying files. It doesn’t make much sense to try to copy files without supplying a destination and at least one source. Hence, fails if you run it with no arguments. However, it has a flexible, useful syntax that does not require any options at all:





The Python Library Reference, Release 3.13.2



You can get pretty far with just that. Most implementations provide a bunch of options to tweak exactly how the files are copied: you can preserve mode and modification time, avoid following symlinks, ask before clobbering existing files, etc. But none of this distracts from the core mission of , which is to copy either one file to another, or several files to another directory.



What are positional arguments for?

Positional arguments are for those pieces of information that your program absolutely, positively requires to run.

A good user interface should have as few absolute requirements as possible. If your program requires 17 distinct pieces of information in order to run successfully, it doesn’t much matter how you get that information from the user—most people will give up and walk away before they successfully run the program. This applies whether the user interface is a command-line, a configuration file, or a GUI: if you make that many demands on your users, most of them will simply give up.

In short, try to minimize the amount of information that users are absolutely required to supply—use sensible defaults whenever possible. Of course, you also want to make your programs reasonably flexible. That’s what options are for. Again, it doesn’t matter if they are entries in a config file, widgets in the “Preferences” dialog of a GUI, or command-line options—the more options you implement, the more flexible your program is, and the more complicated its implementation becomes. Too much flexibility has drawbacks as well, of course; too many options can overwhelm users and make your code much harder to maintain.





While is quite flexible and powerful, it’s also straightforward to use in most cases. This section covers the

code patterns that are common to any -based program.

First, you need to import the OptionParser class; then, early in the main program, create an OptionParser instance:





Then you can start defining options. The basic syntax is:





Each option has one or more option strings, such as or, and several option attributes that tell what to expect and what to do when it encounters that option on the command line.

Typically, each option will have one short option string and one long option string, e.g.:





You’re free to define as many short option strings and as many long option strings as you like (including zero), as long as there is at least one option string overall.

The option strings passed to are effectively labels for the option defined by that

call. For brevity, we will frequently refer to encountering an option on the command line; in reality, encounters option strings and looks up options from them.

Once all of your options are defined, instruct to parse your program’s command line:





(If you like, you can pass a custom argument list to , but that’s rarely necessary: by default it uses .)

returns two values:

• , an object containing values for all of your options—e.g. if takes a single string argument,

then will be the filename supplied by the user, or if the user did not supply that option The Python Library Reference, Release 3.13.2



• , the list of positional arguments leftover after parsing options

This tutorial section only covers the four most important option attributes: , , (destination), and

. Of these, is the most fundamental.



Understanding option actions

Actions tell what to do when it encounters an option on the command line. There is a fixed set of actions

hard-coded into ; adding new actions is an advanced topic covered in section Extending optparse. Most

actions tell to store a value in some variable—for example, take a string from the command line and store it in an attribute of .

If you don’t specify an option action, defaults to .



The store action

The most common option action is , which tells to take the next argument (or the remainder of the current argument), ensure that it is of the correct type, and store it to your chosen destination.

For example:





Now let’s make up a fake command line and ask to parse it:





When sees the option string, it consumes the next argument, , and stores it in

. So, after this call to , is .

Some other option types supported by are and . Here’s an option that expects an integer argument:





Note that this option has no long option string, which is perfectly acceptable. Also, there’s no explicit action, since the default is .

Let’s parse another fake command-line. This time, we’ll jam the option argument right up against the option: since (one argument) is equivalent to (two arguments), the code





will print .

If you don’t specify a type, assumes . Combined with the fact that the default action is , that means our first example can be a lot shorter:





If you don’t supply a destination, figures out a sensible default from the option strings: if the first long

option string is, then the default destination is . If there are no long option strings, looks at the first short option string: the default destination for is .

also includes the built-in type. Adding types is covered in section Extending optparse.



The Python Library Reference, Release 3.13.2



Handling boolean (flag) options

Flag options—set a variable to true or false when a particular option is seen—are quite common. supports them with two separate actions, and . For example, you might have a flag that is turned on with and off with:





Here we have two different options with the same destination, which is perfectly OK. (It just means you have to be a bit careful when setting default values—see below.)

When encounters on the command line, it sets to ; when it encounters, is set to .



Other actions

Some other actions supported by are:



store a constant value, pre-set via



append this option’s argument to a list



increment a counter by one



call a specified function

These are covered in section Reference Guide, and section Option Callbacks.



Default values

All of the above examples involve setting some variable (the “destination”) when certain command-line options are seen. What happens if those options are never seen? Since we didn’t supply any defaults, they are all set to . This

is usually fine, but sometimes you want more control. lets you supply a default value for each destination, which is assigned before the command line is parsed.

First, consider the verbose/quiet example. If we want to set to unless is seen, then we can do this:





Since default values apply to the destination rather than to any particular option, and these two options happen to have the same destination, this is exactly equivalent:





Consider this:





Again, the default value for will be : the last default value supplied for any particular destination is the one that counts.

A clearer way to specify default values is the method of OptionParser, which you can call at any

time before calling :

The Python Library Reference, Release 3.13.2





As before, the last value specified for a given option destination is the one that counts. For clarity, try to use one method or the other of setting default values, not both.



Generating help

’s ability to generate help and usage text automatically is useful for creating user-friendly command-line

interfaces. All you have to do is supply a value for each option, and optionally a short usage message for your whole program. Here’s an OptionParser populated with user-friendly (documented) options:





If encounters either or on the command-line, or if you just call , it prints the following to standard output:





(If the help output is triggered by a help option, exits after printing the help text.)

There’s a lot going on here to help generate the best possible help message:

• the script defines its own usage message:





expands in the usage string to the name of the current program, i.e.

. The expanded string is then printed before the detailed option help.

If you don’t supply a usage string, uses a bland but sensible default:

, which is fine if your script doesn’t take any positional arguments.

• every option defines a help string, and doesn’t worry about line-wrapping— takes care of wrapping

lines and making the help output look good.

• options that take a value indicate this fact in their automatically generated help message, e.g. for the “mode”

option:

The Python Library Reference, Release 3.13.2





Here, “MODE” is called the meta-variable: it stands for the argument that the user is expected to supply to

/. By default, converts the destination variable name to uppercase and uses that for the

meta-variable. Sometimes, that’s not what you want—for example, the option explicitly sets

, resulting in this automatically generated option description:





This is important for more than just saving space, though: the manually written help text uses the meta-variable

to clue the user in that there’s a connection between the semi-formal syntax and the informal

semantic description “write output to FILE”. This is a simple but effective way to make your help text a lot

clearer and more useful for end users.

• options that have a default value can include in the help string— will replace it with

of the option’s default value. If an option has no default value (or the default value is ),

expands to .



Grouping Options

When dealing with many options, it is convenient to group these options for better help output. An can contain several option groups, each of which can contain several options.

An option group is obtained using the class :

parser, title, description=None

where

• parser is the instance the group will be inserted in to

• title is the group title

• description, optional, is a long description of the group

inherits from (like ) and so the method can be used to add an option to the group.

Once all the options are declared, using the method the group is added to the previously defined parser.

Continuing with the parser defined in the previous section, adding an to a parser is easy:





This would result in the following help output:





The Python Library Reference, Release 3.13.2





A bit more complete example might involve using more than one group: still extending the previous example:





that results in the following output:





Another interesting method, in particular when working programmatically with option groups is:

opt_str

Return the to which the short or long option string opt_str (e.g. or ) belongs.

If there’s no such , return .



Printing a version string

Similar to the brief usage string, can also print a version string for your program. You have to supply the string as the argument to OptionParser:



The Python Library Reference, Release 3.13.2



is expanded just like it is in . Apart from that, can contain anything you like. When you

supply it, automatically adds a option to your parser. If it encounters this option on the command line, it expands your string (by replacing ), prints it to stdout, and exits.

For example, if your script is called :





The following two methods can be used to print and get the string:

file=None

Print the version message for the current program () to file (default stdout). As with

, any occurrence of in is replaced with the name of the current

program. Does nothing if is empty or undefined.



Same as but returns the version string instead of printing it.



How handles errors

There are two broad classes of errors that has to worry about: programmer errors and user errors. Pro-

grammer errors are usually erroneous calls to , e.g. invalid option strings, unknown option attributes, missing option attributes, etc. These are dealt with in the usual way: raise an exception (either

or ) and let the program crash.

Handling user errors is much more important, since they are guaranteed to happen no matter how stable your code

is. can automatically detect some user errors, such as bad option arguments (passing where takes an integer argument), missing arguments ( at the end of the command line, where takes an argument of any type). Also, you can call to signal an application-defined error condition:





In either case, handles the error the same way: it prints the program’s usage message and an error message to standard error and exits with error status 2.

Consider the first example above, where the user passes to an option that takes an integer:





Or, where the user fails to pass a value at all:





-generated error messages take care always to mention the option involved in the error; be sure to do the same when calling from your application code.

If ’s default error-handling behaviour does not suit your needs, you’ll need to subclass OptionParser and override its and/or methods.



The Python Library Reference, Release 3.13.2



Putting it all together

Here’s what -based scripts usually look like:





Creating the parser

The first step in using is to create an OptionParser instance.

...

The OptionParser constructor has no required arguments, but a number of optional keyword arguments. You

should always pass them as keyword arguments, i.e. do not rely on the order in which the arguments are

declared.

(default: )

The usage summary to print when your program is run incorrectly or with a help option. When prints the usage string, it expands to (or to if you passed that keyword argument). To suppress a usage message, pass the special value .

(default: )

A list of Option objects to populate the parser with. The options in are added after any options in (a class attribute that may be set by OptionParser subclasses), but

before any version or help options. Deprecated; use after creating the parser instead.

(default: optparse.Option)

Class to use when adding options to the parser in .

(default: )

A version string to print when the user supplies a version option. If you supply a true value for ,

automatically adds a version option with the single option string. The substring is expanded the same as for .

(default: )

Specifies what to do when options with conflicting option strings are added to the parser; see section

Conflicts between options.

(default: )

A paragraph of text giving a brief overview of your program. reformats this paragraph to fit

The Python Library Reference, Release 3.13.2



the current terminal width and prints it when the user requests help (after , but before the list of options).

(default: a new )

An instance of optparse.HelpFormatter that will be used for printing help text. provides two concrete classes for this purpose: IndentedHelpFormatter and TitledHelpFormatter.

(default: )

If true, will add a help option (with option strings and) to the parser.



The string to use when expanding in and instead of .

(default: )

A paragraph of help text to print after the option help.



Populating the parser

There are several ways to populate the parser with options. The preferred way is by using

, as shown in section Tutorial. can be called in one of two ways:

• pass it an Option instance (as returned by )

• pass it any combination of positional and keyword arguments that are acceptable to (i.e., to

the Option constructor), and it will create the Option instance for you

The other alternative is to pass a list of pre-constructed Option instances to the OptionParser constructor, as in:





( is a factory function for creating Option instances; currently it is an alias for the Option constructor.

A future version of may split Option into several classes, and will pick the right class to instantiate. Do not instantiate Option directly.)



Defining options

Each Option instance represents a set of synonymous command-line option strings, e.g. and. You can specify any number of short or long option strings, but you must specify at least one overall option string.

The canonical way to create an instance is with the method of .

option

*opt_str, attr=value, ...

To define an option with only a short option string:





And to define an option with only a long option string:





The keyword arguments define attributes of the new Option object. The most important option attribute is

, and it largely determines which other attributes are relevant or required. If you pass irrelevant option

attributes, or fail to pass required ones, raises an exception explaining your mistake.

An option’s action determines what does when it encounters this option on the command-line. The

standard option actions hard-coded into are:

The Python Library Reference, Release 3.13.2





store this option’s argument (default)



store a constant value, pre-set via



store



store



append this option’s argument to a list



append a constant value to a list, pre-set via



increment a counter by one



call a specified function



print a usage message including all options and the documentation for them

(If you don’t supply an action, the default is . For this action, you may also supply and

option attributes; see Standard option actions.)

As you can see, most actions involve storing or updating a value somewhere. always creates a special

object for this, conventionally called , which is an instance of .



An object holding parsed argument names and values as attributes. Normally created by calling when calling

, and can be overridden by a custom subclass passed to the values argument

of (as described in Parsing arguments).

Option arguments (and various other values) are stored as attributes of this object, according to the (destination) option attribute.

For example, when you call





one of the first things does is create the object:





If one of the options in this parser is defined with





and the command-line being parsed includes any of the following:





then , on seeing this option, will do the equivalent of





The and option attributes are almost as important as , but is the only one that makes sense for all options.

The Python Library Reference, Release 3.13.2



Option attributes



A single command line argument, with various attributes passed by keyword to the constructor. Normally

created with rather than directly, and can be overridden by a custom class

via the option_class argument to .

The following option attributes may be passed as keyword arguments to . If you

pass an option attribute that is not relevant to a particular option, or fail to pass a required option attribute,

raises .



(default: )

Determines ’s behaviour when this option is seen on the command line; the available options are

documented here.



(default: )

The argument type expected by this option (e.g., or ); the available option types are docu-

mented here.



(default: derived from option strings)

If the option’s action implies writing or modifying a value somewhere, this tells where to write it:

names an attribute of the object that builds as it parses the command line.



The value to use for this option’s destination if the option is not seen on the command line. See also

.



(default: 1)

How many arguments of type should be consumed when this option is seen. If > 1, will store

a tuple of values to .



For actions that store a constant value, the constant value to store.



For options of type , the list of strings the user may choose from.



For options with action , the callable to call when this option is seen. See section Option Callbacks

for detail on the arguments passed to the callable.





Additional positional and keyword arguments to pass to after the four standard callback arguments.



Help text to print for this option when listing all available options after the user supplies a option (such

as). If no help text is supplied, the option will be listed without help text. To hide this option, use the

special value .



(default: derived from option strings)

Stand-in for the option argument(s) to use when printing help text. See section Tutorial for an example.

The Python Library Reference, Release 3.13.2



Standard option actions

The various option actions all have slightly different requirements and effects. Most actions have several relevant

option attributes which you may specify to guide ’s behaviour; a few have required attributes, which you must specify for any option using that action.

• [relevant: , , , ]

The option must be followed by an argument, which is converted to a value according to and stored

in . If > 1, multiple arguments will be consumed from the command line; all will be converted

according to and stored to as a tuple. See the Standard option types section.

If is supplied (a list or tuple of strings), the type defaults to .

If is not supplied, it defaults to .

If is not supplied, derives a destination from the first long option string (e.g.,

implies ). If there are no long option strings, derives a destination from the first short

option string (e.g., implies ).

Example:





As it parses the command line





will set





• [required: ; relevant: ]

The value is stored in .

Example:





If is seen, will set





• [relevant: ]

A special case of that stores to .

• [relevant: ]

Like , but stores .

Example:





The Python Library Reference, Release 3.13.2



• [relevant: , , , ]

The option must be followed by an argument, which is appended to the list in . If no default value for

is supplied, an empty list is automatically created when first encounters this option on the

command-line. If > 1, multiple arguments are consumed, and a tuple of length is appended to

.

The defaults for and are the same as for the action.

Example:





If is seen on the command-line, does the equivalent of:





If, a little later on, is seen, it does:





The action calls the method on the current value of the option. This means that any default

value specified must have an method. It also means that if the default value is non-empty, the default

elements will be present in the parsed value for the option, with any values from the command line appended

after those default values:





• [required: ; relevant: ]

Like , but the value is appended to ; as with , defaults to ,

and an empty list is automatically created the first time the option is encountered.

• [relevant: ]

Increment the integer stored at . If no default value is supplied, is set to zero before being incre-

mented the first time.

Example:





The first time is seen on the command line, does the equivalent of:





Every subsequent occurrence of results in





• [required: ; relevant: , , , ]

Call the function specified by , which is called as





See section Option Callbacks for more detail.

The Python Library Reference, Release 3.13.2



•

Prints a complete help message for all the options in the current option parser. The help message is constructed

from the string passed to OptionParser’s constructor and the string passed to every option.

If no string is supplied for an option, it will still be listed in the help message. To omit an option entirely,

use the special value .

automatically adds a option to all OptionParsers, so you do not normally need to create one.

Example:





If sees either or on the command line, it will print something like the following help

message to stdout (assuming is ):





After printing the help message, terminates your process with .

•

Prints the version number supplied to the OptionParser to stdout and exits. The version number is actually

formatted and printed by the method of OptionParser. Generally only relevant if the

argument is supplied to the OptionParser constructor. As with options, you will rarely create

options, since automatically adds them when needed.



Standard option types

has five built-in option types: , , , and . If you need

to add new option types, see section Extending optparse.

Arguments to string options are not checked or converted in any way: the text on the command line is stored in the destination (or passed to the callback) as-is.

Integer arguments (type ) are parsed as follows:

• if the number starts with , it is parsed as a hexadecimal number

• if the number starts with , it is parsed as an octal number

• if the number starts with , it is parsed as a binary number

• otherwise, the number is parsed as a decimal number

The conversion is done by calling with the appropriate base (2, 8, 10, or 16). If this fails, so will , although with a more useful error message.

The Python Library Reference, Release 3.13.2



and option arguments are converted directly with and , with similar error-handling.

options are a subtype of options. The option attribute (a sequence of strings) de-fines the set of allowed option arguments. compares user-supplied option arguments

against this master list and raises if an invalid string is given.



Parsing arguments

The whole point of creating and populating an OptionParser is to call its method.

args=None, values=None

Parse the command-line options found in args.

The input parameters are



the list of arguments to process (default: )



a object to store option arguments in (default: a new instance of ) – if you give an existing object, the option defaults will not be initialized on it

and the return value is a pair where



the same object that was passed in as values, or the instance created by



the leftover positional arguments after all options have been processed

The most common usage is to supply neither keyword argument. If you supply , it will be modified with

repeated calls (roughly one for every option argument stored to an option destination) and returned by

.

If encounters any errors in the argument list, it calls the OptionParser’s method with an appropriate end-user error message. This ultimately terminates your process with an exit status of 2 (the traditional Unix exit status for command-line errors).



Querying and manipulating your option parser

The default behavior of the option parser can be customized slightly, and you can also poke around your option parser and see what’s there. OptionParser provides several methods to help you out:



Set parsing to stop on the first non-option. For example, if and are both simple options that take no

arguments, normally accepts this syntax:





and treats it as equivalent to





To disable this feature, call . This restores traditional Unix syntax, where

option parsing stops with the first non-option argument.

Use this if you have a command processor which runs another command which has options of its own and you

want to make sure these options don’t get confused. For example, each command might have a different set of

options.



Set parsing to not stop on the first non-option, allowing interspersing switches with command arguments. This

is the default behavior.

The Python Library Reference, Release 3.13.2



opt_str

Returns the Option instance with the option string opt_str, or if no options have that option string.

opt_str

Return if the OptionParser has an option with option string opt_str (e.g., or).

opt_str

If the has an option corresponding to opt_str, that option is removed. If that option provided

any other option strings, all of those option strings become invalid. If opt_str does not occur in any option

belonging to this , raises .



Conflicts between options

If you’re not careful, it’s easy to define options with conflicting option strings:





(This is particularly true if you’ve defined your own OptionParser subclass with some standard options.)

Every time you add an option, checks for conflicts with existing options. If it finds any, it invokes the current conflict-handling mechanism. You can set the conflict-handling mechanism either in the constructor:





or with a separate call:





The available conflict handlers are:

(default)

assume option conflicts are a programming error and raise



resolve option conflicts intelligently (see below)

As an example, let’s define an that resolves conflicts intelligently and add conflicting options to it:





At this point, detects that a previously added option is already using the option string. Since is , it resolves the situation by removing from the earlier option’s list of option strings. Now is the only way for the user to activate that option. If the user asks for help, the help message will reflect that:





It’s possible to whittle away the option strings for a previously added option until there are none left, and the user has

no way of invoking that option from the command-line. In that case, removes that option completely, so it doesn’t show up in help text or anywhere else. Carrying on with our existing OptionParser:





At this point, the original/ option is no longer accessible, so removes it, leaving this help text:

The Python Library Reference, Release 3.13.2





Cleanup

OptionParser instances have several cyclic references. This should not be a problem for Python’s garbage collector, but you may wish to break the cyclic references explicitly by calling on your OptionParser once you are done with it. This is particularly useful in long-running applications where large object graphs are reachable from your OptionParser.



Other methods

OptionParser supports several other public methods:

usage

Set the usage string according to the rules described above for the constructor keyword argument.

Passing sets the default usage string; use to suppress a usage message.

file=None

Print the usage message for the current program () to file (default stdout). Any occurrence of the

string in is replaced with the name of the current program. Does nothing if

is empty or not defined.



Same as but returns the usage string instead of printing it.

dest=value, ...

Set default values for several option destinations at once. Using is the preferred way to

set default values for options, since multiple options can share the same destination. For example, if several

“mode” options all set the same destination, any one of them can set the default, and the last one wins:





To avoid this confusion, use :





When ’s built-in actions and types aren’t quite enough for your needs, you have two choices: extend

or define a callback option. Extending is more general, but overkill for a lot of simple cases. Quite often a simple callback is all you need.

There are two steps to defining a callback option:

• define the option itself using the action

• write the callback; this is a function (or method) that takes at least four arguments, as described below The Python Library Reference, Release 3.13.2



Defining a callback option

As always, the easiest way to define a callback option is by using the method.

Apart from , the only option attribute you must specify is , the function to call:





is a function (or other callable object), so you must have already defined when you

create this callback option. In this simple case, doesn’t even know if takes any arguments, which usually means that the option takes no arguments—the mere presence of on the command-line is all it needs to know. In some circumstances, though, you might want your callback to consume an arbitrary number of command-line arguments. This is where writing callbacks gets tricky; it’s covered later in this section.

always passes four particular arguments to your callback, and it will only pass additional arguments if you

specify them via and . Thus, the minimal callback function signature is:





The four arguments to a callback are described below.

There are several other option attributes that you can supply when you define a callback option:



has its usual meaning: as with the or actions, it instructs to consume one

argument and convert it to . Rather than storing the converted value(s) anywhere, though,

passes it to your callback function.



also has its usual meaning: if it is supplied and > 1, will consume arguments, each of which

must be convertible to . It then passes a tuple of converted values to your callback.



a tuple of extra positional arguments to pass to the callback



a dictionary of extra keyword arguments to pass to the callback



How callbacks are called

All callbacks are called as follows:





where



is the Option instance that’s calling the callback



is the option string seen on the command-line that’s triggering the callback. (If an abbreviated long option was

used, will be the full, canonical option string—e.g. if the user puts on the command-line as

an abbreviation for, then will be .)



is the argument to this option seen on the command-line. will only expect an argument if

is set; the type of will be the type implied by the option’s type. If for this option is (no

argument expected), then will be . If > 1, will be a tuple of values of the appropriate

type.



is the OptionParser instance driving the whole thing, mainly useful because you can access some other inter-

esting data through its instance attributes:



the current list of leftover arguments, ie. arguments that have been consumed but are neither options nor

The Python Library Reference, Release 3.13.2



option arguments. Feel free to modify , e.g. by adding more arguments to it. (This list

will become , the second return value of .)



the current list of remaining arguments, ie. with and (if applicable) removed, and only the arguments following them still there. Feel free to modify , e.g. by consuming more arguments.



the object where option values are by default stored (an instance of optparse.OptionValues). This lets

callbacks use the same mechanism as the rest of for storing option values; you don’t need to mess around with globals or closures. You can also access or modify the value(s) of any options already encountered on the command-line.



is a tuple of arbitrary positional arguments supplied via the option attribute.



is a dictionary of arbitrary keyword arguments supplied via .



Raising errors in a callback

The callback function should raise if there are any problems with the option or its argument(s).

catches this and terminates the program, printing the error message you supply to stderr. Your message should be clear, concise, accurate, and mention the option at fault. Otherwise, the user will have a hard time figuring out what they did wrong.



Callback example 1: trivial callback

Here’s an example of a callback option that takes no arguments, and simply records that the option was seen:





Of course, you could do that with the action.



Callback example 2: check option order

Here’s a slightly more interesting example: record the fact that is seen, but blow up if it comes after in the command-line.





Callback example 3: check option order (generalized)

If you want to reuse this callback for several similar options (set a flag, but blow up if has already been seen), it needs a bit of work: the error message and the flag that it sets must be generalized.





The Python Library Reference, Release 3.13.2





Callback example 4: check arbitrary condition

Of course, you could put any condition in there—you’re not limited to checking the values of already-defined options. For example, if you have options that should not be called when the moon is full, all you have to do is this:





(The definition of is left as an exercise for the reader.)



Callback example 5: fixed arguments

Things get slightly more interesting when you define callback options that take a fixed number of arguments. Spec-ifying that a callback option takes arguments is similar to defining a or option: if you define

, then the option takes one argument that must be convertible to that type; if you further define , then

the option takes arguments.

Here’s an example that just emulates the standard action:





Note that takes care of consuming 3 arguments and converting them to integers for you; all you have to do is store them. (Or whatever; obviously you don’t need a callback for this example.)



Callback example 6: variable arguments

Things get hairy when you want an option to take a variable number of arguments. For this case, you must write a

callback, as doesn’t provide any built-in capabilities for it. And you have to deal with certain intricacies

of conventional Unix command-line parsing that normally handles for you. In particular, callbacks should implement the conventional rules for bareandarguments:

• eitherorcan be option arguments

• bare(if not the argument to some option): halt command-line processing and discard the

• bare(if not the argument to some option): halt command-line processing but keep the(append it to

)

If you want an option that takes a variable number of arguments, there are several subtle, tricky issues to worry about. The exact implementation you choose will be based on which trade-offs you’re willing to make for your application

(which is why doesn’t support this sort of thing directly).

Nevertheless, here’s a stab at a callback for an option with variable arguments:

The Python Library Reference, Release 3.13.2





Since the two major controlling factors in how interprets command-line options are the action and type of each option, the most likely direction of extension is to add new actions and new types.



Adding new types

To add new types, you need to define your own subclass of ’s class. This class has a couple of

attributes that define ’s types: and .



A tuple of type names; in your subclass, simply define a new tuple that builds on the standard one.



A dictionary mapping type names to type-checking functions. A type-checking function has the following

signature:





where is an instance, is an option string (e.g.,), and is the string from the

command line that must be checked and converted to your desired type. should return an

object of the hypothetical type . The value returned by a type-checking function will wind up in the

OptionValues instance returned by , or be passed to a callback as the

parameter.

Your type-checking function should raise if it encounters any problems.

takes a single string argument, which is passed as-is to ’s

method, which in turn prepends the program name and the string and prints everything to stderr

before terminating the process.

Here’s a silly example that demonstrates adding a option type to parse Python-style complex numbers on

the command line. (This is even sillier than it used to be, because 1.3 added built-in support for complex The Python Library Reference, Release 3.13.2



numbers, but never mind.)

First, the necessary imports:





You need to define your type-checker first, since it’s referred to later (in the class attribute of your Option subclass):





Finally, the Option subclass:





(If we didn’t make a of , we would end up modifying the attribute

of ’s Option class. This being Python, nothing stops you from doing that except good manners and common sense.)

That’s it! Now you can write a script that uses the new option type just like any other -based script, except you have to instruct your OptionParser to use MyOption instead of Option:





Alternately, you can build your own option list and pass it to OptionParser; if you don’t use in the above way, you don’t need to tell OptionParser which option class to use:





Adding new actions

Adding new actions is a bit trickier, because you have to understand that has a couple of classifications for actions:

“store” actions

actions that result in storing a value to an attribute of the current OptionValues instance; these

options require a attribute to be supplied to the Option constructor.

“typed” actions

actions that take a value from the command line and expect it to be of a certain type; or rather, a string that

can be converted to a certain type. These options require a attribute to the Option constructor.

These are overlapping sets: some default “store” actions are , , , and , while the default “typed” actions are , , and .

When you add an action, you need to categorize it by listing it in at least one of the following class attributes of Option (all are lists of strings):



All actions must be listed in ACTIONS.

The Python Library Reference, Release 3.13.2





“store” actions are additionally listed here.



“typed” actions are additionally listed here.



Actions that always take a type (i.e. whose options always take a value) are additionally listed here. The only

effect of this is that assigns the default type, , to options with no explicit type whose

action is listed in .

In order to actually implement your new action, you must override Option’s method and add a case that recognizes your action.

For example, let’s add an action. This is similar to the standard action, but instead of taking a single value from the command-line and appending it to an existing list, will take multiple values in a single comma-delimited string, and extend an existing list with them. That is, if is an option of type , the command line





would result in a list





Again we define a subclass of Option:





Features of note:

• both expects a value on the command-line and stores that value somewhere, so it goes in both

and .

• to ensure that assigns the default type of to actions, we put the

action in as well.

• implements just this one new action, and passes control back to

for the standard actions.

• is an instance of the optparse_parser.Values class, which provides the very useful

method. is essentially with a safety valve; it is called as





If the attribute of doesn’t exist or is , then ensure_value() first sets it to , and then re-

turns . This is very handy for actions like , , and , all of which accumulate

data in a variable and expect that variable to be of a certain type (a list for the first two, an integer for the latter).

Using means that scripts using your action don’t have to worry about setting a default value The Python Library Reference, Release 3.13.2



for the option destinations in question; they can just leave the default as and will take

care of getting it right when it’s needed.





Raised if an instance is created with invalid or inconsistent arguments.



Raised if conflicting options are added to an .



Raised if an invalid option value is encountered on the command line.



Raised if an invalid option is passed on the command line.



Raised if an ambiguous option is passed on the command line.





Source code: Lib/getpass.py



Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.

The module provides two functions:

prompt=’Password: ’, stream=None

Prompt the user for a password without echoing. The user is prompted using the string prompt, which defaults

to . On Unix, the prompt is written to the file-like object stream using the replace error handler

if needed. stream defaults to the controlling terminal () or if that is unavailable to

(this argument is ignored on Windows).

If echo free input is unavailable getpass() falls back to printing a warning message to stream and reading from

and issuing a .



® Note

If you call getpass from within IDLE, the input may be done in the terminal you launched IDLE from rather than the idle window itself.





A subclass issued when password input may be echoed.



Return the “login name” of the user.

This function checks the environment variables , , and , in order, and returns

the value of the first one which is set to a non-empty string. If none are set, the login name from the password

database is returned on systems which support the module, otherwise, an is raised.

In general, this function should be preferred over .

Changed in version 3.13: Previously, various exceptions beyond just were raised.



The Python Library Reference, Release 3.13.2





Source code: Lib/fileinput.py



This module implements a helper class and functions to quickly write a loop over standard input or a list of files. If

you just want to read or write one file see .

The typical use is:





This iterates over the lines of all files listed in , defaulting to if the list is empty. If a filename is , it is also replaced by and the optional arguments mode and openhook are ignored. To

specify an alternative list of filenames, pass it as the first argument to . A single file name is also allowed.

All files are opened in text mode by default, but you can override this by specifying the mode parameter in the call

to or . If an I/O error occurs during opening or reading a file, is raised.

Changed in version 3.3: used to be raised; it is now an alias of .

If is used more than once, the second and further use will return no lines, except perhaps for interactive use, or if it has been explicitly reset (e.g. using ).

Empty files are opened and immediately closed; the only time their presence in the list of filenames is noticeable at all is when the last file opened is empty.

Lines are returned with any newlines intact, which means that the last line in a file may not have one.

You can control how files are opened by providing an opening hook via the openhook parameter to

or . The hook must be a function that takes two arguments, filename and mode, and returns an accordingly opened file-like object. If encoding and/or errors are specified, they will be passed to the hook as

additional keyword arguments. This module provides a to support compressed files.

The following function is the primary interface of this module:

files=None, inplace=False, backup=”, *, mode=’r’, openhook=None, encoding=None,

errors=None

Create an instance of the class. The instance will be used as global state for the functions of this

module, and is also returned to use during iteration. The parameters to this function will be passed along to

the constructor of the class.

The instance can be used as a context manager in the statement. In this example, input is

closed after the statement is exited, even if an exception occurs:





Changed in version 3.2: Can be used as a context manager.

Changed in version 3.8: The keyword parameters mode and openhook are now keyword-only.

Changed in version 3.10: The keyword-only parameter encoding and errors are added.

The following functions use the global state created by ; if there is no active state,

is raised.



Return the name of the file currently being read. Before the first line has been read, returns .



The Python Library Reference, Release 3.13.2





Return the integer “file descriptor” for the current file. When no file is opened (before the first line and between

files), returns.



Return the cumulative line number of the line that has just been read. Before the first line has been read,

returns . After the last line of the last file has been read, returns the line number of that line.



Return the line number in the current file. Before the first line has been read, returns . After the last line of

the last file has been read, returns the line number of that line within the file.



Return if the line just read is the first line of its file, otherwise return .



Return if the last line was read from , otherwise return .



Close the current file so that the next iteration will read the first line from the next file (if any); lines not read

from the file will not count towards the cumulative line count. The filename is not changed until after the first

line of the next file has been read. Before the first line has been read, this function has no effect; it cannot be

used to skip the first file. After the last line of the last file has been read, this function has no effect.



Close the sequence.

The class which implements the sequence behavior provided by the module is available for subclassing as well:

files=None, inplace=False, backup=”, *, mode=’r’ , openhook=None,

encoding=None, errors=None

Class is the implementation; its methods , , , ,

, , and correspond to the functions of the same name

in the module. In addition it is iterable and has a method which returns the next input line. The

sequence must be accessed in strictly sequential order; random access and cannot be mixed.

With mode you can specify which file mode will be passed to . It must be one of and .

The openhook, when given, must be a function that takes two arguments, filename and mode, and returns an

accordingly opened file-like object. You cannot use inplace and openhook together.

You can specify encoding and errors that is passed to or openhook.

A instance can be used as a context manager in the statement. In this example, input is

closed after the statement is exited, even if an exception occurs:





Changed in version 3.2: Can be used as a context manager.

Changed in version 3.8: The keyword parameter mode and openhook are now keyword-only.

Changed in version 3.10: The keyword-only parameter encoding and errors are added.

Changed in version 3.11: The and modes and the method have been removed.

Optional in-place filtering: if the keyword argument is passed to or to the

constructor, the file is moved to a backup file and standard output is directed to the input file (if a file of the same name as the backup file already exists, it will be replaced silently). This makes it possible to write a filter that rewrites its input file in place. If the backup parameter is given (typically as ), it specifies the extension for the backup file, and the backup file remains around; by default, the extension is and it is deleted when the output file is closed. In-place filtering is disabled when standard input is read.

The two following opening hooks are provided by this module:

The Python Library Reference, Release 3.13.2



filename, mode, *, encoding=None, errors=None

Transparently opens files compressed with gzip and bzip2 (recognized by the extensions and )

using the and modules. If the filename extension is not or , the file is opened normally

(ie, using without any decompression).

The encoding and errors values are passed to for compressed files and open for normal

files.

Usage example:



Changed in version 3.10: The keyword-only parameter encoding and errors are added.

encoding, errors=None

Returns a hook which opens each file with , using the given encoding and errors to read the file.

Usage example:



Changed in version 3.6: Added the optional errors parameter.

Deprecated since version 3.10: This function is deprecated since and now

have encoding and errors parameters.





Source code: Lib/curses



The module provides an interface to the curses library, the de-facto standard for portable advanced terminal handling.

While curses is most widely used in the Unix environment, versions are available for Windows, DOS, and possibly other systems as well. This extension module is designed to match the API of ncurses, an open-source curses library hosted on Linux and the BSD variants of Unix.

Availability: not Android, not iOS, not WASI.

This module is not supported on mobile platforms or WebAssembly platforms.



® Note

Whenever the documentation mentions a character it can be specified as an integer, a one-character Unicode

string or a one-byte byte string.

Whenever the documentation mentions a character string it can be specified as a Unicode string or a byte string.



µ See also

Module

Utilities for working with ASCII characters, regardless of your locale settings.

Module

A panel stack extension that adds depth to curses windows.

Module

Editable text widget for curses supporting -like bindings.

curses-howto

Tutorial material on using curses with Python, by Andrew Kuchling and Eric Raymond.

The Python Library Reference, Release 3.13.2





The module defines the following exception:



Exception raised when a curses library function returns an error.



® Note

Whenever x or y arguments to a function or a method are optional, they default to the current cursor location.

Whenever attr is optional, it defaults to .



The module defines the following functions:



Return the output speed of the terminal in bits per second. On software terminal emulators it will have a fixed

high value. Included for historical reasons; in former times, it was used to write output loops for time delays

and occasionally to change interfaces depending on the line speed.



Emit a short attention sound.



Return or , depending on whether the programmer can change the colors displayed by the terminal.



Enter cbreak mode. In cbreak mode (sometimes called “rare” mode) normal tty line buffering is turned off and

characters are available to be read one by one. However, unlike raw mode, special characters (interrupt, quit,

suspend, and flow control) retain their effects on the tty driver and calling program. Calling first then

leaves the terminal in cbreak mode.

color_number

Return the intensity of the red, green, and blue (RGB) components in the color color_number, which must be

between and . Return a 3-tuple, containing the R,G,B values for the given color, which will be

between (no component) and (maximum amount of component).

pair_number

Return the attribute value for displaying text in the specified color pair. Only the first 256 color pairs are

supported. This attribute value can be combined with , , and the other attributes.

is the counterpart to this function.

visibility

Set the cursor state. visibility can be set to , , or , for invisible, normal, or very visible. If the terminal

supports the visibility requested, return the previous cursor state; otherwise raise an exception. On many

terminals, the “visible” mode is an underline cursor and the “very visible” mode is a block cursor.



Save the current terminal mode as the “program” mode, the mode when the running program is using

curses. (Its counterpart is the “shell” mode, for when the program is not in curses.) Subsequent calls to

will restore this mode.



Save the current terminal mode as the “shell” mode, the mode when the running program is not using curses.

(Its counterpart is the “program” mode, when the program is using curses capabilities.) Subsequent calls to

will restore this mode.

ms

Insert an ms millisecond pause in output.



The Python Library Reference, Release 3.13.2





Update the physical screen. The curses library keeps two data structures, one representing the current physical

screen contents and a virtual screen representing the desired next state. The ground updates the

physical screen to match the virtual screen.

The virtual screen may be updated by a call after write operations such as

have been performed on a window. The normal call is simply followed by

; if you have to update multiple windows, you can speed performance and perhaps reduce screen

flicker by issuing calls on all windows, followed by a single .



Enter echo mode. In echo mode, each character input is echoed to the screen as it is entered.



De-initialize the library, and return terminal to normal status.



Return the user’s current erase character as a one-byte bytes object. Under Unix operating systems this is a

property of the controlling tty of the curses program, and is not set by the curses library itself.



The routine, if used, must be called before is called. The effect is that, during those

calls, is set to ; the capabilities , , , , , , are disabled; and the

string is set to the value of . The effect is that the cursor is confined to the current line, and so are screen

updates. This may be used for enabling character-at-a-time line editing without touching the rest of the screen.



Flash the screen. That is, change it to reverse-video and then change it back in a short interval. Some people

prefer such as ‘visible bell’ to the audible attention signal produced by .



Flush all input buffers. This throws away any typeahead that has been typed by the user and has not yet been

processed by the program.



After returns to signal a mouse event, this method should be called to retrieve

the queued mouse event, represented as a 5-tuple . id is an ID value used

to distinguish multiple devices, and x, y, z are the event’s coordinates. (z is currently unused.)

is an integer value whose bits will be set to indicate the type of event, and will be the bitwise OR of

one or more of the following constants, where n is the button number from 1 to 5: ,

, , , ,

, , .

Changed in version 3.10: The constants are now exposed if they are provided by the underlying

curses library.



Return the current coordinates of the virtual screen cursor as a tuple . If is currently ,

then return .

file

Read window related data stored in the file by an earlier call. The routine then creates

and initializes a new window using that data, returning the new window object.



Return if the terminal can display colors; otherwise, return .



Return if the module supports extended colors; otherwise, return . Extended color support allows

more than 256 color pairs for terminals that support more than 16 colors (e.g. xterm-256color).

Extended color support requires ncurses version 6.1 or later.

The Python Library Reference, Release 3.13.2



Added in version 3.10.



Return if the terminal has insert- and delete-character capabilities. This function is included for historical

reasons only, as all modern software terminal emulators have such capabilities.



Return if the terminal has insert- and delete-line capabilities, or can simulate them using scrolling regions.

This function is included for historical reasons only, as all modern software terminal emulators have such

capabilities.

ch

Take a key value ch, and return if the current terminal type recognizes a key with that value.

tenths

Used for half-delay mode, which is similar to cbreak mode in that characters typed by the user are immediately

available to the program. However, after blocking for tenths tenths of seconds, raise an exception if nothing has

been typed. The value of tenths must be a number between and . Use to leave half-delay

mode.

color_number, r, g, b

Change the definition of a color, taking the number of the color to be changed followed by three RGB values

(for the amounts of red, green, and blue components). The value of color_number must be between and

. Each of r, g, b, must be a value between and . When is used, all

occurrences of that color on the screen immediately change to the new definition. This function is a no-op on

most terminals; it is active only if returns .

pair_number, fg, bg

Change the definition of a color-pair. It takes three arguments: the number of the color-pair to be changed,

the foreground color number, and the background color number. The value of pair_number must be between

and (the color pair is wired to white on black and cannot be changed). The value of

fg and bg arguments must be between and , or, after calling ,.

If the color-pair was previously initialized, the screen is refreshed and all occurrences of that color-pair are

changed to the new definition.



Initialize the library. Return a window object which represents the whole screen.



® Note

If there is an error opening the terminal, the underlying curses library may cause the interpreter to exit.



nlines, ncols

Return if would modify the window structure, otherwise.



Return if has been called (that is, the curses library has been deinitialized).

k

Return the name of the key numbered k as a bytes object. The name of a key generating printable ASCII

character is the key’s character. The name of a control-key combination is a two-byte bytes object consisting of

a caret () followed by the corresponding printable ASCII character. The name of an alt-key combination

(128–255) is a bytes object consisting of the prefix followed by the name of the corresponding ASCII

character.



Return the user’s current line kill character as a one-byte bytes object. Under Unix operating systems this is a

property of the controlling tty of the curses program, and is not set by the curses library itself.

The Python Library Reference, Release 3.13.2





Return a bytes object containing the terminfo long name field describing the current terminal. The maximum

length of a verbose description is 128 characters. It is defined only after the call to .

flag

If flag is , allow 8-bit characters to be input. If flag is , allow only 7-bit chars.

interval

Set the maximum time in milliseconds that can elapse between press and release events in order for them to

be recognized as a click, and return the previous interval value. The default value is 200 milliseconds, or one

fifth of a second.

mousemask

Set the mouse events to be reported, and return a tuple . availmask indicates which

of the specified mouse events can be reported; on complete failure it returns . oldmask is the previous value

of the given window’s mouse event mask. If this function is never called, no mouse events are ever reported.

ms

Sleep for ms milliseconds.

nlines, ncols

Create and return a pointer to a new pad data structure with the given number of lines and columns. Return a

pad as a window object.

A pad is like a window, except that it is not restricted by the screen size, and is not necessarily associated with

a particular part of the screen. Pads can be used when a large window is needed, and only a part of the window

will be on the screen at one time. Automatic refreshes of pads (such as from scrolling or echoing of input) do

not occur. The and methods of a pad require 6 arguments to specify the part of

the pad to be displayed and the location on the screen to be used for the display. The arguments are pminrow,

pmincol, sminrow, smincol, smaxrow, smaxcol; the p arguments refer to the upper left corner of the pad region

to be displayed and the s arguments define a clipping box on the screen within which the pad region is to be

displayed.

nlines, ncols

nlines, ncols, begin_y, begin_x

Return a new window, whose left-upper corner is at , and whose height/width is

nlines/ncols.

By default, the window will extend from the specified position to the lower right corner of the screen.



Enter newline mode. This mode translates the return key into newline on input, and translates newline into

return and line-feed on output. Newline mode is initially on.



Leave cbreak mode. Return to normal “cooked” mode with line buffering.



Leave echo mode. Echoing of input characters is turned off.



Leave newline mode. Disable translation of return into newline on input, and disable low-level translation of

newline into newline/return on output (but this does not change the behavior of , which always

does the equivalent of return and line feed on the virtual screen). With translation off, curses can sometimes

speed up vertical motion a little; also, it will be able to detect the return key on input.



When the routine is used, normal flush of input and output queues associated with the ,

and characters will not be done. You may want to call in a signal handler if you

want output to continue as though the interrupt had not occurred, after the handler exits.

The Python Library Reference, Release 3.13.2





Leave raw mode. Return to normal “cooked” mode with line buffering.

pair_number

Return a tuple containing the colors for the requested color pair. The value of pair_number must

be between and .

attr

Return the number of the color-pair set by the attribute value attr. is the counterpart to this

function.

str

Equivalent to ; emit the value of a specified terminfo capability for the current

terminal. Note that the output of always goes to standard output.

flag

If flag is , the effect is the same as calling . If flag is , or no argument is provided,

the queues will be flushed when these control characters are read.



Enter raw mode. In raw mode, normal line buffering and processing of interrupt, quit, suspend, and flow

control keys are turned off; characters are presented to curses input functions one by one.



Restore the terminal to “program” mode, as previously saved by .



Restore the terminal to “shell” mode, as previously saved by .



Restore the state of the terminal modes to what it was at the last call to .

nlines, ncols

Backend function used by , performing most of the work; when resizing the windows,

blank-fills the areas that are extended. The calling application should fill in these areas

with appropriate data. The function attempts to resize all windows. However, due to the

calling convention of pads, it is not possible to resize these without additional interaction with the application.

nlines, ncols

Resize the standard and current windows to the specified dimensions, and adjusts other bookkeeping data used

by the curses library that record the window dimensions (in particular the SIGWINCH handler).



Save the current state of the terminal modes in a buffer, usable by .



Retrieves the value set by .

Added in version 3.9.

ms

Sets the number of milliseconds to wait after reading an escape character, to distinguish between an individual

escape character entered on the keyboard from escape sequences sent by cursor and function keys.

Added in version 3.9.



Retrieves the value set by .

Added in version 3.9.



The Python Library Reference, Release 3.13.2



size

Sets the number of columns used by the curses library when converting a tab character to spaces as it adds the

tab to a window.

Added in version 3.9.

y, x

Set the virtual screen cursor to y, x. If y and x are both, then is set .

term=None, fd=-1

Initialize the terminal. term is a string giving the terminal name, or ; if omitted or , the value of the

environment variable will be used. fd is the file descriptor to which any initialization sequences will be

sent; if not supplied or, the file descriptor for will be used.



Must be called if the programmer wants to use colors, and before any other color manipulation routine is called.

It is good practice to call this routine right after .

initializes eight basic colors (black, red, green, yellow, blue, magenta, cyan, and white), and

two global variables in the module, and , containing the maximum number of

colors and color-pairs the terminal can support. It also restores the colors on the terminal to the values they

had when the terminal was just turned on.



Return a logical OR of all video attributes supported by the terminal. This information is useful when a curses

program needs complete control over the appearance of the screen.



Return the value of the environment variable , as a bytes object, truncated to 14 characters.

capname

Return the value of the Boolean capability corresponding to the terminfo capability name capname as an

integer. Return the value if capname is not a Boolean capability, or if it is canceled or absent from the

terminal description.

capname

Return the value of the numeric capability corresponding to the terminfo capability name capname as an

integer. Return the value if capname is not a numeric capability, or if it is canceled or absent from the

terminal description.

capname

Return the value of the string capability corresponding to the terminfo capability name capname as a bytes

object. Return if capname is not a terminfo “string capability”, or is canceled or absent from the terminal

description.

str , ...

Instantiate the bytes object str with the supplied parameters, where str should be a parameterized string obtained

from the terminfo database. E.g. could result in , the

exact result depending on terminal type.

fd

Specify that the file descriptor fd be used for typeahead checking. If fd is, then no typeahead checking is

done.

The curses library does “line-breakout optimization” by looking for typeahead periodically while updating the

screen. If input is found, and it is coming from a tty, the current update is postponed until refresh or doupdate

is called again, allowing faster response to commands typed in advance. This function allows specifying a

different file descriptor for typeahead checking.

ch

Return a bytes object which is a printable representation of the character ch. Control characters are represented

as a caret followed by the character, for example as . Printing characters are left as they are.

The Python Library Reference, Release 3.13.2



ch

Push ch so the next will return it.



® Note

Only one ch can be pushed before is called.





Update the and module variables. Useful for detecting manual screen resize.

Added in version 3.5.

ch

Push ch so the next will return it.



® Note

Only one ch can be pushed before is called.



Added in version 3.3.

id, x, y, z, bstate

Push a event onto the input queue, associating the given state data with it.

flag

If used, this function should be called before or newterm are called. When flag is , the

values of lines and columns specified in the terminfo database will be used, even if environment variables

and (used by default) are set, or if curses is running in a window (in which case default

behavior would be to use the window size if and are not set).



Allow use of default values for colors on terminals supporting this feature. Use this to support transparency

in your application. The default color is assigned to the color number. After calling this function,

initializes, for instance, color pair x to a red foreground color

on the default background.

func, / , *args, **kwargs

Initialize curses and call another callable object, func, which should be the rest of your curses-using application.

If the application raises an exception, this function will restore the terminal to a sane state before re-raising

the exception and generating a traceback. The callable object func is then passed the main window ‘stdscr’ as

its first argument, followed by any other arguments passed to . Before calling func,

turns on cbreak mode, turns off echo, enables the terminal keypad, and initializes colors if the terminal has

color support. On exit (whether normally or by exception) it restores cooked mode, turns on echo, and disables

the terminal keypad.





Window objects, as returned by and above, have the following methods and attributes:

ch, attr

y, x, ch , attr

Paint character ch at with attributes attr, overwriting any character previously painted at that location.

By default, the character position and attributes are the current settings for the window object.



The Python Library Reference, Release 3.13.2



® Note

Writing outside the window, subwindow, or pad raises a . Attempting to write to the lower right corner of a window, subwindow, or pad will cause an exception to be raised after the character is printed.



str, n, attr

y, x, str, n, attr

Paint at most n characters of the character string str at with attributes attr, overwriting anything

previously on the display.

str , attr

y, x, str , attr

Paint the character string str at with attributes attr, overwriting anything previously on the display.



® Note



• Writing outside the window, subwindow, or pad raises . Attempting to write to the

lower right corner of a window, subwindow, or pad will cause an exception to be raised after the string is printed.

• A bug in ncurses, the backend for this Python module, can cause SegFaults when resizing windows.

This is fixed in ncurses-6.1-20190511. If you are stuck with an earlier ncurses, you can avoid trigger-

ing this if you do not call with a str that has embedded newlines. Instead, call separately for each line.



attr

Remove attribute attr from the “background” set applied to all writes to the current window.

attr

Add attribute attr from the “background” set applied to all writes to the current window.

attr

Set the “background” set of attributes to attr. This set is initially (no attributes).

ch, attr

Set the background property of the window to the character ch, with attributes attr. The change is then applied

to every character position in that window:

• The attribute of every character in the window is changed to the new background attribute.

• Wherever the former background character appears, it is changed to the new background character.

ch , attr

Set the window’s background. A window’s background consists of a character and any combination of at-

tributes. The attribute part of the background is combined (OR’ed) with all non-blank characters that are

written into the window. Both the character and attribute parts of the background are combined with the

blank characters. The background becomes a property of the character and moves with the character through

any scrolling and insert/delete line/character operations.

ls , rs, ts, bs, tl, tr, bl, br

Draw a border around the edges of the window. Each parameter specifies the character to use for a specific

part of the border; see the table below for more details.



The Python Library Reference, Release 3.13.2



® Note

A value for any parameter will cause the default character to be used for that parameter. Keyword parameters can not be used. The defaults are listed in this table:



Parameter Description Default value

ls Left side

rs Right side

ts Top

bs Bottom

tl Upper-left corner

tr Upper-right corner

bl Bottom-left corner

br Bottom-right corner



vertch , horch

Similar to , but both ls and rs are vertch and both ts and bs are horch. The default corner characters

are always used by this function.

attr

num, attr

y, x, attr

y, x, num, attr

Set the attributes of num characters at the current cursor position, or at position if supplied. If num

is not given or is, the attribute will be set on all the characters to the end of the line. This function moves

cursor to position if supplied. The changed line will be touched using the method so

that the contents will be redisplayed by the next window refresh.



Like , but also cause the whole window to be repainted upon next call to .

flag

If flag is , the next call to will clear the window completely.



Erase from cursor to the end of the window: all lines below the cursor are deleted, and then the equivalent of

is performed.



Erase from cursor to the end of the line.



Update the current cursor position of all the ancestors of the window to reflect the current cursor position of

the window.

y , x

Delete any character at .



Delete the line under the cursor. All following lines are moved up by one line.

begin_y, begin_x

nlines, ncols, begin_y, begin_x

An abbreviation for “derive window”, is the same as calling , except that begin_y and

begin_x are relative to the origin of the window, rather than relative to the entire screen. Return a window

object for the derived window.

The Python Library Reference, Release 3.13.2



ch , attr

Add character ch with attribute attr, and immediately call on the window.

y, x

Test whether the given pair of screen-relative character-cell coordinates are enclosed by the given window,

returning or . It is useful for determining what subset of the screen windows enclose the location

of a mouse event.

Changed in version 3.10: Previously it returned or instead of or .



Encoding used to encode method arguments (Unicode strings and characters). The encoding attribute is inher-

ited from the parent window when a subwindow is created, for example with . By default,

current locale encoding is used (see ).

Added in version 3.3.



Clear the window.



Return a tuple of coordinates of upper-left corner.



Return the given window’s current background character/attribute pair.

y , x

Get a character. Note that the integer returned does not have to be in ASCII range: function keys, keypad

keys and so on are represented by numbers higher than 255. In no-delay mode, return if there is no input,

otherwise wait until a key is pressed.

y , x

Get a wide character. Return a character for most keys, or an integer for function keys, keypad keys, and other

special keys. In no-delay mode, raise an exception if there is no input.

Added in version 3.3.

y , x

Get a character, returning a string instead of an integer, as does. Function keys, keypad keys and

other special keys return a multibyte string containing the key name. In no-delay mode, raise an exception if

there is no input.



Return a tuple of the height and width of the window.



Return the beginning coordinates of this window relative to its parent window as a tuple . Return

if this window has no parent.



n

y, x

y, x, n

Read a bytes object from the user, with primitive line editing capacity.



Return a tuple of current cursor position relative to the window’s upper-left corner.

ch, n

y, x, ch, n

Display a horizontal line starting at with length n consisting of the character ch.

The Python Library Reference, Release 3.13.2



flag

If flag is , curses no longer considers using the hardware insert/delete character feature of the terminal; if

flag is , use of character insertion and deletion is enabled. When curses is first initialized, use of character

insert/delete is enabled by default.

flag

If flag is , will try and use hardware line editing facilities. Otherwise, line insertion/deletion are

disabled.

flag

If flag is , any change in the window image automatically causes the window to be refreshed; you no

longer have to call yourself. However, it may degrade performance considerably, due to repeated

calls to wrefresh. This option is disabled by default.

y , x

Return the character at the given position in the window. The bottom 8 bits are the character proper, and upper

bits are the attributes.

ch, attr

y, x, ch , attr

Paint character ch at with attributes attr, moving the line from position x right by one character.

nlines

Insert nlines lines into the specified window above the current line. The nlines bottom lines are lost. For

negative nlines, delete nlines lines starting with the one under the cursor, and move the remaining lines up. The

bottom nlines lines are cleared. The current cursor position remains the same.



Insert a blank line under the cursor. All following lines are moved down by one line.

str, n, attr

y, x, str, n, attr

Insert a character string (as many characters as will fit on the line) before the character under the cursor, up to

n characters. If n is zero or negative, the entire string is inserted. All characters to the right of the cursor are

shifted right, with the rightmost characters on the line being lost. The cursor position does not change (after

moving to y, x, if specified).

str , attr

y, x, str , attr

Insert a character string (as many characters as will fit on the line) before the character under the cursor. All

characters to the right of the cursor are shifted right, with the rightmost characters on the line being lost. The

cursor position does not change (after moving to y, x, if specified).

n

y, x, n

Return a bytes object of characters, extracted from the window starting at the current cursor position, or at y,

x if specified. Attributes are stripped from the characters. If n is specified, returns a string at most

n characters long (exclusive of the trailing NUL).

line

Return if the specified line was modified since the last call to ; otherwise return .

Raise a exception if line is not valid for the given window.



Return if the specified window was modified since the last call to ; otherwise return .

flag

If flag is , escape sequences generated by some keys (keypad, function keys) will be interpreted by

. If flag is , escape sequences will be left as is in the input stream.

The Python Library Reference, Release 3.13.2



flag

If flag is , cursor is left where it is on update, instead of being at “cursor position.” This reduces cursor

movement where possible. If possible the cursor will be made invisible.

If flag is , cursor will always be at “cursor position” after an update.

new_y, new_x

Move cursor to .

y, x

Move the window inside its parent window. The screen-relative parameters of the window are not changed.

This routine is used to display different parts of the parent window at the same physical position on the screen.

new_y, new_x

Move the window so its upper-left corner is at .

flag

If flag is , will be non-blocking.

flag

If flag is , escape sequences will not be timed out.

If flag is , after a few milliseconds, an escape sequence will not be interpreted, and will be left in the

input stream as is.



Mark for refresh but wait. This function updates the data structure representing the desired state of the window,

but does not force an update of the physical screen. To accomplish that, call .

destwin, sminrow, smincol, dminrow, dmincol, dmaxrow, dmaxcol

Overlay the window on top of destwin. The windows need not be the same size, only the overlapping region is

copied. This copy is non-destructive, which means that the current background character does not overwrite

the old contents of destwin.

To get fine-grained control over the copied region, the second form of can be used. sminrow and

smincol are the upper-left coordinates of the source window, and the other variables mark a rectangle in the

destination window.

destwin, sminrow, smincol, dminrow, dmincol, dmaxrow, dmaxcol

Overwrite the window on top of destwin. The windows need not be the same size, in which case only the

overlapping region is copied. This copy is destructive, which means that the current background character

overwrites the old contents of destwin.

To get fine-grained control over the copied region, the second form of can be used. sminrow

and smincol are the upper-left coordinates of the source window, the other variables mark a rectangle in the

destination window.

file

Write all data associated with the window into the provided file object. This information can be later retrieved

using the function.

beg, num

Indicate that the num screen lines, starting at line beg, are corrupted and should be completely redrawn on the

next call.



Touch the entire window, causing it to be completely redrawn on the next call.

pminrow , pmincol, sminrow, smincol, smaxrow, smaxcol

Update the display immediately (sync actual screen with previous drawing/deleting methods).

The 6 optional arguments can only be specified when the window is a pad created with . The

additional parameters are needed to indicate what part of the pad and screen are involved. pminrow and

pmincol specify the upper left-hand corner of the rectangle to be displayed in the pad. sminrow, smincol, The Python Library Reference, Release 3.13.2



smaxrow, and smaxcol specify the edges of the rectangle to be displayed on the screen. The lower right-hand

corner of the rectangle to be displayed in the pad is calculated from the screen coordinates, since the rectangles

must be the same size. Both rectangles must be entirely contained within their respective structures. Negative

values of pminrow, pmincol, sminrow, or smincol are treated as if they were zero.

nlines, ncols

Reallocate storage for a curses window to adjust its dimensions to the specified values. If either dimension is

larger than the current values, the window’s data is filled with blanks that have the current background rendition

(as set by ) merged into them.

lines=1

Scroll the screen or scrolling region upward by lines lines.

flag

Control what happens when the cursor of a window is moved off the edge of the window or scrolling region,

either as a result of a newline action on the bottom line, or typing the last character of the last line. If flag is

, the cursor is left on the bottom line. If flag is , the window is scrolled up one line. Note that in

order to get the physical scrolling effect on the terminal, it is also necessary to call .

top, bottom

Set the scrolling region from line top to line bottom. All scrolling actions will take place in this region.



Turn off the standout attribute. On some terminals this has the side effect of turning off all attributes.



Turn on attribute A_STANDOUT.

begin_y, begin_x

nlines, ncols, begin_y, begin_x

Return a sub-window, whose upper-left corner is at , and whose width/height is

ncols/nlines.

begin_y, begin_x

nlines, ncols, begin_y, begin_x

Return a sub-window, whose upper-left corner is at , and whose width/height is

ncols/nlines.

By default, the sub-window will extend from the specified position to the lower right corner of the window.



Touch each location in the window that has been touched in any of its ancestor windows. This routine is called

by , so it should almost never be necessary to call it manually.

flag

If flag is , then is called automatically whenever there is a change in the window.



Touch all locations in ancestors of the window that have been changed in the window.

delay

Set blocking or non-blocking read behavior for the window. If delay is negative, blocking read is used (which

will wait indefinitely for input). If delay is zero, then non-blocking read is used, and will return

if no input is waiting. If delay is positive, then will block for delay milliseconds, and return if

there is still no input at the end of that time.

start, count , changed

Pretend count lines have been changed, starting with line start. If changed is supplied, it specifies whether the

affected lines are marked as having been changed (changed) or unchanged (changed).



Pretend the whole window has been changed, for purposes of drawing optimizations.

The Python Library Reference, Release 3.13.2





Mark all lines in the window as unchanged since the last call to .

ch, n, attr

y, x, ch, n , attr

Display a vertical line starting at with length n consisting of the character ch with attributes attr.





The module defines the following data members:



Some curses routines that return an integer, such as , return upon failure.



Some curses routines that return an integer, such as , return upon success.





A bytes object representing the current version of the module.



A named tuple containing the three components of the ncurses library version: major, minor, and patch. All

values are integers. The components can also be accessed by name, so is

equivalent to and so on.

Availability: if the ncurses library is used.

Added in version 3.8.



The maximum number of colors the terminal can support. It is defined only after the call to .



The maximum number of color pairs the terminal can support.

.



The width of the screen, i.e., the number of columns. It is defined only after the call to . Updated

by , and .



The height of the screen, i.e., the number of lines. It is defined only after the call to . Updated by

, and .

Some constants are available to specify character cell attributes. The exact constants available are system dependent.



The Python Library Reference, Release 3.13.2



Attribute Meaning

Alternate character set mode





Blink mode





Bold mode





Dim mode





Invisible or blank mode





Italic mode





Normal attribute





Protected mode





Reverse background and foreground colors





Standout mode





Underline mode





Horizontal highlight





Left highlight





Low highlight





Right highlight





Top highlight





Vertical highlight





Added in version 3.7: was added.

Several constants are available to extract corresponding attributes returned by some methods.

The Python Library Reference, Release 3.13.2



Bit-mask Meaning

Bit-mask to extract attributes





Bit-mask to extract a character





Bit-mask to extract color-pair field information





Keys are referred to by integer constants with names starting with . The exact keycaps available are system dependent.



Key constant Key

Minimum key value





Break key (unreliable)





Down-arrow





Up-arrow





Left-arrow





Right-arrow





Home key (upward+left arrow)





Backspace (unreliable)





Function keys. Up to 64 function keys are supported.





Value of function key n





Delete line





Insert line





Delete character





continues on next page

The Python Library Reference, Release 3.13.2



Table 1 – continued from previous page

Key constant Key

Insert char or enter insert mode





Exit insert char mode





Clear screen





Clear to end of screen





Clear to end of line





Scroll 1 line forward





Scroll 1 line backward (reverse)





Next page





Previous page





Set tab





Clear tab





Clear all tabs





Enter or send (unreliable)





Soft (partial) reset (unreliable)





Reset or hard reset (unreliable)





Print





Home down or bottom (lower left)





Upper left of keypad





continues on next page

The Python Library Reference, Release 3.13.2



Table 1 – continued from previous page

Key constant Key

Upper right of keypad





Center of keypad





Lower left of keypad





Lower right of keypad





Back tab





Beg (beginning)





Cancel





Close





Cmd (command)





Copy





Create





End





Exit





Find





Help





Mark





Message





Move





continues on next page

The Python Library Reference, Release 3.13.2



Table 1 – continued from previous page

Key constant Key

Next





Open





Options





Prev (previous)





Redo





Ref (reference)





Refresh





Replace





Restart





Resume





Save





Shifted Beg (beginning)





Shifted Cancel





Shifted Command





Shifted Copy





Shifted Create





Shifted Delete char





Shifted Delete line





continues on next page

The Python Library Reference, Release 3.13.2



Table 1 – continued from previous page

Key constant Key

Select





Shifted End





Shifted Clear line





Shifted Exit





Shifted Find





Shifted Help





Shifted Home





Shifted Input





Shifted Left arrow





Shifted Message





Shifted Move





Shifted Next





Shifted Options





Shifted Prev





Shifted Print





Shifted Redo





Shifted Replace





Shifted Right arrow





continues on next page

The Python Library Reference, Release 3.13.2



Table 1 – continued from previous page

Key constant Key

Shifted Resume





Shifted Save





Shifted Suspend





Shifted Undo





Suspend





Undo





Mouse event has occurred





Terminal resize event





Maximum key value





On VT100s and their software emulations, such as X terminal emulators, there are normally at least four function keys

(, , , ) available, and the arrow keys mapped to , , and

in the obvious way. If your machine has a PC keyboard, it is safe to expect arrow keys and twelve function keys (older PC keyboards may have only ten function keys); also, the following keypad mappings are standard:



Keycap Constant

KEY_IC

KEY_DC

KEY_HOME

KEY_END

KEY_PPAGE

KEY_NPAGE



The following table lists characters from the alternate character set. These are inherited from the VT100 terminal, and will generally be available on software emulations such as X terminals. When there is no graphic available, curses falls back on a crude printable ASCII approximation.



® Note

These are available only after has been called.



The Python Library Reference, Release 3.13.2



ACS code Meaning

alternate name for upper right corner





solid square block





board of squares





alternate name for horizontal line





alternate name for upper left corner





alternate name for top tee





bottom tee





bullet





checker board (stipple)





arrow pointing down





degree symbol





diamond





greater-than-or-equal-to





horizontal line





lantern symbol





left arrow





less-than-or-equal-to





lower left-hand corner





continues on next page



The Python Library Reference, Release 3.13.2



Table 2 – continued from previous page

ACS code Meaning

lower right-hand corner





left tee





not-equal sign





letter pi





plus-or-minus sign





big plus sign





right arrow





right tee





scan line 1





scan line 3





scan line 7





scan line 9





alternate name for lower right corner





alternate name for vertical line





alternate name for right tee





alternate name for lower left corner





alternate name for bottom tee





alternate name for left tee





continues on next page

The Python Library Reference, Release 3.13.2



Table 2 – continued from previous page

ACS code Meaning

alternate name for crossover or big plus





pound sterling





top tee





up arrow





upper left corner





upper right corner





vertical line





The following table lists mouse button constants used by :



Mouse button constant Meaning

Mouse button n pressed





Mouse button n released





Mouse button n clicked





Mouse button n double clicked





Mouse button n triple clicked





Shift was down during button state change





Control was down during button state change





Control was down during button state change





Changed in version 3.10: The constants are now exposed if they are provided by the underlying curses library.

The following table lists the predefined colors:

The Python Library Reference, Release 3.13.2



Constant Color

Black





Blue





Cyan (light greenish blue)





Green





Magenta (purplish red)





Red





White





Yellow





The module provides a class that handles elementary text editing in a curses win-dow, supporting a set of keybindings resembling those of Emacs (thus, also of Netscape Navigator, BBedit 6.x, FrameMaker, and many other programs). The module also provides a rectangle-drawing function useful for framing text boxes or for other purposes.

The module defines the following function:

win, uly, ulx, lry, lrx

Draw a rectangle. The first argument must be a window object; the remaining arguments are coordinates

relative to that window. The second and third arguments are the y and x coordinates of the upper left hand

corner of the rectangle to be drawn; the fourth and fifth arguments are the y and x coordinates of the lower

right hand corner. The rectangle will be drawn using VT100/IBM PC forms characters on terminals that make

this possible (including xterm and most other software terminal emulators). Otherwise it will be drawn with

ASCII dashes, vertical bars, and plus signs.





You can instantiate a object as follows:

win

Return a textbox widget object. The win argument should be a curses window object in which the textbox is to

be contained. The edit cursor of the textbox is initially located at the upper left hand corner of the containing

window, with coordinates . The instance’s flag is initially on.

objects have the following methods:

validator

This is the entry point you will normally use. It accepts editing keystrokes until one of the termination keystrokes is entered. If validator is supplied, it must be a function. It will be called for each keystroke

The Python Library Reference, Release 3.13.2



entered with the keystroke as a parameter; command dispatch is done on the result. This method re-turns the window contents as a string; whether blanks in the window are included is affected by the

attribute.

ch

Process a single command keystroke. Here are the supported special keystrokes:



Keystroke Action

Go to left edge of window.

Cursor left, wrapping to previous line if appropriate.

Delete character under cursor.

Go to right edge (stripspaces off) or end of line (stripspaces on). Cursor right, wrapping to next line when appropriate.

Terminate, returning the window contents.

Delete character backward.

Terminate if the window is 1 line, otherwise insert newline. If line is blank, delete it, otherwise clear to end of line.

Refresh screen.

Cursor down; move down one line.

Insert a blank line at cursor location.

Cursor up; move up one line.



Move operations do nothing if the cursor is at an edge where the movement is not possible. The following synonyms are supported where possible:



Constant Keystroke





All other keystrokes are treated as a command to insert the given character and move right (with line wrapping).



Return the window contents as a string; whether blanks in the window are included is affected by the

member.



This attribute is a flag which controls the interpretation of blanks in the window. When it is on, trailing blanks on each line are ignored; any cursor motion that would land the cursor on a trailing blank goes to the end of that line instead, and trailing blanks are stripped when the window contents are gathered.





Source code: Lib/curses/ascii.py



The module supplies name constants for ASCII characters and functions to test membership in various ASCII character classes. The constants supplied are names for control characters as follows:



The Python Library Reference, Release 3.13.2



Name Meaning





Start of heading, console interrupt





Start of text





End of text





End of transmission





Enquiry, goes with flow control





Acknowledgement





Bell





Backspace





Tab





Alias for : “Horizontal tab”





Line feed





Alias for : “New line”





Vertical tab





Form feed





Carriage return





Shift-out, begin alternate character set





Shift-in, resume default character set





continues on next page



The Python Library Reference, Release 3.13.2



Table 3 – continued from previous page

Name Meaning

Data-link escape





XON, for flow control





Device control 2, block-mode flow control





XOFF, for flow control





Device control 4





Negative acknowledgement





Synchronous idle





End transmission block





Cancel





End of medium





Substitute





Escape





File separator





Group separator





Record separator, block-mode terminator





Unit separator





Space





Delete





Note that many of these have little practical significance in modern usage. The mnemonics derive from teleprinter The Python Library Reference, Release 3.13.2



conventions that predate digital computers.

The module supplies the following functions, patterned on those in the standard C library:

c

Checks for an ASCII alphanumeric character; it is equivalent to .

c

Checks for an ASCII alphabetic character; it is equivalent to .

c

Checks for a character value that fits in the 7-bit ASCII set.

c

Checks for an ASCII whitespace character; space or horizontal tab.

c

Checks for an ASCII control character (in the range 0x00 to 0x1f or 0x7f).

c

Checks for an ASCII decimal digit, through . This is equivalent to .

c

Checks for ASCII any printable character except space.

c

Checks for an ASCII lower-case character.

c

Checks for any ASCII printable character including space.

c

Checks for any printable ASCII character which is not a space or an alphanumeric character.

c

Checks for ASCII white-space characters; space, line feed, carriage return, form feed, horizontal tab, vertical

tab.

c

Checks for an ASCII uppercase letter.

c

Checks for an ASCII hexadecimal digit. This is equivalent to .

c

Checks for an ASCII control character (ordinal values 0 to 31).

c

Checks for a non-ASCII character (ordinal values 0x80 and above).

These functions accept either integers or single-character strings; when the argument is a string, it is first converted

using the built-in function .

Note that all these functions check ordinal bit values derived from the character of the string you pass in; they do not actually know anything about the host machine’s character encoding.

The following two functions take either a single-character string or integer byte value; they return a value of the same type.

c

Return the ASCII value corresponding to the low 7 bits of c.



The Python Library Reference, Release 3.13.2



c

Return the control character corresponding to the given character (the character bit value is bitwise-anded with

0x1f).

c

Return the 8-bit character corresponding to the given ASCII character (the character bit value is bitwise-ored

with 0x80).

The following function takes either a single-character string or integer value; it returns a string.

c

Return a string representation of the ASCII character c. If c is printable, this string is the character itself. If the

character is a control character (0x00–0x1f) the string consists of a caret () followed by the corresponding

uppercase letter. If the character is an ASCII delete (0x7f) the string is . If the character has its meta bit

(0x80) set, the meta bit is stripped, the preceding rules applied, and prepended to the result.



A 33-element string array that contains the ASCII mnemonics for the thirty-two ASCII control characters from

0 (NUL) to 0x1f (US), in order, plus the mnemonic for the space character.





Panels are windows with the added feature of depth, so they can be stacked on top of each other, and only the visible portions of each window will be displayed. Panels can be added, moved up or down in the stack, and removed.





The module defines the following functions:



Returns the bottom panel in the panel stack.

win

Returns a panel object, associating it with the given window win. Be aware that you need to keep the returned

panel object referenced explicitly. If you don’t, the panel object is garbage collected and removed from the

panel stack.



Returns the top panel in the panel stack.



Updates the virtual screen after changes in the panel stack. This does not call , so you’ll

have to do this yourself.





Panel objects, as returned by above, are windows with a stacking order. There’s always a window associated with a panel which determines the content, while the panel methods are responsible for the window’s depth in the panel stack.

Panel objects have the following methods:



Returns the panel above the current panel.



Returns the panel below the current panel.

The Python Library Reference, Release 3.13.2





Push the panel to the bottom of the stack.



Returns if the panel is hidden (not visible), otherwise.



Hide the panel. This does not delete the object, it just makes the window on screen invisible.

y, x

Move the panel to the screen coordinates .

win

Change the window associated with the panel to the window win.

obj

Set the panel’s user pointer to obj. This is used to associate an arbitrary piece of data with the panel, and can

be any Python object.



Display the panel (which might have been hidden).



Push panel to the top of the stack.



Returns the user pointer for the panel. This might be any Python object.



Returns the window object associated with the panel.





CHAPTER





The modules described in this chapter provide support for concurrent execution of code. The appropriate choice of tool will depend on the task to be executed (CPU bound vs IO bound) and preferred style of development (event driven cooperative multitasking vs preemptive multitasking). Here’s an overview:





Source code: Lib/threading.py



This module constructs higher-level threading interfaces on top of the lower level module.

Changed in version 3.7: This module used to be optional, it is now always available.



µ See also

offers a higher level interface to push tasks to a background

thread without blocking execution of the calling thread, while still being able to retrieve their results when needed.

provides a thread-safe interface for exchanging data between running threads.

offers an alternative approach to achieving task level concurrency without requiring the use of multiple

operating system threads.



® Note

In the Python 2.x series, this module contained names for some methods and functions. These are

deprecated as of Python 3.10, but they are still supported for compatibility with Python 2.5 and lower.



CPython implementation detail: In CPython, due to the Global Interpreter Lock, only one thread can execute Python code at once (even though certain performance-oriented libraries might overcome this limitation). If you want your application to make better use of the computational resources of multi-core machines, you are advised

to use or . However, threading is still an appropriate model if you want to run multiple I/O-bound tasks simultaneously.

Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.

This module defines the following functions:



Return the number of objects currently alive. The returned count is equal to the length of the list

returned by .

The function is a deprecated alias for this function.

The Python Library Reference, Release 3.13.2





Return the current object, corresponding to the caller’s thread of control. If the caller’s thread of

control was not created through the module, a dummy thread object with limited functionality is

returned.

The function is a deprecated alias for this function.

args, /

Handle uncaught exception raised by .

The args argument has the following attributes:

• exc_type: Exception type.

• exc_value: Exception value, can be .

• exc_traceback: Exception traceback, can be .

• thread: Thread which raised the exception, can be .

If exc_type is , the exception is silently ignored. Otherwise, the exception is printed out on

.

If this function raises an exception, is called to handle it.

can be overridden to control how uncaught exceptions raised by

are handled.

Storing exc_value using a custom hook can create a reference cycle. It should be cleared explicitly to break the

reference cycle when the exception is no longer needed.

Storing thread using a custom hook can resurrect it if it is set to an object which is being finalized. Avoid

storing thread after the custom hook completes to avoid resurrecting objects.



µ See also

handles uncaught exceptions.



Added in version 3.8.



Holds the original value of . It is saved so that the original value can be restored

in case they happen to get replaced with broken or alternative objects.

Added in version 3.10.



Return the ‘thread identifier’ of the current thread. This is a nonzero integer. Its value has no direct meaning;

it is intended as a magic cookie to be used e.g. to index a dictionary of thread-specific data. Thread identifiers

may be recycled when a thread exits and another thread is created.

Added in version 3.3.



Return the native integral Thread ID of the current thread assigned by the kernel. This is a non-negative integer.

Its value may be used to uniquely identify this particular thread system-wide (until the thread terminates, after

which the value may be recycled by the OS).

Availability: Windows, FreeBSD, Linux, macOS, OpenBSD, NetBSD, AIX, DragonFlyBSD,

GNU/kFreeBSD.

Added in version 3.8.

Changed in version 3.13: Added support for GNU/kFreeBSD.

The Python Library Reference, Release 3.13.2





Return a list of all objects currently active. The list includes daemonic threads and dummy thread

objects created by . It excludes terminated threads and threads that have not yet been

started. However, the main thread is always part of the result, even when terminated.



Return the main object. In normal conditions, the main thread is the thread from which the Python

interpreter was started.

Added in version 3.4.

func

Set a trace function for all threads started from the module. The func will be passed to

for each thread, before its method is called.

func

Set a trace function for all threads started from the module and all Python threads that are currently

executing.

The func will be passed to for each thread, before its method is called.

Added in version 3.12.



Get the trace function as set by .

Added in version 3.10.

func

Set a profile function for all threads started from the module. The func will be passed to

for each thread, before its method is called.

func

Set a profile function for all threads started from the module and all Python threads that are

currently executing.

The func will be passed to for each thread, before its method is called.

Added in version 3.12.



Get the profiler function as set by .

Added in version 3.10.

size

Return the thread stack size used when creating new threads. The optional size argument specifies the stack size

to be used for subsequently created threads, and must be 0 (use platform or configured default) or a positive

integer value of at least 32,768 (32 KiB). If size is not specified, 0 is used. If changing the thread stack size

is unsupported, a is raised. If the specified stack size is invalid, a is raised

and the stack size is unmodified. 32 KiB is currently the minimum supported stack size value to guarantee

sufficient stack space for the interpreter itself. Note that some platforms may have particular restrictions on

values for the stack size, such as requiring a minimum stack size > 32 KiB or requiring allocation in multiples

of the system memory page size - platform documentation should be referred to for more information (4 KiB

pages are common; using multiples of 4096 for the stack size is the suggested approach in the absence of more

specific information).

Availability: Windows, pthreads.

Unix platforms with POSIX threads support.

This module also defines the following constant:



The Python Library Reference, Release 3.13.2





The maximum value allowed for the timeout parameter of blocking functions (,

, , etc.).

.

Added in version 3.2.

This module defines a number of classes, which are detailed in the sections below.

The design of this module is loosely based on Java’s threading model. However, where Java makes locks and condi-

tion variables basic behavior of every object, they are separate objects in Python. Python’s class supports a subset of the behavior of Java’s Thread class; currently, there are no priorities, no thread groups, and threads can-not be destroyed, stopped, suspended, resumed, or interrupted. The static methods of Java’s Thread class, when implemented, are mapped to module-level functions.

All of the methods described below are executed atomically.





Thread-local data is data whose values are thread specific. To manage thread-local data, just create an instance of

(or a subclass) and store attributes on it:





The instance’s values will be different for separate threads.



A class that represents thread-local data.

For more details and extensive examples, see the documentation string of the module:

Lib/_threading_local.py.





The class represents an activity that is run in a separate thread of control. There are two ways to specify

the activity: by passing a callable object to the constructor, or by overriding the method in a subclass. No other methods (except for the constructor) should be overridden in a subclass. In other words, only override the

and methods of this class.

Once a thread object is created, its activity must be started by calling the thread’s method. This invokes

the method in a separate thread of control.

Once the thread’s activity is started, the thread is considered ‘alive’. It stops being alive when its method

terminates – either normally, or by raising an unhandled exception. The method tests whether the thread is alive.

Other threads can call a thread’s method. This blocks the calling thread until the thread whose method is called is terminated.

A thread has a name. The name can be passed to the constructor, and read or changed through the attribute.

If the method raises an exception, is called to handle it.

ignores silently .

A thread can be flagged as a “daemon thread”. The significance of this flag is that the entire Python program exits when only daemon threads are left. The initial value is inherited from the creating thread. The flag can be set through

the property or the daemon constructor argument.



® Note



The Python Library Reference, Release 3.13.2



Daemon threads are abruptly stopped at shutdown. Their resources (such as open files, database transactions,

etc.) may not be released properly. If you want your threads to stop gracefully, make them non-daemonic and

use a suitable signalling mechanism such as an .



There is a “main thread” object; this corresponds to the initial thread of control in the Python program. It is not a daemon thread.

There is the possibility that “dummy thread objects” are created. These are thread objects corresponding to “alien threads”, which are threads of control started outside the threading module, such as directly from C code. Dummy

thread objects have limited functionality; they are always considered alive and daemonic, and cannot be joined. They are never deleted, since it is impossible to detect the termination of alien threads.

group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None

This constructor should always be called with keyword arguments. Arguments are:

group should be ; reserved for future extension when a class is implemented.

target is the callable object to be invoked by the method. Defaults to , meaning nothing is called.

name is the thread name. By default, a unique name is constructed of the form “Thread-N” where N is a

small decimal number, or “Thread-N (target)” where “target” is if the target argument is

specified.

args is a list or tuple of arguments for the target invocation. Defaults to .

kwargs is a dictionary of keyword arguments for the target invocation. Defaults to .

If not , daemon explicitly sets whether the thread is daemonic. If (the default), the daemonic

property is inherited from the current thread.

If the subclass overrides the constructor, it must make sure to invoke the base class constructor (

) before doing anything else to the thread.

Changed in version 3.3: Added the daemon parameter.

Changed in version 3.10: Use the target name if name argument is omitted.



Start the thread’s activity.

It must be called at most once per thread object. It arranges for the object’s method to be invoked in a separate thread of control.

This method will raise a if called more than once on the same thread object.



Method representing the thread’s activity.

You may override this method in a subclass. The standard method invokes the callable object passed to the object’s constructor as the target argument, if any, with positional and keyword arguments taken from the args and kwargs arguments, respectively.

Using list or tuple as the args argument which passed to the could achieve the same effect.

Example:





The Python Library Reference, Release 3.13.2



timeout=None

Wait until the thread terminates. This blocks the calling thread until the thread whose method is called terminates – either normally or through an unhandled exception – or until the optional timeout occurs.

When the timeout argument is present and not , it should be a floating-point number specifying a

timeout for the operation in seconds (or fractions thereof). As always returns , you must

call after to decide whether a timeout happened – if the thread is still alive, the

call timed out.

When the timeout argument is not present or , the operation will block until the thread terminates.

A thread can be joined many times.

raises a if an attempt is made to join the current thread as that would cause a

deadlock. It is also an error to a thread before it has been started and attempts to do so raise the same exception.



A string used for identification purposes only. It has no semantics. Multiple threads may be given the same name. The initial name is set by the constructor.





Deprecated getter/setter API for ; use it directly as a property instead.

Deprecated since version 3.10.



The ‘thread identifier’ of this thread or if the thread has not been started. This is a nonzero integer.

See the function. Thread identifiers may be recycled when a thread exits and another thread is created. The identifier is available even after the thread has exited.



The Thread ID () of this thread, as assigned by the OS (kernel). This is a non-negative integer, or

if the thread has not been started. See the function. This value may be used to uniquely identify this particular thread system-wide (until the thread terminates, after which the value may be recycled by the OS).



® Note

Similar to Process IDs, Thread IDs are only valid (guaranteed unique system-wide) from the time the thread is created until the thread has been terminated.



Availability: Windows, FreeBSD, Linux, macOS, OpenBSD, NetBSD, AIX, DragonFlyBSD.

Added in version 3.8.



Return whether the thread is alive.

This method returns just before the method starts until just after the method termi-

nates. The module function returns a list of all alive threads.



A boolean value indicating whether this thread is a daemon thread () or not (). This must

be set before is called, otherwise is raised. Its initial value is inherited from the creating thread; the main thread is not a daemon thread and therefore all threads created in the main

thread default to = .

The entire Python program exits when no alive non-daemon threads are left.



The Python Library Reference, Release 3.13.2





Deprecated getter/setter API for ; use it directly as a property instead.

Deprecated since version 3.10.





A primitive lock is a synchronization primitive that is not owned by a particular thread when locked. In Python,

it is currently the lowest level synchronization primitive available, implemented directly by the extension module.

A primitive lock is in one of two states, “locked” or “unlocked”. It is created in the unlocked state. It has two basic

methods, and . When the state is unlocked, changes the state to locked and

returns immediately. When the state is locked, blocks until a call to in another thread

changes it to unlocked, then the call resets it to locked and returns. The method should only be called in the locked state; it changes the state to unlocked and returns immediately. If an attempt is made to

release an unlocked lock, a will be raised.

Locks also support the context management protocol.

When more than one thread is blocked in waiting for the state to turn to unlocked, only one thread

proceeds when a call resets the state to unlocked; which one of the waiting threads proceeds is not defined, and may vary across implementations.

All methods are executed atomically.



The class implementing primitive lock objects. Once a thread has acquired a lock, subsequent attempts to

acquire it block, until it is released; any thread may release it.

Changed in version 3.13: is now a class. In earlier Pythons, was a factory function which returned

an instance of the underlying private lock type.

blocking=True, timeout=-1

Acquire a lock, blocking or non-blocking.

When invoked with the blocking argument set to (the default), block until the lock is unlocked, then set it to locked and return .

When invoked with the blocking argument set to , do not block. If a call with blocking set to would block, return immediately; otherwise, set the lock to locked and return .

When invoked with the floating-point timeout argument set to a positive value, block for at most the number of seconds specified by timeout and as long as the lock cannot be acquired. A timeout argument of specifies an unbounded wait. It is forbidden to specify a timeout when blocking is .

The return value is if the lock is acquired successfully, if not (for example if the timeout expired).

Changed in version 3.2: The timeout parameter is new.

Changed in version 3.2: Lock acquisition can now be interrupted by signals on POSIX if the underlying threading implementation supports it.



Release a lock. This can be called from any thread, not only the thread which has acquired the lock.

When the lock is locked, reset it to unlocked, and return. If any other threads are blocked waiting for the lock to become unlocked, allow exactly one of them to proceed.

When invoked on an unlocked lock, a is raised.

There is no return value.



Return if the lock is acquired.

The Python Library Reference, Release 3.13.2





A reentrant lock is a synchronization primitive that may be acquired multiple times by the same thread. Internally, it uses the concepts of “owning thread” and “recursion level” in addition to the locked/unlocked state used by primitive locks. In the locked state, some thread owns the lock; in the unlocked state, no thread owns it.

Threads call a lock’s method to lock it, and its method to unlock it.



® Note

Reentrant locks support the context management protocol, so it is recommended to use instead of manually

calling and to handle acquiring and releasing the lock for a block of code.



RLock’s / call pairs may be nested, unlike Lock’s /. Only the final

(the of the outermost pair) resets the lock to an unlocked state and allows another thread

blocked in to proceed.

/ must be used in pairs: each acquire must have a release in the thread that has acquired the lock. Failing to call release as many times the lock has been acquired can lead to deadlock.



This class implements reentrant lock objects. A reentrant lock must be released by the thread that acquired it.

Once a thread has acquired a reentrant lock, the same thread may acquire it again without blocking; the thread

must release it once for each time it has acquired it.

Note that is actually a factory function which returns an instance of the most efficient version of the

concrete RLock class that is supported by the platform.

blocking=True, timeout=-1

Acquire a lock, blocking or non-blocking.



µ See also



Using RLock as a context manager

Recommended over manual and calls whenever practical.



When invoked with the blocking argument set to (the default):

• If no thread owns the lock, acquire the lock and return immediately.

• If another thread owns the lock, block until we are able to acquire lock, or timeout, if set to a positive

float value.

• If the same thread owns the lock, acquire the lock again, and return immediately. This is the dif-

ference between and ; handles this case the same as the previous, blocking until the lock can be acquired.

When invoked with the blocking argument set to :

• If no thread owns the lock, acquire the lock and return immediately.

• If another thread owns the lock, return immediately.

• If the same thread owns the lock, acquire the lock again and return immediately.

In all cases, if the thread was able to acquire the lock, return . If the thread was unable to acquire the lock (i.e. if not blocking or the timeout was reached) return .

If called multiple times, failing to call as many times may lead to deadlock. Consider using as a context manager rather than calling acquire/release directly.

Changed in version 3.2: The timeout parameter is new.

The Python Library Reference, Release 3.13.2





Release a lock, decrementing the recursion level. If after the decrement it is zero, reset the lock to unlocked (not owned by any thread), and if any other threads are blocked waiting for the lock to become unlocked, allow exactly one of them to proceed. If after the decrement the recursion level is still nonzero, the lock remains locked and owned by the calling thread.

Only call this method when the calling thread owns the lock. A is raised if this method is called when the lock is not acquired.

There is no return value.





A condition variable is always associated with some kind of lock; this can be passed in or one will be created by default. Passing one in is useful when several condition variables must share the same lock. The lock is part of the condition object: you don’t have to track it separately.

A condition variable obeys the context management protocol: using the statement acquires the associated lock for

the duration of the enclosed block. The and methods also call the corresponding methods of the associated lock.

Other methods must be called with the associated lock held. The method releases the lock, and then blocks

until another thread awakens it by calling or . Once awakened, re-acquires the lock and returns. It is also possible to specify a timeout.

The method wakes up one of the threads waiting for the condition variable, if any are waiting. The

method wakes up all threads waiting for the condition variable.

Note: the and methods don’t release the lock; this means that the thread or threads

awakened will not return from their call immediately, but only when the thread that called or

finally relinquishes ownership of the lock.

The typical programming style using condition variables uses the lock to synchronize access to some shared state;

threads that are interested in a particular change of state call repeatedly until they see the desired state, while

threads that modify the state call or when they change the state in such a way that it could possibly be a desired state for one of the waiters. For example, the following code is a generic producer-consumer situation with unlimited buffer capacity:





The loop checking for the application’s condition is necessary because can return after an arbitrary

long time, and the condition which prompted the call may no longer hold true. This is inherent to multi-

threaded programming. The method can be used to automate the condition checking, and eases the computation of timeouts:





To choose between and , consider whether one state change can be interesting for only one or several waiting threads. E.g. in a typical producer-consumer situation, adding one item to the buffer only needs to wake up one consumer thread.

The Python Library Reference, Release 3.13.2



lock=None

This class implements condition variable objects. A condition variable allows one or more threads to wait until

they are notified by another thread.

If the lock argument is given and not , it must be a or object, and it is used as the underlying

lock. Otherwise, a new object is created and used as the underlying lock.

Changed in version 3.3: changed from a factory function to a class.

*args

Acquire the underlying lock. This method calls the corresponding method on the underlying lock; the return value is whatever that method returns.



Release the underlying lock. This method calls the corresponding method on the underlying lock; there is no return value.

timeout=None

Wait until notified or until a timeout occurs. If the calling thread has not acquired the lock when this

method is called, a is raised.

This method releases the underlying lock, and then blocks until it is awakened by a or

call for the same condition variable in another thread, or until the optional timeout occurs. Once awakened or timed out, it re-acquires the lock and returns.

When the timeout argument is present and not , it should be a floating-point number specifying a timeout for the operation in seconds (or fractions thereof).

When the underlying lock is an , it is not released using its method, since this may not actually unlock the lock when it was acquired multiple times recursively. Instead, an internal interface of

the class is used, which really unlocks it even when it has been recursively acquired several times. Another internal interface is then used to restore the recursion level when the lock is reacquired.

The return value is unless a given timeout expired, in which case it is .

Changed in version 3.2: Previously, the method always returned .

predicate, timeout=None

Wait until a condition evaluates to true. predicate should be a callable which result will be interpreted as a boolean value. A timeout may be provided giving the maximum time to wait.

This utility method may call repeatedly until the predicate is satisfied, or until a timeout occurs. The return value is the last return value of the predicate and will evaluate to if the method timed out.

Ignoring the timeout feature, calling this method is roughly equivalent to writing:





Therefore, the same rules apply as with : The lock must be held when called and is re-acquired on return. The predicate is evaluated with the lock held.

Added in version 3.2.

n=1

By default, wake up one thread waiting on this condition, if any. If the calling thread has not acquired

the lock when this method is called, a is raised.

This method wakes up at most n of the threads waiting for the condition variable; it is a no-op if no threads are waiting.

The current implementation wakes up exactly n threads, if at least n threads are waiting. However, it’s not safe to rely on this behavior. A future, optimized implementation may occasionally wake up more than n threads.

The Python Library Reference, Release 3.13.2



Note: an awakened thread does not actually return from its call until it can reacquire the lock.

Since does not release the lock, its caller should.



Wake up all threads waiting on this condition. This method acts like , but wakes up all waiting threads instead of one. If the calling thread has not acquired the lock when this method is called, a

is raised.

The method is a deprecated alias for this method.





This is one of the oldest synchronization primitives in the history of computer science, invented by the early Dutch

computer scientist Edsger W. Dijkstra (he used the names and instead of and ).

A semaphore manages an internal counter which is decremented by each call and incremented by each

call. The counter can never go below zero; when finds that it is zero, it blocks, waiting until

some other thread calls .

Semaphores also support the context management protocol.

value=1

This class implements semaphore objects. A semaphore manages an atomic counter representing the number

of calls minus the number of calls, plus an initial value. The method

blocks if necessary until it can return without making the counter negative. If not given, value defaults to 1.

The optional argument gives the initial value for the internal counter; it defaults to . If the value given is less

than 0, is raised.

Changed in version 3.3: changed from a factory function to a class.

blocking=True, timeout=None

Acquire a semaphore.

When invoked without arguments:

• If the internal counter is larger than zero on entry, decrement it by one and return immediately.

• If the internal counter is zero on entry, block until awoken by a call to . Once awoken

(and the counter is greater than 0), decrement the counter by 1 and return . Exactly one thread

will be awoken by each call to . The order in which threads are awoken should not be relied on.

When invoked with blocking set to , do not block. If a call without an argument would block, return immediately; otherwise, do the same thing as when called without arguments, and return .

When invoked with a timeout other than , it will block for at most timeout seconds. If acquire does not complete successfully in that interval, return . Return otherwise.

Changed in version 3.2: The timeout parameter is new.

n=1

Release a semaphore, incrementing the internal counter by n. When it was zero on entry and other threads are waiting for it to become larger than zero again, wake up n of those threads.

Changed in version 3.9: Added the n parameter to release multiple waiting threads at once.

value=1

Class implementing bounded semaphore objects. A bounded semaphore checks to make sure its current value

doesn’t exceed its initial value. If it does, is raised. In most situations semaphores are used to

guard resources with limited capacity. If the semaphore is released too many times it’s a sign of a bug. If not

given, value defaults to 1.

Changed in version 3.3: changed from a factory function to a class.

The Python Library Reference, Release 3.13.2



Example

Semaphores are often used to guard resources with limited capacity, for example, a database server. In any situation where the size of the resource is fixed, you should use a bounded semaphore. Before spawning any worker threads, your main thread would initialize the semaphore:





Once spawned, worker threads call the semaphore’s acquire and release methods when they need to connect to the server:





The use of a bounded semaphore reduces the chance that a programming error which causes the semaphore to be released more than it’s acquired will go undetected.





This is one of the simplest mechanisms for communication between threads: one thread signals an event and other threads wait for it.

An event object manages an internal flag that can be set to true with the method and reset to false with the

method. The method blocks until the flag is true.



Class implementing event objects. An event manages a flag that can be set to true with the method and

reset to false with the method. The method blocks until the flag is true. The flag is initially

false.

Changed in version 3.3: changed from a factory function to a class.



Return if and only if the internal flag is true.

The method is a deprecated alias for this method.



Set the internal flag to true. All threads waiting for it to become true are awakened. Threads that call

once the flag is true will not block at all.



Reset the internal flag to false. Subsequently, threads calling will block until is called to set the internal flag to true again.

timeout=None

Block as long as the internal flag is false and the timeout, if given, has not expired. The return value represents the reason that this blocking method returned; if returning because the internal flag is set to true, or if a timeout is given and the internal flag did not become true within the given wait time.

When the timeout argument is present and not , it should be a floating-point number specifying a timeout for the operation in seconds, or fractions thereof.

Changed in version 3.1: Previously, the method always returned .

The Python Library Reference, Release 3.13.2





This class represents an action that should be run only after a certain amount of time has passed — a timer.

is a subclass of and as such also functions as an example of creating custom threads.

Timers are started, as with threads, by calling their method. The timer can be stopped (before its

action has begun) by calling the method. The interval the timer will wait before executing its action may not be exactly the same as the interval specified by the user.

For example:





interval, function, args=None, kwargs=None

Create a timer that will run function with arguments args and keyword arguments kwargs, after interval seconds

have passed. If args is (the default) then an empty list will be used. If kwargs is (the default) then

an empty dict will be used.

Changed in version 3.3: changed from a factory function to a class.



Stop the timer, and cancel the execution of the timer’s action. This will only work if the timer is still in its waiting stage.





Added in version 3.2.

This class provides a simple synchronization primitive for use by a fixed number of threads that need to wait for

each other. Each of the threads tries to pass the barrier by calling the method and will block until all of the

threads have made their calls. At this point, the threads are released simultaneously.

The barrier can be reused any number of times for the same number of threads.

As an example, here is a simple way to synchronize a client and server thread:





parties, action=None, timeout=None

Create a barrier object for parties number of threads. An action, when provided, is a callable to be called

by one of the threads when they are released. timeout is the default timeout value if none is specified for the

method.



The Python Library Reference, Release 3.13.2



timeout=None

Pass the barrier. When all the threads party to the barrier have called this function, they are all released simultaneously. If a timeout is provided, it is used in preference to any that was supplied to the class constructor.

The return value is an integer in the range 0 to parties – 1, different for each thread. This can be used to select a thread to do some special housekeeping, e.g.:





If an action was provided to the constructor, one of the threads will have called it prior to being released. Should this call raise an error, the barrier is put into the broken state.

If the call times out, the barrier is put into the broken state.

This method may raise a exception if the barrier is broken or reset while a thread is waiting.



Return the barrier to the default, empty state.

exception.

Note that using this function may require some external synchronization if there are other threads whose state is unknown. If a barrier is broken it may be better to just leave it and create a new one.



Put the barrier into a broken state. This causes any active or future calls to to fail with the

. Use this for example if one of the threads needs to abort, to avoid deadlocking the application.

It may be preferable to simply create the barrier with a sensible timeout value to automatically guard against one of the threads going awry.



The number of threads required to pass the barrier.



The number of threads currently waiting in the barrier.



A boolean that is if the barrier is in the broken state.



This exception, a subclass of , is raised when the object is reset or broken.





All of the objects provided by this module that have and methods can be used as context managers for a statement. The method will be called when the block is entered, and will be called when the block is exited. Hence, the following snippet:





is equivalent to:





The Python Library Reference, Release 3.13.2





Currently, , , , , and objects may be used as state-ment context managers.





Source code: Lib/multiprocessing/



Availability: not Android, not iOS, not WASI.

This module is not supported on mobile platforms or WebAssembly platforms.





is a package that supports spawning processes using an API similar to the module.

The package offers both local and remote concurrency, effectively side-stepping the Global

Interpreter Lock by using subprocesses instead of threads. Due to this, the module allows the programmer to fully leverage multiple processors on a given machine. It runs on both POSIX and Windows.

The module also introduces APIs which do not have analogs in the module. A

prime example of this is the object which offers a convenient means of parallelizing the execution of a function across multiple input values, distributing the input data across processes (data parallelism). The following example demonstrates the common practice of defining such functions in a module so that child processes can successfully

import that module. This basic example of data parallelism using ,





will print to standard output





µ See also

offers a higher level interface to push tasks to a background

process without blocking execution of the calling process. Compared to using the interface directly, the

API more readily allows the submission of work to the underlying process pool to be

separated from waiting for the results.



The class

In , processes are spawned by creating a object and then calling its method.

follows the API of . A trivial example of a multiprocess program is





The Python Library Reference, Release 3.13.2





To show the individual process IDs involved, here is an expanded example:





For an explanation of why the part is necessary, see Programming guidelines.



Contexts and start methods

Depending on the platform, supports three ways to start a process. These start methods are

spawn

The parent process starts a fresh Python interpreter process. The child process will only inherit

those resources necessary to run the process object’s method. In particular, unnecessary file descriptors and handles from the parent process will not be inherited. Starting a process using this method is rather slow compared to using fork or forkserver.

Available on POSIX and Windows platforms. The default on Windows and macOS.

fork

The parent process uses to fork the Python interpreter. The child process, when it begins, is effectively identical to the parent process. All resources of the parent are inherited by the child process. Note that safely forking a multithreaded process is problematic.

Available on POSIX systems. Currently the default on POSIX except macOS.



® Note

The default start method will change away from fork in Python 3.14. Code that requires fork

should explicitly specify that via or .



Changed in version 3.12: If Python is able to detect that your process has multiple threads, the

function that this start method calls internally will raise a .

Use a different start method. See the documentation for further explanation.

The Python Library Reference, Release 3.13.2



forkserver

When the program starts and selects the forkserver start method, a server process is spawned. From then on, whenever a new process is needed, the parent process connects to the server and requests that it fork a new process. The fork server process is single threaded unless system libraries or

preloaded imports spawn threads as a side-effect so it is generally safe for it to use . No unnecessary resources are inherited.

Available on POSIX platforms which support passing file descriptors over Unix pipes such as Linux.

Changed in version 3.4: spawn added on all POSIX platforms, and forkserver added for some POSIX platforms. Child processes no longer inherit all of the parents inheritable handles on Windows.

Changed in version 3.8: On macOS, the spawn start method is now the default. The fork start method should be considered unsafe as it can lead to crashes of the subprocess as macOS system libraries may start threads. See

bpo-33725.

On POSIX using the spawn or forkserver start methods will also start a resource tracker process which tracks the

unlinked named system resources (such as named semaphores or objects) created by processes of the program. When all processes have exited the resource tracker unlinks any remaining tracked object. Usually there should be none, but if a process was killed by a signal there may be some “leaked” resources. (Neither leaked semaphores nor shared memory segments will be automatically unlinked until the next reboot. This is problematic for both objects because the system allows only a limited number of named semaphores, and shared memory segments occupy some space in the main memory.)

To select a start method you use the in the clause of the main module. For example:





should not be used more than once in the program.

Alternatively, you can use to obtain a context object. Context objects have the same API as the multiprocessing module, and allow one to use multiple start methods in the same program.





Note that objects related to one context may not be compatible with processes for a different context. In particular, locks created using the fork context cannot be passed to processes started using the spawn or forkserver start methods.

The Python Library Reference, Release 3.13.2



A library which wants to use a particular start method should probably use to avoid interfering with the choice of the library user.



Á Warning

The and start methods generally cannot be used with “frozen” executables (i.e., bina-

ries produced by packages like PyInstaller and cx_Freeze) on POSIX systems. The start method may

work if code does not use threads.



Exchanging objects between processes

supports two types of communication channel between processes:

Queues

The class is a near clone of . For example:





Queues are thread and process safe. Any object put into a queue will be serialized.

Pipes

The function returns a pair of connection objects connected by a pipe which by default is duplex

(two-way). For example:





The two connection objects returned by represent the two ends of the pipe. Each connection

object has and methods (among others). Note that data in a pipe may become corrupted

if two processes (or threads) try to read from or write to the same end of the pipe at the same time. Of

course there is no risk of corruption from processes using different ends of the pipe at the same time.

The method serializes the object and re-creates the object.



The Python Library Reference, Release 3.13.2



Synchronization between processes

contains equivalents of all the synchronization primitives from . For instance one can use a lock to ensure that only one process prints to standard output at a time:





Without using the lock output from the different processes is liable to get all mixed up.



Sharing state between processes

As mentioned above, when doing concurrent programming it is usually best to avoid using shared state as far as possible. This is particularly true when using multiple processes.

However, if you really do need to use some shared data then provides a couple of ways of doing so.

Shared memory

Data can be stored in a shared memory map using or . For example, the following code





will print





The and arguments used when creating and are typecodes of the kind used by the

module: indicates a double precision float and indicates a signed integer. These shared

objects will be process and thread-safe.

The Python Library Reference, Release 3.13.2



For more flexibility in using shared memory one can use the

module which supports the creation of arbitrary ctypes objects allocated from shared memory.

Server process

A manager object returned by controls a server process which holds Python objects and

allows other processes to manipulate them using proxies.

A manager returned by will support types , , , , ,

, , , , , , and . For

example,





will print





Server process managers are more flexible than using shared memory objects because they can be made

to support arbitrary object types. Also, a single manager can be shared by processes on different com-

puters over a network. They are, however, slower than using shared memory.



Using a pool of workers

The class represents a pool of worker processes. It has methods which allows tasks to be offloaded to the worker processes in a few different ways.

For example:





The Python Library Reference, Release 3.13.2





Note that the methods of a pool should only ever be used by the process which created it.



® Note

Functionality within this package requires that the module be importable by the children. This is

covered in Programming guidelines however it is worth pointing out here. This means that some examples, such

as the examples will not work in the interactive interpreter. For example:





The Python Library Reference, Release 3.13.2



(If you try this it will actually output three full tracebacks interleaved in a semi-random fashion, and then you

may have to stop the parent process somehow.)





The package mostly replicates the API of the module.



and exceptions

group=None, target=None, name=None, args=(), kwargs={}, *,

daemon=None

Process objects represent activity that is run in a separate process. The class has equivalents of all

the methods of .

The constructor should always be called with keyword arguments. group should always be ; it exists solely

for compatibility with . target is the callable object to be invoked by the method.

It defaults to , meaning nothing is called. name is the process name (see for more details). args

is the argument tuple for the target invocation. kwargs is a dictionary of keyword arguments for the target

invocation. If provided, the keyword-only daemon argument sets the process flag to or .

If (the default), this flag will be inherited from the creating process.

By default, no arguments are passed to target. The args argument, which defaults to , can be used to specify

a list or tuple of the arguments to pass to target.

If a subclass overrides the constructor, it must make sure it invokes the base class constructor (

) before doing anything else to the process.

Changed in version 3.3: Added the daemon parameter.



Method representing the process’s activity.

You may override this method in a subclass. The standard method invokes the callable object passed to the object’s constructor as the target argument, if any, with sequential and keyword arguments taken from the args and kwargs arguments, respectively.

Using a list or tuple as the args argument passed to achieves the same effect.

Example:





Start the process’s activity.

This must be called at most once per process object. It arranges for the object’s method to be invoked in a separate process.

timeout

If the optional argument timeout is (the default), the method blocks until the process whose method is called terminates. If timeout is a positive number, it blocks at most timeout seconds. Note that the method returns if its process terminates or if the method times out. Check the process’s

to determine if it terminated.

A process can be joined many times.

The Python Library Reference, Release 3.13.2



A process cannot join itself because this would cause a deadlock. It is an error to attempt to join a process before it has been started.



The process’s name. The name is a string used for identification purposes only. It has no semantics. Multiple processes may be given the same name.

The initial name is set by the constructor. If no explicit name is provided to the constructor, a name of the form ‘Process-N:N:…:N’ is constructed, where each N is the N-th child of its parent.



Return whether the process is alive.

Roughly, a process object is alive from the moment the method returns until the child process terminates.



The process’s daemon flag, a Boolean value. This must be set before is called.

The initial value is inherited from the creating process.

When a process exits, it attempts to terminate all of its daemonic child processes.

Note that a daemonic process is not allowed to create child processes. Otherwise a daemonic process would leave its children orphaned if it gets terminated when its parent process exits. Additionally, these are not Unix daemons or services, they are normal processes that will be terminated (and not joined) if non-daemonic processes have exited.

In addition to the API, objects also support the following attributes and meth-

ods:



Return the process ID. Before the process is spawned, this will be .



The child’s exit code. This will be if the process has not yet terminated.

If the child’s method returned normally, the exit code will be 0. If it terminated via with an integer argument N, the exit code will be N.

If the child terminated due to an exception not caught within , the exit code will be 1. If it was terminated by signal N, the exit code will be the negative value-N.



The process’s authentication key (a byte string).

When is initialized the main process is assigned a random string using

.

When a object is created, it will inherit the authentication key of its parent process, although

this may be changed by setting to another byte string.

See Authentication keys.



A numeric handle of a system object which will become “ready” when the process ends.

You can use this value if you want to wait on several events at once using

. Otherwise calling is simpler.

On Windows, this is an OS handle usable with the and family of API calls.

with primitives from the module.

Added in version 3.3.

The Python Library Reference, Release 3.13.2





Terminate the process. On POSIX this is done using the signal; on Windows is used. Note that exit handlers and finally clauses, etc., will not be executed.

Note that descendant processes of the process will not be terminated – they will simply become orphaned.



Á Warning

If this method is used when the associated process is using a pipe or queue then the pipe or queue is liable to become corrupted and may become unusable by other process. Similarly, if the process has acquired a lock or semaphore etc. then terminating it is liable to cause other processes to deadlock.





Same as but using the signal on POSIX.

Added in version 3.7.



Close the object, releasing all resources associated with it. is raised if the un-

derlying process is still running. Once returns successfully, most other methods and attributes

of the object will raise .

Added in version 3.7.

Note that the , , , and methods should only be called

by the process that created the process object.

Example usage of some of the methods of :





The base class of all exceptions.



Exception raised by when the supplied buffer object is too small for the

message read.

If is an instance of then will give the message as a byte string.



Raised when there is an authentication error.



Raised by methods with a timeout when the timeout expires.



The Python Library Reference, Release 3.13.2



Pipes and Queues

When using multiple processes, one generally uses message passing for communication between processes and avoids having to use any synchronization primitives like locks.

For passing messages one can use (for a connection between two processes) or a queue (which allows multiple producers and consumers).

The , and types are multi-producer, multi-consumer FIFO queues modelled

on the class in the standard library. They differ in that lacks the and

methods introduced into Python 2.5’s class.

If you use then you must call for each task removed from the queue or else the semaphore used to count the number of unfinished tasks may eventually overflow, raising an ex-ception.

One difference from other Python queue implementations, is that queues serializes all objects

that are put into them using . The object return by the get method is a re-created object that does not share memory with the original object.

Note that one can also create a shared queue by using a manager object – see Managers.



® Note

uses the usual and exceptions to signal a timeout. They are

not available in the namespace so you need to import them from .



® Note

When an object is put on a queue, the object is pickled and a background thread later flushes the pickled data to

an underlying pipe. This has some consequences which are a little surprising, but should not cause any practical

difficulties – if they really bother you then you can instead use a queue created with a manager.

(1) After putting an object on an empty queue there may be an infinitesimal delay before the queue’s

method returns and can return without raising .

(2) If multiple processes are enqueuing objects, it is possible for the objects to be received at the other end

out-of-order. However, objects enqueued by the same process will always be in the expected order with respect to each other.



Á Warning

If a process is killed using or while it is trying to use a , then the

data in the queue is likely to become corrupted. This may cause any other process to get an exception when it

tries to use the queue later on.



Á Warning

As mentioned above, if a child process has put items on a queue (and it has not used

), then that process will not terminate until all buffered items have been flushed to the

pipe.

This means that if you try joining that process you may get a deadlock unless you are sure that all items which

have been put on the queue have been consumed. Similarly, if the child process is non-daemonic then the parent

process may hang on exit when it tries to join all its non-daemonic children.

Note that a queue created using a manager does not have this issue. See Programming guidelines.

The Python Library Reference, Release 3.13.2



For an example of the usage of queues for interprocess communication see Examples.

duplex

Returns a pair of objects representing the ends of a pipe.

If duplex is (the default) then the pipe is bidirectional. If duplex is then the pipe is unidirectional:

can only be used for receiving messages and can only be used for sending messages.

The method serializes the object using and the re-creates the object.

maxsize

Returns a process shared queue implemented using a pipe and a few locks/semaphores. When a process first

puts an item on the queue a feeder thread is started which transfers objects from a buffer into the pipe.

The usual and exceptions from the standard library’s module are raised

to signal timeouts.

implements all the methods of except for and .



Return the approximate size of the queue. Because of multithreading/multiprocessing semantics, this number is not reliable.

Note that this may raise on platforms like macOS where is not implemented.



Return if the queue is empty, otherwise. Because of multithreading/multiprocessing se-mantics, this is not reliable.

May raise an on closed queues. (not guaranteed)



Return if the queue is full, otherwise. Because of multithreading/multiprocessing semantics, this is not reliable.

obj, block, timeout

Put obj into the queue. If the optional argument block is (the default) and timeout is (the default), block if necessary until a free slot is available. If timeout is a positive number, it blocks at most

timeout seconds and raises the exception if no free slot was available within that time. Otherwise (block is ), put an item on the queue if a free slot is immediately available, else raise

the exception (timeout is ignored in that case).

Changed in version 3.8: If the queue is closed, is raised instead of .

obj

Equivalent to .

block , timeout

Remove and return an item from the queue. If optional args block is (the default) and timeout is (the default), block if necessary until an item is available. If timeout is a positive number, it blocks

at most timeout seconds and raises the exception if no item was available within that time.

Otherwise (block is ), return an item if one is immediately available, else raise the exception (timeout is ignored in that case).

Changed in version 3.8: If the queue is closed, is raised instead of .



Equivalent to .

has a few additional methods not found in . These methods are

usually unnecessary for most code:



The Python Library Reference, Release 3.13.2





Indicate that no more data will be put on this queue by the current process. The background thread will quit once it has flushed all buffered data to the pipe. This is called automatically when the queue is garbage collected.



Join the background thread. This can only be used after has been called. It blocks until the background thread exits, ensuring that all data in the buffer has been flushed to the pipe.

By default if a process is not the creator of the queue then on exit it will attempt to join the queue’s back-

ground thread. The process can call to make do nothing.



Prevent from blocking. In particular, this prevents the background thread from being

joined automatically when the process exits – see .

A better name for this method might be . It is likely to cause en-queued data to be lost, and you almost certainly will not need to use it. It is really only there if you need the current process to exit immediately without waiting to flush enqueued data to the underlying pipe, and you don’t care about lost data.



® Note

This class’s functionality requires a functioning shared semaphore implementation on the host operating

system. Without one, the functionality in this class will be disabled, and attempts to instantiate a

will result in an . See bpo-3770 for additional information. The same holds true for any of the specialized queue types listed below.





It is a simplified type, very close to a locked .



Close the queue: release internal resources.

A queue must not be used anymore after it is closed. For example, , and methods must no longer be called.

Added in version 3.9.



Return if the queue is empty, otherwise.

Always raises an if the SimpleQueue is closed.



Remove and return an item from the queue.

item

Put item into the queue.

maxsize

, a subclass, is a queue which additionally has and methods.





Indicate that a formerly enqueued task is complete. Used by queue consumers. For each used to

fetch a task, a subsequent call to tells the queue that the processing on the task is complete.

If a is currently blocking, it will resume when all items have been processed (meaning that a

call was received for every item that had been into the queue).

Raises a if called more times than there were items placed in the queue.

The Python Library Reference, Release 3.13.2





Block until all items in the queue have been gotten and processed.

The count of unfinished tasks goes up whenever an item is added to the queue. The count goes down

whenever a consumer calls to indicate that the item was retrieved and all work on it is

complete. When the count of unfinished tasks drops to zero, unblocks.



Miscellaneous



Return list of all live children of the current process.

Calling this has the side effect of “joining” any processes which have already finished.



Return the number of CPUs in the system.

This number is not equivalent to the number of CPUs the current process can use. The number of usable CPUs

can be obtained with (or ).

When the number of CPUs cannot be determined a is raised.



µ See also





Changed in version 3.13: The return value can also be overridden using the flag or

as this is merely a wrapper around the cpu count APIs.



Return the object corresponding to the current process.

An analogue of .



Return the object corresponding to the parent process of the . For the main

process, will be .

Added in version 3.8.



Add support for when a program which uses has been frozen to produce a Windows

executable. (Has been tested with py2exe, PyInstaller and cx_Freeze.)

One needs to call this function straight after the line of the main module.

For example:





If the line is omitted then trying to run the frozen executable will raise .

Calling has no effect when invoked on any operating system other than Windows. In

addition, if the module is being run normally by the Python interpreter on Windows (the program has not been

frozen), then has no effect.

The Python Library Reference, Release 3.13.2





Returns a list of the supported start methods, the first of which is the default. The possible start methods

are , and . Not all platforms support all methods. See Contexts and start

methods.

Added in version 3.4.

method=None

Return a context object which has the same attributes as the module.

If method is then the default context is returned. Otherwise method should be , ,

. is raised if the specified start method is not available. See Contexts and start

methods.

Added in version 3.4.

allow_none=False

Return the name of start method used for starting processes.

If the start method has not been fixed and allow_none is false, then the start method is fixed to the default and

the name is returned. If the start method has not been fixed and allow_none is true then is returned.

The return value can be , , or . See Contexts and start methods.

Added in version 3.4.

Changed in version 3.8: On macOS, the spawn start method is now the default. The fork start method should

be considered unsafe as it can lead to crashes of the subprocess. See bpo-33725.

executable

Set the path of the Python interpreter to use when starting a child process. (By default is

used). Embedders will probably need to do some thing like





before they can create child processes.

Changed in version 3.4: Now supported on POSIX when the start method is used.

Changed in version 3.11: Accepts a path-like object.

module_names

Set a list of module names for the forkserver main process to attempt to import so that their already imported

state is inherited by forked processes. Any when doing so is silently ignored. This can be used

as a performance enhancement to avoid repeated work in every process.

For this to work, it must be called before the forkserver process has been launched (before creating a or

starting a ).

Only meaningful when using the start method. See Contexts and start methods.

Added in version 3.4.

method, force=False

Set the method which should be used to start child processes. The method argument can be ,

or . Raises if the start method has already been set and force is not . If

method is and force is then the start method is set to . If method is and force is

then the context is set to the default context.

Note that this should be called at most once, and it should be protected inside the

clause of the main module.

See Contexts and start methods.

Added in version 3.4.

The Python Library Reference, Release 3.13.2



® Note

contains no analogues of , ,

, , , or .



Connection Objects

Connection objects allow the sending and receiving of picklable objects or strings. They can be thought of as message oriented connected sockets.

Connection objects are usually created using – see also Listeners and Clients.



obj

Send an object to the other end of the connection which should be read using .

The object must be picklable. Very large pickles (approximately 32 MiB+, though it depends on the OS)

may raise a exception.



Return an object sent from the other end of the connection using . Blocks until there is something

to receive. Raises if there is nothing left to receive and the other end was closed.



Return the file descriptor or handle used by the connection.



Close the connection.

This is called automatically when the connection is garbage collected.

timeout

Return whether there is any data available to be read.

If timeout is not specified then it will return immediately. If timeout is a number then this specifies the maximum time in seconds to block. If timeout is then an infinite timeout is used.

Note that multiple connection objects may be polled at once by using

.

buffer , offset, size

Send byte data from a bytes-like object as a complete message.

If offset is given then data is read from that position in buffer. If size is given then that many bytes will be read from buffer. Very large buffers (approximately 32 MiB+, though it depends on the OS) may raise a

exception

maxlength

Return a complete message of byte data sent from the other end of the connection as a string. Blocks

until there is something to receive. Raises if there is nothing left to receive and the other end has closed.

If maxlength is specified and the message is longer than maxlength then is raised and the connection will no longer be readable.

Changed in version 3.3: This function used to raise , which is now an alias of .

buffer , offset

Read into buffer a complete message of byte data sent from the other end of the connection and return

the number of bytes in the message. Blocks until there is something to receive. Raises if there is nothing left to receive and the other end was closed.

The Python Library Reference, Release 3.13.2



buffer must be a writable bytes-like object. If offset is given then the message will be written into the buffer from that position. Offset must be a non-negative integer less than the length of buffer (in bytes).

If the buffer is too short then a exception is raised and the complete message is available as where is the exception instance.

Changed in version 3.3: Connection objects themselves can now be transferred between processes using

and .

Connection objects also now support the context management protocol – see Context Manager Types.

returns the connection object, and calls .

For example:





Á Warning

The method automatically unpickles the data it receives, which can be a security risk

unless you can trust the process which sent the message.

Therefore, unless the connection object was produced using you should only use the and

methods after performing some sort of authentication. See Authentication keys.



Á Warning

If a process is killed while it is trying to read or write to a pipe then the data in the pipe is likely to become

corrupted, because it may become impossible to be sure where the message boundaries lie.



Synchronization primitives

Generally synchronization primitives are not as necessary in a multiprocess program as they are in a multithreaded

program. See the documentation for module.

Note that one can also create synchronization primitives by using a manager object – see Managers.

parties , action, timeout

A barrier object: a clone of .

Added in version 3.3.

value

A bounded semaphore object: a close analog of .

The Python Library Reference, Release 3.13.2



A solitary difference from its close analog exists: its method’s first argument is named block, as is

consistent with .



® Note

On macOS, this is indistinguishable from because is not implemented on that platform.



lock

A condition variable: an alias for .

If lock is specified then it should be a or object from .

Changed in version 3.3: The method was added.



A clone of .



A non-recursive lock object: a close analog of . Once a process or thread has acquired a

lock, subsequent attempts to acquire it from any process or thread will block until it is released; any process or

thread may release it. The concepts and behaviors of as it applies to threads are replicated

here in as it applies to either processes or threads, except as noted.

Note that is actually a factory function which returns an instance of

initialized with a default context.

supports the context manager protocol and thus may be used in statements.

block=True, timeout=None

Acquire a lock, blocking or non-blocking.

With the block argument set to (the default), the method call will block until the lock is in an unlocked state, then set it to locked and return . Note that the name of this first argument differs

from that in .

With the block argument set to , the method call does not block. If the lock is currently in a locked state, return ; otherwise set the lock to a locked state and return .

When invoked with a positive, floating-point value for timeout, block for at most the number of seconds specified by timeout as long as the lock can not be acquired. Invocations with a negative value for time-out are equivalent to a timeout of zero. Invocations with a timeout value of (the default) set the timeout period to infinite. Note that the treatment of negative or values for timeout differs from

the implemented behavior in . The timeout argument has no practical implications if the block argument is set to and is thus ignored. Returns if the lock has been acquired or if the timeout period has elapsed.



Release a lock. This can be called from any process or thread, not only the process or thread which originally acquired the lock.

Behavior is the same as in except that when invoked on an unlocked

lock, a is raised.



A recursive lock object: a close analog of . A recursive lock must be released by the

process or thread that acquired it. Once a process or thread has acquired a recursive lock, the same process or

thread may acquire it again without blocking; that process or thread must release it once for each time it has

been acquired.

Note that is actually a factory function which returns an instance of

initialized with a default context.

The Python Library Reference, Release 3.13.2



supports the context manager protocol and thus may be used in statements.

block=True, timeout=None

Acquire a lock, blocking or non-blocking.

When invoked with the block argument set to , block until the lock is in an unlocked state (not owned by any process or thread) unless the lock is already owned by the current process or thread. The current process or thread then takes ownership of the lock (if it does not already have ownership) and the recursion level inside the lock increments by one, resulting in a return value of . Note that there

are several differences in this first argument’s behavior compared to the implementation of

, starting with the name of the argument itself.

When invoked with the block argument set to , do not block. If the lock has already been acquired (and thus is owned) by another process or thread, the current process or thread does not take ownership and the recursion level within the lock is not changed, resulting in a return value of . If the lock is in an unlocked state, the current process or thread takes ownership and the recursion level is incremented, resulting in a return value of .

Use and behaviors of the timeout argument are the same as in . Note that some of

these behaviors of timeout differ from the implemented behaviors in .



Release a lock, decrementing the recursion level. If after the decrement the recursion level is zero, reset the lock to unlocked (not owned by any process or thread) and if any other processes or threads are blocked waiting for the lock to become unlocked, allow exactly one of them to proceed. If after the decrement the recursion level is still nonzero, the lock remains locked and owned by the calling process or thread.

Only call this method when the calling process or thread owns the lock. An is raised if this method is called by a process or thread other than the owner or if the lock is in an unlocked (unowned) state. Note that the type of exception raised in this situation differs from the implemented

behavior in .

value

A semaphore object: a close analog of .

A solitary difference from its close analog exists: its method’s first argument is named block, as is

consistent with .



® Note

On macOS, is unsupported, so calling with a timeout will emulate that function’s

behavior using a sleeping loop.



® Note

Some of this package’s functionality requires a functioning shared semaphore implementation on the host oper-

ating system. Without one, the module will be disabled, and attempts to

import it will result in an . See bpo-3770 for additional information.



Shared Objects

It is possible to create shared objects using shared memory which can be inherited by child processes.

typecode_or_type, *args, lock=True

Return a object allocated from shared memory. By default the return value is actually a synchronized

wrapper for the object. The object itself can be accessed via the value attribute of a .

typecode_or_type determines the type of the returned object: it is either a ctypes type or a one character

typecode of the kind used by the module. *args is passed on to the constructor for the type.

The Python Library Reference, Release 3.13.2



If lock is (the default) then a new recursive lock object is created to synchronize access to the value. If

lock is a or object then that will be used to synchronize access to the value. If lock is

then access to the returned object will not be automatically protected by a lock, so it will not necessarily be

“process-safe”.

Operations like which involve a read and write are not atomic. So if, for instance, you want to atomically

increment a shared value it is insufficient to just do





Assuming the associated lock is recursive (which it is by default) you can instead do





Note that lock is a keyword-only argument.

typecode_or_type, size_or_initializer, *, lock=True

Return a ctypes array allocated from shared memory. By default the return value is actually a synchronized

wrapper for the array.

typecode_or_type determines the type of the elements of the returned array: it is either a ctypes type or a one

character typecode of the kind used by the module. If size_or_initializer is an integer, then it determines

the length of the array, and the array will be initially zeroed. Otherwise, size_or_initializer is a sequence which

is used to initialize the array and whose length determines the length of the array.

If lock is (the default) then a new lock object is created to synchronize access to the value. If lock is a

or object then that will be used to synchronize access to the value. If lock is then access

to the returned object will not be automatically protected by a lock, so it will not necessarily be “process-safe”.

Note that lock is a keyword only argument.

Note that an array of has value and raw attributes which allow one to use it to store and

retrieve strings.



The module

The module provides functions for allocating objects from shared memory which can be inherited by child processes.



® Note

Although it is possible to store a pointer in shared memory remember that this will refer to a location in the

address space of a specific process. However, the pointer is quite likely to be invalid in the context of a second

process and trying to dereference the pointer from the second process may cause a crash.



typecode_or_type, size_or_initializer

Return a ctypes array allocated from shared memory.

typecode_or_type determines the type of the elements of the returned array: it is either a ctypes type or a one

character typecode of the kind used by the module. If size_or_initializer is an integer then it determines

the length of the array, and the array will be initially zeroed. Otherwise size_or_initializer is a sequence which

is used to initialize the array and whose length determines the length of the array.

Note that setting and getting an element is potentially non-atomic – use instead to make sure that

access is automatically synchronized using a lock.

typecode_or_type, *args

Return a ctypes object allocated from shared memory.

typecode_or_type determines the type of the returned object: it is either a ctypes type or a one character

typecode of the kind used by the module. *args is passed on to the constructor for the type.

The Python Library Reference, Release 3.13.2



Note that setting and getting the value is potentially non-atomic – use instead to make sure that

access is automatically synchronized using a lock.

Note that an array of has and attributes which allow one to use it to store and

retrieve strings – see documentation for .

typecode_or_type, size_or_initializer, *, lock=True

The same as except that depending on the value of lock a process-safe synchronization wrapper

may be returned instead of a raw ctypes array.

If lock is (the default) then a new lock object is created to synchronize access to the value. If lock is a

or object then that will be used to synchronize access to the value. If lock is then access

to the returned object will not be automatically protected by a lock, so it will not necessarily be “process-safe”.

Note that lock is a keyword-only argument.

typecode_or_type, *args, lock=True

The same as except that depending on the value of lock a process-safe synchronization wrapper

may be returned instead of a raw ctypes object.

If lock is (the default) then a new lock object is created to synchronize access to the value. If lock is a

or object then that will be used to synchronize access to the value. If lock is then access

to the returned object will not be automatically protected by a lock, so it will not necessarily be “process-safe”.

Note that lock is a keyword-only argument.

obj

Return a ctypes object allocated from shared memory which is a copy of the ctypes object obj.

obj, lock

Return a process-safe wrapper object for a ctypes object which uses lock to synchronize access. If lock is

(the default) then a object is created automatically.

A synchronized wrapper will have two methods in addition to those of the object it wraps: returns

the wrapped object and returns the lock object used for synchronization.

Note that accessing the ctypes object through the wrapper can be a lot slower than accessing the raw ctypes

object.

Changed in version 3.5: Synchronized objects support the context manager protocol.

The table below compares the syntax for creating shared ctypes objects from shared memory with the normal ctypes

syntax. (In the table is some subclass of .)



ctypes sharedctypes using type sharedctypes using typecode

c_double(2.4) RawValue(c_double, 2.4) RawValue(‘d’, 2.4)

MyStruct(4, 6) RawValue(MyStruct, 4, 6)

(c_short * 7)() RawArray(c_short, 7) RawArray(‘h’, 7)

(c_int * 3)(9, 2, 8) RawArray(c_int, (9, 2, 8)) RawArray(‘i’, (9, 2, 8))



Below is an example where a number of ctypes objects are modified by a child process:





The Python Library Reference, Release 3.13.2





The results printed are





Managers

Managers provide a way to create data which can be shared between different processes, including sharing over a network between processes running on different machines. A manager object controls a server process which manages shared objects. Other processes can access the shared objects by using proxies.



Returns a started object which can be used for sharing objects between processes. The returned

manager object corresponds to a spawned child process and has methods which will create shared objects and

return corresponding proxies.

Manager processes will be shutdown as soon as they are garbage collected or their parent process exits. The manager

classes are defined in the module:

address=None, authkey=None, serializer=’pickle’,

ctx=None, *, shutdown_timeout=1.0

Create a BaseManager object.

Once created one should call or to ensure that the manager

object refers to a started manager process.

address is the address on which the manager process listens for new connections. If address is then an

arbitrary one is chosen.

authkey is the authentication key which will be used to check the validity of incoming connections to the server

process. If authkey is then is used. Otherwise authkey is used and it

must be a byte string.

serializer must be (use serialization) or (use serializa-

tion).

The Python Library Reference, Release 3.13.2



ctx is a context object, or (use the current context). See the function.

shutdown_timeout is a timeout in seconds used to wait until the process used by the manager completes in the

method. If the shutdown times out, the process is terminated. If terminating the process also

times out, the process is killed.

Changed in version 3.11: Added the shutdown_timeout parameter.

initializer , initargs

Start a subprocess to start the manager. If initializer is not then the subprocess will call when it starts.



Returns a object which represents the actual server under the control of the Manager. The object supports the method:





additionally has an attribute.



Connect a local manager object to a remote manager process:





Stop the process used by the manager. This is only available if has been used to start the server process.

This can be called multiple times.

typeid, callable, proxytype, exposed, method_to_typeid, create_method

A classmethod which can be used for registering a type or callable with the manager class.

typeid is a “type identifier” which is used to identify a particular type of shared object. This must be a string.

callable is a callable used for creating objects for this type identifier. If a manager instance will be

connected to the server using the method, or if the create_method argument is then this can be left as .

proxytype is a subclass of which is used to create proxies for shared objects with this typeid. If then a proxy class is created automatically.

exposed is used to specify a sequence of method names which proxies for this typeid should be allowed

to access using . (If exposed is then is used instead if it exists.) In the case where no exposed list is specified, all “public methods” of the shared object will be accessible. (Here a “public method” means any attribute which has a method and whose name does not begin with .)

method_to_typeid is a mapping used to specify the return type of those exposed methods which should return a proxy. It maps method names to typeid strings. (If method_to_typeid is then is used instead if it exists.) If a method’s name is not a key of this mapping or if the mapping is then the object returned by the method will be copied by value.

create_method determines whether a method should be created with name typeid which can be used to tell the server process to create a new shared object and return a proxy for it. By default it is .

instances also have one read-only property:

The Python Library Reference, Release 3.13.2





The address used by the manager.

Changed in version 3.3: Manager objects support the context management protocol – see Context Manager

Types. starts the server process (if it has not already started) and then returns the manager

object. calls .

In previous versions did not start the manager’s server process if it was not already started.



A subclass of which can be used for the synchronization of processes. Objects of this type are

returned by .

Its methods create and return Proxy Objects for a number of commonly used data types to be synchronized

across processes. This notably includes shared lists and dictionaries.

parties, action, timeout

Create a shared object and return a proxy for it.

Added in version 3.3.

value

Create a shared object and return a proxy for it.

lock

Create a shared object and return a proxy for it.

If lock is supplied then it should be a proxy for a or object.

Changed in version 3.3: The method was added.



Create a shared object and return a proxy for it.



Create a shared object and return a proxy for it.



Create a shared object and return a proxy for it.

maxsize

Create a shared object and return a proxy for it.



Create a shared object and return a proxy for it.

value

Create a shared object and return a proxy for it.

typecode, sequence

Create an array and return a proxy for it.

typecode, value

Create an object with a writable attribute and return a proxy for it.



mapping

sequence

Create a shared object and return a proxy for it.





The Python Library Reference, Release 3.13.2



sequence

Create a shared object and return a proxy for it.

Changed in version 3.6: Shared objects are capable of being nested. For example, a shared container object

such as a shared list can contain other shared objects which will all be managed and synchronized by the

.



A type that can register with .

A namespace object has no public methods, but does have writable attributes. Its representation shows the

values of its attributes.

However, when using a proxy for a namespace object, an attribute beginning with will be an attribute of

the proxy and not an attribute of the referent:





Customized managers

To create one’s own manager, one creates a subclass of and uses the classmethod to register new types or callables with the manager class. For example:





Using a remote manager

It is possible to run a manager server on one machine and have clients use it from other machines (assuming that the firewalls involved allow it).

Running the following commands creates a server for a single shared queue which remote clients can access:





The Python Library Reference, Release 3.13.2





One client can access the server as follows:





Another client can also use it:





Local processes can also access that queue, using the code from above on the client to access it remotely:





Proxy Objects

A proxy is an object which refers to a shared object which lives (presumably) in a different process. The shared object is said to be the referent of the proxy. Multiple proxy objects may have the same referent.

A proxy object has methods which invoke corresponding methods of its referent (although not every method of the referent will necessarily be available through the proxy). In this way, a proxy can be used just like its referent can:



The Python Library Reference, Release 3.13.2





Notice that applying to a proxy will return the representation of the referent, whereas applying will return the representation of the proxy.

An important feature of proxy objects is that they are picklable so they can be passed between processes. As such, a

referent can contain Proxy Objects. This permits nesting of these managed lists, dicts, and other Proxy Objects:





Similarly, dict and list proxies may be nested inside one another:





If standard (non-proxy) or objects are contained in a referent, modifications to those mutable values will not be propagated through the manager because the proxy has no way of knowing when the values contained within are modified. However, storing a value in a container proxy (which triggers a on the proxy object) does propagate through the manager and so to effectively modify such an item, one could re-assign the modified value to the container proxy:





This approach is perhaps less convenient than employing nested Proxy Objects for most use cases but also demonstrates a level of control over the synchronization.

The Python Library Reference, Release 3.13.2



® Note

The proxy types in do nothing to support comparisons by value. So, for instance, we have:





One should just use a copy of the referent instead when making comparisons.





Proxy objects are instances of subclasses of .

methodname, args, kwds

Call and return the result of a method of the proxy’s referent.

If is a proxy whose referent is then the expression





will evaluate the expression





in the manager’s process.

The returned value will be a copy of the result of the call or a proxy to a new shared object – see

documentation for the method_to_typeid argument of .

If an exception is raised by the call, then is re-raised by . If some other exception is raised in the manager’s process then this is converted into a exception and is raised by

.

Note in particular that an exception will be raised if methodname has not been exposed.

An example of the usage of :





Return a copy of the referent.

If the referent is unpicklable then this will raise an exception.



Return a representation of the proxy object.



Return the representation of the referent.



The Python Library Reference, Release 3.13.2



Cleanup

A proxy object uses a weakref callback so that when it gets garbage collected it deregisters itself from the manager which owns its referent.

A shared object gets deleted from the manager process when there are no longer any proxies referring to it.



Process Pools

One can create a pool of processes which will carry out tasks submitted to it with the class.

processes , initializer, initargs, maxtasksperchild, context

A process pool object which controls a pool of worker processes to which jobs can be submitted. It supports

asynchronous results with timeouts and callbacks and has a parallel map implementation.

processes is the number of worker processes to use. If processes is then the number returned by

is used.

If initializer is not then each worker process will call when it starts.

maxtasksperchild is the number of tasks a worker process can complete before it will exit and be replaced with

a fresh worker process, to enable unused resources to be freed. The default maxtasksperchild is , which

means worker processes will live as long as the pool.

context can be used to specify the context used for starting the worker processes. Usually a pool is created

using the function or the method of a context object. In both cases

context is set appropriately.

Note that the methods of the pool object should only be called by the process which created the pool.



Á Warning

objects have internal resources that need to be properly managed (like any

other resource) by using the pool as a context manager or by calling and manually. Failure to do this can lead to the process hanging on finalization.

Note that it is not correct to rely on the garbage collector to destroy the pool as CPython does not assure that the finalizer of the pool will be called (see for more information).



Changed in version 3.2: Added the maxtasksperchild parameter.

Changed in version 3.4: Added the context parameter.

Changed in version 3.13: processes uses by default, instead of

.



® Note

Worker processes within a typically live for the complete duration of the Pool’s work queue. A frequent pattern found in other systems (such as Apache, mod_wsgi, etc) to free resources held by workers is to allow a worker within a pool to complete only a set amount of work before being exiting, being cleaned

up and a new process spawned to replace the old one. The maxtasksperchild argument to the exposes this ability to the end user.



func, args, kwds

Call func with arguments args and keyword arguments kwds. It blocks until the result is ready. Given

this blocks, is better suited for performing work in parallel. Additionally, func is only executed in one of the workers of the pool.



The Python Library Reference, Release 3.13.2



func , args, kwds, callback, error_callback

A variant of the method which returns a object.

If callback is specified then it should be a callable which accepts a single argument. When the result becomes ready callback is applied to it, that is unless the call failed, in which case the error_callback is applied instead.

If error_callback is specified then it should be a callable which accepts a single argument. If the target function fails, then the error_callback is called with the exception instance.

Callbacks should complete immediately since otherwise the thread which handles the results will get blocked.

func, iterable , chunksize

A parallel equivalent of the built-in function (it supports only one iterable argument though, for

multiple iterables see ). It blocks until the result is ready.

This method chops the iterable into a number of chunks which it submits to the process pool as separate tasks. The (approximate) size of these chunks can be specified by setting chunksize to a positive integer.

Note that it may cause high memory usage for very long iterables. Consider using or

with explicit chunksize option for better efficiency.

func, iterable, chunksize, callback, error_callback

A variant of the method which returns a object.

If callback is specified then it should be a callable which accepts a single argument. When the result becomes ready callback is applied to it, that is unless the call failed, in which case the error_callback is applied instead.

If error_callback is specified then it should be a callable which accepts a single argument. If the target function fails, then the error_callback is called with the exception instance.

Callbacks should complete immediately since otherwise the thread which handles the results will get blocked.

func, iterable , chunksize

A lazier version of .

The chunksize argument is the same as the one used by the method. For very long iterables using a large value for chunksize can make the job complete much faster than using the default value of .

Also if chunksize is then the method of the iterator returned by the method has an

optional timeout parameter: will raise if the result cannot be returned within timeout seconds.

func, iterable, chunksize

The same as except that the ordering of the results from the returned iterator should be consid-ered arbitrary. (Only when there is only one worker process is the order guaranteed to be “correct”.)

func, iterable, chunksize

Like except that the elements of the iterable are expected to be iterables that are unpacked as arguments.

Hence an iterable of results in .

Added in version 3.3.

func, iterable, chunksize, callback, error_callback

A combination of and that iterates over iterable of iterables and calls func with the iterables unpacked. Returns a result object.

Added in version 3.3.



The Python Library Reference, Release 3.13.2





Prevents any more tasks from being submitted to the pool. Once all the tasks have been completed the worker processes will exit.



Stops the worker processes immediately without completing outstanding work. When the pool object is

garbage collected will be called immediately.



Wait for the worker processes to exit. One must call or before using .

Changed in version 3.3: Pool objects now support the context management protocol – see Context Manager

Types. returns the pool object, and calls .



The class of the result returned by and .

timeout

Return the result when it arrives. If timeout is not and the result does not arrive within timeout

seconds then is raised. If the remote call raised an exception then

that exception will be reraised by .

timeout

Wait until the result is available or until timeout seconds pass.



Return whether the call has completed.



Return whether the call completed without raising an exception. Will raise if the result is not ready.

Changed in version 3.7: If the result is not ready, is raised instead of .

The following example demonstrates the use of a pool:





The Python Library Reference, Release 3.13.2



Listeners and Clients

Usually message passing between processes is done using queues or by using objects returned by

.

However, the module allows some extra flexibility. It basically gives a high level message oriented API for dealing with sockets or Windows named pipes. It also has support for digest authentication

using the module, and for polling multiple connections at the same time.

connection, authkey

Send a randomly generated message to the other end of the connection and wait for a reply.

If the reply matches the digest of the message using authkey as the key then a welcome message is sent to the

other end of the connection. Otherwise is raised.

connection, authkey

Receive a message, calculate the digest of the message using authkey as the key, and then send the digest back.

If a welcome message is not received, then is raised.

address, family, authkey

Attempt to set up a connection to the listener which is using address address, returning a .

The type of the connection is determined by family argument, but this can generally be omitted since it can

usually be inferred from the format of address. (See Address Formats)

If authkey is given and not , it should be a byte string and will be used as the secret key for an HMAC-

based authentication challenge. No authentication is done if authkey is . is

raised if authentication fails. See Authentication keys.

address , family, backlog, authkey

A wrapper for a bound socket or Windows named pipe which is ‘listening’ for connections.

address is the address to be used by the bound socket or named pipe of the listener object.



® Note

If an address of ‘0.0.0.0’ is used, the address will not be a connectable end point on Windows. If you require a connectable end-point, you should use ‘127.0.0.1’.



family is the type of socket (or named pipe) to use. This can be one of the strings (for a TCP

socket), (for a Unix domain socket) or (for a Windows named pipe). Of these only

the first is guaranteed to be available. If family is then the family is inferred from the format of address.

If address is also then a default is chosen. This default is the family which is assumed to be the fastest

available. See Address Formats. Note that if family is and address is then the socket will

be created in a private temporary directory created using .

If the listener object uses a socket then backlog (1 by default) is passed to the method of the socket

once it has been bound.

If authkey is given and not , it should be a byte string and will be used as the secret key for an HMAC-

based authentication challenge. No authentication is done if authkey is . is

raised if authentication fails. See Authentication keys.



Accept a connection on the bound socket or named pipe of the listener object and return a

object. If authentication is attempted and fails, then is raised.



Close the bound socket or named pipe of the listener object. This is called automatically when the listener is garbage collected. However it is advisable to call it explicitly.

Listener objects have the following read-only properties:

The Python Library Reference, Release 3.13.2





The address which is being used by the Listener object.



The address from which the last accepted connection came. If this is unavailable then it is .

Changed in version 3.3: Listener objects now support the context management protocol – see Context Manager

Types. returns the listener object, and calls .

object_list, timeout=None

Wait till an object in object_list is ready. Returns the list of those objects in object_list which are ready. If

timeout is a float then the call blocks for at most that many seconds. If timeout is then it will block for

an unlimited period. A negative timeout is equivalent to a zero timeout.

For both POSIX and Windows, an object can appear in object_list if it is

• a readable object;

• a connected and readable object; or

• the attribute of a object.

A connection or socket object is ready when there is data available to be read from it, or the other end has been

closed.

POSIX: almost equivalent

. The difference is that, if is interrupted by a signal, it can raise

with an error number of , whereas will not.

Windows: An item in object_list must either be an integer handle which is waitable (according to the definition

used by the documentation of the Win32 function ) or it can be an object with

a method which returns a socket handle or pipe handle. (Note that pipe handles and socket handles

are not waitable handles.)

Added in version 3.3.

Examples

The following server code creates a listener which uses as an authentication key. It then waits for a connection and sends some data to the client:





The following code connects to the server and receives some data from the server:





The Python Library Reference, Release 3.13.2





The following code uses to wait for messages from multiple processes at once:





Address Formats

• An address is a tuple of the form where hostname is a string and port is an

integer.

• An address is a string representing a filename on the filesystem.

• An address is a string of the form . To use to connect

to a named pipe on a remote computer called ServerName one should use an address of the form

instead.

Note that any string beginning with two backslashes is assumed by default to be an address rather than an address.



The Python Library Reference, Release 3.13.2



Authentication keys

When one uses , the data received is automatically unpickled. Unfortunately unpickling data

from an untrusted source is a security risk. Therefore and use the module to provide digest authentication.

An authentication key is a byte string which can be thought of as a password: once a connection is established both ends will demand proof that the other knows the authentication key. (Demonstrating that both ends are using the same key does not involve sending the key over the connection.)

If authentication is requested but no authentication key is specified then the return value of

is used (see ). This value will be automatically inherited by any object that the current process creates. This means that (by default) all processes of a multi-process program will share a single authentication key which can be used when setting up connections between themselves.

Suitable authentication keys can also be generated by using .



Logging

Some support for logging is available. Note, however, that the package does not use process shared locks so it is possible (depending on the handler type) for messages from different processes to get mixed up.



Returns the logger used by . If necessary, a new one will be created.

When first created the logger has level and no default handler. Messages sent to this logger

will not by default propagate to the root logger.

Note that on Windows child processes will only inherit the level of the parent process’s logger – any other

customization of the logger will not be inherited.

level=None

This function performs a call to but in addition to returning the logger created by get_logger, it

adds a handler which sends output to using format

. You can modify of the logger by passing a argument.

Below is an example session with logging turned on:





For a full table of logging levels, see the module.



The module

replicates the API of but is no more than a wrapper around the

module.

In particular, the function provided by returns an instance of , which

is a subclass of that supports all the same method calls but uses a pool of worker threads rather than worker processes.



The Python Library Reference, Release 3.13.2



processes , initializer, initargs

A thread pool object which controls a pool of worker threads to which jobs can be submitted. in-

stances are fully interface compatible with instances, and their resources must also be properly managed,

either by using the pool as a context manager or by calling and manually.

processes is the number of worker threads to use. If processes is then the number returned by

is used.

If initializer is not then each worker process will call when it starts.

Unlike , maxtasksperchild and context cannot be provided.



® Note

A shares the same interface as , which is designed around a pool of processes and

predates the introduction of the module. As such, it inherits some operations that don’t make sense for a pool backed by threads, and it has its own type for representing the status of

asynchronous jobs, , that is not understood by any other libraries.

Users should generally prefer to use , which has a sim-

pler interface that was designed around threads from the start, and which returns

instances that are compatible with many other libraries, including .





There are certain guidelines and idioms which should be adhered to when using .



All start methods

The following applies to all start methods.

Avoid shared state

As far as possible one should try to avoid shifting large amounts of data between processes.

It is probably best to stick to using queues or pipes for communication between processes rather than

using the lower level synchronization primitives.

Picklability

Ensure that the arguments to the methods of proxies are picklable.

Thread safety of proxies

Do not use a proxy object from more than one thread unless you protect it with a lock.

(There is never a problem with different processes using the same proxy.)

Joining zombie processes

On POSIX when a process finishes but has not been joined it becomes a zombie. There should never be

very many because each time a new process starts (or is called) all completed

processes which have not yet been joined will be joined. Also calling a finished process’s

will join the process. Even so it is probably good practice to explicitly join all the processes

that you start.

Better to inherit than pickle/unpickle

When using the spawn or forkserver start methods many types from need to be

picklable so that child processes can use them. However, one should generally avoid sending shared

objects to other processes using pipes or queues. Instead you should arrange the program so that a process

which needs access to a shared resource created elsewhere can inherit it from an ancestor process.

Avoid terminating processes

The Python Library Reference, Release 3.13.2



Using the method to stop a process is liable to cause any shared resources (such

as locks, semaphores, pipes and queues) currently being used by the process to become broken or un-

available to other processes.

Therefore it is probably best to only consider using on processes which never

use any shared resources.

Joining processes that use queues

Bear in mind that a process that has put items in a queue will wait before terminating until all the

buffered items are fed by the “feeder” thread to the underlying pipe. (The child process can call the

method of the queue to avoid this behaviour.)

This means that whenever you use a queue you need to make sure that all items which have been put

on the queue will eventually be removed before the process is joined. Otherwise you cannot be sure

that processes which have put items on the queue will terminate. Remember also that non-daemonic

processes will be joined automatically.

An example which will deadlock is the following:





A fix here would be to swap the last two lines (or simply remove the line).

Explicitly pass resources to child processes

On POSIX using the fork start method, a child process can make use of a shared resource created in

a parent process using a global resource. However, it is better to pass the object as an argument to the

constructor for the child process.

Apart from making the code (potentially) compatible with Windows and the other start methods this

also ensures that as long as the child process is still alive the object will not be garbage collected in the

parent process. This might be important if some resource is freed when the object is garbage collected

in the parent process.

So for instance





should be rewritten as





The Python Library Reference, Release 3.13.2





Beware of replacing with a “file like object”

originally unconditionally called:





in the method — this resulted in issues with

processes-in-processes. This has been changed to:





Which solves the fundamental issue of processes colliding with each other resulting in a bad file descrip-

tor error, but introduces a potential danger to applications which replace with a “file-like

object” with output buffering. This danger is that if multiple processes call on this file-like

object, it could result in the same data being flushed to the object multiple times, resulting in corruption.

If you write a file-like object and implement your own caching, you can make it fork-safe by storing the

pid whenever you append to the cache, and discarding the cache when the pid changes. For example:





For more information, see bpo-5155, bpo-5313 and bpo-5331



The spawn and forkserver start methods

There are a few extra restrictions which don’t apply to the fork start method.

More picklability

Ensure that all arguments to are picklable. Also, if you subclass then

make sure that instances will be picklable when the method is called.

Global variables

Bear in mind that if code run in a child process tries to access a global variable, then the value it sees

(if any) may not be the same as the value in the parent process at the time that was

called.

However, global variables which are just module level constants cause no problems.

Safe importing of main module

Make sure that the main module can be safely imported by a new Python interpreter without causing

unintended side effects (such as starting a new process).

For example, using the spawn or forkserver start method running the following module would fail with

a :

The Python Library Reference, Release 3.13.2





Instead one should protect the “entry point” of the program by using

as follows:





(The line can be omitted if the program will be run normally instead of frozen.)

This allows the newly spawned Python interpreter to safely import the module and then run the module’s

function.

Similar restrictions apply if a pool or manager is created in the main module.





Demonstration of how to create and use customized managers and proxies:





The Python Library Reference, Release 3.13.2





The Python Library Reference, Release 3.13.2





Using :





The Python Library Reference, Release 3.13.2





The Python Library Reference, Release 3.13.2





An example showing how to use queues to feed tasks to a collection of worker processes and collect the results:





The Python Library Reference, Release 3.13.2





The Python Library Reference, Release 3.13.2





Source code: Lib/multiprocessing/shared_memory.py

Added in version 3.8.



This module provides a class, , for the allocation and management of shared memory to be ac-cessed by one or more processes on a multicore or symmetric multiprocessor (SMP) machine. To assist with

the life-cycle management of shared memory especially across distinct processes, a subclass,

, is also provided in the module.

In this module, shared memory refers to “POSIX style” shared memory blocks (though is not necessarily imple-mented explicitly as such) and does not refer to “distributed shared memory”. This style of shared memory permits distinct processes to potentially read and write to a common (or shared) region of volatile memory. Processes are conventionally limited to only have access to their own process memory space but shared memory permits the shar-ing of data between processes, avoiding the need to instead send messages between processes containing that data. Sharing data directly via memory can provide significant performance benefits compared to sharing data via disk or socket or other communications requiring the serialization/deserialization and copying of data.

name=None, create=False, size=0, *,

track=True

Create an instance of the class for either creating a new shared memory block or attaching

to an existing shared memory block. Each shared memory block is assigned a unique name. In this way, one

process can create a shared memory block with a particular name and a different process can attach to that

same shared memory block using that same name.

As a resource for sharing data across processes, shared memory blocks may outlive the original process that

created them. When one process no longer needs access to a shared memory block that might still be needed

by other processes, the method should be called. When a shared memory block is no longer needed

by any process, the method should be called to ensure proper cleanup.

Parameters



The Python Library Reference, Release 3.13.2



• ( ) – The unique name for the requested shared memory, specified as

a string. When creating a new shared memory block, if (the default) is supplied for the name, a novel name will be generated.

• () – Control whether a new shared memory block is created () or an

existing shared memory block is attached ().

• () – The requested number of bytes when creating a new shared memory block.

Because some platforms choose to allocate chunks of memory based upon that platform’s memory page size, the exact size of the shared memory block may be larger or equal to the size requested. When attaching to an existing shared memory block, the size parameter is ignored.

• () – When , register the shared memory block with a resource tracker

process on platforms where the OS does not do this automatically. The resource tracker ensures proper cleanup of the shared memory even if all other processes with access to the memory exit without doing so. Python processes created from a common ancestor

using facilities share a single resource tracker process, and the life-time of shared memory segments is handled automatically among these processes. Python processes created in any other way will receive their own resource tracker when access-ing shared memory with track enabled. This will cause the shared memory to be deleted by the resource tracker of the first process that terminates. To avoid this issue, users of

or standalone Python processes should set track to when there is al-ready another process in place that does the bookkeeping. track is ignored on Windows, which has its own tracking and automatically deletes shared memory when all handles to it have been closed.

Changed in version 3.13: Added the track parameter.



Close the file descriptor/handle to the shared memory from this instance. should be called once access to the shared memory block from this instance is no longer needed. Depending on operating system, the underlying memory may or may not be freed even if all handles to it have been closed. To

ensure proper cleanup, use the method.



Delete the underlying shared memory block. This should be called only once per shared memory block

regardless of the number of handles to it, even in other processes. and can be

called in any order, but trying to access data inside a shared memory block after may result in memory access errors, depending on platform.

This method has no effect on Windows, where the only way to delete a shared memory block is to close all handles.



A memoryview of contents of the shared memory block.



Read-only access to the unique name of the shared memory block.



Read-only access to size in bytes of the shared memory block.

The following example demonstrates low-level use of instances:





The Python Library Reference, Release 3.13.2





The following example demonstrates a practical use of the class with NumPy arrays, accessing the same from two distinct Python shells:





The Python Library Reference, Release 3.13.2





address , authkey

A subclass of which can be used for the management of

shared memory blocks across processes.

A call to on a instance causes a new process to be started. This new

process’s sole purpose is to manage the life cycle of all shared memory blocks created through it. To trigger

the release of all shared memory blocks managed by that process, call on the instance. This

triggers a call on all of the objects managed by that process and then stops the

process itself. By creating instances through a , we avoid the need

to manually track and trigger the freeing of shared memory resources.

This class provides methods for creating and returning instances and for creating a list-like

object () backed by shared memory.

Refer to for a description of the inherited address and authkey optional input arguments and

how they may be used to connect to an existing service from other processes.

size

Create and return a new object with the specified size in bytes.

sequence

Create and return a new object, initialized by the values from the input sequence.

The following example demonstrates the basic mechanisms of a :





The following example depicts a potentially more convenient pattern for using objects via the statement to ensure that all shared memory blocks are released after they are no longer needed:





When using a in a statement, the shared memory blocks created using that manager are all released when the statement’s code block finishes execution.

sequence=None, *, name=None

The Python Library Reference, Release 3.13.2



Provide a mutable list-like object where all values stored within are stored in a shared memory block. This

constrains storable values to the following built-in data types:

• (signed 64-bit)

•

•

• (less than 10M bytes each when encoded as UTF-8)

• (less than 10M bytes each)

•

It also notably differs from the built-in type in that these lists can not change their overall length (i.e. no

, , etc.) and do not support the dynamic creation of new instances via

slicing.

sequence is used in populating a new full of values. Set to to instead attach to an

already existing by its unique shared memory name.

name is the unique name for the requested shared memory, as described in the definition for .

When attaching to an existing , specify its shared memory block’s unique name while leaving

sequence set to .



® Note

A known issue exists for and values. If they end with nul bytes or characters, those may be silently stripped when fetching them by index from the . This

behavior is considered a bug and may go away in the future. See gh-106939.



For applications where rstripping of trailing nulls is a problem, work around it by always unconditionally

appending an extra non-0 byte to the end of such values when storing and unconditionally removing it when

fetching:





value

Return the number of occurrences of value.

value

Return first index position of value. Raise if value is not present.



Read-only attribute containing the packing format used by all currently stored values.

The Python Library Reference, Release 3.13.2





The instance where the values are stored.

The following example demonstrates basic use of a instance:





The following example depicts how one, two, or many processes may access the same by supplying the name of the shared memory block behind it:





The following examples demonstrates that (and underlying ) objects can be pickled and unpickled if needed. Note, that it will still be the same shared object. This happens, because the deserialized object has the same unique name and is just attached to an existing object with the same name (if the object is still alive):





The Python Library Reference, Release 3.13.2





Currently, there is only one module in this package:

• – Launching parallel tasks





Added in version 3.2.

Source code: Lib/concurrent/futures/thread.py and Lib/concurrent/futures/process.py



The module provides a high-level interface for asynchronously executing callables.

The asynchronous execution can be performed with threads, using , or separate processes,

using . Both implement the same interface, which is defined by the abstract class.

Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.





An abstract class that provides methods to execute calls asynchronously. It should not be used directly, but

through its concrete subclasses.

fn, / , *args, **kwargs

Schedules the callable, fn, to be executed as and returns a object representing the execution of the callable.





The Python Library Reference, Release 3.13.2



fn, *iterables, timeout=None, chunksize=1

Similar to except:

• the iterables are collected immediately rather than lazily;

• fn is executed asynchronously and several calls to fn may be made concurrently.

The returned iterator raises a if is called and the result isn’t available after

timeout seconds from the original call to . timeout can be an int or a float. If timeout is not specified or , there is no limit to the wait time.

If a fn call raises an exception, then that exception will be raised when its value is retrieved from the iterator.

When using , this method chops iterables into a number of chunks which it submits to the pool as separate tasks. The (approximate) size of these chunks can be specified by setting chunksize to a positive integer. For very long iterables, using a large value for chunksize can significantly

improve performance compared to the default size of 1. With , chunksize has no effect.

Changed in version 3.5: Added the chunksize argument.

wait=True, *, cancel_futures=False

Signal the executor that it should free any resources that it is using when the currently pending futures

are done executing. Calls to and made after shutdown will

raise .

If wait is then this method will not return until all the pending futures are done executing and the resources associated with the executor have been freed. If wait is then this method will return immediately and the resources associated with the executor will be freed when all pending futures are done executing. Regardless of the value of wait, the entire Python program will not exit until all pending futures are done executing.

If cancel_futures is , this method will cancel all pending futures that the executor has not started running. Any futures that are completed or running won’t be cancelled, regardless of the value of can-cel_futures.

If both cancel_futures and wait are , all futures that the executor has started running will be com-pleted prior to this method returning. The remaining futures are cancelled.

You can avoid having to call this method explicitly if you use the statement, which will shutdown

the (waiting as if were called with wait set to ):





Changed in version 3.9: Added cancel_futures.





is an subclass that uses a pool of threads to execute calls asynchronously.

Deadlocks can occur when the callable associated with a waits on the results of another . For example:





The Python Library Reference, Release 3.13.2





And:





max_workers=None, thread_name_prefix=” ,

initializer=None, initargs=()

An subclass that uses a pool of at most max_workers threads to execute calls asynchronously.

All threads enqueued to will be joined before the interpreter can exit. Note that the

exit handler which does this is executed before any exit handlers added using . This means exceptions

in the main thread must be caught and handled in order to signal threads to exit gracefully. For this reason, it

is recommended that not be used for long-running tasks.

initializer is an optional callable that is called at the start of each worker thread; initargs is a tuple of argu-

ments passed to the initializer. Should initializer raise an exception, all currently pending jobs will raise a

, as well as any attempt to submit more jobs to the pool.

Changed in version 3.5: If max_workers is or not given, it will default to the number of processors on the

machine, multiplied by , assuming that is often used to overlap I/O instead of CPU

work and the number of workers should be higher than the number of workers for .

Changed in version 3.6: Added the thread_name_prefix parameter to allow users to control the

names for worker threads created by the pool for easier debugging.

Changed in version 3.7: Added the initializer and initargs arguments.

Changed in version 3.8: Default value of max_workers is changed to .

This default value preserves at least 5 workers for I/O bound tasks. It utilizes at most 32 CPU cores for CPU

bound tasks which release the GIL. And it avoids using very large resources implicitly on many-core machines.

ThreadPoolExecutor now reuses idle worker threads before starting max_workers worker threads too.

Changed in version 3.13: Default value of max_workers is changed to

.



ThreadPoolExecutor Example





The Python Library Reference, Release 3.13.2





The class is an subclass that uses a pool of processes to execute calls asyn-

chronously. uses the module, which allows it to side-step the Global

Interpreter Lock but also means that only picklable objects can be executed and returned.

The module must be importable by worker subprocesses. This means that will not work in the interactive interpreter.

Calling or methods from a callable submitted to a will result in dead-lock.

max_workers=None, mp_context=None,

initializer=None, initargs=(),

max_tasks_per_child=None

An subclass that executes calls asynchronously using a pool of at most max_workers processes. If

max_workers is or not given, it will default to . If max_workers is less than

or equal to , then a will be raised. On Windows, max_workers must be less than or equal to .

If it is not then will be raised. If max_workers is , then the default chosen will be at most

, even if more processors are available. mp_context can be a context or . It will

be used to launch the workers. If mp_context is or not given, the default context is

used. See Contexts and start methods.

initializer is an optional callable that is called at the start of each worker process; initargs is a tuple of argu-

ments passed to the initializer. Should initializer raise an exception, all currently pending jobs will raise a

, as well as any attempt to submit more jobs to the pool.

max_tasks_per_child is an optional argument that specifies the maximum number of tasks a single process

can execute before it will exit and be replaced with a fresh worker process. By default max_tasks_per_child

is which means worker processes will live as long as the pool. When a max is specified, the “spawn”

multiprocessing start method will be used by default in absence of a mp_context parameter. This feature is

incompatible with the “fork” start method.

Changed in version 3.3: When one of the worker processes terminates abruptly, a error

is now raised. Previously, behaviour was undefined but operations on the executor or its futures would often

freeze or deadlock.

The Python Library Reference, Release 3.13.2



Changed in version 3.7: The mp_context argument was added to allow users to control the start_method for

worker processes created by the pool.

Added the initializer and initargs arguments.



® Note

The default start method (see Contexts and start methods) will change away from

fork in Python 3.14. Code that requires fork be used for their should explicitly specify that by passing a parameter.



Changed in version 3.11: The max_tasks_per_child argument was added to allow users to control the lifetime

of workers in the pool.

Changed in version 3.12:

context uses the start method: The function called internally to

spawn workers may raise a . Pass a mp_context configured to use a different start

method. See the documentation for further explanation.

Changed in version 3.13: max_workers uses by default, instead of

.



ProcessPoolExecutor Example





The Python Library Reference, Release 3.13.2





The class encapsulates the asynchronous execution of a callable. instances are created by

.



Encapsulates the asynchronous execution of a callable. instances are created by

and should not be created directly except for testing.



Attempt to cancel the call. If the call is currently being executed or finished running and cannot be cancelled then the method will return , otherwise the call will be cancelled and the method will return .



Return if the call was successfully cancelled.



Return if the call is currently being executed and cannot be cancelled.



Return if the call was successfully cancelled or finished running.

timeout=None

Return the value returned by the call. If the call hasn’t yet completed then this method will wait up to

timeout seconds. If the call hasn’t completed in timeout seconds, then a will be raised. timeout can be an int or float. If timeout is not specified or , there is no limit to the wait time.

If the future is cancelled before completing then will be raised.

If the call raised an exception, this method will raise the same exception.

timeout=None

Return the exception raised by the call. If the call hasn’t yet completed then this method will wait up to

timeout seconds. If the call hasn’t completed in timeout seconds, then a will be raised. timeout can be an int or float. If timeout is not specified or , there is no limit to the wait time.

If the future is cancelled before completing then will be raised.

If the call completed without raising, is returned.

fn

Attaches the callable fn to the future. fn will be called, with the future as its only argument, when the future is cancelled or finishes running.

Added callables are called in the order that they were added and are always called in a thread belonging to

the process that added them. If the callable raises an subclass, it will be logged and ignored.

If the callable raises a subclass, the behavior is undefined.

If the future has already completed or been cancelled, fn will be called immediately.

The following methods are meant for use in unit tests and implementations.



This method should only be called by implementations before executing the work associated

with the and by unit tests.

If the method returns then the was cancelled, i.e. was called and

returned . Any threads waiting on the completing (i.e. through or

) will be woken up.

If the method returns then the was not cancelled and has been put in the running state, i.e.

calls to will return .

This method can only be called once and cannot be called after or

have been called.

The Python Library Reference, Release 3.13.2



result

Sets the result of the work associated with the to result.

This method should only be used by implementations and unit tests.

Changed in version 3.8: This method raises if the

is already done.

exception

Sets the result of the work associated with the to the exception.

This method should only be used by implementations and unit tests.

Changed in version 3.8: This method raises if the

is already done.





fs, timeout=None, return_when=ALL_COMPLETED

Wait for the instances (possibly created by different instances) given by fs to complete.

Duplicate futures given to fs are removed and will be returned only once. Returns a named 2-tuple of sets.

The first set, named , contains the futures that completed (finished or cancelled futures) before the wait

completed. The second set, named , contains the futures that did not complete (pending or running

futures).

timeout can be used to control the maximum number of seconds to wait before returning. timeout can be an

int or float. If timeout is not specified or , there is no limit to the wait time.

return_when indicates when this function should return. It must be one of the following constants:



Constant Description

The function will return when any future finishes or

is cancelled.

The function will return when any future finishes by



then it is equivalent to .

The function will return when all futures finish or are

cancelled.



fs, timeout=None

Returns an iterator over the instances (possibly created by different instances) given by fs

that yields futures as they complete (finished or cancelled futures). Any futures given by fs that are duplicated

will be returned once. Any futures that completed before is called will be yielded first. The

returned iterator raises a if is called and the result isn’t available after timeout

seconds from the original call to . timeout can be an int or float. If timeout is not specified

or , there is no limit to the wait time.



µ See also

PEP 3148 – futures - execute computations asynchronously

The proposal which described this feature for inclusion in the Python standard library.



The Python Library Reference, Release 3.13.2





Raised when a future is cancelled.



A deprecated alias of , raised when a future operation exceeds the given timeout.

Changed in version 3.11: This class was made an alias of .



Derived from , this exception class is raised when an executor is broken for some reason, and

cannot be used to submit or execute new tasks.

Added in version 3.7.



Raised when an operation is performed on a future that is not allowed in the current state.

Added in version 3.8.



Derived from , this exception class is raised when one of the workers of a

has failed initializing.

Added in version 3.7.



Derived from (formerly ), this exception class is raised when one of the

workers of a has terminated in a non-clean fashion (for example, if it was killed

from the outside).

Added in version 3.3.





Source code: Lib/subprocess.py



The module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. This module intends to replace several older modules and functions:





Information about how the module can be used to replace these modules and functions can be found in the following sections.



µ See also

PEP 324 – PEP proposing the subprocess module



Availability: not Android, not iOS, not WASI.

This module is not supported on mobile platforms or WebAssembly platforms.





The recommended approach to invoking subprocesses is to use the function for all use cases it can handle.

For more advanced use cases, the underlying interface can be used directly.

The Python Library Reference, Release 3.13.2



args, *, stdin=None, input=None, stdout=None, stderr=None, capture_output=False, shell=False,

cwd=None, timeout=None, check=False, encoding=None, errors=None, text=None, env=None, universal_newlines=None, **other_popen_kwargs

Run the command described by args. Wait for command to complete, then return a

instance.

The arguments shown above are merely the most common ones, described below in Frequently Used Arguments

(hence the use of keyword-only notation in the abbreviated signature). The full function signature is largely

the same as that of the constructor - most of the arguments to this function are passed through to that

interface. (timeout, input, check, and capture_output are not.)

If capture_output is true, stdout and stderr will be captured. When used, the internal object is automat-

ically created with stdout and stderr both set to . The stdout and stderr arguments may not be supplied at

the same time as capture_output. If you wish to capture and combine both streams into one, set stdout to

and stderr to , instead of using capture_output.

A timeout may be specified in seconds, it is internally passed on to . If the timeout

expires, the child process will be killed and waited for. The exception will be re-raised after

the child process has terminated. The initial process creation itself cannot be interrupted on many platform

APIs so you are not guaranteed to see a timeout exception until at least after however long process creation

takes.

The input argument is passed to and thus to the subprocess’s stdin. If used it must

be a byte sequence, or a string if encoding or errors is specified or text is true. When used, the internal

object is automatically created with stdin set to , and the stdin argument may not be used as well.

If check is true, and the process exits with a non-zero exit code, a exception will

be raised. Attributes of that exception hold the arguments, the exit code, and stdout and stderr if they were

captured.

If encoding or errors are specified, or text is true, file objects for stdin, stdout and stderr are opened in text mode

using the specified encoding and errors or the default. The universal_newlines argument

is equivalent to text and is provided for backwards compatibility. By default, file objects are opened in binary

mode.

If env is not , it must be a mapping that defines the environment variables for the new process; these

are used instead of the default behavior of inheriting the current process’ environment. It is passed directly

to . This mapping can be str to str on any platform or bytes to bytes on POSIX platforms much like

or .

Examples:





Added in version 3.5.

Changed in version 3.6: Added encoding and errors parameters

Changed in version 3.7: Added the text parameter, as a more understandable alias of universal_newlines. Added

the capture_output parameter.

Changed in version 3.12: Changed Windows shell search order for . The current directory and

are replaced with and . As a result, dropping a

malicious program named into a current directory no longer works.

The Python Library Reference, Release 3.13.2





The return value from , representing a process that has finished.



The arguments used to launch the process. This may be a list or a string.



Exit status of the child process. Typically, an exit status of 0 indicates that it ran successfully.

A negative value indicates that the child was terminated by signal (POSIX only).



Captured stdout from the child process. A bytes sequence, or a string if was called with an encoding, errors, or text=True. if stdout was not captured.

If you ran the process with , stdout and stderr will be combined in this

attribute, and will be .



Captured stderr from the child process. A bytes sequence, or a string if was called with an encoding, errors, or text=True. if stderr was not captured.



If is non-zero, raise a .

Added in version 3.5.



Special value that can be used as the stdin, stdout or stderr argument to and indicates that the special

file will be used.

Added in version 3.3.



Special value that can be used as the stdin, stdout or stderr argument to and indicates that a pipe to the

standard stream should be opened. Most useful with .



Special value that can be used as the stderr argument to and indicates that standard error should go into

the same handle as standard output.



Base class for all other exceptions from this module.

Added in version 3.3.



Subclass of , raised when a timeout expires while waiting for a child process.



Command that was used to spawn the child process.



Timeout in seconds.



Output of the child process if it was captured by or . Otherwise, . This is

always when any output was captured regardless of the setting. It may remain instead of when no output was observed.



Alias for output, for symmetry with .

The Python Library Reference, Release 3.13.2





Stderr output of the child process if it was captured by . Otherwise, . This is always when stderr output was captured regardless of the setting. It may remain instead of when no stderr output was observed.

Added in version 3.3.

Changed in version 3.5: stdout and stderr attributes added



Subclass of , raised when a process run by , , or

(with ) returns a non-zero exit status.



Exit status of the child process. If the process exited due to a signal, this will be the negative signal number.



Command that was used to spawn the child process.



Output of the child process if it was captured by or . Otherwise, .



Alias for output, for symmetry with .



Stderr output of the child process if it was captured by . Otherwise, .

Changed in version 3.5: stdout and stderr attributes added



Frequently Used Arguments

To support a wide variety of use cases, the constructor (and the convenience functions) accept a large number of optional arguments. For most typical use cases, many of these arguments can be safely left at their default values. The arguments that are most commonly needed are:

args is required for all calls and should be a string, or a sequence of program arguments. Providing

a sequence of arguments is generally preferred, as it allows the module to take care of any required

escaping and quoting of arguments (e.g. to permit spaces in file names). If passing a single string, either

shell must be (see below) or else the string must simply name the program to be executed without

specifying any arguments.

stdin, stdout and stderr specify the executed program’s standard input, standard output and standard error

file handles, respectively. Valid values are , , , an existing file descriptor (a positive

integer), and an existing file object with a valid file descriptor. With the default settings of , no

redirection will occur. indicates that a new pipe to the child should be created. indicates

that the special file will be used. Additionally, stderr can be , which indicates that

the stderr data from the child process should be captured into the same file handle as for stdout.

If encoding or errors are specified, or text (also known as universal_newlines) is true, the file objects

stdin, stdout and stderr will be opened in text mode using the encoding and errors specified in the call or

the defaults for .

For stdin, line ending characters in the input will be converted to the default line separator

. For stdout and stderr, all line endings in the output will be converted to . For more

information see the documentation of the class when the newline argument to its

constructor is .

If text mode is not used, stdin, stdout and stderr will be opened as binary streams. No encoding or line

ending conversion is performed.

Changed in version 3.6: Added the encoding and errors parameters.

Changed in version 3.7: Added the text parameter as an alias for universal_newlines.

The Python Library Reference, Release 3.13.2



® Note

The newlines attribute of the file objects , and are

not updated by the method.



If shell is , the specified command will be executed through the shell. This can be useful if you

are using Python primarily for the enhanced control flow it offers over most system shells and still want

convenient access to other shell features such as shell pipes, filename wildcards, environment variable

expansion, and expansion of to a user’s home directory. However, note that Python itself offers

implementations of many shell-like features (in particular, , , ,

, , and ).

Changed in version 3.3: When universal_newlines is , the class uses the encoding

instead of . See the

class for more information on this change.



® Note

Read the Security Considerations section before using .



These options, along with all of the other options, are described in more detail in the constructor documen-tation.



Popen Constructor

The underlying process creation and management in this module is handled by the class. It offers a lot of flexibility so that developers are able to handle the less common cases not covered by the convenience functions.

args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None,

preexec_fn=None, close_fds=True, shell=False, cwd=None, env=None,

universal_newlines=None, startupinfo=None, creationflags=0, restore_signals=True, start_new_session=False, pass_fds=(), *, group=None, extra_groups=None, user=None, umask=-1, encoding=None, errors=None, text=None, pipesize=-1, process_group=None

Execute a child program in a new process. On POSIX, the class uses -like behavior to execute

the child program. On Windows, the class uses the Windows function. The arguments

to are as follows.

args should be a sequence of program arguments or else a single string or path-like object. By default, the

program to execute is the first item in args if args is a sequence. If args is a string, the interpretation is

platform-dependent and described below. See the shell and executable arguments for additional differences

from the default behavior. Unless otherwise stated, it is recommended to pass args as a sequence.



Á Warning

For maximum reliability, use a fully qualified path for the executable. To search for an unqualified name

on , use . On all platforms, passing is the recommended way to launch the current Python interpreter again, and use the command-line format to launch an installed module.

Resolving the path of executable (or the first item of args) is platform dependent. For POSIX, see

, and note that when resolving or searching for the executable path, cwd overrides the current working directory and env can override the environment variable. For Windows, see the documen-tation of the and parameters of WinAPI , and note that when resolving or searching for the executable path with , cwd does not override the current working directory and env cannot override the environment variable. Using a full path avoids all of these variations.

The Python Library Reference, Release 3.13.2



An example of passing some arguments to an external program as a sequence is:





On POSIX, if args is a string, the string is interpreted as the name or path of the program to execute. However,

this can only be done if not passing arguments to the program.



® Note

It may not be obvious how to break a shell command into a sequence of arguments, especially in complex

cases. can illustrate how to determine the correct tokenization for args:





Note in particular that options (such as-input) and arguments (such as eggs.txt) that are separated by whitespace in the shell go in separate list elements, while arguments that need quoting or backslash escaping when used in the shell (such as filenames containing spaces or the echo command shown above) are single list elements.



On Windows, if args is a sequence, it will be converted to a string in a manner described in Converting an

argument sequence to a string on Windows. This is because the underlying operates on

strings.

Changed in version 3.6: args parameter accepts a path-like object if shell is and a sequence containing

path-like objects on POSIX.

Changed in version 3.8: args parameter accepts a path-like object if shell is and a sequence containing

bytes and path-like objects on Windows.

The shell argument (which defaults to ) specifies whether to use the shell as the program to execute. If

shell is , it is recommended to pass args as a string rather than as a sequence.

On POSIX with , the shell defaults to . If args is a string, the string specifies the

command to execute through the shell. This means that the string must be formatted exactly as it would be

when typed at the shell prompt. This includes, for example, quoting or backslash escaping filenames with

spaces in them. If args is a sequence, the first item specifies the command string, and any additional items will

be treated as additional arguments to the shell itself. That is to say, does the equivalent of:





On Windows with , the environment variable specifies the default shell. The only time

you need to specify on Windows is when the command you wish to execute is built into the shell

(e.g. or ). You do not need to run a batch file or console-based executable.



® Note

Read the Security Considerations section before using .



bufsize will be supplied as the corresponding argument to the function when creating the

stdin/stdout/stderr pipe file objects:

• means unbuffered (read and write are one system call and can return short)

The Python Library Reference, Release 3.13.2



• means line buffered (only usable if or )

• any other positive value means use a buffer of approximately that size

• negative bufsize (the default) means the system default of io.DEFAULT_BUFFER_SIZE will be used.

Changed in version 3.3.1: bufsize now defaults to -1 to enable buffering by default to match the behavior

that most code expects. In versions prior to Python 3.2.4 and 3.3.1 it incorrectly defaulted to which was

unbuffered and allowed short reads. This was unintentional and did not match the behavior of Python 2 as

most code expected.

The executable argument specifies a replacement program to execute. It is very seldom needed. When

, executable replaces the program to execute specified by args. However, the original args is

still passed to the program. Most programs treat the program specified by args as the command name, which

can then be different from the program actually executed. On POSIX, the args name becomes the display

name for the executable in utilities such as . If , on POSIX the executable argument specifies

a replacement shell for the default .

Changed in version 3.6: executable parameter accepts a path-like object on POSIX.

Changed in version 3.8: executable parameter accepts a bytes and path-like object on Windows.

Changed in version 3.12: Changed Windows shell search order for . The current directory and

are replaced with and . As a result, dropping a

malicious program named into a current directory no longer works.

stdin, stdout and stderr specify the executed program’s standard input, standard output and standard error file

handles, respectively. Valid values are , , , an existing file descriptor (a positive integer),

and an existing file object with a valid file descriptor. With the default settings of , no redirection will

occur. indicates that a new pipe to the child should be created. indicates that the special file

will be used. Additionally, stderr can be , which indicates that the stderr data from the

applications should be captured into the same file handle as for stdout.

If preexec_fn is set to a callable object, this object will be called in the child process just before the child is

executed. (POSIX only)



Á Warning

The preexec_fn parameter is NOT SAFE to use in the presence of threads in your application. The child process could deadlock before exec is called.



® Note

If you need to modify the environment for the child use the env parameter rather than doing it in a pre-exec_fn. The start_new_session and process_group parameters should take the place of code using pre-

exec_fn to call or in the child.



Changed in version 3.8: The preexec_fn parameter is no longer supported in subinterpreters. The use of the

parameter in a subinterpreter raises . The new restriction may affect applications that are

deployed in mod_wsgi, uWSGI, and other embedded environments.

If close_fds is true, all file descriptors except , and will be closed before the child process is executed.

Otherwise when close_fds is false, file descriptors obey their inheritable flag as described in Inheritance of File

Descriptors.

On Windows, if close_fds is true then no handles will be inherited by the child process unless explicitly passed

in the element of , or by standard handle redirection.

Changed in version 3.2: The default for close_fds was changed from to what is described above.

Changed in version 3.7: On Windows the default for close_fds was changed from to when redi-

recting the standard handles. It’s now possible to set close_fds to when redirecting the standard handles.

The Python Library Reference, Release 3.13.2



pass_fds is an optional sequence of file descriptors to keep open between the parent and child. Providing any

pass_fds forces close_fds to be . (POSIX only)

Changed in version 3.2: The pass_fds parameter was added.

If cwd is not , the function changes the working directory to cwd before executing the child. cwd can be

a string, bytes or path-like object. On POSIX, the function looks for executable (or for the first item in args)

relative to cwd if the executable path is a relative path.

Changed in version 3.6: cwd parameter accepts a path-like object on POSIX.

Changed in version 3.7: cwd parameter accepts a path-like object on Windows.

Changed in version 3.8: cwd parameter accepts a bytes object on Windows.

If restore_signals is true (the default) all signals that Python has set to SIG_IGN are restored to SIG_DFL in the

child process before the exec. Currently this includes the SIGPIPE, SIGXFZ and SIGXFSZ signals. (POSIX

only)

Changed in version 3.2: restore_signals was added.

If start_new_session is true the system call will be made in the child process prior to the execution

of the subprocess.

Availability: POSIX

Changed in version 3.2: start_new_session was added.

If process_group is a non-negative integer, the system call will be made in the child

process prior to the execution of the subprocess.

Availability: POSIX

Changed in version 3.11: process_group was added.

If group is not , the setregid() system call will be made in the child process prior to the execution of

the subprocess. If the provided value is a string, it will be looked up via and the value in

will be used. If the value is an integer, it will be passed verbatim. (POSIX only)

Availability: POSIX

Added in version 3.9.

If extra_groups is not , the setgroups() system call will be made in the child process prior to the execution

of the subprocess. Strings provided in extra_groups will be looked up via and the values in

will be used. Integer values will be passed verbatim. (POSIX only)

Availability: POSIX

Added in version 3.9.

If user is not , the setreuid() system call will be made in the child process prior to the execution of the

subprocess. If the provided value is a string, it will be looked up via and the value in

will be used. If the value is an integer, it will be passed verbatim. (POSIX only)

Availability: POSIX

Added in version 3.9.

If umask is not negative, the umask() system call will be made in the child process prior to the execution of

the subprocess.

Availability: POSIX

Added in version 3.9.

If env is not , it must be a mapping that defines the environment variables for the new process; these are

used instead of the default behavior of inheriting the current process’ environment. This mapping can be str

to str on any platform or bytes to bytes on POSIX platforms much like or .



The Python Library Reference, Release 3.13.2



® Note

If specified, env must provide any variables required for the program to execute. On Windows, in order to

run a side-by-side assembly the specified env must include a valid .



If encoding or errors are specified, or text is true, the file objects stdin, stdout and stderr are opened in text

mode with the specified encoding and errors, as described above in Frequently Used Arguments. The univer-

sal_newlines argument is equivalent to text and is provided for backwards compatibility. By default, file objects

are opened in binary mode.

Added in version 3.6: encoding and errors were added.

Added in version 3.7: text was added as a more readable alias for universal_newlines.

If given, startupinfo will be a object, which is passed to the underlying func-

tion.

If given, creationflags, can be one or more of the following flags:

•

•

•

•

•

•

•

•

•

•

•

•

pipesize can be used to change the size of the pipe when is used for stdin, stdout or stderr. The size of

the pipe is only changed on platforms that support this (only Linux at this time of writing). Other platforms

will ignore this parameter.

Changed in version 3.10: Added the pipesize parameter.

Popen objects are supported as context managers via the statement: on exit, standard file descriptors are

closed, and the process is waited for.





Popen and the other functions in this module that use it raise an auditing event with

arguments , , , and . The value for may be a single string or a list of strings,

depending on platform.

Changed in version 3.2: Added context manager support.

Changed in version 3.6: Popen destructor now emits a warning if the child process is still

running.

Changed in version 3.8: Popen can use in some cases for better performance. On

Windows Subsystem for Linux and QEMU User Emulation, Popen constructor using

The Python Library Reference, Release 3.13.2



no longer raise an exception on errors like missing program, but the child process fails with a non-zero

.



Exceptions

Exceptions raised in the child process, before the new program has started to execute, will be re-raised in the parent.

The most common exception raised is . This occurs, for example, when trying to execute a non-existent file.

Applications should prepare for exceptions. Note that, when , will be raised by the child only if the selected shell itself was not found. To determine if the shell failed to find the requested application, it is necessary to check the return code or output from the subprocess.

A will be raised if is called with invalid arguments.

and will raise if the called process returns a non-zero return code.

All of the functions and methods that accept a timeout parameter, such as and will

raise if the timeout expires before the process exits.

Exceptions defined in this module all inherit from .

Added in version 3.3: The base class was added.





Unlike some other popen functions, this library will not implicitly choose to call a system shell. This means that all characters, including shell metacharacters, can safely be passed to child processes. If the shell is invoked explicitly, via , it is the application’s responsibility to ensure that all whitespace and metacharacters are quoted

appropriately to avoid shell injection vulnerabilities. On some platforms, it is possible to use for this escaping.

On Windows, batch files ( or ) may be launched by the operating system in a system shell regardless of the arguments passed to this library. This could result in arguments being parsed according to shell rules, but without any escaping added by Python. If you are intentionally launching a batch file with arguments from untrusted

sources, consider passing to allow Python to escape special characters. See gh-114539 for additional discussion.





Instances of the class have the following methods:



Check if child process has terminated. Set and return attribute. Otherwise, returns .

timeout=None

Wait for child process to terminate. Set and return attribute.

If the process does not terminate after timeout seconds, raise a exception. It is safe to catch

this exception and retry the wait.



® Note

This will deadlock when using or and the child process generates enough

output to a pipe such that it blocks waiting for the OS pipe buffer to accept more data. Use

when using pipes to avoid that.



® Note



The Python Library Reference, Release 3.13.2



When the parameter is not , then (on POSIX) the function is implemented using a busy loop

(non-blocking call and short sleeps). Use the module for an asynchronous wait: see

.



Changed in version 3.3: timeout was added.

input=None, timeout=None

Interact with process: Send data to stdin. Read data from stdout and stderr, until end-of-file is reached. Wait

for process to terminate and set the attribute. The optional input argument should be data to be

sent to the child process, or , if no data should be sent to the child. If streams were opened in text mode,

input must be a string. Otherwise, it must be bytes.

returns a tuple . The data will be strings if streams were

opened in text mode; otherwise, bytes.

Note that if you want to send data to the process’s stdin, you need to create the Popen object with .

Similarly, to get anything other than in the result tuple, you need to give and/or

too.

If the process does not terminate after timeout seconds, a exception will be raised. Catching

this exception and retrying communication will not lose any output.

The child process is not killed if the timeout expires, so in order to cleanup properly a well-behaved application

should kill the child process and finish communication:





® Note

The data read is buffered in memory, so do not use this method if the data size is large or unlimited.



Changed in version 3.3: timeout was added.

signal

Sends the signal signal to the child.

Do nothing if the process completed.



® Note

On Windows, SIGTERM is an alias for . CTRL_C_EVENT and CTRL_BREAK_EVENT can be sent to processes started with a creationflags parameter which includes .





Stop the child. On POSIX OSs the method sends to the child. On Windows the Win32 API function

is called to stop the child.



Kills the child. On POSIX OSs the function sends SIGKILL to the child. On Windows is an alias for

.

The following attributes are also set by the class for you to access. Reassigning them to new values is unsupported:

The Python Library Reference, Release 3.13.2





The args argument as it was passed to – a sequence of program arguments or else a single string.

Added in version 3.3.



If the stdin argument was , this attribute is a writeable stream object as returned by . If the

encoding or errors arguments were specified or the text or universal_newlines argument was , the stream

is a text stream, otherwise it is a byte stream. If the stdin argument was not , this attribute is .



If the stdout argument was , this attribute is a readable stream object as returned by . Reading

from the stream provides output from the child process. If the encoding or errors arguments were specified or

the text or universal_newlines argument was , the stream is a text stream, otherwise it is a byte stream. If

the stdout argument was not , this attribute is .



If the stderr argument was , this attribute is a readable stream object as returned by . Reading

from the stream provides error output from the child process. If the encoding or errors arguments were specified

or the text or universal_newlines argument was , the stream is a text stream, otherwise it is a byte stream.

If the stderr argument was not , this attribute is .



Á Warning

Use rather than , or to avoid deadlocks due

to any of the other OS pipe buffers filling up and blocking the child process.





The process ID of the child process.

Note that if you set the shell argument to , this is the process ID of the spawned shell.



The child return code. Initially , is set by a call to the , , or

methods if they detect that the process has terminated.

A value indicates that the process hadn’t yet terminated at the time of the last method call.

A negative value indicates that the child was terminated by signal (POSIX only).





The class and following constants are only available on Windows.

*, dwFlags=0, hStdInput=None, hStdOutput=None, hStdError=None,

wShowWindow=0, lpAttributeList=None

Partial support of the Windows STARTUPINFO structure is used for creation. The following attributes

can be set by passing them as keyword-only arguments.

Changed in version 3.7: Keyword-only argument support was added.



A bit field that determines whether certain attributes are used when the process creates a window.





The Python Library Reference, Release 3.13.2





If specifies , this attribute is the standard input handle for the pro-

cess. If is not specified, the default for standard input is the keyboard buffer.



If specifies , this attribute is the standard output handle for the process. Otherwise, this attribute is ignored and the default for standard output is the console window’s buffer.



If specifies , this attribute is the standard error handle for the pro-cess. Otherwise, this attribute is ignored and the default for standard error is the console window’s buffer.



If specifies , this attribute can be any of the values that can be

specified in the parameter for the ShowWindow function, except for . Otherwise, this attribute is ignored.

is provided for this attribute. It is used when is called with .



A dictionary of additional attributes for process creation as given in , see UpdateProc-

ThreadAttribute.

Supported attributes:

handle_list

Sequence of handles that will be inherited. close_fds must be true if non-empty.

The handles must be temporarily made inheritable by

when passed to the constructor, else will be raised with Windows error (87).



Á Warning

In a multithreaded process, use caution to avoid leaking handles that are marked inheritable when combining this feature with concurrent calls to other process creation functions that in-

herit all handles such as . This also applies to standard handle redirection, which temporarily creates inheritable handles.



Added in version 3.7.



Windows Constants

The module exposes the following constants.



The standard input device. Initially, this is the console input buffer, .



The standard output device. Initially, this is the active console screen buffer, .



The standard error device. Initially, this is the active console screen buffer, .



Hides the window. Another window will be activated.



Specifies that the , , and

attributes contain additional information.

The Python Library Reference, Release 3.13.2





Specifies that the attribute contains additional information.



A parameter to specify that the Working in Background mouse cursor will be dis-

played while a process is launching. This is the default behavior for GUI processes.

Added in version 3.13.



A parameter to specify that the mouse cursor will not be changed when launching

a process.

Added in version 3.13.



The new process has a new console, instead of inheriting its parent’s console (the default).



A parameter to specify that a new process group will be created. This flag is necessary

for using on the subprocess.

This flag is ignored if is specified.



A parameter to specify that a new process will have an above average priority.

Added in version 3.7.



A parameter to specify that a new process will have a below average priority.

Added in version 3.7.



A parameter to specify that a new process will have a high priority.

Added in version 3.7.



A parameter to specify that a new process will have an idle (lowest) priority.

Added in version 3.7.



A parameter to specify that a new process will have a normal priority. (default)

Added in version 3.7.



A parameter to specify that a new process will have realtime priority. You should

almost never use REALTIME_PRIORITY_CLASS, because this interrupts system threads that manage mouse

input, keyboard input, and background disk flushing. This class can be appropriate for applications that “talk”

directly to hardware or that perform brief tasks that should have limited interruptions.

Added in version 3.7.



A parameter to specify that a new process will not create a window.

Added in version 3.7.



A parameter to specify that a new process will not inherit its parent’s console. This

value cannot be used with CREATE_NEW_CONSOLE.

Added in version 3.7.

The Python Library Reference, Release 3.13.2





A parameter to specify that a new process does not inherit the error mode of the

calling process. Instead, the new process gets the default error mode. This feature is particularly useful for

multithreaded shell applications that run with hard errors disabled.

Added in version 3.7.



A parameter to specify that a new process is not associated with the job.

Added in version 3.7.





Prior to Python 3.5, these three functions comprised the high level API to subprocess. You can now use in many cases, but lots of existing code calls these functions.

args, *, stdin=None, stdout=None, stderr=None, shell=False, cwd=None, timeout=None,

**other_popen_kwargs

Run the command described by args. Wait for command to complete, then return the attribute.

Code needing to capture stdout or stderr should use instead:





To suppress stdout or stderr, supply a value of .

The arguments shown above are merely some common ones. The full function signature is the same as that of

the constructor - this function passes all supplied arguments other than timeout directly through to that

interface.



® Note

Do not use or with this function. The child process will block if it generates enough output to a pipe to fill up the OS pipe buffer as the pipes are not being read from.



Changed in version 3.3: timeout was added.

Changed in version 3.12: Changed Windows shell search order for . The current directory and

are replaced with and . As a result, dropping a

malicious program named into a current directory no longer works.

args, *, stdin=None, stdout=None, stderr=None, shell=False, cwd=None,

timeout=None, **other_popen_kwargs

Run command with arguments. Wait for command to complete. If the return code was zero then return,

otherwise raise . The object will have the return code in the

attribute. If was unable to start the process it will propagate the exception that

was raised.

Code needing to capture stdout or stderr should use instead:





To suppress stdout or stderr, supply a value of .

The arguments shown above are merely some common ones. The full function signature is the same as that of

the constructor - this function passes all supplied arguments other than timeout directly through to that

interface.



The Python Library Reference, Release 3.13.2



® Note

Do not use or with this function. The child process will block if it generates enough output to a pipe to fill up the OS pipe buffer as the pipes are not being read from.



Changed in version 3.3: timeout was added.

Changed in version 3.12: Changed Windows shell search order for . The current directory and

are replaced with and . As a result, dropping a

malicious program named into a current directory no longer works.

args, *, stdin=None, stderr=None, shell=False, cwd=None, encoding=None,

errors=None, universal_newlines=None, timeout=None, text=None,

**other_popen_kwargs

Run command with arguments and return its output.

If the return code was non-zero it raises a . The object will

have the return code in the attribute and any output in the attribute.

This is equivalent to:





The arguments shown above are merely some common ones. The full function signature is largely the same as

that of - most arguments are passed directly through to that interface. One API deviation from

behavior exists: passing will behave the same as (or , depending on other

arguments) rather than using the parent’s standard input file handle.

By default, this function will return the data as encoded bytes. The actual encoding of the output data may

depend on the command being invoked, so the decoding to text will often need to be handled at the application

level.

This behaviour may be overridden by setting text, encoding, errors, or universal_newlines to as described

in Frequently Used Arguments and .

To also capture standard error in the result, use :





Added in version 3.1.

Changed in version 3.3: timeout was added.

Changed in version 3.4: Support for the input keyword argument was added.

Changed in version 3.6: encoding and errors were added. See for details.

Added in version 3.7: text was added as a more readable alias for universal_newlines.

Changed in version 3.12: Changed Windows shell search order for . The current directory and

are replaced with and . As a result, dropping a

malicious program named into a current directory no longer works.





In this section, “a becomes b” means that b can be used as a replacement for a.



The Python Library Reference, Release 3.13.2



® Note

All “a” functions in this section fail (more or less) silently if the executed program cannot be found; the “b”

replacements raise instead.

In addition, the replacements using will fail with a if the requested

operation produces a non-zero return code. The output is still available as the attribute of the raised

exception.



In the following examples, we assume that the relevant functions have already been imported from the module.



Replacing shell command substitution





becomes:





Replacing shell pipeline





becomes:





The call after starting the p2 is important in order for p1 to receive a SIGPIPE if p2 exits before p1.

Alternatively, for trusted input, the shell’s own pipeline support may still be used directly:





becomes:





Replacing





Notes:

• Calling the program through the shell is usually not required.

• The return value is encoded differently to that of .

• The function ignores SIGINT and SIGQUIT signals while the command is running, but the

caller must do this separately when using the module.

A more realistic example would look like this:

The Python Library Reference, Release 3.13.2





Replacing the family

P_NOWAIT example:





P_WAIT example:





Vector example:





Environment example:





Replacing , ,





The Python Library Reference, Release 3.13.2





Return code handling translates as follows:





Replacing functions from the module



® Note

If the cmd argument to popen2 functions is a string, the command is executed through /bin/sh. If it is a list, the

command is directly executed.





and basically work as , except that:

• raises an exception if the execution fails.

• The capturestderr argument is replaced with the stderr argument.

• and must be specified.

• popen2 closes all file descriptors by default, but you have to specify with to guar-

antee this behavior on all platforms or past Python versions.





This module also provides the following legacy functions from the 2.x module. These operations implic-itly invoke the system shell and none of the guarantees described above regarding security and exception handling consistency are valid for these functions.

cmd, *, encoding=None, errors=None

Return of executing cmd in a shell.

The Python Library Reference, Release 3.13.2



Execute the string cmd in a shell with and return a 2-tuple

. encoding and errors are used to decode output; see the notes on Frequently Used Arguments for

more details.

A trailing newline is stripped from the output. The exit code for the command can be interpreted as the return

code of subprocess. Example:





Availability: Unix, Windows.

Changed in version 3.3.4: Windows support was added.

The function now returns (exitcode, output) instead of (status, output) as it did in Python 3.3.3 and earlier.

exitcode has the same value as .

Changed in version 3.11: Added the encoding and errors parameters.

cmd, *, encoding=None, errors=None

Return output (stdout and stderr) of executing cmd in a shell.

Like , except the exit code is ignored and the return value is a string containing the

command’s output. Example:





Availability: Unix, Windows.

Changed in version 3.3.4: Windows support added

Changed in version 3.11: Added the encoding and errors parameters.





Converting an argument sequence to a string on Windows

On Windows, an args sequence is converted to a string that can be parsed using the following rules (which correspond to the rules used by the MS C runtime):

1. Arguments are delimited by white space, which is either a space or a tab.

2. A string surrounded by double quotation marks is interpreted as a single argument, regardless of white space

contained within. A quoted string can be embedded in an argument.

3. A double quotation mark preceded by a backslash is interpreted as a literal double quotation mark.

4. Backslashes are interpreted literally, unless they immediately precede a double quotation mark.

5. If backslashes immediately precede a double quotation mark, every pair of backslashes is interpreted as a literal

backslash. If the number of backslashes is odd, the last backslash escapes the next double quotation mark as

described in rule 3.



µ See also



Module which provides function to parse and escape command lines.

The Python Library Reference, Release 3.13.2



Disabling use of or

On Linux, defaults to using the system call internally when it is safe to do so rather than . This greatly improves performance.

If you ever encounter a presumed highly unusual situation where you need to prevent from being used by Python, you can set the attribute to a false value.





Setting this has no impact on use of which could use internally within its libc implemen-tation. There is a similar attribute if you need to prevent use of that.





It is safe to set these to false on any Python version. They will have no effect on older versions when unsupported. Do not assume the attributes are available to read. Despite their names, a true value does not indicate that the corresponding function will be used, only that it may be.

Please file issues any time you have to use these private knobs with a way to reproduce the issue you were seeing. Link to that issue from a comment in your code.

Added in version 3.8:

Added in version 3.11:





Source code: Lib/sched.py



The module defines a class which implements a general purpose event scheduler:

timefunc=time.monotonic, delayfunc=time.sleep

The class defines a generic interface to scheduling events. It needs two functions to actually deal

with the “outside world” — timefunc should be callable without arguments, and return a number (the “time”,

in any units whatsoever). The delayfunc function should be callable with one argument, compatible with the

output of timefunc, and should delay that many time units. delayfunc will also be called with the argument

after each event is run to allow other threads an opportunity to run in multi-threaded applications.

Changed in version 3.3: timefunc and delayfunc parameters are optional.

Changed in version 3.3: class can be safely used in multi-threaded environments.

Example:





The Python Library Reference, Release 3.13.2





instances have the following methods and attributes:

time, priority, action, argument=(), kwargs={}

Schedule a new event. The time argument should be a numeric type compatible with the return value of the

timefunc function passed to the constructor. Events scheduled for the same time will be executed in the order

of their priority. A lower number represents a higher priority.

Executing the event means executing . argument is a sequence holding

the positional arguments for action. kwargs is a dictionary holding the keyword arguments for action.

Return value is an event which may be used for later cancellation of the event (see ).

Changed in version 3.3: argument parameter is optional.

Changed in version 3.3: kwargs parameter was added.

delay, priority, action, argument=(), kwargs={}

Schedule an event for delay more time units. Other than the relative time, the other arguments, the effect and

the return value are the same as those for .

Changed in version 3.3: argument parameter is optional.

Changed in version 3.3: kwargs parameter was added.

event

Remove the event from the queue. If event is not an event currently in the queue, this method will raise a

.



Return if the event queue is empty.

blocking=True

Run all scheduled events. This method will wait (using the delayfunc function passed to the constructor) for

the next event, then execute it and so on until there are no more scheduled events.

If blocking is false executes the scheduled events due to expire soonest (if any) and then return the deadline of

the next scheduled call in the scheduler (if any).

Either action or delayfunc can raise an exception. In either case, the scheduler will maintain a consistent state

and propagate the exception. If an exception is raised by action, the event will not be attempted in future calls

to .

If a sequence of events takes longer to run than the time available before the next event, the scheduler will

simply fall behind. No events will be dropped; the calling code is responsible for canceling events which are

no longer pertinent.

Changed in version 3.3: blocking parameter was added.



The Python Library Reference, Release 3.13.2





Read-only attribute returning a list of upcoming events in the order they will be run. Each event is shown as a

named tuple with the following fields: time, priority, action, argument, kwargs.





Source code: Lib/queue.py



The module implements multi-producer, multi-consumer queues. It is especially useful in threaded pro-

gramming when information must be exchanged safely between multiple threads. The class in this module implements all the required locking semantics.

The module implements three types of queue, which differ only in the order in which the entries are retrieved. In a FIFO queue, the first tasks added are the first retrieved. In a LIFO queue, the most recently added entry is the first

retrieved (operating like a stack). With a priority queue, the entries are kept sorted (using the module) and the lowest valued entry is retrieved first.

Internally, those three types of queues use locks to temporarily block competing threads; however, they are not designed to handle reentrancy within a thread.

In addition, the module implements a “simple” FIFO queue type, , whose specific implementation provides additional guarantees in exchange for the smaller functionality.

The module defines the following classes and exceptions:

maxsize=0

Constructor for a FIFO queue. maxsize is an integer that sets the upperbound limit on the number of items

that can be placed in the queue. Insertion will block once this size has been reached, until queue items are

consumed. If maxsize is less than or equal to zero, the queue size is infinite.

maxsize=0

Constructor for a LIFO queue. maxsize is an integer that sets the upperbound limit on the number of items

that can be placed in the queue. Insertion will block once this size has been reached, until queue items are

consumed. If maxsize is less than or equal to zero, the queue size is infinite.

maxsize=0

Constructor for a priority queue. maxsize is an integer that sets the upperbound limit on the number of items

that can be placed in the queue. Insertion will block once this size has been reached, until queue items are

consumed. If maxsize is less than or equal to zero, the queue size is infinite.

The lowest valued entries are retrieved first (the lowest valued entry is the one that would be returned by

). A typical pattern for entries is a tuple in the form: .

If the data elements are not comparable, the data can be wrapped in a class that ignores the data item and only

compares the priority number:





Constructor for an unbounded FIFO queue. Simple queues lack advanced functionality such as task tracking.

Added in version 3.7.

The Python Library Reference, Release 3.13.2





Exception raised when non-blocking (or ) is called on a object which is empty.



Exception raised when non-blocking (or ) is called on a object which is full.



Exception raised when or is called on a object which has been shut down.

Added in version 3.13.





Queue objects (, , or ) provide the public methods described below.



Return the approximate size of the queue. Note, qsize() > 0 doesn’t guarantee that a subsequent get() will not

block, nor will qsize() < maxsize guarantee that put() will not block.



Return if the queue is empty, otherwise. If empty() returns it doesn’t guarantee that a sub-

sequent call to put() will not block. Similarly, if empty() returns it doesn’t guarantee that a subsequent

call to get() will not block.



Return if the queue is full, otherwise. If full() returns it doesn’t guarantee that a subsequent

call to get() will not block. Similarly, if full() returns it doesn’t guarantee that a subsequent call to put()

will not block.

item, block=True, timeout=None

Put item into the queue. If optional args block is true and timeout is (the default), block if necessary until

a free slot is available. If timeout is a positive number, it blocks at most timeout seconds and raises the

exception if no free slot was available within that time. Otherwise (block is false), put an item on the queue if

a free slot is immediately available, else raise the exception (timeout is ignored in that case).

Raises if the queue has been shut down.

item

Equivalent to .

block=True, timeout=None

Remove and return an item from the queue. If optional args block is true and timeout is (the default),

block if necessary until an item is available. If timeout is a positive number, it blocks at most timeout seconds

and raises the exception if no item was available within that time. Otherwise (block is false), return an

item if one is immediately available, else raise the exception (timeout is ignored in that case).

Prior to 3.0 on POSIX systems, and for all versions on Windows, if block is true and timeout is , this

operation goes into an uninterruptible wait on an underlying lock. This means that no exceptions can occur,

and in particular a SIGINT will not trigger a .

Raises if the queue has been shut down and is empty, or if the queue has been shut down immedi-

ately.



Equivalent to .

Two methods are offered to support tracking whether enqueued tasks have been fully processed by daemon consumer threads.



Indicate that a formerly enqueued task is complete. Used by queue consumer threads. For each used

to fetch a task, a subsequent call to tells the queue that the processing on the task is complete.

The Python Library Reference, Release 3.13.2



If a is currently blocking, it will resume when all items have been processed (meaning that a

call was received for every item that had been into the queue).

calls for each remaining item in the queue.

Raises a if called more times than there were items placed in the queue.



Blocks until all items in the queue have been gotten and processed.

The count of unfinished tasks goes up whenever an item is added to the queue. The count goes down whenever

a consumer thread calls to indicate that the item was retrieved and all work on it is complete.

When the count of unfinished tasks drops to zero, unblocks.

Example of how to wait for enqueued tasks to be completed:





Terminating queues

objects can be made to prevent further interaction by shutting them down.

immediate=False

Shut down the queue, making and raise .

By default, on a shut down queue will only raise once the queue is empty. Set immediate to true to

make raise immediately instead.

All blocked callers of and will be unblocked. If immediate is true, a task will be marked as done

for each remaining item in the queue, which may unblock callers of .

Added in version 3.13.





objects provide the public methods described below.



Return the approximate size of the queue. Note, qsize() > 0 doesn’t guarantee that a subsequent get() will not

block.

The Python Library Reference, Release 3.13.2





Return if the queue is empty, otherwise. If empty() returns it doesn’t guarantee that a

subsequent call to get() will not block.

item, block=True, timeout=None

Put item into the queue. The method never blocks and always succeeds (except for potential low-level errors

such as failure to allocate memory). The optional args block and timeout are ignored and only provided for

compatibility with .

CPython implementation detail: This method has a C implementation which is reentrant. That is, a

or call can be interrupted by another call in the same thread without deadlocking or corrupting

internal state inside the queue. This makes it appropriate for use in destructors such as methods or

callbacks.

item

Equivalent to , provided for compatibility with .

block=True, timeout=None

Remove and return an item from the queue. If optional args block is true and timeout is (the default),

block if necessary until an item is available. If timeout is a positive number, it blocks at most timeout seconds

and raises the exception if no item was available within that time. Otherwise (block is false), return an

item if one is immediately available, else raise the exception (timeout is ignored in that case).



Equivalent to .



µ See also

Class

A queue class for use in a multi-processing (rather than multi-threading) context.

is an alternative implementation of unbounded queues with fast atomic and

operations that do not require locking and also support indexing.





This module provides APIs to manage, store, and access context-local state. The class is used to declare

and work with Context Variables. The function and the class should be used to manage the current context in asynchronous frameworks.

Context managers that have state should use Context Variables instead of to prevent their state from bleeding to other code unexpectedly, when used in concurrent code.

See also PEP 567 for additional details.

Added in version 3.7.





name, *, default

This class is used to declare a new Context Variable, e.g.:





The required name parameter is used for introspection and debug purposes.

The optional keyword-only default parameter is returned by when no value for the vari-

able is found in the current context.

The Python Library Reference, Release 3.13.2



Important: Context Variables should be created at the top module level and never in closures.

objects hold strong references to context variables which prevents context variables from being properly garbage

collected.



The name of the variable. This is a read-only property.

Added in version 3.7.1.

default

Return a value for the context variable for the current context.

If there is no value for the variable in the current context, the method will:

• return the value of the default argument of the method, if provided; or

• return the default value for the context variable, if it was created with one; or

• raise a .

value

Call to set a new value for the context variable in the current context.

The required value argument is the new value for the context variable.

Returns a object that can be used to restore the variable to its previous value via the

method.

token

Reset the context variable to the value it had before the that created the token was used.

For example:





Token objects are returned by the method. They can be passed to the

method to revert the value of the variable to what it was before the corresponding set.



A read-only property. Points to the object that created the token.



A read-only property. Set to the value the variable had before the method call that

created the token. It points to if the variable was not set before the call.



A marker object used by .





Returns a copy of the current object.

The following snippet gets a copy of the current context and prints all variables and their values that are set in

it:

The Python Library Reference, Release 3.13.2





The function has an O(1) complexity, i.e. works equally fast for contexts with a few context variables and for

contexts that have a lot of them.



A mapping of to their values.

creates an empty context with no values in it. To get a copy of the current context use the

function.

Each thread has its own effective stack of objects. The current context is the object at the

top of the current thread’s stack. All objects in the stacks are considered to be entered.

Entering a context, which can be done by calling its method, makes the context the current context by

pushing it onto the top of the current thread’s context stack.

Exiting from the current context, which can be done by returning from the callback passed to the

method, restores the current context to what it was before the context was entered by popping the context off

the top of the context stack.

Since each thread has its own context stack, objects behave in a similar fashion to

when values are assigned in different threads.

Attempting to enter an already entered context, including contexts entered in other threads, raises a

.

After exiting a context, it can later be re-entered (from any thread).

Any changes to values via the method are recorded in the current context.

The method returns the value associated with the current context. Exiting a context

effectively reverts any changes made to context variables while the context was entered (if needed, the values

can be restored by re-entering the context).

Context implements the interface.

callable, *args, **kwargs

Enters the Context, executes , then exits the Context.

callable’s return value, or propagates an exception if one occurred.

Example:





The Python Library Reference, Release 3.13.2





Return a shallow copy of the context object.



Return if the context has a value for var set; return otherwise.



Return the value of the var variable. If the variable is not set in the context object, a

is raised.

var, default

Return the value for var if var has the value in the context object. Return default otherwise. If default is not given, return .



Return an iterator over the variables stored in the context object.



Return the number of variables set in the context object.



Return a list of all variables in the context object.



Return a list of all variables’ values in the context object.



Return a list of 2-tuples containing all variables and their values in the context object.





Context variables are natively supported in and are ready to be used without any extra configuration. For example, here is a simple echo server, that uses a context variable to make the address of a remote client available in the Task that handles that client:





The Python Library Reference, Release 3.13.2





The following are support modules for some of the above services:





This module provides low-level primitives for working with multiple threads (also called light-weight processes or tasks) — multiple threads of control sharing their global data space. For synchronization, simple locks (also called

mutexes or binary semaphores) are provided. The module provides an easier to use and higher-level threading API built on top of this module.

Changed in version 3.7: This module used to be optional, it is now always available.

This module defines the following constants and functions:



Raised on thread-specific errors.

Changed in version 3.3: This is now a synonym of the built-in .



This is the type of lock objects.

function, args , kwargs

Start a new thread and return its identifier. The thread executes the function function with the argument list

args (which must be a tuple). The optional kwargs argument specifies a dictionary of keyword arguments.

The Python Library Reference, Release 3.13.2



When the function returns, the thread silently exits.

When the function terminates with an unhandled exception, is called to handle the

exception. The object attribute of the hook argument is function. By default, a stack trace is printed and then

the thread exits (but other threads continue to run).

When the function raises a exception, it is silently ignored.

Raises an auditing event with arguments , , .

Changed in version 3.8: is now used to handle unhandled exceptions.

signum=signal.SIGINT, /

Simulate the effect of a signal arriving in the main thread. A thread can use this function to interrupt the main

thread, though there is no guarantee that the interruption will happen immediately.

If given, signum is the number of the signal to simulate. If signum is not given, is simulated.

If the given signal isn’t handled by Python (it was set to or ), this function

does nothing.

Changed in version 3.10: The signum argument is added to customize the signal number.



® Note

This does not emit the corresponding signal but schedules a call to the associated handler (if it exists). If

you want to truly emit the signal, use .





Raise the exception. When not caught, this will cause the thread to exit silently.



Return a new lock object. Methods of locks are described below. The lock is initially unlocked.



Return the ‘thread identifier’ of the current thread. This is a nonzero integer. Its value has no direct meaning;

it is intended as a magic cookie to be used e.g. to index a dictionary of thread-specific data. Thread identifiers

may be recycled when a thread exits and another thread is created.



Return the native integral Thread ID of the current thread assigned by the kernel. This is a non-negative integer.

Its value may be used to uniquely identify this particular thread system-wide (until the thread terminates, after

which the value may be recycled by the OS).

Availability: Windows, FreeBSD, Linux, macOS, OpenBSD, NetBSD, AIX, DragonFlyBSD,

GNU/kFreeBSD.

Added in version 3.8.

Changed in version 3.13: Added support for GNU/kFreeBSD.

size

Return the thread stack size used when creating new threads. The optional size argument specifies the stack size

to be used for subsequently created threads, and must be 0 (use platform or configured default) or a positive

integer value of at least 32,768 (32 KiB). If size is not specified, 0 is used. If changing the thread stack size

is unsupported, a is raised. If the specified stack size is invalid, a is raised

and the stack size is unmodified. 32 KiB is currently the minimum supported stack size value to guarantee

sufficient stack space for the interpreter itself. Note that some platforms may have particular restrictions on

values for the stack size, such as requiring a minimum stack size > 32 KiB or requiring allocation in multiples

of the system memory page size - platform documentation should be referred to for more information (4 KiB

pages are common; using multiples of 4096 for the stack size is the suggested approach in the absence of more

specific information).

Availability: Windows, pthreads.

The Python Library Reference, Release 3.13.2



Unix platforms with POSIX threads support.



The maximum value allowed for the timeout parameter of . Specifying a timeout greater than

this value will raise an .

Added in version 3.2.

Lock objects have the following methods:

blocking=True, timeout=-1

Without any optional argument, this method acquires the lock unconditionally, if necessary waiting until it is

released by another thread (only one thread at a time can acquire a lock — that’s their reason for existence).

If the blocking argument is present, the action depends on its value: if it is false, the lock is only acquired if it

can be acquired immediately without waiting, while if it is true, the lock is acquired unconditionally as above.

If the floating-point timeout argument is present and positive, it specifies the maximum wait time in seconds

before returning. A negative timeout argument specifies an unbounded wait. You cannot specify a timeout if

blocking is false.

The return value is if the lock is acquired successfully, if not.

Changed in version 3.2: The timeout parameter is new.

Changed in version 3.2: Lock acquires can now be interrupted by signals on POSIX.



Releases the lock. The lock must have been acquired earlier, but not necessarily by the same thread.



Return the status of the lock: if it has been acquired by some thread, if not.

In addition to these methods, lock objects can also be used via the statement, e.g.:





Caveats:

• Interrupts always go to the main thread (the exception will be received by that thread.)

• Calling or raising the exception is equivalent to calling .

• It is platform-dependent whether the method on a lock can be interrupted (so that the

exception will happen immediately, rather than only after the lock has been acquired

or the operation has timed out). It can be interrupted on POSIX, but not on Windows.

• When the main thread exits, it is system defined whether the other threads survive. On most systems, they are

killed without executing … clauses or executing object destructors.



The Python Library Reference, Release 3.13.2





CHAPTER





The modules described in this chapter provide mechanisms for networking and inter-processes communication.

Some modules only work for two processes that are on the same machine, e.g. and . Other modules support networking protocols that two or more processes can use to communicate across machines.

The list of modules described in this chapter is:





Hello World!





asyncio is a library to write concurrent code using the async/await syntax.

asyncio is used as a foundation for multiple Python asynchronous frameworks that provide high-performance network and web-servers, database connection libraries, distributed task queues, etc.

asyncio is often a perfect fit for IO-bound and high-level structured network code.

asyncio provides a set of high-level APIs to:

• run Python coroutines concurrently and have full control over their execution;

• perform network IO and IPC;

• control subprocesses;

• distribute tasks via queues;

• synchronize concurrent code;

Additionally, there are low-level APIs for library and framework developers to:

• create and manage event loops, which provide asynchronous APIs for networking, running subprocesses, han-

dling OS signals, etc;

• implement efficient protocols using transports;

• bridge callback-based libraries and code with async/await syntax.

The Python Library Reference, Release 3.13.2



Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.



asyncio REPL

You can experiment with an concurrent context in the REPL:





Raises an auditing event with no arguments.

Changed in version 3.12.5: (also 3.11.10, 3.10.15, 3.9.20, and 3.8.20) Emits audit events.

Changed in version 3.13: Uses PyREPL if possible, in which case is also executed. Emits audit events.



Reference



Source code: Lib/asyncio/runners.py

This section outlines high-level asyncio primitives to run asyncio code.

They are built on top of an event loop with the aim to simplify async code usage for common wide-spread scenarios.



• Running an asyncio Program

• Runner context manager

• Handling Keyboard Interruption



Running an asyncio Program

coro, *, debug=None, loop_factory=None

Execute the coroutine coro and return the result.

This function runs the passed coroutine, taking care of managing the asyncio event loop, finalizing asynchronous

generators, and closing the executor.

This function cannot be called when another asyncio event loop is running in the same thread.

If debug is , the event loop will be run in debug mode. disables debug mode explicitly. is

used to respect the global Debug Mode settings.

If loop_factory is not , it is used to create a new event loop; otherwise

is used. The loop is closed at the end. This function should be used as a main entry point for asyncio programs,

and should ideally only be called once. It is recommended to use loop_factory to configure the event loop

instead of policies. Passing allows running asyncio without the policy system.

The executor is given a timeout duration of 5 minutes to shutdown. If the executor hasn’t finished within that

duration, a warning is emitted and the executor is closed.

Example:

The Python Library Reference, Release 3.13.2





Added in version 3.7.

Changed in version 3.9: Updated to use .

Changed in version 3.10: debug is by default to respect the global debug mode settings.

Changed in version 3.12: Added loop_factory parameter.



Runner context manager

*, debug=None, loop_factory=None

A context manager that simplifies multiple async function calls in the same context.

Sometimes several top-level async functions should be called in the same event loop and

.

If debug is , the event loop will be run in debug mode. disables debug mode explicitly. is

used to respect the global Debug Mode settings.

loop_factory could be used for overriding the loop creation. It is the responsibility of the loop_factory to set the

created loop as the current one. By default is used and set as current event

loop with if loop_factory is .

Basically, example can be rewritten with the runner usage:





Added in version 3.11.

coro, *, context=None

Run a coroutine coro in the embedded loop.

Return the coroutine’s result or raise its exception.

An optional keyword-only context argument allows specifying a custom for the coro to run in. The runner’s default context is used if .

This function cannot be called when another asyncio event loop is running in the same thread.



Close the runner.

Finalize asynchronous generators, shutdown default executor, close the event loop and release embedded

.



Return the event loop associated with the runner instance.



® Note

uses the lazy initialization strategy, its constructor doesn’t initialize underlying low-level structures.

The Python Library Reference, Release 3.13.2



Embedded loop and context are created at the body entering or the first call of or

.



Handling Keyboard Interruption

Added in version 3.11.

When is raised by , exception is raised in the main thread by

default. However this doesn’t work with because it can interrupt asyncio internals and can hang the program from exiting.

To mitigate this issue, handles as follows:

1. installs a custom handler before any user code is executed and

removes it when exiting from the function.

2. The creates the main task for the passed coroutine for its execution.

3. When is raised by , the custom signal handler cancels the main task by calling

which raises inside the main task. This causes the

Python stack to unwind, and blocks can be used for resource cleanup. After the

main task is cancelled, raises .

4. A user could write a tight loop which cannot be interrupted by , in which case the

second following immediately raises the without cancelling the main task.





This section outlines high-level asyncio APIs to work with coroutines and Tasks.



• Coroutines

• Awaitables

• Creating Tasks

• Task Cancellation

• Task Groups

• Sleeping

• Running Tasks Concurrently

• Eager Task Factory

• Shielding From Cancellation

• Timeouts

• Waiting Primitives

• Running in Threads

• Scheduling From Other Threads

• Introspection

• Task Object



The Python Library Reference, Release 3.13.2



Coroutines

Source code: Lib/asyncio/coroutines.py



Coroutines declared with the async/await syntax is the preferred way of writing asyncio applications. For example, the following snippet of code prints “hello”, waits 1 second, and then prints “world”:





Note that simply calling a coroutine will not schedule it to be executed:





To actually run a coroutine, asyncio provides the following mechanisms:

• The function to run the top-level entry point “main()” function (see the above example.)

• Awaiting on a coroutine. The following snippet of code will print “hello” after waiting for 1 second, and then

print “world” after waiting for another 2 seconds:





Expected output:





• The function to run coroutines concurrently as asyncio .

Let’s modify the above example and run two coroutines concurrently:



The Python Library Reference, Release 3.13.2





Note that expected output now shows that the snippet runs 1 second faster than before:





• The class provides a more modern alternative to . Using this API,

the last example becomes:





The timing and output should be the same as for the previous version.

Added in version 3.11: .



Awaitables

We say that an object is an awaitable object if it can be used in an expression. Many asyncio APIs are designed to accept awaitables.

There are three main types of awaitable objects: coroutines, Tasks, and Futures.



Coroutines

Python coroutines are awaitables and therefore can be awaited from other coroutines:





The Python Library Reference, Release 3.13.2





ǩ Important

In this documentation the term “coroutine” can be used for two closely related concepts:

• a coroutine function: an function;

• a coroutine object: an object returned by calling a coroutine function.



Tasks

Tasks are used to schedule coroutines concurrently.

When a coroutine is wrapped into a Task with functions like the coroutine is automat-ically scheduled to run soon:





Futures

A is a special low-level awaitable object that represents an eventual result of an asynchronous operation.

When a Future object is awaited it means that the coroutine will wait until the Future is resolved in some other place.

Future objects in asyncio are needed to allow callback-based code to be used with async/await.

Normally there is no need to create Future objects at the application level code.

Future objects, sometimes exposed by libraries and some asyncio APIs, can be awaited:





The Python Library Reference, Release 3.13.2





A good example of a low-level function that returns a Future object is .



Creating Tasks

Source code: Lib/asyncio/tasks.py



coro, *, name=None, context=None

Wrap the coro coroutine into a and schedule its execution. Return the Task object.

If name is not , it is set as the name of the task using .

An optional keyword-only context argument allows specifying a custom for the coro

to run in. The current context copy is created when no context is provided.

The task is executed in the loop returned by , is raised if there is no

running loop in current thread.



® Note

is a new alternative leveraging structural concurrency; it allows for waiting for a group of related tasks with strong safety guarantees.



ǩ Important

Save a reference to the result of this function, to avoid a task disappearing mid-execution. The event loop only keeps weak references to tasks. A task that isn’t referenced elsewhere may get garbage collected at any time, even before it’s done. For reliable “fire-and-forget” background tasks, gather them in a collection:





Added in version 3.7.

Changed in version 3.8: Added the name parameter.

Changed in version 3.11: Added the context parameter.



The Python Library Reference, Release 3.13.2



Task Cancellation

Tasks can easily and safely be cancelled. When a task is cancelled, will be raised in the task at the next opportunity.

It is recommended that coroutines use blocks to robustly perform clean-up logic. In case

is explicitly caught, it should generally be propagated when clean-up is complete.

directly subclasses so most code will not need to be aware of it.

The asyncio components that enable structured concurrency, like and

, are implemented using cancellation internally and might misbehave if a coroutine swallows

. Similarly, user code should not generally call . However, in cases when suppressing

is truly desired, it is necessary to also call to completely remove the cancellation state.



Task Groups

Task groups combine a task creation API with a convenient and reliable way to wait for all tasks in the group to finish.





An asynchronous context manager holding a group of tasks.

. All tasks are awaited when the context manager exits.

Added in version 3.11.

coro, *, name=None, context=None

Create a task in this task group. The signature matches that of . If the task group is inactive (e.g. not yet entered, already finished, or in the process of shutting down), we will close the given .

Changed in version 3.13: Close the given coroutine if the task group is not active.

Example:





The statement will wait for all tasks in the group to finish. While waiting, new tasks may still be added to the group (for example, by passing into one of the coroutines and calling in that coroutine). Once the last task has finished and the block is exited, no new tasks may be added to the group.

The first time any of the tasks belonging to the group fails with an exception other than , the remaining tasks in the group are cancelled. No further tasks can then be added to the group. At this point, if the body of the statement is still active (i.e., hasn’t been called yet), the task directly

containing the statement is also cancelled. The resulting will interrupt an , but it will not bubble out of the containing statement.

Once all tasks have finished, if any tasks have failed with an exception other than ,

those exceptions are combined in an or (as appropriate; see their doc-umentation) which is then raised.

Two base exceptions are treated specially: If any task fails with or , the task

group still cancels the remaining tasks and waits for them, but then the initial or

is re-raised instead of or .

If the body of the statement exits with an exception (so is called with an exception set), this is treated the same as if one of the tasks failed: the remaining tasks are cancelled and then waited for, and non-cancellation exceptions are grouped into an exception group and raised. The exception passed into , The Python Library Reference, Release 3.13.2



unless it is , is also included in the exception group. The same special case is made for

and as in the previous paragraph.

Task groups are careful not to mix up the internal cancellation used to “wake up” their with cancel-lation requests for the task in which they are running made by other parties. In particular, when one task group is syntactically nested in another, and both experience an exception in one of their child tasks simultaneously, the inner task group will process its exceptions, and then the outer task group will receive another cancellation and process its own exceptions.

In the case where a task group is cancelled externally and also must raise an , it will call the parent

task’s method. This ensures that a will be raised at the next , so the cancellation is not lost.

Task groups preserve the cancellation count reported by .

Changed in version 3.13: Improved handling of simultaneous internal and external cancellations and correct preser-vation of cancellation counts.



Terminating a Task Group

While terminating a task group is not natively supported by the standard library, termination can be achieved by adding an exception-raising task to the task group and ignoring the raised exception:





Expected output:





The Python Library Reference, Release 3.13.2



Sleeping

delay, result=None

Block for delay seconds.

If result is provided, it is returned to the caller when the coroutine completes.

always suspends the current task, allowing other tasks to run.

Setting the delay to 0 provides an optimized path to allow other tasks to run. This can be used by long-running

functions to avoid blocking the event loop for the full duration of the function call.

Example of coroutine displaying the current date every second for 5 seconds:





Changed in version 3.10: Removed the loop parameter.

Changed in version 3.13: Raises if delay is .



Running Tasks Concurrently

*aws, return_exceptions=False

Run awaitable objects in the aws sequence concurrently.

If any awaitable in aws is a coroutine, it is automatically scheduled as a Task.

If all awaitables are completed successfully, the result is an aggregate list of returned values. The order of

result values corresponds to the order of awaitables in aws.

If return_exceptions is (default), the first raised exception is immediately propagated to the task that

awaits on . Other awaitables in the aws sequence won’t be cancelled and will continue to run.

If return_exceptions is , exceptions are treated the same as successful results, and aggregated in the result

list.

If is cancelled, all submitted awaitables (that have not completed yet) are also cancelled.

If any Task or Future from the aws sequence is cancelled, it is treated as if it raised – the

call is not cancelled in this case. This is to prevent the cancellation of one submitted Task/Future

to cause other Tasks/Futures to be cancelled.



® Note

A new alternative to create and run tasks concurrently and wait for their completion is

. TaskGroup provides stronger safety guarantees than gather for scheduling a nesting of sub-tasks: if a task (or a subtask, a task scheduled by a task) raises an exception, TaskGroup will, while gather will not, cancel the remaining scheduled tasks).



Example:

The Python Library Reference, Release 3.13.2





® Note

If return_exceptions is false, cancelling gather() after it has been marked done won’t cancel any submitted awaitables. For instance, gather can be marked done after propagating an exception to the caller, therefore, calling after catching an exception (raised by one of the awaitables) from gather won’t cancel any other awaitables.



Changed in version 3.7: If the gather itself is cancelled, the cancellation is propagated regardless of re-

turn_exceptions.

Changed in version 3.10: Removed the loop parameter.

Deprecated since version 3.10: Deprecation warning is emitted if no positional arguments are provided or not

all positional arguments are Future-like objects and there is no running event loop.



Eager Task Factory

loop, coro, *, name=None, context=None

A task factory for eager task execution.

When using this factory (via ), coroutines

begin execution synchronously during construction. Tasks are only scheduled on the event loop if they

The Python Library Reference, Release 3.13.2



block. This can be a performance improvement as the overhead of loop scheduling is avoided for coroutines

that complete synchronously.

A common example where this is beneficial is coroutines which employ caching or memoization to avoid actual

I/O when possible.



® Note

Immediate execution of the coroutine is a semantic change. If the coroutine returns or raises, the task is never scheduled to the event loop. If the coroutine execution blocks, the task is scheduled to the event loop. This change may introduce behavior changes to existing applications. For example, the application’s task execution order is likely to change.



Added in version 3.12.

custom_task_constructor

Create an eager task factory, similar to , using the provided cus-

tom_task_constructor when creating a new task instead of the default .

custom_task_constructor must be a callable with the signature matching the signature of .

The callable must return a -compatible object.

This function returns a callable intended to be used as a task factory of an event loop via

).

Added in version 3.12.



Shielding From Cancellation

aw

Protect an awaitable object from being .

If aw is a coroutine it is automatically scheduled as a Task.

The statement:





is equivalent to:





except that if the coroutine containing it is cancelled, the Task running in is not cancelled. From

the point of view of , the cancellation did not happen. Although its caller is still cancelled, so

the “await” expression still raises a .

If is cancelled by other means (i.e. from within itself) that would also cancel .

If it is desired to completely ignore cancellation (not recommended) the function should be com-

bined with a try/except clause, as follows:





The Python Library Reference, Release 3.13.2



ǩ Important

Save a reference to tasks passed to this function, to avoid a task disappearing mid-execution. The event loop only keeps weak references to tasks. A task that isn’t referenced elsewhere may get garbage collected at any time, even before it’s done.



Changed in version 3.10: Removed the loop parameter.

Deprecated since version 3.10: Deprecation warning is emitted if aw is not Future-like object and there is no

running event loop.



Timeouts

delay

Return an asynchronous context manager that can be used to limit the amount of time spent waiting on some-

thing.

delay can either be , or a float/int number of seconds to wait. If delay is , no time limit will be

applied; this can be useful if the delay is unknown when the context manager is created.

In either case, the context manager can be rescheduled after creation using .

Example:





If takes more than 10 seconds to complete, the context manager will cancel the current

task and handle the resulting internally, transforming it into a

which can be caught and handled.



® Note

The context manager is what transforms the into a

, which means the can only be caught outside of the context manager.



Example of catching :





The context manager produced by can be rescheduled to a different deadline and in-

spected.

when

An asynchronous context manager for cancelling overdue coroutines.

should be an absolute time at which the context should time out, as measured by the event loop’s clock:

• If is , the timeout will never trigger.

• If , the timeout will trigger on the next iteration of the event loop.

The Python Library Reference, Release 3.13.2



→ float | None

Return the current deadline, or if the current deadline is not set.

when: float | None

Reschedule the timeout.

→ bool

Return whether the context manager has exceeded its deadline (expired).

Example:





Timeout context managers can be safely nested.

Added in version 3.11.

when

Similar to , except when is the absolute time to stop waiting, or .

Example:





Added in version 3.11.

aw, timeout

Wait for the aw awaitable to complete with a timeout.

If aw is a coroutine it is automatically scheduled as a Task.

timeout can either be or a float or int number of seconds to wait for. If timeout is , block until the

future completes.

If a timeout occurs, it cancels the task and raises .

To avoid the task , wrap it in .

The function will wait until the future is actually cancelled, so the total wait time may exceed the timeout. If

an exception happens during cancellation, it is propagated.

The Python Library Reference, Release 3.13.2



If the wait is cancelled, the future aw is also cancelled.

Example:





Changed in version 3.7: When aw is cancelled due to a timeout, waits for aw to be cancelled.

Previously, it raised immediately.

Changed in version 3.10: Removed the loop parameter.

Changed in version 3.11: Raises instead of .



Waiting Primitives

aws, *, timeout=None, return_when=ALL_COMPLETED

Run and instances in the aws iterable concurrently and block until the condition specified by

return_when.

The aws iterable must not be empty.

Returns two sets of Tasks/Futures: .

Usage:





timeout (a float or int), if specified, can be used to control the maximum number of seconds to wait before

returning.

Note that this function does not raise . Futures or Tasks that aren’t done when the timeout

occurs are simply returned in the second set.

return_when indicates when this function should return. It must be one of the following constants:



Constant Description

The function will return when any future finishes or

is cancelled.

The function will return when any future finishes by



then it is equivalent to .

The function will return when all futures finish or are

cancelled.

The Python Library Reference, Release 3.13.2



Unlike , does not cancel the futures when a timeout occurs.

Changed in version 3.10: Removed the loop parameter.

Changed in version 3.11: Passing coroutine objects to directly is forbidden.

Changed in version 3.12: Added support for generators yielding tasks.

aws, *, timeout=None

Run awaitable objects in the aws iterable concurrently. The returned object can be iterated to obtain the results

of the awaitables as they finish.

The object returned by can be iterated as an asynchronous iterator or a plain iterator. When

asynchronous iteration is used, the originally-supplied awaitables are yielded if they are tasks or futures. This

makes it easy to correlate previously-scheduled tasks with their results. Example:





During asynchronous iteration, implicitly-created tasks will be yielded for supplied awaitables that aren’t tasks

or futures.

When used as a plain iterator, each iteration yields a new coroutine that returns the result or raises the exception

of the next completed awaitable. This pattern is compatible with Python versions older than 3.13:





A is raised if the timeout occurs before all awaitables are done. This is raised by the

loop during asynchronous iteration or by the coroutines yielded during plain iteration.

Changed in version 3.10: Removed the loop parameter.

Deprecated since version 3.10: Deprecation warning is emitted if not all awaitable objects in the aws iterable

are Future-like objects and there is no running event loop.

Changed in version 3.12: Added support for generators yielding tasks.

Changed in version 3.13: The result can now be used as either an asynchronous iterator or as a plain iterator

(previously it was only a plain iterator).



The Python Library Reference, Release 3.13.2



Running in Threads

func, / , *args, **kwargs

Asynchronously run function func in a separate thread.

Any *args and **kwargs supplied for this function are directly passed to func.

is propagated, allowing context variables from the event loop thread to be accessed

in the separate thread.

Return a coroutine that can be awaited to get the eventual result of func.

This coroutine function is primarily intended to be used for executing IO-bound functions/methods that would

otherwise block the event loop if they were run in the main thread. For example:





Directly calling in any coroutine would block the event loop for its duration, resulting in an

additional 1 second of run time. Instead, by using , we can run it in a separate thread

without blocking the event loop.



® Note

Due to the GIL, can typically only be used to make IO-bound functions non-blocking. However, for extension modules that release the GIL or alternative Python implementations that don’t have one, can also be used for CPU-bound functions.



Added in version 3.9.



Scheduling From Other Threads

coro, loop

Submit a coroutine to the given event loop. Thread-safe.

Return a to wait for the result from another OS thread.

The Python Library Reference, Release 3.13.2



This function is meant to be called from a different OS thread than the one where the event loop is running.

Example:





If an exception is raised in the coroutine, the returned Future will be notified. It can also be used to cancel the

task in the event loop:





See the concurrency and multithreading section of the documentation.

Unlike other asyncio functions this function requires the loop argument to be passed explicitly.

Added in version 3.5.1.



Introspection

loop=None

Return the currently running instance, or if no task is running.

If loop is is used to get the current loop.

Added in version 3.7.

loop=None

Return a set of not yet finished objects run by the loop.

If loop is , is used for getting current loop.

Added in version 3.7.

obj

Return if obj is a coroutine object.

Added in version 3.4.



Task Object

coro, *, loop=None, name=None, context=None, eager_start=False

A object that runs a Python coroutine. Not thread-safe.

Tasks are used to run coroutines in event loops. If a coroutine awaits on a Future, the Task suspends the

execution of the coroutine and waits for the completion of the Future. When the Future is done, the execution

of the wrapped coroutine resumes.

Event loops use cooperative scheduling: an event loop runs one Task at a time. While a Task awaits for the

completion of a Future, the event loop runs other Tasks, callbacks, or performs IO operations.

The Python Library Reference, Release 3.13.2



Use the high-level function to create Tasks, or the low-level

or functions. Manual instantiation of Tasks is discouraged.

To cancel a running Task use the method.

exception into the wrapped coroutine. If a coroutine is awaiting on a Future object during

cancellation, the Future object will be cancelled.

can be used to check if the Task was cancelled. The method returns if the wrapped

coroutine did not suppress the exception and was actually cancelled.

inherits from all of its APIs except and

.

An optional keyword-only context argument allows specifying a custom for the coro

to run in. If no context is provided, the Task copies the current context and later runs its coroutine in the copied

context.

An optional keyword-only eager_start argument allows eagerly starting the execution of the

at task creation time. If set to and the event loop is running, the task will start executing the coroutine

immediately, until the first time the coroutine blocks. If the coroutine returns or raises without blocking, the

task will be finished eagerly and will skip scheduling to the event loop.

Changed in version 3.7: Added support for the module.

Changed in version 3.8: Added the name parameter.

Deprecated since version 3.10: Deprecation warning is emitted if loop is not specified and there is no running

event loop.

Changed in version 3.11: Added the context parameter.

Changed in version 3.12: Added the eager_start parameter.



Return if the Task is done.

A Task is done when the wrapped coroutine either returned a value, raised an exception, or the Task was cancelled.



Return the result of the Task.

If the Task is done, the result of the wrapped coroutine is returned (or if the coroutine raised an exception, that exception is re-raised.)

If the Task has been cancelled, this method raises a exception.

If the Task’s result isn’t yet available, this method raises an exception.



Return the exception of the Task.

If the wrapped coroutine raised an exception that exception is returned. If the wrapped coroutine returned normally this method returns .

If the Task has been cancelled, this method raises a exception.

If the Task isn’t done yet, this method raises an exception.

callback, *, context=None

Add a callback to be run when the Task is done.

This method should only be used in low-level callback-based code.

See the documentation of for more details.



The Python Library Reference, Release 3.13.2



callback

Remove callback from the callbacks list.

This method should only be used in low-level callback-based code.

See the documentation of for more details.

*, limit=None

Return the list of stack frames for this Task.

If the wrapped coroutine is not done, this returns the stack where it is suspended. If the coroutine has completed successfully or was cancelled, this returns an empty list. If the coroutine was terminated by an exception, this returns the list of traceback frames.

The frames are always ordered from oldest to newest.

Only one stack frame is returned for a suspended coroutine.

The optional limit argument sets the maximum number of frames to return; by default all available frames are returned. The ordering of the returned list differs depending on whether a stack or a traceback is returned: the newest frames of a stack are returned, but the oldest frames of a traceback are returned. (This matches the behavior of the traceback module.)

*, limit=None, file=None

Print the stack or traceback for this Task.

This produces output similar to that of the traceback module for the frames retrieved by .

The limit argument is passed to directly.

The file argument is an I/O stream to which the output is written; by default output is written to

.



Return the coroutine object wrapped by the .



® Note

This will return for Tasks which have already completed eagerly. See the Eager Task Factory.



Added in version 3.8.

Changed in version 3.12: Newly added eager task execution means result may be .



Return the object associated with the task.

Added in version 3.12.



Return the name of the Task.

If no name has been explicitly assigned to the Task, the default asyncio Task implementation generates a default name during instantiation.

Added in version 3.8.

value

Set the name of the Task.

The value argument can be any object, which is then converted to a string.

In the default Task implementation, the name will be visible in the output of a task object.

Added in version 3.8.

The Python Library Reference, Release 3.13.2



msg=None

Request the Task to be cancelled.

This arranges for a exception to be thrown into the wrapped coroutine on the next cycle of the event loop.

The coroutine then has a chance to clean up or even deny the request by suppressing the exception with

a … … … block. Therefore, unlike ,

does not guarantee that the Task will be cancelled, although suppressing cancellation completely is not common and is actively discouraged. Should the coroutine nevertheless decide to sup-

press the cancellation, it needs to call in addition to catching the exception.

Changed in version 3.9: Added the msg parameter.

Changed in version 3.11: The parameter is propagated from cancelled task to its awaiter.

following example illustrates how coroutines can intercept the cancellation request:





Return if the Task is cancelled.

The Task is cancelled when the cancellation was requested with and the wrapped coroutine

propagated the exception thrown into it.



Decrement the count of cancellation requests to this Task.

Returns the remaining number of cancellation requests.

The Python Library Reference, Release 3.13.2



Note that once execution of a cancelled task completed, further calls to are ineffective.

Added in version 3.11.

This method is used by asyncio’s internals and isn’t expected to be used by end-user code. In particular, if

a Task gets successfully uncancelled, this allows for elements of structured concurrency like Task Groups

and to continue running, isolating cancellation to the respective structured block. For example:





While the block with and might get cancelled due to the timeout, should continue running even in case of the timeout. This is imple-

mented with . context managers use in a similar fashion.

If end-user code is, for some reason, suppressing cancellation by catching , it needs to call this method to remove the cancellation state.

When this method decrements the cancellation count to zero, the method checks if a previous

call had arranged for to be thrown into the task. If it hasn’t been thrown yet, that arrangement will be rescinded (by resetting the internal flag).

Changed in version 3.13: Changed to rescind pending cancellation requests upon reaching zero.



Return the number of pending cancellation requests to this Task, i.e., the number of calls to

less the number of calls.

Note that if this number is greater than zero but the Task is still executing, will still return

. This is because this number can be lowered by calling , which can lead to the task not being cancelled after all if the cancellation requests go down to zero.

This method is used by asyncio’s internals and isn’t expected to be used by end-user code. See

for more details.

Added in version 3.11.





Source code: Lib/asyncio/streams.py



Streams are high-level async/await-ready primitives to work with network connections. Streams allow sending and receiving data without using callbacks or low-level protocols and transports.

Here is an example of a TCP echo client written using asyncio streams:





The Python Library Reference, Release 3.13.2





See also the Examples section below.



Stream Functions

The following top-level asyncio functions can be used to create and work with streams:

host=None, port=None, *, limit=None, ssl=None, family=0, proto=0,

flags=0, sock=None, local_addr=None, server_hostname=None,

ssl_handshake_timeout=None, ssl_shutdown_timeout=None,

happy_eyeballs_delay=None, interleave=None

Establish a network connection and return a pair of objects.

The returned reader and writer objects are instances of and classes.

limit determines the buffer size limit used by the returned instance. By default the limit is set

to 64 KiB.

The rest of the arguments are passed directly to .



® Note

The sock argument transfers ownership of the socket to the created. To close the socket,

call its method.



Changed in version 3.7: Added the ssl_handshake_timeout parameter.

Changed in version 3.8: Added the happy_eyeballs_delay and interleave parameters.

Changed in version 3.10: Removed the loop parameter.

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.

client_connected_cb, host=None, port=None, *, limit=None,

family=socket.AF_UNSPEC, flags=socket.AI_PASSIVE, sock=None,

backlog=100, ssl=None, reuse_address=None, reuse_port=None,

keep_alive=None, ssl_handshake_timeout=None,

ssl_shutdown_timeout=None, start_serving=True

Start a socket server.

The client_connected_cb callback is called whenever a new client connection is established. It receives a

pair as two arguments, instances of the and classes.

client_connected_cb can be a plain callable or a coroutine function; if it is a coroutine function, it will be

automatically scheduled as a .

limit determines the buffer size limit used by the returned instance. By default the limit is set

to 64 KiB.

The rest of the arguments are passed directly to .

The Python Library Reference, Release 3.13.2



® Note

The sock argument transfers ownership of the socket to the server created. To close the socket, call the

server’s method.



Changed in version 3.7: Added the ssl_handshake_timeout and start_serving parameters.

Changed in version 3.10: Removed the loop parameter.

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.

Changed in version 3.13: Added the keep_alive parameter.



Unix Sockets

path=None, *, limit=None, ssl=None, sock=None,

server_hostname=None, ssl_handshake_timeout=None,

ssl_shutdown_timeout=None

Establish a Unix socket connection and return a pair of .

Similar to but operates on Unix sockets.

See also the documentation of .



® Note

The sock argument transfers ownership of the socket to the created. To close the socket,

call its method.



Availability: Unix.

Changed in version 3.7: Added the ssl_handshake_timeout parameter. The path parameter can now be a

path-like object

Changed in version 3.10: Removed the loop parameter.

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.

client_connected_cb, path=None, *, limit=None, sock=None,

backlog=100, ssl=None, ssl_handshake_timeout=None,

ssl_shutdown_timeout=None, start_serving=True

Start a Unix socket server.

Similar to but works with Unix sockets.

See also the documentation of .



® Note

The sock argument transfers ownership of the socket to the server created. To close the socket, call the

server’s method.



Availability: Unix.

Changed in version 3.7: Added the ssl_handshake_timeout and start_serving parameters. The path parameter

can now be a path-like object.

Changed in version 3.10: Removed the loop parameter.

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.

The Python Library Reference, Release 3.13.2



StreamReader



Represents a reader object that provides APIs to read data from the IO stream. As an asynchronous iterable,

the object supports the statement.

It is not recommended to instantiate StreamReader objects directly; use and

instead.



Acknowledge the EOF.

n=-1

Read up to n bytes from the stream.

If n is not provided or set to, read until EOF, then return all read . If EOF was received and the internal buffer is empty, return an empty object.

If n is , return an empty object immediately.

If n is positive, return at most n available as soon as at least 1 byte is available in the internal buffer. If EOF is received before any byte is read, return an empty object.



Read one line, where “line” is a sequence of bytes ending with .

If EOF is received and was not found, the method returns partially read data.

If EOF is received and the internal buffer is empty, return an empty object.

n

Read exactly n bytes.

Raise an if EOF is reached before n can be read.

attribute to get the partially read data.

separator=b’\n’

Read data from the stream until separator is found.

On success, the data and separator will be removed from the internal buffer (consumed). Returned data will include the separator at the end.

If the amount of data read exceeds the configured stream limit, a exception is raised, and the data is left in the internal buffer and can be read again.

If EOF is reached before the complete separator is found, an exception is

raised, and the internal buffer is reset. The attribute may contain a portion of the separator.

The separator may also be a tuple of separators. In this case the return value will be the shortest possible

that has any separator as the suffix. For the purposes of , the shortest possible separator is considered to be the one that matched.

Added in version 3.5.2.

Changed in version 3.13: The separator parameter may now be a of separators.



Return if the buffer is empty and was called.



StreamWriter



Represents a writer object that provides APIs to write data to the IO stream.

It is not recommended to instantiate StreamWriter objects directly; use and

instead.

The Python Library Reference, Release 3.13.2



data

The method attempts to write the data to the underlying socket immediately. If that fails, the data is queued in an internal write buffer until it can be sent.

The method should be used along with the method:





data

The method writes a list (or any iterable) of bytes to the underlying socket immediately. If that fails, the data is queued in an internal write buffer until it can be sent.

The method should be used along with the method:





The method closes the stream and the underlying socket.

The method should be used, though not mandatory, along with the method:





Return if the underlying transport supports the method, otherwise.



Close the write end of the stream after the buffered write data is flushed.



Return the underlying asyncio transport.

name, default=None

Access optional transport information; see for details.



Wait until it is appropriate to resume writing to the stream. Example:





This is a flow control method that interacts with the underlying IO write buffer. When the size of the buffer reaches the high watermark, drain() blocks until the size of the buffer is drained down to the

low watermark and writing can be resumed. When there is nothing to wait for, the returns immediately.

sslcontext, *, server_hostname=None, ssl_handshake_timeout=None,

ssl_shutdown_timeout=None

Upgrade an existing stream-based connection to TLS.

Parameters:

• sslcontext: a configured instance of .

• server_hostname: sets or overrides the host name that the target server’s certificate will be matched

against.

• ssl_handshake_timeout is the time in seconds to wait for the TLS handshake to complete before

aborting the connection. seconds if (default).

The Python Library Reference, Release 3.13.2



• ssl_shutdown_timeout is the time in seconds to wait for the SSL shutdown to complete before abort-

ing the connection. seconds if (default).

Added in version 3.11.

Changed in version 3.12: Added the ssl_shutdown_timeout parameter.



Return if the stream is closed or in the process of being closed.

Added in version 3.7.



Wait until the stream is closed.

Should be called after to wait until the underlying connection is closed, ensuring that all data has been flushed before e.g. exiting the program.

Added in version 3.7.



Examples

TCP echo client using streams

TCP echo client using the function:





µ See also

The TCP echo client protocol example uses the low-level method.



TCP echo server using streams

TCP echo server using the function:





The Python Library Reference, Release 3.13.2





µ See also

The TCP echo server protocol example uses the method.



Get HTTP headers

Simple example querying HTTP headers of the URL passed on the command line:





The Python Library Reference, Release 3.13.2





Usage:





or with HTTPS:





Register an open socket to wait for data using streams

Coroutine waiting until a socket receives data using the function:





µ See also

The Python Library Reference, Release 3.13.2



The register an open socket to wait for data using a protocol example uses a low-level protocol and the

method.

The watch a file descriptor for read events example uses the low-level method to watch a

file descriptor.





Source code: Lib/asyncio/locks.py



asyncio synchronization primitives are designed to be similar to those of the module with two important caveats:

• asyncio primitives are not thread-safe, therefore they should not be used for OS thread synchronization (use

for that);

• methods of these synchronization primitives do not accept the timeout argument; use the

function to perform operations with timeouts.

asyncio has the following basic synchronization primitives:

•

•

•

•

•

•



Lock



Implements a mutex lock for asyncio tasks. Not thread-safe.

An asyncio lock can be used to guarantee exclusive access to a shared resource.

The preferred way to use a Lock is an statement:





which is equivalent to:





Changed in version 3.10: Removed the loop parameter.

The Python Library Reference, Release 3.13.2





Acquire the lock.

This method waits until the lock is unlocked, sets it to locked and returns .

When more than one coroutine is blocked in waiting for the lock to be unlocked, only one coroutine eventually proceeds.

Acquiring a lock is fair: the coroutine that proceeds will be the first coroutine that started waiting on the lock.



Release the lock.

When the lock is locked, reset it to unlocked and return.

If the lock is unlocked, a is raised.



Return if the lock is locked.



Event



An event object. Not thread-safe.

An asyncio event can be used to notify multiple asyncio tasks that some event has happened.

An Event object manages an internal flag that can be set to true with the method and reset to false with

the method. The method blocks until the flag is set to true. The flag is set to false initially.

Changed in version 3.10: Removed the loop parameter. Example:





Wait until the event is set.

If the event is set, return immediately. Otherwise block until another task calls .



Set the event.

All tasks waiting for event to be set will be immediately awakened.

The Python Library Reference, Release 3.13.2





Clear (unset) the event.

Tasks awaiting on will now block until the method is called again.



Return if the event is set.



Condition

lock=None

A Condition object. Not thread-safe.

An asyncio condition primitive can be used by a task to wait for some event to happen and then get exclusive

access to a shared resource.

In essence, a Condition object combines the functionality of an and a . It is possible to have

multiple Condition objects share one Lock, which allows coordinating exclusive access to a shared resource

between different tasks interested in particular states of that shared resource.

The optional lock argument must be a object or . In the latter case a new Lock object is created

automatically.

Changed in version 3.10: Removed the loop parameter.

The preferred way to use a Condition is an statement:





which is equivalent to:





Acquire the underlying lock.

This method waits until the underlying lock is unlocked, sets it to locked and returns .

n=1

Wake up n tasks (1 by default) waiting on this condition. If fewer than n tasks are waiting they are all awakened.

The lock must be acquired before this method is called and released shortly after. If called with an

unlocked lock a error is raised.



Return if the underlying lock is acquired.



Wake up all tasks waiting on this condition.

This method acts like , but wakes up all waiting tasks.

The Python Library Reference, Release 3.13.2



The lock must be acquired before this method is called and released shortly after. If called with an

unlocked lock a error is raised.



Release the underlying lock.

When invoked on an unlocked lock, a is raised.



Wait until notified.

If the calling task has not acquired the lock when this method is called, a is raised.

This method releases the underlying lock, and then blocks until it is awakened by a or

call. Once awakened, the Condition re-acquires its lock and this method returns .

Note that a task may return from this call spuriously, which is why the caller should always re-check the

state and be prepared to again. For this reason, you may prefer to use instead.

predicate

Wait until a predicate becomes true.

The predicate must be a callable which result will be interpreted as a boolean value. The method will

repeatedly until the predicate evaluates to true. The final value is the return value.



Semaphore

value=1

A Semaphore object. Not thread-safe.

A semaphore manages an internal counter which is decremented by each call and incremented by

each call. The counter can never go below zero; when finds that it is zero, it blocks,

waiting until some task calls .

The optional value argument gives the initial value for the internal counter ( by default). If the given value is

less than a is raised.

Changed in version 3.10: Removed the loop parameter.

The preferred way to use a Semaphore is an statement:





which is equivalent to:





Acquire a semaphore.

If the internal counter is greater than zero, decrement it by one and return immediately. If it is

zero, wait until a is called and return .

The Python Library Reference, Release 3.13.2





Returns if semaphore can not be acquired immediately.



Release a semaphore, incrementing the internal counter by one. Can wake up a task waiting to acquire the semaphore.

Unlike , allows making more calls than calls.



BoundedSemaphore

value=1

A bounded semaphore object. Not thread-safe.

Bounded Semaphore is a version of that raises a in if it increases the

internal counter above the initial value.

Changed in version 3.10: Removed the loop parameter.



Barrier

parties

A barrier object. Not thread-safe.

A barrier is a simple synchronization primitive that allows to block until parties number of tasks are waiting

on it. Tasks can wait on the method and would be blocked until the specified number of tasks end up

waiting on . At that point all of the waiting tasks would unblock simultaneously.

can be used as an alternative to awaiting on .

The barrier can be reused any number of times.

Example:





Result of this example is:





The Python Library Reference, Release 3.13.2



Added in version 3.11.



Pass the barrier. When all the tasks party to the barrier have called this function, they are all unblocked simultaneously.

When a waiting or blocked task in the barrier is cancelled, this task exits the barrier which stays in the same state. If the state of the barrier is “filling”, the number of waiting task decreases by 1.

The return value is an integer in the range of 0 to , different for each task. This can be used to select a task to do some special housekeeping, e.g.:





This method may raise a exception if the barrier is broken or reset while a task

is waiting. It could raise a if a task is cancelled.



Return the barrier to the default, empty state.

exception.

If a barrier is broken it may be better to just leave it and create a new one.



Put the barrier into a broken state. This causes any active or future calls to to fail with the

. Use this for example if one of the tasks needs to abort, to avoid infinite waiting tasks.



The number of tasks required to pass the barrier.



The number of tasks currently waiting in the barrier while filling.



A boolean that is if the barrier is in the broken state.



This exception, a subclass of , is raised when the object is reset or broken.



Changed in version 3.9: Acquiring a lock using or and/or statement ( , ) was removed. Use instead.





Source code: Lib/asyncio/subprocess.py, Lib/asyncio/base_subprocess.py



This section describes high-level async/await asyncio APIs to create and manage subprocesses.

Here’s an example of how asyncio can run a shell command and obtain its result:





The Python Library Reference, Release 3.13.2





will print:





Because all asyncio subprocess functions are asynchronous and asyncio provides many tools to work with such func-tions, it is easy to execute and monitor multiple subprocesses in parallel. It is indeed trivial to modify the above example to run several commands simultaneously:





See also the Examples subsection.



Creating Subprocesses

program, *args, stdin=None, stdout=None, stderr=None,

limit=None, **kwds

Create a subprocess.

The limit argument sets the buffer limit for wrappers for and

(if is passed to stdout and stderr arguments).

Return a instance.

See the documentation of for other parameters.

Changed in version 3.10: Removed the loop parameter.

cmd, stdin=None, stdout=None, stderr=None, limit=None,

**kwds

Run the cmd shell command.

The limit argument sets the buffer limit for wrappers for and

(if is passed to stdout and stderr arguments).

Return a instance.

See the documentation of for other parameters.



The Python Library Reference, Release 3.13.2



ǩ Important

It is the application’s responsibility to ensure that all whitespace and special characters are quoted appropri-

ately to avoid shell injection vulnerabilities. The function can be used to properly escape whitespace and special shell characters in strings that are going to be used to construct shell commands.



Changed in version 3.10: Removed the loop parameter.



® Note

Subprocesses are available for Windows if a is used. See Subprocess Support on Windows

for details.



µ See also

asyncio also has the following low-level APIs to work with subprocesses: ,

, , , as well as the

Subprocess Transports and Subprocess Protocols.



Constants



Can be passed to the stdin, stdout or stderr parameters.

If PIPE is passed to stdin argument, the attribute will point to a instance.

If PIPE is passed to stdout or stderr arguments, the and attributes will

point to instances.



Special value that can be used as the stderr argument and indicates that standard error should be redirected

into standard output.



Special value that can be used as the stdin, stdout or stderr argument to process creation functions. It indicates

that the special file will be used for the corresponding subprocess stream.



Interacting with Subprocesses

Both and functions return instances of the Pro-cess class. Process is a high-level wrapper that allows communicating with subprocesses and watching for their completion.



An object that wraps OS processes created by the and

functions.

This class is designed to have a similar API to the class, but there are some notable

differences:

• unlike Popen, Process instances do not have an equivalent to the method;

• the and methods don’t have a timeout parameter: use the func-

tion;

• the method is asynchronous, whereas method is im-

plemented as a blocking busy loop;

• the universal_newlines parameter is not supported.

The Python Library Reference, Release 3.13.2



This class is not thread safe.

See also the Subprocess and Threads section.



Wait for the child process to terminate.

Set and return the attribute.



® Note

This method can deadlock when using or and the child process gen-erates so much output that it blocks waiting for the OS pipe buffer to accept more data. Use the

method when using pipes to avoid this condition.



input=None

Interact with process:

1. send data to stdin (if input is not );

2. closes stdin;

3. read data from stdout and stderr, until EOF is reached;

4. wait for process to terminate.

The optional input argument is the data ( object) that will be sent to the child process.

Return a tuple .

If either or exception is raised when writing input into stdin, the exception is ignored. This condition occurs when the process exits before all data are written into stdin.

If it is desired to send data to the process’ stdin, the process needs to be created with . Simi-larly, to get anything other than in the result tuple, the process has to be created with and/or arguments.

Note, that the data read is buffered in memory, so do not use this method if the data size is large or unlimited.

Changed in version 3.12: stdin gets closed when input=None too.

signal

Sends the signal signal to the child process.



® Note

On Windows, is an alias for . and can be sent to processes started with a creationflags parameter which includes .





Stop the child process.

On POSIX systems this method sends to the child process.

On Windows the Win32 API function is called to stop the child process.



Kill the child process.

On POSIX systems this method sends to the child process.

On Windows this method is an alias for .

The Python Library Reference, Release 3.13.2





Standard input stream () or if the process was created with .



Standard output stream () or if the process was created with .



Standard error stream () or if the process was created with .



Á Warning

Use the method rather than ,

or . This avoids deadlocks due to streams pausing reading or writing and blocking the child process.





Process identification number (PID).

Note that for processes created by the function, this attribute is the PID of the spawned shell.



Return code of the process when it exits.

A value indicates that the process has not terminated yet.

A negative value indicates that the child was terminated by signal (POSIX only).



Subprocess and Threads

Standard asyncio event loop supports running subprocesses from different threads by default.

On Windows subprocesses are provided by only (default), has no subprocess support.

On UNIX child watchers are used for subprocess finish waiting, see Process Watchers for more info.

Changed in version 3.8: UNIX switched to use for spawning subprocesses from different threads without any limitation.

Spawning a subprocess with inactive current child watcher raises .

Note that alternative event loop implementations might have own limitations; please refer to their documentation.



µ See also

The Concurrency and multithreading in asyncio section.



Examples

An example using the class to control a subprocess and the class to read from its standard output.

The subprocess is created by the function:





The Python Library Reference, Release 3.13.2





See also the same example written using low-level APIs.





Source code: Lib/asyncio/queues.py



asyncio queues are designed to be similar to classes of the module. Although asyncio queues are not thread-safe, they are designed to be used specifically in async/await code.

Note that methods of asyncio queues don’t have a timeout parameter; use function to do queue operations with a timeout.

See also the Examples section below.



Queue

maxsize=0

A first in, first out (FIFO) queue.

If maxsize is less than or equal to zero, the queue size is infinite. If it is an integer greater than , then

blocks when the queue reaches maxsize until an item is removed by .

Unlike the standard library threading , the size of the queue is always known and can be returned by

calling the method.

Changed in version 3.10: Removed the loop parameter.

This class is not thread safe.



Number of items allowed in the queue.



Return if the queue is empty, otherwise.



Return if there are items in the queue.

If the queue was initialized with (the default), then never returns .



The Python Library Reference, Release 3.13.2





Remove and return an item from the queue. If queue is empty, wait until an item is available.

Raises if the queue has been shut down and is empty, or if the queue has been shut down immediately.



Return an item if one is immediately available, else raise .



Block until all items in the queue have been received and processed.

The count of unfinished tasks goes up whenever an item is added to the queue. The count goes down

whenever a consumer coroutine calls to indicate that the item was retrieved and all work

on it is complete. When the count of unfinished tasks drops to zero, unblocks.

item

Put an item into the queue. If the queue is full, wait until a free slot is available before adding the item.

Raises if the queue has been shut down.

item

Put an item into the queue without blocking.

If no free slot is immediately available, raise .



Return the number of items in the queue.

immediate=False

Shut down the queue, making and raise .

By default, on a shut down queue will only raise once the queue is empty. Set immediate to true

to make raise immediately instead.

All blocked callers of and will be unblocked. If immediate is true, a task will be marked

as done for each remaining item in the queue, which may unblock callers of .

Added in version 3.13.



Indicate that a formerly enqueued work item is complete.

Used by queue consumers. For each used to fetch a work item, a subsequent call to tells the queue that the processing on the work item is complete.

If a is currently blocking, it will resume when all items have been processed (meaning that a

call was received for every item that had been into the queue).

calls for each remaining item in the queue.

Raises if called more times than there were items placed in the queue.



Priority Queue



A variant of ; retrieves entries in priority order (lowest first).

Entries are typically tuples of the form .



LIFO Queue



A variant of that retrieves most recently added entries first (last in, first out).

The Python Library Reference, Release 3.13.2



Exceptions



This exception is raised when the method is called on an empty queue.



Exception raised when the method is called on a queue that has reached its maxsize.



Exception raised when or is called on a queue which has been shut down.

Added in version 3.13.



Examples

Queues can be used to distribute workload between several concurrent tasks:





The Python Library Reference, Release 3.13.2





Source code: Lib/asyncio/exceptions.py





A deprecated alias of , raised when the operation has exceeded the given deadline.

Changed in version 3.11: This class was made an alias of .



The operation has been cancelled.

This exception can be caught to perform custom operations when asyncio Tasks are cancelled. In almost all

situations the exception must be re-raised.

Changed in version 3.8: is now a subclass of rather than .



Invalid internal state of or .

Can be raised in situations like setting a result value for a Future object that already has a result value set.



The “sendfile” syscall is not available for the given socket or file type.

A subclass of .



The requested read operation did not complete fully.

Raised by the asyncio stream APIs.

This exception is a subclass of .



The total number () of expected bytes.



A string of read before the end of stream was reached.



Reached the buffer size limit while looking for a separator.

Raised by the asyncio stream APIs.



The total number of to be consumed bytes.

The Python Library Reference, Release 3.13.2





Source code: Lib/asyncio/events.py, Lib/asyncio/base_events.py



Preface

The event loop is the core of every asyncio application. Event loops run asynchronous tasks and callbacks, perform network IO operations, and run subprocesses.

Application developers should typically use the high-level asyncio functions, such as , and should rarely need to reference the loop object or call its methods. This section is intended mostly for authors of lower-level code, libraries, and frameworks, who need finer control over the event loop behavior.



Obtaining the Event Loop

The following low-level functions can be used to get, set, or create an event loop:



Return the running event loop in the current OS thread.

Raise a if there is no running event loop.

This function can only be called from a coroutine or a callback.

Added in version 3.7.



Get the current event loop.

When called from a coroutine or a callback (e.g. scheduled with call_soon or similar API), this function will

always return the running event loop.

If there is no running event loop set, the function will return the result of the

call.

Because this function has rather complex behavior (especially when custom event loop policies are in use),

using the function is preferred to in coroutines and callbacks.

As noted above, consider using the higher-level function, instead of using these lower level

functions to manually create and close an event loop.

Deprecated since version 3.12: Deprecation warning is emitted if there is no current event loop. In some future

Python release this will become an error.

loop

Set loop as the current event loop for the current OS thread.



Create and return a new event loop object.

Note that the behaviour of , , and functions can

be altered by setting a custom event loop policy.





Contents


This documentation page contains the following sections:

• The Event Loop Methods section is the reference documentation of the event loop APIs;

• The Callback Handles section documents the and instances which are returned from

scheduling methods such as and ;

• The Server Objects section documents types returned from event loop methods like ;

• The Event Loop Implementations section documents the and

classes;

The Python Library Reference, Release 3.13.2



• The Examples section showcases how to work with some event loop APIs.



Event Loop Methods

Event loops have low-level APIs for the following:



• Running and stopping the loop

• Scheduling callbacks

• Scheduling delayed callbacks

• Creating Futures and Tasks

• Opening network connections

• Creating network servers

• Transferring files

• TLS Upgrade

• Watching file descriptors

• Working with socket objects directly

• DNS

• Working with pipes

• Unix signals

• Executing code in thread or process pools

• Error Handling API

• Enabling debug mode

• Running Subprocesses



Running and stopping the loop

future

Run until the future (an instance of ) has completed.

If the argument is a coroutine object it is implicitly scheduled to run as a .

Return the Future’s result or raise its exception.



Run the event loop until is called.

If is called before is called, the loop will poll the I/O selector once with a timeout

of zero, run all callbacks scheduled in response to I/O events (and those that were already scheduled), and then

exit.

If is called while is running, the loop will run the current batch of callbacks and

then exit. Note that new callbacks scheduled by callbacks will not run in this case; instead, they will run the

next time or is called.



Stop the event loop.



Return if the event loop is currently running.

The Python Library Reference, Release 3.13.2





Return if the event loop was closed.



Close the event loop.

The loop must not be running when this function is called. Any pending callbacks will be discarded.

This method clears all queues and shuts down the executor, but does not wait for the executor to finish.

This method is idempotent and irreversible. No other methods should be called after the event loop is closed.



Schedule all currently open asynchronous generator objects to close with an call. After calling this

method, the event loop will issue a warning if a new asynchronous generator is iterated. This should be used

to reliably finalize all scheduled asynchronous generators.

Note that there is no need to call this function when is used.

Example:





Added in version 3.6.

timeout=None

Schedule the closure of the default executor and wait for it to join all of the threads in the

. Once this method has been called, using the default executor with

will raise a .

The timeout parameter specifies the amount of time (in seconds) the executor will be given to finish

joining. With the default, , the executor is allowed an unlimited amount of time.

If the timeout is reached, a is emitted and the default executor is terminated without waiting

for its threads to finish joining.



® Note

Do not call this method when using , as the latter handles default executor shutdown automatically.



Added in version 3.9.

Changed in version 3.12: Added the timeout parameter.



Scheduling callbacks

callback, *args, context=None

Schedule the callback callback to be called with args arguments at the next iteration of the event loop.

Return an instance of , which can be used later to cancel the callback.

Callbacks are called in the order in which they are registered. Each callback will be called exactly once.

The optional keyword-only context argument specifies a custom for the callback to

run in. Callbacks use the current context when no context is provided.

Unlike , this method is not thread-safe.

The Python Library Reference, Release 3.13.2



callback, *args, context=None

A thread-safe variant of . When scheduling callbacks from another thread, this function must

be used, since is not thread-safe.

This function is safe to be called from a reentrant context or signal handler, however, it is not safe or fruitful

to use the returned handle in such contexts.

Raises if called on a loop that’s been closed. This can happen on a secondary thread when

the main application is shutting down.

See the concurrency and multithreading section of the documentation.

Changed in version 3.7: The context keyword-only parameter was added. See PEP 567 for more details.



® Note

Most scheduling functions don’t allow passing keyword arguments. To do that, use

:





Using partial objects is usually more convenient than using lambdas, as asyncio can render partial objects better

in debug and error messages.



Scheduling delayed callbacks

Event loop provides mechanisms to schedule callback functions to be called at some point in the future. Event loop uses monotonic clocks to track time.

delay, callback, *args, context=None

Schedule callback to be called after the given delay number of seconds (can be either an int or a float).

An instance of is returned which can be used to cancel the callback.

callback will be called exactly once. If two callbacks are scheduled for exactly the same time, the order in

which they are called is undefined.

The optional positional args will be passed to the callback when it is called. If you want the callback to be

called with keyword arguments use .

An optional keyword-only context argument allows specifying a custom for the call-

back to run in. The current context is used when no context is provided.

Changed in version 3.7: The context keyword-only parameter was added. See PEP 567 for more details.

Changed in version 3.8: In Python 3.7 and earlier with the default event loop implementation, the delay could

not exceed one day. This has been fixed in Python 3.8.

when, callback, *args, context=None

Schedule callback to be called at the given absolute timestamp when (an int or a float), using the same time

reference as .

This method’s behavior is the same as .

An instance of is returned which can be used to cancel the callback.

Changed in version 3.7: The context keyword-only parameter was added. See PEP 567 for more details.

Changed in version 3.8: In Python 3.7 and earlier with the default event loop implementation, the difference

between when and the current time could not exceed one day. This has been fixed in Python 3.8.



The Python Library Reference, Release 3.13.2





Return the current time, as a value, according to the event loop’s internal monotonic clock.



® Note

Changed in version 3.8: In Python 3.7 and earlier timeouts (relative delay or absolute when) should not exceed

one day. This has been fixed in Python 3.8.



µ See also

The function.



Creating Futures and Tasks



Create an object attached to the event loop.

This is the preferred way to create Futures in asyncio. This lets third-party event loops provide alternative

implementations of the Future object (with better performance or instrumentation).

Added in version 3.5.2.

coro, *, name=None, context=None

Schedule the execution of coroutine coro. Return a object.

Third-party event loops can use their own subclass of for interoperability. In this case, the result type is

a subclass of .

If the name argument is provided and not , it is set as the name of the task using .

An optional keyword-only context argument allows specifying a custom for the coro

to run in. The current context copy is created when no context is provided.

Changed in version 3.8: Added the name parameter.

Changed in version 3.11: Added the context parameter.

factory

Set a task factory that will be used by .

If factory is the default task factory will be set. Otherwise, factory must be a callable with the signa-

ture matching , where loop is a reference to the active event loop, and coro is a

coroutine object. The callable must pass on all kwargs, and return a -compatible object.



Return a task factory or if the default one is in use.



Opening network connections

protocol_factory, host=None, port=None, *, ssl=None, family=0,

proto=0, flags=0, sock=None, local_addr=None,

server_hostname=None, ssl_handshake_timeout=None,

ssl_shutdown_timeout=None, happy_eyeballs_delay=None,

interleave=None, all_errors=False

Open a streaming transport connection to a given address specified by host and port.

The socket family can be either or depending on host (or the family argument, if pro-

vided).

The socket type will be .

The Python Library Reference, Release 3.13.2



protocol_factory must be a callable returning an asyncio protocol implementation.

This method will try to establish the connection in the background.

pair.

The chronological synopsis of the underlying operation is as follows:

1. The connection is established and a transport is created for it.

2. protocol_factory is called without arguments and is expected to return a protocol instance.

3. The protocol instance is coupled with the transport by calling its method.

4. A tuple is returned on success.

The created transport is an implementation-dependent bidirectional stream.

Other arguments:

• ssl: if given and not false, a SSL/TLS transport is created (by default a plain TCP transport is created).

If ssl is a object, this context is used to create the transport; if ssl is , a default

context returned from is used.



µ See also

SSL/TLS security considerations



• server_hostname sets or overrides the hostname that the target server’s certificate will be matched against.

Should only be passed if ssl is not . By default the value of the host argument is used. If host is empty, there is no default and you must pass a value for server_hostname. If server_hostname is an empty string, hostname matching is disabled (which is a serious security risk, allowing for potential man-in-the-middle attacks).

• family, proto, flags are the optional address family, protocol and flags to be passed through to getad-

drinfo() for host resolution. If given, these should all be integers from the corresponding module constants.

• happy_eyeballs_delay, if given, enables Happy Eyeballs for this connection. It should be a floating-point

number representing the amount of time in seconds to wait for a connection attempt to complete, before

starting the next attempt in parallel. This is the “Connection Attempt Delay” as defined in RFC 8305. A sensible default value recommended by the RFC is (250 milliseconds).

• interleave controls address reordering when a host name resolves to multiple IP addresses. If or un-

specified, no reordering is done, and addresses are tried in the order returned by . If a positive integer is specified, the addresses are interleaved by address family, and the given integer is inter-

preted as “First Address Family Count” as defined in RFC 8305. The default is if happy_eyeballs_delay is not specified, and if it is.

• sock, if given, should be an existing, already connected object to be used by the trans-

port. If sock is given, none of host, port, family, proto, flags, happy_eyeballs_delay, interleave and lo-cal_addr should be specified.



® Note

The sock argument transfers ownership of the socket to the transport created. To close the socket,

call the transport’s method.



• local_addr, if given, is a tuple used to bind the socket locally. The

local_host and local_port are looked up using , similarly to host and port.

• ssl_handshake_timeout is (for a TLS connection) the time in seconds to wait for the TLS handshake to

complete before aborting the connection. seconds if (default).

The Python Library Reference, Release 3.13.2



• ssl_shutdown_timeout is the time in seconds to wait for the SSL shutdown to complete before aborting

the connection. seconds if (default).

• all_errors determines what exceptions are raised when a connection cannot be created. By default, only a

single is raised: the first exception if there is only one or all errors have same message, or a single with the error messages combined. When is , an will be raised containing all exceptions (even if there is only one).

Changed in version 3.5: Added support for SSL/TLS in .

Changed in version 3.6: The socket option socket.TCP_NODELAY is set by default for all TCP connections.

Changed in version 3.7: Added the ssl_handshake_timeout parameter.

Changed in version 3.8: Added the happy_eyeballs_delay and interleave parameters.

Happy Eyeballs Algorithm: Success with Dual-Stack Hosts. When a server’s IPv4 path and protocol are

working, but the server’s IPv6 path and protocol are not working, a dual-stack client application experiences

significant connection delay compared to an IPv4-only client. This is undesirable because it causes the dual-

stack client to have a worse user experience. This document specifies requirements for algorithms that reduce

this user-visible delay and provides an algorithm.

For more information: https://datatracker.ietf.org/doc/html/rfc6555

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.

Changed in version 3.12: all_errors was added.



µ See also

The function is a high-level alternative API. It returns a pair of (,

) that can be used directly in async/await code.



protocol_factory, local_addr=None, remote_addr=None, *,

family=0, proto=0, flags=0, reuse_port=None,

allow_broadcast=None, sock=None

Create a datagram connection.

The socket family can be either , , or , depending on host (or the family argu-

ment, if provided).

The socket type will be .

protocol_factory must be a callable returning a protocol implementation.

A tuple of is returned on success.

Other arguments:

• local_addr, if given, is a tuple used to bind the socket locally. The

local_host and local_port are looked up using .

• remote_addr, if given, is a tuple used to connect the socket to a

remote address. The remote_host and remote_port are looked up using .

• family, proto, flags are the optional address family, protocol and flags to be passed through to

for host resolution. If given, these should all be integers from the corresponding

module constants.

• reuse_port tells the kernel to allow this endpoint to be bound to the same port as other existing end-

points are bound to, so long as they all set this flag when being created. This option is not supported on

Windows and some Unixes. If the socket.SO_REUSEPORT constant is not defined then this capability is unsupported.

• allow_broadcast tells the kernel to allow this endpoint to send messages to the broadcast address.

The Python Library Reference, Release 3.13.2



• sock can optionally be specified in order to use a preexisting, already connected, object

to be used by the transport. If specified, local_addr and remote_addr should be omitted (must be ).



® Note

The sock argument transfers ownership of the socket to the transport created. To close the socket,

call the transport’s method.



See UDP echo client protocol and UDP echo server protocol examples.

Changed in version 3.4.4: The family, proto, flags, reuse_address, reuse_port, allow_broadcast, and sock pa-

rameters were added.

Changed in version 3.8: Added support for Windows.

Changed in version 3.8.1: The reuse_address parameter is no longer supported, as us-

ing socket.SO_REUSEADDR poses a significant security concern for UDP. Explicitly passing

will raise an exception.

When multiple processes with differing UIDs assign sockets to an identical UDP socket address with

, incoming packets can become randomly distributed among the sockets.

For supported platforms, reuse_port can be used as a replacement for similar functionality. With reuse_port,

socket.SO_REUSEPORT is used instead, which specifically prevents processes with differing UIDs from as-

signing sockets to the same socket address.

Changed in version 3.11: The reuse_address parameter, disabled since Python 3.8.1, 3.7.6 and 3.6.10, has

been entirely removed.

protocol_factory, path=None, *, ssl=None, sock=None,

server_hostname=None, ssl_handshake_timeout=None,

ssl_shutdown_timeout=None

Create a Unix connection.

The socket family will be ; socket type will be .

A tuple of is returned on success.

path is the name of a Unix domain socket and is required, unless a sock parameter is specified. Abstract Unix

sockets, , , and paths are supported.

See the documentation of the method for information about arguments to

this method.

Availability: Unix.

Changed in version 3.7: Added the ssl_handshake_timeout parameter. The path parameter can now be a

path-like object.

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.



Creating network servers

protocol_factory, host=None, port=None, *, family=socket.AF_UNSPEC,

flags=socket.AI_PASSIVE, sock=None, backlog=100, ssl=None,

reuse_address=None, reuse_port=None, keep_alive=None,

ssl_handshake_timeout=None, ssl_shutdown_timeout=None,

start_serving=True

Create a TCP server (socket type ) listening on port of the host address.

Returns a object.

Arguments:

• protocol_factory must be a callable returning a protocol implementation.

The Python Library Reference, Release 3.13.2



• The host parameter can be set to several types which determine where the server would be listening:

– If host is a string, the TCP server is bound to a single network interface specified by host.

– If host is a sequence of strings, the TCP server is bound to all network interfaces specified by the

sequence.

– If host is an empty string or , all interfaces are assumed and a list of multiple sockets will be

returned (most likely one for IPv4 and another one for IPv6).

• The port parameter can be set to specify which port the server should listen on. If or (the default),

a random unused port will be selected (note that if host resolves to multiple network interfaces, a different random port will be selected for each interface).

• family can be set to either or to force the socket to use IPv4 or IPv6. If

not set, the family will be determined from host name (defaults to ).

• flags is a bitmask for .

• sock can optionally be specified in order to use a preexisting socket object. If specified, host and port

must not be specified.



® Note

The sock argument transfers ownership of the socket to the server created. To close the socket, call

the server’s method.



• backlog is the maximum number of queued connections passed to (defaults to 100).

• ssl can be set to an instance to enable TLS over the accepted connections.

• reuse_address tells the kernel to reuse a local socket in state, without waiting for its natural

timeout to expire. If not specified will automatically be set to on Unix.

• reuse_port tells the kernel to allow this endpoint to be bound to the same port as other existing endpoints

are bound to, so long as they all set this flag when being created. This option is not supported on Windows.

• keep_alive set to keeps connections active by enabling the periodic transmission of messages.

Changed in version 3.13: Added the keep_alive parameter.

• ssl_handshake_timeout is (for a TLS server) the time in seconds to wait for the TLS handshake to com-

plete before aborting the connection. seconds if (default).

• ssl_shutdown_timeout is the time in seconds to wait for the SSL shutdown to complete before aborting

the connection. seconds if (default).

• start_serving set to (the default) causes the created server to start accepting connections im-

mediately. When set to , the user should await on or

to make the server to start accepting connections.

Changed in version 3.5: Added support for SSL/TLS in .

Changed in version 3.5.1: The host parameter can be a sequence of strings.

Changed in version 3.6: Added ssl_handshake_timeout and start_serving parameters. The socket option

socket.TCP_NODELAY is set by default for all TCP connections.

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.



µ See also

The function is a higher-level alternative API that returns a pair of

and that can be used in an async/await code.



The Python Library Reference, Release 3.13.2



protocol_factory, path=None, *, sock=None, backlog=100, ssl=None,

ssl_handshake_timeout=None, ssl_shutdown_timeout=None,

start_serving=True, cleanup_socket=True

Similar to but works with the socket family.

path is the name of a Unix domain socket, and is required, unless a sock argument is provided. Abstract Unix

sockets, , , and paths are supported.

If cleanup_socket is true then the Unix socket will automatically be removed from the filesystem when the

server is closed, unless the socket has been replaced after the server has been created.

See the documentation of the method for information about arguments to this

method.

Availability: Unix.

Changed in version 3.7: Added the ssl_handshake_timeout and start_serving parameters. The path parameter

can now be a object.

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.

Changed in version 3.13: Added the cleanup_socket parameter.

protocol_factory, sock, *, ssl=None,

ssl_handshake_timeout=None, ssl_shutdown_timeout=None

Wrap an already accepted connection into a transport/protocol pair.

This method can be used by servers that accept connections outside of asyncio but that use asyncio to handle

them.

Parameters:

• protocol_factory must be a callable returning a protocol implementation.

• sock is a preexisting socket object returned from .



® Note

The sock argument transfers ownership of the socket to the transport created. To close the socket,

call the transport’s method.



• ssl can be set to an to enable SSL over the accepted connections.

• ssl_handshake_timeout is (for an SSL connection) the time in seconds to wait for the SSL handshake to

complete before aborting the connection. seconds if (default).

• ssl_shutdown_timeout is the time in seconds to wait for the SSL shutdown to complete before aborting

the connection. seconds if (default).

Returns a pair.

Added in version 3.5.3.

Changed in version 3.7: Added the ssl_handshake_timeout parameter.

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.



Transferring files

transport, file, offset=0, count=None, *, fallback=True

Send a file over a transport. Return the total number of bytes sent.

The method uses high-performance if available.

file must be a regular file object opened in binary mode.

The Python Library Reference, Release 3.13.2



offset tells from where to start reading the file. If specified, count is the total number of bytes to transmit as

opposed to sending the file until EOF is reached. File position is always updated, even when this method raises

an error, and can be used to obtain the actual number of bytes sent.

fallback set to makes asyncio to manually read and send the file when the platform does not support the

sendfile system call (e.g. Windows or SSL socket on Unix).

Raise if the system does not support the sendfile syscall and fallback is

.

Added in version 3.7.



TLS Upgrade

transport, protocol, sslcontext, *, server_side=False, server_hostname=None,

ssl_handshake_timeout=None, ssl_shutdown_timeout=None

Upgrade an existing transport-based connection to TLS.

Create a TLS coder/decoder instance and insert it between the transport and the protocol. The coder/decoder

implements both transport-facing protocol and protocol-facing transport.

Return the created two-interface instance. After await, the protocol must stop using the original transport

and communicate with the returned object only because the coder caches protocol-side data and sporadically

exchanges extra TLS session packets with transport.

In some situations (e.g. when the passed transport is already closing) this may return .

Parameters:

• transport and protocol instances that methods like and

return.

• sslcontext: a configured instance of .

• server_side pass when a server-side connection is being upgraded (like the one created by

).

• server_hostname: sets or overrides the host name that the target server’s certificate will be matched

against.

• ssl_handshake_timeout is (for a TLS connection) the time in seconds to wait for the TLS handshake to

complete before aborting the connection. seconds if (default).

• ssl_shutdown_timeout is the time in seconds to wait for the SSL shutdown to complete before aborting

the connection. seconds if (default).

Added in version 3.7.

Changed in version 3.11: Added the ssl_shutdown_timeout parameter.



Watching file descriptors

fd, callback, *args

Start monitoring the fd file descriptor for read availability and invoke callback with the specified arguments

once fd is available for reading.

Any preexisting callback registered for fd is cancelled and replaced by callback.

fd

Stop monitoring the fd file descriptor for read availability. Returns if fd was previously being monitored

for reads.

fd, callback, *args

Start monitoring the fd file descriptor for write availability and invoke callback with the specified arguments

once fd is available for writing.

Any preexisting callback registered for fd is cancelled and replaced by callback.

The Python Library Reference, Release 3.13.2



Use to pass keyword arguments to callback.

fd

Stop monitoring the fd file descriptor for write availability. Returns if fd was previously being monitored

for writes.

See also Platform Support section for some limitations of these methods.



Working with socket objects directly

In general, protocol implementations that use transport-based APIs such as and

are faster than implementations that work with sockets directly. However, there are

some use cases when performance is not critical, and working with objects directly is more convenient.

sock, nbytes

Receive up to nbytes from sock. Asynchronous version of .

Return the received data as a bytes object.

sock must be a non-blocking socket.

Changed in version 3.7: Even though this method was always documented as a coroutine method, releases

before Python 3.7 returned a . Since Python 3.7 this is an method.

sock, buf

Receive data from sock into the buf buffer. Modeled after the blocking method.

Return the number of bytes written to the buffer.

sock must be a non-blocking socket.

Added in version 3.7.

sock, bufsize

Receive a datagram of up to bufsize from sock. Asynchronous version of .

Return a tuple of (received data, remote address).

sock must be a non-blocking socket.

Added in version 3.11.

sock, buf, nbytes=0

Receive a datagram of up to nbytes from sock into buf. Asynchronous version of .

Return a tuple of (number of bytes received, remote address).

sock must be a non-blocking socket.

Added in version 3.11.

sock, data

Send data to the sock socket. Asynchronous version of .

This method continues to send to the socket until either all data in data has been sent or an error occurs.

is returned on success. On error, an exception is raised. Additionally, there is no way to determine how much

data, if any, was successfully processed by the receiving end of the connection.

sock must be a non-blocking socket.

Changed in version 3.7: Even though the method was always documented as a coroutine method, before Python

3.7 it returned a . Since Python 3.7, this is an method.

sock, data, address

Send a datagram from sock to address. Asynchronous version of .

Return the number of bytes sent.

sock must be a non-blocking socket.

The Python Library Reference, Release 3.13.2



Added in version 3.11.

sock, address

Connect sock to a remote socket at address.

Asynchronous version of .

sock must be a non-blocking socket.

Changed in version 3.5.2: no longer needs to be resolved. will try to check if the

address is already resolved by calling . If not, will be used

to resolve the address.



µ See also

and .



sock

Accept a connection. Modeled after the blocking method.

The socket must be bound to an address and listening for connections. The return value is a pair

where conn is a new socket object usable to send and receive data on the connection, and address

is the address bound to the socket on the other end of the connection.

sock must be a non-blocking socket.

Changed in version 3.7: Even though the method was always documented as a coroutine method, before Python

3.7 it returned a . Since Python 3.7, this is an method.



µ See also

and .



sock, file, offset=0, count=None, *, fallback=True

Send a file using high-performance if possible. Return the total number of bytes sent.

Asynchronous version of .

sock must be a non-blocking .

file must be a regular file object open in binary mode.

offset tells from where to start reading the file. If specified, count is the total number of bytes to transmit as

opposed to sending the file until EOF is reached. File position is always updated, even when this method raises

an error, and can be used to obtain the actual number of bytes sent.

fallback, when set to , makes asyncio manually read and send the file when the platform does not support

the sendfile syscall (e.g. Windows or SSL socket on Unix).

Raise if the system does not support sendfile syscall and fallback is .

sock must be a non-blocking socket.

Added in version 3.7.



DNS

host, port, *, family=0, type=0, proto=0, flags=0

Asynchronous version of .

sockaddr, flags=0

Asynchronous version of .

The Python Library Reference, Release 3.13.2



® Note

Both getaddrinfo and getnameinfo internally utilize their synchronous versions through the loop’s default thread

pool executor. When this executor is saturated, these methods may experience delays, which higher-level net-

working libraries may report as increased timeouts. To mitigate this, consider using a custom executor for other

user tasks, or setting a default executor with a larger number of workers.



Changed in version 3.7: Both getaddrinfo and getnameinfo methods were always documented to return a coroutine, but

prior to Python 3.7 they were, in fact, returning objects. Starting with Python 3.7 both methods are coroutines.



Working with pipes

protocol_factory, pipe

Register the read end of pipe in the event loop.

protocol_factory must be a callable returning an asyncio protocol implementation.

pipe is a file-like object.

Return pair , where transport supports the interface and proto-

col is an object instantiated by the protocol_factory.

With event loop, the pipe is set to non-blocking mode.

protocol_factory, pipe

Register the write end of pipe in the event loop.

protocol_factory must be a callable returning an asyncio protocol implementation.

pipe is file-like object.

Return pair , where transport supports interface and protocol

is an object instantiated by the protocol_factory.

With event loop, the pipe is set to non-blocking mode.



® Note

does not support the above methods on Windows. Use instead

for Windows.



µ See also

The and methods.



Unix signals

signum, callback, *args

Set callback as the handler for the signum signal.

The callback will be invoked by loop, along with other queued callbacks and runnable coroutines of that event

loop. Unlike signal handlers registered using , a callback registered with this function is

allowed to interact with the event loop.

Raise if the signal number is invalid or uncatchable. Raise if there is a problem

setting up the handler.

Use to pass keyword arguments to callback.

Like , this function must be invoked in the main thread.

The Python Library Reference, Release 3.13.2



sig

Remove the handler for the sig signal.

Return if the signal handler was removed, or if no handler was set for the given signal.

Availability: Unix.



µ See also

The module.



Executing code in thread or process pools

executor, func, *args

Arrange for func to be called in the specified executor.

The executor argument should be an instance. The default executor is

used if executor is . The default executor can be set by , otherwise, a

will be lazy-initialized and used by

if needed.

Example:





The Python Library Reference, Release 3.13.2





Note that the entry point guard () is required for option 3 due to the pe-

culiarities of , which is used by . See Safe importing of main

module.

This method returns a object.

Use to pass keyword arguments to func.

Changed in version 3.5.3: no longer configures the of the thread

pool executor it creates, instead leaving it up to the thread pool executor () to set the

default.

executor

Set executor as the default executor used by . executor must be an instance of

.

Changed in version 3.11: executor must be an instance of .



Error Handling API

Allows customizing how exceptions are handled in the event loop.

handler

Set handler as the new event loop exception handler.

If handler is , the default exception handler will be set. Otherwise, handler must be a callable with the

signature matching , where is a reference to the active event loop, and is

a object containing the details of the exception (see documentation for

details about context).

If the handler is called on behalf of a or , it is run in the of that task

or callback handle.

Changed in version 3.12: The handler may be called in the of the task or handle where the exception

originated.



Return the current exception handler, or if no custom exception handler was set.

Added in version 3.5.2.

context

Default exception handler.

This is called when an exception occurs and no exception handler is set. This can be called by a custom

exception handler that wants to defer to the default handler behavior.

context parameter has the same meaning as in .

context

Call the current event loop exception handler.

context is a object containing the following keys (new keys may be introduced in future Python versions):

• ‘message’: Error message;

• ‘exception’ (optional): Exception object;

• ‘future’ (optional): instance;

• ‘task’ (optional): instance;

The Python Library Reference, Release 3.13.2



• ‘handle’ (optional): instance;

• ‘protocol’ (optional): Protocol instance;

• ‘transport’ (optional): Transport instance;

• ‘socket’ (optional): instance;

• ‘asyncgen’ (optional): Asynchronous generator that caused

the exception.



® Note

This method should not be overloaded in subclassed event loops. For custom exception handling, use the

method.



Enabling debug mode



Get the debug mode () of the event loop.

The default value is if the environment variable is set to a non-empty string,

otherwise.

enabled: bool

Set the debug mode of the event loop.

Changed in version 3.7: The new Python Development Mode can now also be used to enable the debug mode.



This attribute can be used to set the minimum execution duration in seconds that is considered “slow”. When

debug mode is enabled, “slow” callbacks are logged.

Default value is 100 milliseconds.



µ See also

The debug mode of asyncio.



Running Subprocesses

Methods described in this subsections are low-level. In regular async/await code consider using the high-level

and convenience func-tions instead.



® Note

On Windows, the default event loop supports subprocesses, whereas

does not. See Subprocess Support on Windows for details.



protocol_factory, *args, stdin=subprocess.PIPE, stdout=subprocess.PIPE,

stderr=subprocess.PIPE, **kwargs

Create a subprocess from one or more string arguments specified by args.

args must be a list of strings represented by:

• ;

• or , encoded to the filesystem encoding.

The Python Library Reference, Release 3.13.2



The first string specifies the program executable, and the remaining strings specify the arguments. Together,

string arguments form the of the program.

This is similar to the standard library class called with and the list of

strings passed as the first argument; however, where takes a single argument which is list of strings,

subprocess_exec takes multiple string arguments.

The protocol_factory must be a callable returning a subclass of the class.

Other parameters:

• stdin can be any of these:

– a file-like object

– an existing file descriptor (a positive integer), for example those created with

– the constant (default) which will create a new pipe and connect it,

– the value which will make the subprocess inherit the file descriptor from this process

– the constant which indicates that the special file will be used

• stdout can be any of these:

– a file-like object

– the constant (default) which will create a new pipe and connect it,

– the value which will make the subprocess inherit the file descriptor from this process

– the constant which indicates that the special file will be used

• stderr can be any of these:

– a file-like object

– the constant (default) which will create a new pipe and connect it,

– the value which will make the subprocess inherit the file descriptor from this process

– the constant which indicates that the special file will be used

– the constant which will connect the standard error stream to the process’

standard output stream

• All other keyword arguments are passed to without interpretation, except for buf-

size, universal_newlines, shell, text, encoding and errors, which should not be specified at all.

The subprocess API does not support decoding the streams as text. can be used to convert the bytes returned from the stream to text.

If a file-like object passed as stdin, stdout or stderr represents a pipe, then the other side of this pipe should be

registered with or for use with the event loop.

See the constructor of the class for documentation on other arguments.

Returns a pair of , where transport conforms to the

base class and protocol is an object instantiated by the protocol_factory.

protocol_factory, cmd, *, stdin=subprocess.PIPE,

stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs

Create a subprocess from cmd, which can be a or a string encoded to the filesystem encoding, using

the platform’s “shell” syntax.

This is similar to the standard library class called with .

The protocol_factory must be a callable returning a subclass of the class.

See for more details about the remaining arguments.

Returns a pair of , where transport conforms to the

base class and protocol is an object instantiated by the protocol_factory.

The Python Library Reference, Release 3.13.2



® Note

It is the application’s responsibility to ensure that all whitespace and special characters are quoted appropriately

to avoid shell injection vulnerabilities. The function can be used to properly escape whitespace

and special characters in strings that are going to be used to construct shell commands.



Callback Handles



A callback wrapper object returned by , .



Return the object associated with the handle.

Added in version 3.12.



Cancel the callback. If the callback has already been canceled or executed, this method has no effect.



Return if the callback was cancelled.

Added in version 3.7.



A callback wrapper object returned by , and .

This class is a subclass of .



Return a scheduled callback time as seconds.

The time is an absolute timestamp, using the same time reference as .

Added in version 3.7.



Server Objects

Server objects are created by , , ,

and functions.

Do not instantiate the class directly.



Server objects are asynchronous context managers. When used in an statement, it’s guaran-

teed that the Server object is closed and not accepting new connections when the statement is

completed:





Changed in version 3.7: Server object is an asynchronous context manager since Python 3.7.

Changed in version 3.11: This class was exposed publicly as in Python 3.9.11, 3.10.3 and

3.11.



The Python Library Reference, Release 3.13.2





Stop serving: close listening sockets and set the attribute to .

The sockets that represent existing incoming client connections are left open.

The server is closed asynchronously; use the coroutine to wait until the server is closed (and no more connections are active).



Close all existing incoming client connections.

Calls on all associated transports.

should be called before when closing the server to avoid races with new clients connecting.

Added in version 3.13.



Close all existing incoming client connections immediately, without waiting for pending operations to complete.

Calls on all associated transports.

should be called before when closing the server to avoid races with new clients connecting.

Added in version 3.13.



Return the event loop associated with the server object.

Added in version 3.7.



Start accepting connections.

This method is idempotent, so it can be called when the server is already serving.

The start_serving keyword-only parameter to and

allows creating a Server object that is not accepting connections initially.

this case , or can be used to make the Server start accepting connections.

Added in version 3.7.



Start accepting connections until the coroutine is cancelled. Cancellation of task causes the server to be closed.

This method can be called if the server is already accepting connections. Only one task can exist per one Server object.

Example:





The Python Library Reference, Release 3.13.2



Added in version 3.7.



Return if the server is accepting new connections.

Added in version 3.7.



Wait until the method completes and all active connections have finished.



List of socket-like objects, , which the server is listening on.

Changed in version 3.7: Prior to Python 3.7 used to return an internal list of server sockets directly. In 3.7 a copy of that list is returned.



Event Loop Implementations

asyncio ships with two different event loop implementations: and .

By default asyncio is configured to use .



A subclass of based on the module.

Uses the most efficient selector available for the given platform. It is also possible to manually configure the

exact selector implementation to be used:





Availability: Unix, Windows.



A subclass of for Windows that uses “I/O Completion Ports” (IOCP).

Availability: Windows.



µ See also

MSDN documentation on I/O Completion Ports.





An alias to the most efficient available subclass of for the given platform.

It is an alias to on Unix and on Windows.

Added in version 3.13.



Abstract base class for asyncio-compliant event loops.

The Event Loop Methods section lists all methods that an alternative implementation of

should have defined.

The Python Library Reference, Release 3.13.2



Examples

Note that all examples in this section purposefully show how to use the low-level event loop APIs, such as

and . Modern asyncio applications rarely need to be written this way; con-

sider using the high-level functions like .



Hello World with call_soon()

An example using the method to schedule a callback. The callback displays and then stops the event loop:





µ See also

A similar Hello World example created with a coroutine and the function.



Display the current date with call_later()

An example of a callback displaying the current date every second. The callback uses the method to reschedule itself after 5 seconds, and then stops the event loop:





The Python Library Reference, Release 3.13.2





µ See also

A similar current date example created with a coroutine and the function.



Watch a file descriptor for read events

Wait until a file descriptor received some data using the method and then close the event loop:





µ See also

• A similar example using transports, protocols, and the method.

• Another similar example using the high-level function and streams.



The Python Library Reference, Release 3.13.2



Set signal handlers for SIGINT and SIGTERM

(This example only works on Unix.)

Register handlers for signals and using the method:





Source code: Lib/asyncio/futures.py, Lib/asyncio/base_futures.py



Future objects are used to bridge low-level callback-based code with high-level async/await code.



Future Functions

obj

Return if obj is either of:

• an instance of ,

• an instance of ,

• a Future-like object with a attribute.

Added in version 3.5.

obj, *, loop=None

Return:

• obj argument as is, if obj is a , a , or a Future-like object ( is used for the test.)

• a object wrapping obj, if obj is a coroutine ( is used for the test); in this case the

coroutine will be scheduled by .

• a object that would await on obj, if obj is an awaitable ( is used for the

test.)

If obj is neither of the above a is raised.

The Python Library Reference, Release 3.13.2



ǩ Important

See also the function which is the preferred way for creating new Tasks.

Save a reference to the result of this function, to avoid a task disappearing mid-execution.



Changed in version 3.5.1: The function accepts any awaitable object.

Deprecated since version 3.10: Deprecation warning is emitted if obj is not a Future-like object and loop is

not specified and there is no running event loop.

future, *, loop=None

Wrap a object in a object.

Deprecated since version 3.10: Deprecation warning is emitted if future is not a Future-like object and loop is

not specified and there is no running event loop.



Future Object

*, loop=None

A Future represents an eventual result of an asynchronous operation. Not thread-safe.

Future is an awaitable object. Coroutines can await on Future objects until they either have a result or an

exception set, or until they are cancelled. A Future can be awaited multiple times and the result is same.

Typically Futures are used to enable low-level callback-based code (e.g. in protocols implemented using asyn-

cio transports) to interoperate with high-level async/await code.

The rule of thumb is to never expose Future objects in user-facing APIs, and the recommended way to create

a Future object is to call . This way alternative event loop implementations can

inject their own optimized implementations of a Future object.

Changed in version 3.7: Added support for the module.

Deprecated since version 3.10: Deprecation warning is emitted if loop is not specified and there is no running

event loop.



Return the result of the Future.

If the Future is done and has a result set by the method, the result value is returned.

If the Future is done and has an exception set by the method, this method raises the exception.

If the Future has been cancelled, this method raises a exception.

If the Future’s result isn’t yet available, this method raises an exception.

result

Mark the Future as done and set its result.

Raises an error if the Future is already done.

exception

Mark the Future as done and set an exception.

Raises an error if the Future is already done.



Return if the Future is done.

A Future is done if it was cancelled or if it has a result or an exception set with or

calls.

The Python Library Reference, Release 3.13.2





Return if the Future was cancelled.

The method is usually used to check if a Future is not cancelled before setting a result or an exception for it:





callback, *, context=None

Add a callback to be run when the Future is done.

The callback is called with the Future object as its only argument.

If the Future is already done when this method is called, the callback is scheduled with

.

An optional keyword-only context argument allows specifying a custom for the callback to run in. The current context is used when no context is provided.

can be used to pass parameters to the callback, e.g.:





Changed in version 3.7: The context keyword-only parameter was added. See PEP 567 for more details.

callback

Remove callback from the callbacks list.

Returns the number of callbacks removed, which is typically 1, unless a callback was added more than once.

msg=None

Cancel the Future and schedule callbacks.

If the Future is already done or cancelled, return . Otherwise, change the Future’s state to cancelled, schedule the callbacks, and return .

Changed in version 3.9: Added the msg parameter.



Return the exception that was set on this Future.

The exception (or if no exception was set) is returned only if the Future is done.

If the Future has been cancelled, this method raises a exception.

If the Future isn’t done yet, this method raises an exception.



Return the event loop the Future object is bound to.

Added in version 3.7.

This example creates a Future object, creates and schedules an asynchronous Task to set result for the Future, and waits until the Future has a result:





The Python Library Reference, Release 3.13.2





ǩ Important

The Future object was designed to mimic . Key differences include:

• unlike asyncio Futures, instances cannot be awaited.

• and do not accept the timeout argu-

ment.

• and raise an

exception when the Future is not done.

• Callbacks registered with are not called immediately. They

are scheduled with instead.

• asyncio Future is not compatible with the and

functions.

• accepts an optional argument, but

does not.





Preface

Transports and Protocols are used by the low-level event loop APIs such as . They use callback-based programming style and enable high-performance implementations of network or IPC protocols (e.g. HTTP).

Essentially, transports and protocols should only be used in libraries and frameworks and never in high-level asyncio applications.

This documentation page covers both Transports and Protocols.



The Python Library Reference, Release 3.13.2



Introduction

At the highest level, the transport is concerned with how bytes are transmitted, while the protocol determines which bytes to transmit (and to some extent when).

A different way of saying the same thing: a transport is an abstraction for a socket (or similar I/O endpoint) while a protocol is an abstraction for an application, from the transport’s point of view.

Yet another view is the transport and protocol interfaces together define an abstract interface for using network I/O and interprocess I/O.

There is always a 1:1 relationship between transport and protocol objects: the protocol calls transport methods to send data, while the transport calls protocol methods to pass it data that has been received.

Most of connection oriented event loop methods (such as ) usually accept a proto-col_factory argument used to create a Protocol object for an accepted connection, represented by a Transport object. Such methods usually return a tuple of .





Contents


This documentation page contains the following sections:

• The Transports section documents asyncio , , ,

, , and classes.

• The Protocols section documents asyncio , , ,

, and classes.

• The Examples section showcases how to work with transports, protocols, and low-level event loop APIs.



Transports

Source code: Lib/asyncio/transports.py



Transports are classes provided by in order to abstract various kinds of communication channels.

Transport objects are always instantiated by an asyncio event loop.

asyncio implements transports for TCP, UDP, SSL, and subprocess pipes. The methods available on a transport depend on the transport’s kind.

The transport classes are not thread safe.



Transports Hierarchy



Base class for all transports. Contains methods that all asyncio transports share.

BaseTransport

A base transport for write-only connections.

Instances of the WriteTransport class are returned from the event loop

method and are also used by subprocess-related methods like .

BaseTransport

A base transport for read-only connections.

Instances of the ReadTransport class are returned from the event loop method

and are also used by subprocess-related methods like .



The Python Library Reference, Release 3.13.2



WriteTransport, ReadTransport

Interface representing a bidirectional transport, such as a TCP connection.

The user does not instantiate a transport directly; they call a utility function, passing it a protocol factory and

other information necessary to create the transport and protocol.

Instances of the Transport class are returned from or used by event loop methods like

, , ,

, etc.

BaseTransport

A transport for datagram (UDP) connections.

Instances of the DatagramTransport class are returned from the

event loop method.

BaseTransport

An abstraction to represent a connection between a parent and its child OS process.

Instances of the SubprocessTransport class are returned from event loop methods

and .



Base Transport



Close the transport.

If the transport has a buffer for outgoing data, buffered data will be flushed asynchronously. No more data will

be received. After all buffered data is flushed, the protocol’s method will

be called with as its argument. The transport should not be used once it is closed.



Return if the transport is closing or is closed.

name, default=None

Return information about the transport or underlying resources it uses.

name is a string representing the piece of transport-specific information to get.

default is the value to return if the information is not available, or if the transport does not support querying it

with the given third-party event loop implementation or on the current platform.

For example, the following code attempts to get the underlying socket object of the transport:





Categories of information that can be queried on some transports:

• socket:

– : the remote address to which the socket is connected, result of

( on error)

– : instance

– : the socket’s own address, result of

• SSL socket:

– : the compression algorithm being used as a string, or if the connection isn’t

compressed; result of

– : a three-value tuple containing the name of the cipher being used, the version of the SSL

protocol that defines its use, and the number of secret bits being used; result of



The Python Library Reference, Release 3.13.2



– : peer certificate; result of

– : instance

– : or instance

• pipe:

– : pipe object

• subprocess:

– : instance

protocol

Set a new protocol.

Switching protocol should only be done when both protocols are documented to support the switch.



Return the current protocol.



Read-only Transports



Return if the transport is receiving new data.

Added in version 3.7.



Pause the receiving end of the transport. No data will be passed to the protocol’s

method until is called.

Changed in version 3.7: The method is idempotent, i.e. it can be called when the transport is already paused

or closed.



Resume the receiving end. The protocol’s method will be called once again

if some data is available for reading.

Changed in version 3.7: The method is idempotent, i.e. it can be called when the transport is already reading.



Write-only Transports



Close the transport immediately, without waiting for pending operations to complete. Buffered data will be

lost. No more data will be received. The protocol’s method will eventually

be called with as its argument.



Return if the transport supports , if not.



Return the current size of the output buffer used by the transport.



Get the high and low watermarks for write flow control. Return a tuple where low and high are

positive number of bytes.

Use to set the limits.

Added in version 3.4.2.



The Python Library Reference, Release 3.13.2



high=None, low=None

Set the high and low watermarks for write flow control.

These two values (measured in number of bytes) control when the protocol’s

and methods are called. If specified, the low watermark must be less than

or equal to the high watermark. Neither high nor low can be negative.

is called when the buffer size becomes greater than or equal to the high value. If writing

has been paused, is called when the buffer size becomes less than or equal to the low

value.

The defaults are implementation-specific. If only the high watermark is given, the low watermark defaults to

an implementation-specific value less than or equal to the high watermark. Setting high to zero forces low to

zero as well, and causes to be called whenever the buffer becomes non-empty. Setting

low to zero causes to be called only once the buffer is empty. Use of zero for either limit

is generally sub-optimal as it reduces opportunities for doing I/O and computation concurrently.

Use to get the limits.

data

Write some data bytes to the transport.

This method does not block; it buffers the data and arranges for it to be sent out asynchronously.

list_of_data

Write a list (or any iterable) of data bytes to the transport. This is functionally equivalent to calling

on each element yielded by the iterable, but may be implemented more efficiently.



Close the write end of the transport after flushing all buffered data. Data may still be received.

This method can raise if the transport (e.g. SSL) doesn’t support half-closed con-

nections.



Datagram Transports

data, addr=None

Send the data bytes to the remote peer given by addr (a transport-dependent target address). If addr is ,

the data is sent to the target address given on transport creation.

This method does not block; it buffers the data and arranges for it to be sent out asynchronously.

Changed in version 3.13: This method can be called with an empty bytes object to send a zero-length datagram.

The buffer size calculation used for flow control is also updated to account for the datagram header.



Close the transport immediately, without waiting for pending operations to complete. Buffered data will be

lost. No more data will be received. The protocol’s method will eventually

be called with as its argument.



Subprocess Transports



Return the subprocess process id as an integer.

fd

Return the transport for the communication pipe corresponding to the integer file descriptor fd:

• : readable streaming transport of the standard input (stdin), or if the subprocess was not created

with

• : writable streaming transport of the standard output (stdout), or if the subprocess was not created

with

The Python Library Reference, Release 3.13.2



• : writable streaming transport of the standard error (stderr), or if the subprocess was not created

with

• other fd:



Return the subprocess return code as an integer or if it hasn’t returned, which is similar to the

attribute.



Kill the subprocess.

On POSIX systems, the function sends SIGKILL to the subprocess. On Windows, this method is an alias for

.

See also .

signal

Send the signal number to the subprocess, as in .



Stop the subprocess.

On POSIX systems, this method sends to the subprocess. On Windows, the Windows API function

is called to stop the subprocess.

See also .



Kill the subprocess by calling the method.

If the subprocess hasn’t returned yet, and close transports of stdin, stdout, and stderr pipes.



Protocols

Source code: Lib/asyncio/protocols.py



asyncio provides a set of abstract base classes that should be used to implement network protocols. Those classes are

meant to be used together with transports.

Subclasses of abstract base protocol classes may implement some or all methods. All these methods are callbacks: they are called by transports on certain events, for example when some data is received. A base protocol method should be called by the corresponding transport.



Base Protocols



Base protocol with methods that all protocols share.

BaseProtocol

The base class for implementing streaming protocols (TCP, Unix sockets, etc).

BaseProtocol

A base class for implementing streaming protocols with manual control of the receive buffer.

BaseProtocol

The base class for implementing datagram (UDP) protocols.

BaseProtocol

The base class for implementing protocols communicating with child processes (unidirectional pipes).



The Python Library Reference, Release 3.13.2



Base Protocol

All asyncio protocols can implement Base Protocol callbacks.



Connection Callbacks

Connection callbacks are called on all protocols, exactly once per a successful connection. All other protocol callbacks can only be called between those two methods.

transport

Called when a connection is made.

The transport argument is the transport representing the connection. The protocol is responsible for storing

the reference to its transport.

exc

Called when the connection is lost or closed.

The argument is either an exception object or . The latter means a regular EOF is received, or the

connection was aborted or closed by this side of the connection.



Flow Control Callbacks

Flow control callbacks can be called by transports to pause or resume writing performed by the protocol.

See the documentation of the method for more details.



Called when the transport’s buffer goes over the high watermark.



Called when the transport’s buffer drains below the low watermark.

If the buffer size equals the high watermark, is not called: the buffer size must go strictly over.

Conversely, is called when the buffer size is equal or lower than the low watermark. These end conditions are important to ensure that things go as expected when either mark is zero.



Streaming Protocols

Event methods, such as , ,

, , ,

, and accept factories that return streaming protocols.

data

Called when some data is received. data is a non-empty bytes object containing the incoming data.

Whether the data is buffered, chunked or reassembled depends on the transport. In general, you shouldn’t rely

on specific semantics and instead make your parsing generic and flexible. However, data is always received in

the correct order.

The method can be called an arbitrary number of times while a connection is open.

However, is called at most once. Once is called,

is not called anymore.



Called when the other end signals it won’t send any more data (for example by calling

, if the other end also uses asyncio).

This method may return a false value (including ), in which case the transport will close itself. Conversely,

if this method returns a true value, the protocol used determines whether to close the transport. Since the default

implementation returns , it implicitly closes the connection.

The Python Library Reference, Release 3.13.2



Some transports, including SSL, don’t support half-closed connections, in which case returning true from this

method will result in the connection being closed.

State machine:





Buffered Streaming Protocols

Added in version 3.7.

Buffered Protocols can be used with any event loop method that supports Streaming Protocols.

implementations allow explicit manual allocation and control of the receive buffer. Event loops can then use the buffer provided by the protocol to avoid unnecessary data copies. This can result in noticeable performance improvement for protocols that receive big amounts of data. Sophisticated protocol implementations can significantly reduce the number of buffer allocations.

The following callbacks are called on instances:

sizehint

Called to allocate a new receive buffer.

sizehint is the recommended minimum size for the returned buffer. It is acceptable to return smaller or larger

buffers than what sizehint suggests. When set to -1, the buffer size can be arbitrary. It is an error to return a

buffer with a zero size.

must return an object implementing the buffer protocol.

nbytes

Called when the buffer was updated with the received data.

nbytes is the total number of bytes that were written to the buffer.



See the documentation of the method.

can be called an arbitrary number of times during a connection. However,

is called at most once and, if called, and won’t be called after it.

State machine:





Datagram Protocols

Datagram Protocol instances should be constructed by protocol factories passed to the

method.

data, addr

Called when a datagram is received. data is a bytes object containing the incoming data. addr is the address

of the peer sending the data; the exact format depends on the transport.

The Python Library Reference, Release 3.13.2



exc

Called when a previous send or receive operation raises an . exc is the instance.

This method is called in rare conditions, when the transport (e.g. UDP) detects that a datagram could not be

delivered to its recipient. In many conditions though, undeliverable datagrams will be silently dropped.



® Note

On BSD systems (macOS, FreeBSD, etc.) flow control is not supported for datagram protocols, because there is

no reliable way to detect send failures caused by writing too many packets.

The socket always appears ‘ready’ and excess packets are dropped. An with set to

may or may not be raised; if it is raised, it will be reported to

but otherwise ignored.



Subprocess Protocols

Subprocess Protocol instances should be constructed by protocol factories passed to the

and methods.

fd, data

Called when the child process writes data into its stdout or stderr pipe.

fd is the integer file descriptor of the pipe.

data is a non-empty bytes object containing the received data.

fd, exc

Called when one of the pipes communicating with the child process is closed.

fd is the integer file descriptor that was closed.



Called when the child process has exited.

It can be called before and methods.



Examples

TCP Echo Server

Create a TCP echo server using the method, send back received data, and close the connection:





The Python Library Reference, Release 3.13.2





µ See also

The TCP echo server using streams example uses the high-level function.



TCP Echo Client

A TCP echo client using the method, sends data, and waits until the connection is closed:





The Python Library Reference, Release 3.13.2





µ See also

The TCP echo client using streams example uses the high-level function.



UDP Echo Server

A UDP echo server, using the method, sends back received data:





The Python Library Reference, Release 3.13.2





UDP Echo Client

A UDP echo client, using the method, sends data and closes the transport when it receives the answer:





The Python Library Reference, Release 3.13.2



Connecting Existing Sockets

Wait until a socket receives data using the method with a protocol:





µ See also

The watch a file descriptor for read events example uses the low-level method to register

an FD.

The Python Library Reference, Release 3.13.2



The register an open socket to wait for data using streams example uses high-level streams created by the

function in a coroutine.



loop.subprocess_exec() and SubprocessProtocol

An example of a subprocess protocol used to get the output of a subprocess and to wait for the subprocess exit.

The subprocess is created by the method:





The Python Library Reference, Release 3.13.2





See also the same example written using high-level APIs.





An event loop policy is a global object used to get and set the current event loop, as well as create new event loops.

The default policy can be replaced with built-in alternatives to use different event loop implementations, or substituted

by a custom policy that can override these behaviors.

The policy object gets and sets a separate event loop per context. This is per-thread by default, though custom policies could define context differently.

Custom event loop policies can control the behavior of , , and

.

Policy objects should implement the APIs defined in the abstract base class.



Getting and Setting the Policy

The following functions can be used to get and set the policy for the current process:



Return the current process-wide policy.

policy

Set the current process-wide policy to policy.

If policy is set to , the default policy is restored.



Policy Objects

The abstract event loop policy base class is defined as follows:



An abstract base class for asyncio policies.



Get the event loop for the current context.

Return an event loop object implementing the interface.

This method should never return .

Changed in version 3.6.

loop

Set the event loop for the current context to loop.



Create and return a new event loop object.

This method should never return .

The Python Library Reference, Release 3.13.2





Get a child process watcher object.

Return a watcher object implementing the interface.

This function is Unix specific.

Deprecated since version 3.12.

watcher

Set the current child process watcher to watcher.

This function is Unix specific.

Deprecated since version 3.12.

asyncio ships with the following built-in policies:



The default asyncio policy. Uses on Unix and on Windows.

There is no need to install the default policy manually. asyncio is configured to use the default policy automat-

ically.

Changed in version 3.8: On Windows, is now used by default.

Deprecated since version 3.12: The method of the default asyncio policy now emits

a if there is no current event loop set and it decides to create one. In some future

Python release this will become an error.



An alternative event loop policy that uses the event loop implementation.

Availability: Windows.



An alternative event loop policy that uses the event loop implementation.

Availability: Windows.



Process Watchers

A process watcher allows customization of how an event loop monitors child processes on Unix. Specifically, the event loop needs to know when a child process has exited.

In asyncio, child processes are created with and functions.

asyncio defines the abstract base class, which child watchers should implement,

and has four different implementations: (configured to be used by default),

, , and .

See also the Subprocess and Threads section.

The following two functions can be used to customize the child process watcher implementation used by the asyncio event loop:



Return the current child watcher for the current policy.

Deprecated since version 3.12.

watcher

Set the current child watcher to watcher for the current policy. watcher must implement methods defined in

the base class.

Deprecated since version 3.12.

The Python Library Reference, Release 3.13.2



® Note

Third-party event loops implementations might not support custom child watchers. For such event loops, using

might be prohibited or have no effect.





pid, callback, *args

Register a new child handler.

Arrange for to be called when a process with PID equal to pid terminates. Specifying another callback for the same process replaces the previous handler.

The callback callable must be thread-safe.

pid

Removes the handler for process with PID equal to pid.

The function returns if the handler was successfully removed, if there was nothing to re-move.

loop

Attach the watcher to an event loop.

If the watcher was previously attached to an event loop, then it is first detached before attaching to the new loop.

Note: loop may be .



Return if the watcher is ready to use.

Spawning a subprocess with inactive current child watcher raises .

Added in version 3.8.



Close the watcher.

This method has to be called to ensure that underlying resources are cleaned-up.

Deprecated since version 3.12.



This implementation starts a new waiting thread for every subprocess spawn.

It works reliably even when the asyncio event loop is run in a non-main OS thread.

There is no noticeable overhead when handling a big number of children (O(1) each time a child terminates),

but starting a thread per process requires extra memory.

This watcher is used by default.

Added in version 3.8.



This implementation registers a signal handler on instantiation. That can break third-party code that

installs a custom handler for signal.

The watcher avoids disrupting other code spawning processes by polling every process explicitly on a

signal.

There is no limitation for running subprocesses from different threads once the watcher is installed.

The solution is safe but it has a significant overhead when handling a big number of processes (O(n) each time

a is received).

The Python Library Reference, Release 3.13.2



Added in version 3.8.

Deprecated since version 3.12.



This implementation uses active event loop from the main thread to handle signal. If the main thread

has no running event loop another thread cannot spawn a subprocess ( is raised).

The watcher avoids disrupting other code spawning processes by polling every process explicitly on a

signal.

This solution is as safe as and has the same O(n) complexity but requires a running

event loop in the main thread to work.

Deprecated since version 3.12.



This implementation reaps every terminated processes by calling directly, possibly break-

ing other code spawning processes and waiting for their termination.

There is no noticeable overhead when handling a big number of children (O(1) each time a child terminates).

This solution requires a running event loop in the main thread to work, as .

Deprecated since version 3.12.



This implementation polls process file descriptors (pidfds) to await child process termination. In some respects,

is a “Goldilocks” child watcher implementation. It doesn’t require signals or threads,

doesn’t interfere with any processes launched outside the event loop, and scales linearly with the number of

subprocesses launched by the event loop. The main disadvantage is that pidfds are specific to Linux, and only

work on recent (5.3+) kernels.

Added in version 3.9.



Custom Policies

To implement a new event loop policy, it is recommended to subclass and override the methods for which custom behavior is wanted, e.g.:





The module is designed to be portable, but some platforms have subtle differences and limitations due to the platforms’ underlying architecture and capabilities.



The Python Library Reference, Release 3.13.2



All Platforms

• and cannot be used to monitor file I/O.



Windows

Source code: Lib/asyncio/proactor_events.py, Lib/asyncio/windows_events.py, Lib/asyncio/windows_utils.py



Changed in version 3.8: On Windows, is now the default event loop.

All event loops on Windows do not support the following methods:

• and are not supported.

socket family is specific to Unix.

• and are not supported.

has the following limitations:

• is used to wait on socket events: it supports sockets and is limited to 512 sockets.

• and only accept socket handles (e.g. pipe file descriptors are

not supported).

• Pipes are not supported, so the and meth-

ods are not implemented.

• Subprocesses are not supported, i.e. and meth-

ods are not implemented.

has the following limitations:

• The and methods are not supported.

The resolution of the monotonic clock on Windows is usually around 15.6 milliseconds. The best resolution is 0.5

milliseconds. The resolution depends on the hardware (availability of HPET) and on the Windows configuration.



Subprocess Support on Windows

On Windows, the default event loop supports subprocesses, whereas does not.

The function is also not supported, as has a different mechanism to watch child processes.



macOS

Modern macOS versions are fully supported.



macOS <= 10.8

On macOS 10.6, 10.7 and 10.8, the default event loop uses , which does not

support character devices on these versions. The can be manually configured to use

or to support character devices on these older versions of macOS. Example:





The Python Library Reference, Release 3.13.2





The main direction for extending is writing custom event loop classes. Asyncio has helpers that could be used to simplify this task.



® Note

Third-parties should reuse existing asyncio code with caution, a new Python version is free to break backward

compatibility in internal part of API.



Writing a Custom Event Loop

declares very many methods. Implementing all them from scratch is a tedious job.

A loop can get many common methods implementation for free by inheriting from .

In turn, the successor should implement a bunch of private methods declared but not implemented in .

For example, checks arguments, resolves DNS addresses, and calls that should be implemented by inherited class. The method is not documented and is considered as an internal API.



Future and Task private constructors

and should be never created directly, please use corresponding

and , or factories instead.

However, third-party event loops may reuse built-in future and task implementations for the sake of getting a complex and highly optimized code for free.

For this purpose the following, private constructors are listed:

*, loop=None

Create a built-in future instance.

loop is an optional event loop instance.

coro, *, loop=None, name=None, context=None

Create a built-in task instance.

loop is an optional event loop instance. The rest of arguments are described in de-

scription.

Changed in version 3.11: context argument is added.



Task lifetime support

A third party task implementation should call the following functions to keep a task visible by

and :

task

Register a new task as managed by asyncio.

Call the function from a task constructor.

task

Unregister a task from asyncio internal structures.

The function should be called when a task is about to finish.



The Python Library Reference, Release 3.13.2



loop, task

Switch the current task to the task argument.

Call the function just before executing a portion of embedded coroutine ( or

).

loop, task

Switch the current task back from task to .

Call the function just after or execution.





This page lists all high-level async/await enabled asyncio APIs.



Tasks

Utilities to run asyncio programs, create Tasks, and await on multiple things with timeouts.





tion calls.

Task object.



a convenient and reliable way to wait for all tasks in the

group to finish.

Start an asyncio Task, then returns it.

Return the current Task.



loop.

Sleep for a number of seconds.

Schedule and wait for things concurrently.

Run with a timeout.

Shield from cancellation.

Monitor for completion.

Run with a timeout. Useful in cases when

is not suitable.



Schedule a coroutine from another OS thread.

Monitor for completion with a loop.



Examples

• Using asyncio.gather() to run things in parallel.

• Using asyncio.wait_for() to enforce a timeout.

• Cancellation.

• Using asyncio.sleep().

• See also the main Tasks documentation page.



Queues

Queues should be used to distribute work amongst multiple asyncio Tasks, implement connection pools, and pub/sub patterns.



A FIFO queue.

A priority queue.

A LIFO queue.

The Python Library Reference, Release 3.13.2



Examples

• Using asyncio.Queue to distribute workload between several Tasks.

• See also the Queues documentation page.



Subprocesses

Utilities to spawn subprocesses and run shell commands.



Create a subprocess.

Run a shell command.



Examples

• Executing a shell command.

• See also the subprocess APIs documentation.



Streams

High-level APIs to work with network IO.



Establish a TCP connection.

Establish a Unix socket connection.

Start a TCP server.

Start a Unix socket server.





Examples

• Example TCP client.

• See also the streams APIs documentation.



Synchronization

Threading-like synchronization primitives that can be used in Tasks.



A mutex lock.

An event object.

A condition object.

A semaphore.

A bounded semaphore.

A barrier object.



Examples

• Using asyncio.Event.

• Using asyncio.Barrier.

• See also the documentation of asyncio synchronization primitives.



The Python Library Reference, Release 3.13.2



Exceptions



Raised when a Task is cancelled. See also

.

Raised when a Barrier is broken. See also

.



Examples

• Handling CancelledError to run code on cancellation request.

• See also the full list of asyncio-specific exceptions.





This page lists all low-level asyncio APIs.



Obtaining the Event Loop



The preferred function to get the running event loop.



current policy).



Create a new event loop.



Examples

• Using asyncio.get_running_loop().



Event Loop Methods

See also the main documentation section about the Event Loop Methods.



Lifecycle



Run a Future/Task/awaitable until complete.

Run the event loop forever.

Stop the event loop.

Close the event loop.

Return if the event loop is running.

Return if the event loop is closed.

Close asynchronous generators.



Debugging



Enable or disable the debug mode.

Get the current debug mode.



Scheduling Callbacks



Invoke a callback soon.

A thread-safe variant of .

Invoke a callback after the given time.

Invoke a callback at the given time.

The Python Library Reference, Release 3.13.2



Thread/Process Pool





executor.

Set the default executor for

.



Tasks and Futures



Create a object.

Schedule coroutine as a .

Set a factory used by to create

.

Get the factory uses to create

.



DNS



Asynchronous version of .

Asynchronous version of .



Networking and IPC



Open a TCP connection.

Create a TCP server.

Open a Unix socket connection.

Create a Unix socket server.

Wrap a into a

pair.

Open a datagram (UDP) connection.

Send a file over a transport.

Upgrade an existing connection to TLS.

Wrap a read end of a pipe into a

pair.

Wrap a write end of a pipe into a

pair.



Sockets



Receive data from the .

Receive data from the into a buffer.

Receive a datagram from the .

Receive a datagram from the into a buffer.

Send data to the .

Send a datagram via the to the given address.

Connect the .

Accept a connection.

Send a file over the .





The Python Library Reference, Release 3.13.2



Unix Signals



Add a handler for a .

Remove a handler for a .



Subprocesses



Spawn a subprocess.

Spawn a subprocess from a shell command.



Error Handling



Call the exception handler.

Set a new exception handler.

Get the current exception handler.

The default exception handler implementation.



Examples

• Using asyncio.new_event_loop() and loop.run_forever().

• Using loop.call_later().

• Using to implement an echo-client.

• Using to connect a socket.

• Using add_reader() to watch an FD for read events.

• Using loop.add_signal_handler().

• Using loop.subprocess_exec().



Transports

All transports implement the following methods:



Close the transport.

Return if the transport is closing or is closed.

Request for information about the transport.

Set a new protocol.

Return the current protocol.



Transports that can receive data (TCP and Unix connections, pipes, etc). Returned from methods like

, , , etc:



Read Transports



Return if the transport is receiving.

Pause receiving.

Resume receiving.



Transports that can Send data (TCP and Unix connections, pipes, etc). Returned from methods like

, , , etc:

The Python Library Reference, Release 3.13.2



Write Transports



Write data to the transport.

Write buffers to the transport.

Return if the transport supports sending EOF.

Close and send EOF after flushing buffered data.

Close the transport immediately.

Return the current size of the output buffer.





Transports returned by :



Datagram Transports



Send data to the remote peer.

Close the transport immediately.



Low-level transport abstraction over subprocesses. Returned by and

:



Subprocess Transports



Return the subprocess process id.



pipe (stdin, stdout, or stderr).

Return the subprocess return code.

Kill the subprocess.

Send a signal to the subprocess.

Stop the subprocess.

Kill the subprocess and close all pipes.



Protocols

Protocol classes can implement the following callback methods:



Called when a connection is made.

Called when the connection is lost or closed.



water mark.



water mark.



Streaming Protocols (TCP, Unix Sockets, Pipes)



Called when some data is received.

Called when an EOF is received.



The Python Library Reference, Release 3.13.2



Buffered Streaming Protocols



Called to allocate a new receive buffer.



data.

Called when an EOF is received.



Datagram Protocols



Called when a datagram is received.



an .



Subprocess Protocols



Called when the child process writes data into its stdout

or stderr pipe.



child process is closed.

Called when the child process has exited. It

can be called before and

methods.



Event Loop Policies

Policies is a low-level mechanism to alter the behavior of functions like . See also

the main policies section for more details.



Accessing Policies



Return the current process-wide policy.

Set a new process-wide policy.

Base class for policy objects.





Asynchronous programming is different from classic “sequential” programming.

This page lists common mistakes and traps and explains how to avoid them.



Debug Mode

By default asyncio runs in production mode. In order to ease the development asyncio has a debug mode.

There are several ways to enable asyncio debug mode:

• Setting the environment variable to .

• Using the Python Development Mode.

• Passing to .

• Calling .

In addition to enabling the debug mode, consider also:

• setting the log level of the asyncio logger to , for example the following snippet of code can

be run at startup of the application:

The Python Library Reference, Release 3.13.2





• configuring the module to display warnings. One way of doing that is by using

the command line option.

When the debug mode is enabled:

• asyncio checks for coroutines that were not awaited and logs them; this mitigates the “forgotten await” pitfall.

• Many non-threadsafe asyncio APIs (such as and methods) raise an

exception if they are called from a wrong thread.

• The execution time of the I/O selector is logged if it takes too long to perform an I/O operation.

• Callbacks taking longer than 100 milliseconds are logged. The attribute

can be used to set the minimum execution duration in seconds that is considered “slow”.



Concurrency and Multithreading

An event loop runs in a thread (typically the main thread) and executes all callbacks and Tasks in its thread. While a Task is running in the event loop, no other Tasks can run in the same thread. When a Task executes an expression, the running Task gets suspended, and the event loop executes the next Task.

To schedule a callback from another OS thread, the method should be used. Example:





Almost all asyncio objects are not thread safe, which is typically not a problem unless there is code that works with them from outside of a Task or a callback. If there’s a need for such code to call a low-level asyncio API, the

method should be used, e.g.:





To schedule a coroutine object from a different OS thread, the function should

be used. It returns a to access the result:





To handle signals the event loop must be run in the main thread.

The method can be used with a to execute blocking code in a different OS thread without blocking the OS thread that the event loop runs in.

There is currently no way to schedule coroutines or callbacks directly from a different process (such as one started

with ). The Event Loop Methods section lists APIs that can read from pipes and watch file

descriptors without blocking the event loop. In addition, asyncio’s Subprocess APIs provide a way to start a process

and communicate with it from the event loop. Lastly, the aforementioned method can

also be used with a to execute code in a different process.



Running Blocking Code

Blocking (CPU-bound) code should not be called directly. For example, if a function performs a CPU-intensive calculation for 1 second, all concurrent asyncio Tasks and IO operations would be delayed by 1 second.

The Python Library Reference, Release 3.13.2



An executor can be used to run a task in a different thread or even in a different process to avoid blocking the OS

thread with the event loop. See the method for more details.



Logging

asyncio uses the module and all logging is performed via the logger.

The default log level is , which can be easily adjusted:





Network logging can block the event loop. It is recommended to use a separate thread for handling logs or use non-blocking IO. For example, see blocking-handlers.



Detect never-awaited coroutines

When a coroutine function is called, but not awaited (e.g. instead of ) or the coroutine is

not scheduled with , asyncio will emit a :





Output:





Output in debug mode:





The usual fix is to either await the coroutine or call the function:





Detect never-retrieved exceptions

If a is called but the Future object is never awaited on, the exception would never be propagated to the user code. In this case, asyncio would emit a log message when the Future object is garbage collected.

Example of an unhandled exception:

The Python Library Reference, Release 3.13.2





Output:





Enable the debug mode to get the traceback where the task was created:





Output in debug mode:





® Note

The source code for asyncio can be found in Lib/asyncio/.





Source code: Lib/socket.py



This module provides access to the BSD socket interface. It is available on all modern Unix systems, Windows, MacOS, and probably additional platforms.



The Python Library Reference, Release 3.13.2



® Note

Some behavior may be platform dependent, since calls are made to the operating system socket APIs.



Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.

The Python interface is a straightforward transliteration of the Unix system call and library interface for sockets to

Python’s object-oriented style: the function returns a socket object whose methods implement the various socket system calls. Parameter types are somewhat higher-level than in the C interface: as with and operations on Python files, buffer allocation on receive operations is automatic, and buffer length is implicit on send operations.



µ See also

Module

Classes that simplify writing network servers.

Module

A TLS/SSL wrapper for socket objects.





Depending on the system and the build options, various socket families are supported by this module.

The address format required by a particular socket object is automatically selected based on the address family specified when the socket object was created. Socket addresses are represented as follows:

• The address of an socket bound to a file system node is represented as a string, using the file sys-

tem encoding and the error handler (see PEP 383). An address in Linux’s abstract

namespace is returned as a bytes-like object with an initial null byte; note that sockets in this namespace can

communicate with normal file system sockets, so programs intended to run on Linux may need to deal with

both types of address. A string or bytes-like object can be used for either type of address when passing it as

an argument.

Changed in version 3.3: Previously, socket paths were assumed to use UTF-8 encoding.

Changed in version 3.5: Writable bytes-like object is now accepted.

• A pair is used for the address family, where host is a string representing either a

hostname in internet domain notation like or an IPv4 address like ,

and port is an integer.

– For IPv4 addresses, two special forms are accepted instead of a host address: represents ,

which is used to bind to all interfaces, and the string represents . This behavior is not compatible with IPv6, therefore, you may want to avoid these if you intend to support IPv6 with your Python programs.

• For address family, a four-tuple is used, where

flowinfo and scope_id represent the and members in

in C. For module methods, flowinfo and scope_id can be omitted just for back-

ward compatibility. Note, however, omission of scope_id can cause problems in manipulating scoped IPv6

addresses.

Changed in version 3.7: For multicast addresses (with scope_id meaningful) address may not contain

(or ) part. This information is superfluous and may be safely omitted (recommended).

• sockets are represented as pairs .

• Linux-only support for TIPC is available using the address family. TIPC is an open, non-IP based

networked protocol designed for use in clustered computer environments. Addresses are represented by a The Python Library Reference, Release 3.13.2



tuple, and the fields depend on the address type. The general tuple form is

, where:

– addr_type is one of , , or .

– scope is one of , , and .

– If addr_type is , then v1 is the server type, v2 is the port identifier, and v3 should be

0.

If addr_type is , then v1 is the server type, v2 is the lower port number, and v3 is the upper port number.

If addr_type is , then v1 is the node, v2 is the reference, and v3 should be set to 0.

• A tuple is used for the address family, where interface is a string representing a

network interface name like . The network interface name can be used to receive packets from all

network interfaces of this family.

– protocol require a tuple where both additional pa-

rameters are unsigned long integer that represent a CAN identifier (standard or extended).

– protocol require a tuple where additional parame-

ters are 64-bit unsigned integer representing the ECU name, a 32-bit unsigned integer representing the Parameter Group Number (PGN), and an 8-bit integer representing the address.

• A string or a tuple is used for the protocol of the family. The

string is the name of a kernel control using a dynamically assigned ID. The tuple can be used if ID and unit

number of the kernel control are known or if a registered ID is used.

Added in version 3.3.

• supports the following protocols and address formats:

– accepts where is the Bluetooth address as a string and

is an integer.

– accepts where is the Bluetooth address as a string

and is an integer.

– accepts where is either an integer or a string with the Blue-

tooth address of the interface. (This depends on your OS; NetBSD and DragonFlyBSD expect a Blue-tooth address while everything else expects an integer.)

Changed in version 3.2: NetBSD and DragonFlyBSD support added.

– accepts where is a object containing the Bluetooth address in a

string format. (ex. ) This protocol is not supported under FreeBSD.

• is a Linux-only socket based interface to Kernel cryptography. An algorithm socket is configured

with a tuple of two to four elements , where:

– type is the algorithm type as string, e.g. , , or .

– name is the algorithm name and operation mode as string, e.g. , , or

.

– feat and mask are unsigned 32bit integers.

Availability: Linux >= 2.6.38.

Some algorithm types require more recent Kernels.

Added in version 3.6.

• allows communication between virtual machines and their hosts. The sockets are represented as a

tuple where the context ID or CID and port are integers.

Availability: Linux >= 3.9

See

The Python Library Reference, Release 3.13.2



Added in version 3.7.

• is a low-level interface directly to network devices. The addresses are represented by the tuple

where:

– ifname- String specifying the device name.

– proto- The Ethernet protocol number. May be to capture all protocols, one of the ETHER-

TYPE_* constants or any other Ethernet protocol number.

– pkttype- Optional integer specifying the packet type:

∗ (the default) - Packet addressed to the local host.

∗ - Physical-layer broadcast packet.

∗ - Packet sent to a physical-layer multicast address.

∗ - Packet to some other host that has been caught by a device driver in promis-

cuous mode.

∗ - Packet originating from the local host that is looped back to a packet socket.

– hatype- Optional integer specifying the ARP hardware address type.

– addr- Optional bytes-like object specifying the hardware physical address, whose interpretation depends

on the device.

Availability: Linux >= 2.2.

• is a Linux-only socket based interface for communicating with services running on co-processors

in Qualcomm platforms. The address family is represented as a tuple where the node and port

are non-negative integers.

Availability: Linux >= 4.7.

Added in version 3.8.

• is a variant of UDP which allows you to specify what portion of a packet is covered with

the checksum. It adds two socket options that you can change.

will change what portion of outgoing packets are covered by the

checksum and will filter

out packets which cover too little of their data. In both cases should be in

.

Such a socket should be constructed with for

IPv4 or for IPv6.

Availability: Linux >= 2.6.20, FreeBSD >= 10.1

Added in version 3.9.

• is a Windows-only socket based interface for communicating with Hyper-V hosts and guests.

The address family is represented as a tuple where the and

are UUID strings.

The is the virtual machine identifier or a set of known VMID values if the target is not a specific virtual

machine. Known VMID constants defined on are:

–

–

– - Used to bind on itself and accept connections from all partitions.

– - Used to bind on itself and accept connection from child partitions.

– - Used as a target to itself.

– - When used as a bind accepts connection from the parent partition. When used as

an address target it will connect to the parent partition.

The Python Library Reference, Release 3.13.2



The is the service identifier of the registered service.

Added in version 3.12.

If you use a hostname in the host portion of IPv4/v6 socket address, the program may show a nondeterministic behavior, as Python uses the first address returned from the DNS resolution. The socket address will be resolved differently into an actual IPv4/v6 address, depending on the results from DNS resolution and/or the host configuration. For deterministic behavior use a numeric address in host portion.

All errors raise exceptions. The normal exceptions for invalid argument types and out-of-memory conditions can be

raised. Errors related to socket or address semantics raise or one of its subclasses.

Non-blocking mode is supported through . A generalization of this based on timeouts is supported

through .





The module exports the following elements.



Exceptions



A deprecated alias of .

Changed in version 3.3: Following PEP 3151, this class was made an alias of .



A subclass of , this exception is raised for address-related errors, i.e. for functions that use h_errno

in the POSIX C API, including and . The accompanying value

is a pair representing an error returned by a library call. h_errno is a numeric value,

while string represents the description of h_errno, as returned by the C function.

Changed in version 3.3: This class was made a subclass of .



A subclass of , this exception is raised for address-related errors by and

. The accompanying value is a pair representing an error returned by a

library call. string represents the description of error, as returned by the C function. The

numeric error value will match one of the constants defined in this module.

Changed in version 3.3: This class was made a subclass of .



A deprecated alias of .

A subclass of , this exception is raised when a timeout occurs on a socket which has had timeouts en-

abled via a prior call to (or implicitly through ). The accompanying

value is a string whose value is currently always “timed out”.

Changed in version 3.3: This class was made a subclass of .

Changed in version 3.10: This class was made an alias of .



Constants

The AF_* and SOCK_* constants are now and collections.

Added in version 3.4.





These constants represent the address (and protocol) families, used for the first argument to . If the

constant is not defined then this protocol is unsupported. More constants may be available depending

on the system.

The Python Library Reference, Release 3.13.2





means that should return socket addresses for any address family (either IPv4,

IPv6, or any other) that can be used.





These constants represent the socket types, used for the second argument to . More constants may

be available depending on the system. (Only and appear to be generally useful.)





These two constants, if defined, can be combined with the socket types and allow you to set some flags atomi-

cally (thus avoiding possible race conditions and the need for separate calls).



µ See also

Secure File Descriptor Handling for a more thorough explanation.



Availability: Linux >= 2.6.27.

Added in version 3.2.





Many constants of these forms, documented in the Unix documentation on sockets and/or the IP protocol,

are also defined in the socket module. They are generally used in arguments to the and

methods of socket objects. In most cases, only those symbols that are defined in the Unix

header files are defined; for a few symbols, default values are provided.

Changed in version 3.6: , , , , ,

were added.

Changed in version 3.6.5: On Windows, , appear if run-time Windows sup-

ports.

Changed in version 3.7: was added.

On Windows, , appear if run-time Windows supports.

Changed in version 3.10: was added. Added . On MacOS this constant can

be used in the same way that is used on Linux.

The Python Library Reference, Release 3.13.2



Changed in version 3.11: Added . On MacOS this constant can be used in the same

way that is used on Linux and BSD.

Changed in version 3.12: Added and . On OpenBSD and FreeBSD respec-

tively those constants can be used in the same way that is used on Linux. Also added missing

TCP socket options from Linux: , , ,

, , , , ,

, , , , ,

, , , ,

, , . Added , ,

, , .

Changed in version 3.13: Added . On Linux this constant can be used in the same way

that is used, but with the index of a network interface instead of its name.





Many constants of these forms, documented in the Linux documentation, are also defined in the socket module.

Availability: Linux >= 2.6.25, NetBSD >= 8.

Added in version 3.3.

Changed in version 3.11: NetBSD support was added.





CAN_BCM, in the CAN protocol family, is the broadcast manager (BCM) protocol. Broadcast manager

constants, documented in the Linux documentation, are also defined in the socket module.

Availability: Linux >= 2.6.25.



® Note

The flag is only available on Linux >= 4.8.



Added in version 3.4.



Enables CAN FD support in a CAN_RAW socket. This is disabled by default. This allows your application to

send both CAN and CAN FD frames; however, you must accept both CAN and CAN FD frames when reading

from the socket.

This constant is documented in the Linux documentation.

Availability: Linux >= 3.6.

Added in version 3.5.



Joins the applied CAN filters such that only CAN frames that match all given CAN filters are passed to user

space.

This constant is documented in the Linux documentation.

Availability: Linux >= 4.1.

Added in version 3.9.



The Python Library Reference, Release 3.13.2





CAN_ISOTP, in the CAN protocol family, is the ISO-TP (ISO 15765-2) protocol. ISO-TP constants, docu-

mented in the Linux documentation.

Availability: Linux >= 2.6.25.

Added in version 3.7.



CAN_J1939, in the CAN protocol family, is the SAE J1939 protocol. J1939 constants, documented in the

Linux documentation.

Availability: Linux >= 5.4.

Added in version 3.9.





These two constants, documented in the FreeBSD divert(4) manual page, are also defined in the socket module.

Availability: FreeBSD >= 14.0.

Added in version 3.12.





Many constants of these forms, documented in the Linux documentation, are also defined in the socket module.

Availability: Linux >= 2.2.



can be used in the constructor as proto for the family in order to capture

every packet, regardless of protocol.

For more information, see the manpage.

Availability: Linux.

Added in version 3.12.





Many constants of these forms, documented in the Linux documentation, are also defined in the socket module.

Availability: Linux >= 2.6.30.

Added in version 3.3.





Constants for Windows’ WSAIoctl(). The constants are used as arguments to the method of socket

objects.

Changed in version 3.6: was added.



TIPC related constants, matching the ones exported by the C socket API. See the TIPC documentation for

more information.



The Python Library Reference, Release 3.13.2





Constants for Linux Kernel cryptography.

Availability: Linux >= 2.6.38.

Added in version 3.6.





Constants for Linux host/guest communication.

Availability: Linux >= 4.8.

Added in version 3.7.



Availability: BSD, macOS.

Added in version 3.4.



This constant contains a boolean value which indicates if IPv6 is supported on this platform.





These are string constants containing Bluetooth addresses with special meanings. For example,

can be used to indicate any address when specifying the binding socket with .





For use with . is not available for NetBSD or DragonFlyBSD.

and are not available for FreeBSD, NetBSD, or DragonFlyBSD.



Constant for Qualcomm’s IPC router protocol, used to communicate with service providing remote processors.

Availability: Linux >= 4.7.





LOCAL_CREDS and LOCAL_CREDS_PERSISTENT can be used with SOCK_DGRAM,

SOCK_STREAM sockets, equivalent to Linux/DragonFlyBSD SO_PASSCRED, while LOCAL_CREDS

sends the credentials at first read, LOCAL_CREDS_PERSISTENT sends for each read, SCM_CREDS2

must be then used for the latter for the message type.

Added in version 3.11.

Availability: FreeBSD.



Constant to optimize CPU locality, to be used in conjunction with .

Added in version 3.11.

Availability: Linux >= 3.9





The Python Library Reference, Release 3.13.2





Constants for Windows Hyper-V sockets for host/guest communications.

Availability: Windows.

Added in version 3.12.





IEEE 802.3 protocol number. constants.

Availability: Linux, FreeBSD, macOS.

Added in version 3.12.





These constants are used by the method of socket objects.

Availability: not WASI.



Functions

Creating sockets

The following functions all create socket objects.

family=AF_INET , type=SOCK_STREAM , proto=0, fileno=None

Create a new socket using the given address family, socket type and protocol number. The address family should

be (the default), , , , , or . The socket type should

be (the default), , or perhaps one of the other constants. The

protocol number is usually zero and may be omitted or in the case where the address family is the

protocol should be one of , , or .

If fileno is specified, the values for family, type, and proto are auto-detected from the specified file descriptor.

Auto-detection can be overruled by calling the function with explicit family, type, or proto arguments. This

only affects how Python represents e.g. the return value of but not the actual OS

resource. Unlike , fileno will return the same socket and not a duplicate. This may help

close a detached socket using .

The newly created socket is non-inheritable.

Raises an auditing event with arguments , , , .

Changed in version 3.3: The AF_CAN family was added. The AF_RDS family was added.

Changed in version 3.4: The CAN_BCM protocol was added.

Changed in version 3.4: The returned socket is now non-inheritable.

The Python Library Reference, Release 3.13.2



Changed in version 3.7: The CAN_ISOTP protocol was added.

Changed in version 3.7: When or bit flags are applied to type they are

cleared, and will not reflect them. They are still passed to the underlying system

call. Therefore,





will still create a non-blocking socket on OSes that support , but will be set to

.

Changed in version 3.9: The CAN_J1939 protocol was added.

Changed in version 3.10: The IPPROTO_MPTCP protocol was added.

family , type, proto

Build a pair of connected socket objects using the given address family, socket type, and protocol number.

Address family, socket type, and protocol number are as for the function above. The default family

is if defined on the platform; otherwise, the default is .

The newly created sockets are non-inheritable.

Changed in version 3.2: The returned socket objects now support the whole socket API, rather than a subset.

Changed in version 3.4: The returned sockets are now non-inheritable.

Changed in version 3.5: Windows support added.

address, timeout=GLOBAL_DEFAULT, source_address=None, *,

all_errors=False

Connect to a TCP service listening on the internet address (a 2-tuple ), and return the socket

object. This is a higher-level function than : if host is a non-numeric hostname, it will

try to resolve it for both and , and then try to connect to all possible addresses in turn

until a connection succeeds. This makes it easy to write clients that are compatible to both IPv4 and IPv6.

Passing the optional timeout parameter will set the timeout on the socket instance before attempting to connect.

If no timeout is supplied, the global default timeout setting returned by is used.

If supplied, source_address must be a 2-tuple for the socket to bind to as its source address

before connecting. If host or port are ‘’ or 0 respectively the OS default behavior will be used.

When a connection cannot be created, an exception is raised. By default, it is the exception from the last

address in the list. If all_errors is , it is an containing the errors of all attempts.

Changed in version 3.2: source_address was added.

Changed in version 3.11: all_errors was added.

address, *, family=AF_INET , backlog=None, reuse_port=False, dualstack_ipv6=False

Convenience function which creates a TCP socket bound to address (a 2-tuple ) and returns

the socket object.

family should be either or . backlog is the queue size passed to ; if

not specified , a default reasonable value is chosen. reuse_port dictates whether to set the

socket option.

If dualstack_ipv6 is true and the platform supports it the socket will be able to accept both IPv4 and IPv6

connections, else it will raise . Most POSIX platforms and Windows are supposed to support this

functionality. When this functionality is enabled the address returned by when an

IPv4 connection occurs will be an IPv6 address represented as an IPv4-mapped IPv6 address. If dualstack_ipv6

is false it will explicitly disable this functionality on platforms that enable it by default (e.g. Linux). This

parameter can be used in conjunction with :

The Python Library Reference, Release 3.13.2





® Note

On POSIX platforms the socket option is set in order to immediately reuse previous sockets which were bound on the same address and remained in TIME_WAIT state.



Added in version 3.8.



Return if the platform supports creating a TCP socket which can handle both IPv4 and IPv6 connections.

Added in version 3.8.

fd, family, type, proto=0

Duplicate the file descriptor fd (an integer as returned by a file object’s method) and build a socket

object from the result. Address family, socket type and protocol number are as for the function

above. The file descriptor should refer to a socket, but this is not checked — subsequent operations on the

object may fail if the file descriptor is invalid. This function is rarely needed, but can be used to get or set

socket options on a socket passed to a program as standard input or output (such as a server started by the Unix

inet daemon). The socket is assumed to be in blocking mode.

The newly created socket is non-inheritable.

Changed in version 3.4: The returned socket is now non-inheritable.

data

Instantiate a socket from data obtained from the method. The socket is assumed to be in

blocking mode.

Availability: Windows.

Added in version 3.3.



This is a Python type object that represents the socket object type. It is the same as .



Other functions

The module also offers various network-related services:

fd

Close a socket file descriptor. This is like , but for sockets. On some platforms (most noticeable

Windows) does not work for socket file descriptors.

Added in version 3.7.

host, port, family=AF_UNSPEC, type=0, proto=0, flags=0

This function wraps the C function of the underlying system.

Translate the host/port argument into a sequence of 5-tuples that contain all the necessary arguments for cre-

ating a socket connected to that service. host is a domain name, a string representation of an IPv4/v6 address

or . port is a string service name such as , a numeric port number or . By passing as

the value of host and port, you can pass to the underlying C API.

The Python Library Reference, Release 3.13.2



The family, type and proto arguments can be optionally specified in order to provide options and limit the list

of addresses returned. Pass their default values (, 0, and 0, respectively) to not limit the results.

See the note below for details.

The flags argument can be one or several of the constants, and will influence how results are computed

and returned. For example, will disable domain name resolution and will raise an error if

host is a domain name.

The function returns a list of 5-tuples with the following structure:



In these tuples, family, type, proto are all integers and are meant to be passed to the function.

canonname will be a string representing the canonical name of the host if is part of the

flags argument; else canonname will be empty. sockaddr is a tuple describing a socket address, whose for-

mat depends on the returned family (a 2-tuple for , a

4-tuple for ), and is meant to be passed to the

method.



® Note

If you intend to use results from to create a socket (rather than, for example, retrieve

canonname), consider limiting the results by type (e.g. or ) and/or proto (e.g. or ) that your application can handle.

The behavior with default values of family, type, proto and flags is system-specific.

Many systems (for example, most Linux configurations) will return a sorted list of all matching addresses. These addresses should generally be tried in order until a connection succeeds (possibly tried in parallel,

for example, using a Happy Eyeballs algorithm). In these cases, limiting the type and/or proto can help eliminate unsuccessful or unusable connection attempts.

Some systems will, however, only return a single address. (For example, this was reported on Solaris and AIX configurations.) On these systems, limiting the type and/or proto helps ensure that this address is usable.



Raises an auditing event with arguments , , , , .

The following example fetches address information for a hypothetical TCP connection to on

port 80 (results may differ on your system if IPv6 isn’t enabled):





Changed in version 3.2: parameters can now be passed using keyword arguments.

Changed in version 3.7: for IPv6 multicast addresses, string representing an address will not contain

part.

name

Return a fully qualified domain name for name. If name is omitted or empty, it is interpreted as the local

host. To find the fully qualified name, the hostname returned by is checked, followed by

aliases for the host, if available. The first name which includes a period is selected. In case no fully qualified

domain name is available and name was provided, it is returned unchanged. If name was empty or equal to

, the hostname from is returned.

hostname

Translate a host name to IPv4 address format. The IPv4 address is returned as a string, such as

. If the host name is an IPv4 address itself it is returned unchanged. See for a

The Python Library Reference, Release 3.13.2



more complete interface. does not support IPv6 name resolution, and

should be used instead for IPv4/v6 dual stack support.

Raises an auditing event with argument .

Availability: not WASI.

hostname

Translate a host name to IPv4 address format, extended interface. Return a 3-tuple

where hostname is the host’s primary host name, aliaslist is a (possibly empty)

list of alternative host names for the same address, and ipaddrlist is a list of IPv4 addresses for the same inter-

face on the same host (often but not always a single address). does not support IPv6

name resolution, and should be used instead for IPv4/v6 dual stack support.

Raises an auditing event with argument .

Availability: not WASI.



Return a string containing the hostname of the machine where the Python interpreter is currently executing.

Raises an auditing event with no arguments.

Note: doesn’t always return the fully qualified domain name; use for that.

Availability: not WASI.

ip_address

Return a 3-tuple where hostname is the primary host name re-

sponding to the given ip_address, aliaslist is a (possibly empty) list of alternative host names for the same

address, and ipaddrlist is a list of IPv4/v6 addresses for the same interface on the same host (most likely

containing only a single address). To find the fully qualified domain name, use the function .

supports both IPv4 and IPv6.

Raises an auditing event with argument .

Availability: not WASI.

sockaddr, flags

Translate a socket address sockaddr into a 2-tuple . Depending on the settings of flags, the

result can contain a fully qualified domain name or numeric address representation in host. Similarly, port can

contain a string port name or a numeric port number.

For IPv6 addresses, is appended to the host part if sockaddr contains meaningful scope_id. Usually

this happens for multicast addresses.

For more information about flags you can consult .

Raises an auditing event with argument .

Availability: not WASI.

protocolname

Translate an internet protocol name (for example, ) to a constant suitable for passing as the (optional)

third argument to the function. This is usually only needed for sockets opened in “raw” mode

(); for the normal socket modes, the correct protocol is chosen automatically if the protocol is

omitted or zero.

Availability: not WASI.

servicename, protocolname

Translate an internet service name and protocol name to a port number for that service. The optional protocol

name, if given, should be or , otherwise any protocol will match.

Raises an auditing event with arguments , .

Availability: not WASI.

The Python Library Reference, Release 3.13.2



port , protocolname

Translate an internet port number and protocol name to a service name for that service. The optional protocol

name, if given, should be or , otherwise any protocol will match.

Raises an auditing event with arguments , .

Availability: not WASI.

x

Convert 32-bit positive integers from network to host byte order. On machines where the host byte order is

the same as network byte order, this is a no-op; otherwise, it performs a 4-byte swap operation.

x

Convert 16-bit positive integers from network to host byte order. On machines where the host byte order is

the same as network byte order, this is a no-op; otherwise, it performs a 2-byte swap operation.

Changed in version 3.10: Raises if x does not fit in a 16-bit unsigned integer.

x

Convert 32-bit positive integers from host to network byte order. On machines where the host byte order is

the same as network byte order, this is a no-op; otherwise, it performs a 4-byte swap operation.

x

Convert 16-bit positive integers from host to network byte order. On machines where the host byte order is

the same as network byte order, this is a no-op; otherwise, it performs a 2-byte swap operation.

Changed in version 3.10: Raises if x does not fit in a 16-bit unsigned integer.

ip_string

Convert an IPv4 address from dotted-quad string format (for example, ‘123.45.67.89’) to 32-bit packed binary

format, as a bytes object four characters in length. This is useful when conversing with a program that uses the

standard C library and needs objects of type , which is the C type for the 32-bit packed binary this

function returns.

also accepts strings with less than three dots; see the Unix manual page for details.

If the IPv4 address string passed to this function is invalid, will be raised. Note that exactly what is

valid depends on the underlying C implementation of .

does not support IPv6, and should be used instead for IPv4/v6 dual stack sup-

port.

packed_ip

Convert a 32-bit packed IPv4 address (a bytes-like object four bytes in length) to its standard dotted-quad

string representation (for example, ‘123.45.67.89’). This is useful when conversing with a program that uses

the standard C library and needs objects of type , which is the C type for the 32-bit packed binary

data this function takes as an argument.

If the byte sequence passed to this function is not exactly 4 bytes in length, will be raised.

does not support IPv6, and should be used instead for IPv4/v6 dual stack sup-

port.

Changed in version 3.5: Writable bytes-like object is now accepted.

address_family, ip_string

Convert an IP address from its family-specific string format to a packed, binary format. is

useful when a library or network protocol calls for an object of type (similar to ) or

.

Supported values for address_family are currently and . If the IP address string ip_string

is invalid, will be raised. Note that exactly what is valid depends on both the value of address_family

and the underlying implementation of .

Availability: Unix, Windows.

Changed in version 3.4: Windows support added

The Python Library Reference, Release 3.13.2



address_family, packed_ip

Convert a packed IP address (a bytes-like object of some number of bytes) to its standard, family-specific

string representation (for example, or ). is useful when a library

or network protocol returns an object of type (similar to ) or .

Supported values for address_family are currently and . If the bytes object packed_ip is

not the correct length for the specified address family, will be raised. is raised for

errors from the call to .

Availability: Unix, Windows.

Changed in version 3.4: Windows support added

Changed in version 3.5: Writable bytes-like object is now accepted.

length

Return the total length, without trailing padding, of an ancillary data item with associated data of the given

length. This value can often be used as the buffer size for to receive a single item of ancillary data,

but RFC 3542 requires portable applications to use and thus include space for padding, even

when the item will be the last in the buffer. Raises if length is outside the permissible range

of values.

Availability: Unix, not WASI.

Most Unix platforms.

Added in version 3.3.

length

Return the buffer size needed for to receive an ancillary data item with associated data of the

given length, along with any trailing padding. The buffer space needed to receive multiple items is the sum of

the values for their associated data lengths. Raises if length is outside the

permissible range of values.

Note that some systems might support ancillary data without providing this function. Also note that setting the

buffer size using the results of this function may not precisely limit the amount of ancillary data that can be

received, since additional data may be able to fit into the padding area.

Availability: Unix, not WASI.

most Unix platforms.

Added in version 3.3.



Return the default timeout in seconds (float) for new socket objects. A value of indicates that new socket

objects have no timeout. When the socket module is first imported, the default is .

timeout

Set the default timeout in seconds (float) for new socket objects. When the socket module is first imported, the

default is . See for possible values and their respective meanings.

name

Set the machine’s hostname to name. This will raise an if you don’t have enough rights.

Raises an auditing event with argument .

Availability: Unix, not Android.

Added in version 3.3.



Return a list of network interface information (index int, name string) tuples. if the system call fails.

Availability: Unix, Windows, not WASI.

Added in version 3.3.

The Python Library Reference, Release 3.13.2



Changed in version 3.8: Windows support was added.



® Note

On Windows network interfaces have different names in different contexts (all names are examples):

• UUID:

• name:

• friendly name:

• description:

This function returns names of the second form from the list, in this example case.



if_name

Return a network interface index number corresponding to an interface name. if no interface with

the given name exists.

Availability: Unix, Windows, not WASI.

Added in version 3.3.

Changed in version 3.8: Windows support was added.



µ See also

“Interface name” is a name as documented in .



if_index

Return a network interface name corresponding to an interface index number. if no interface with

the given index exists.

Availability: Unix, Windows, not WASI.

Added in version 3.3.

Changed in version 3.8: Windows support was added.



µ See also

“Interface name” is a name as documented in .



sock, buffers, fds, flags, address

Send the list of file descriptors fds over an socket sock. The fds parameter is a sequence of file

descriptors. Consult for the documentation of these parameters.

Availability: Unix, Windows, not WASI.

Unix platforms supporting and mechanism.

Added in version 3.9.

sock, bufsize, maxfds, flags

Receive up to maxfds file descriptors from an socket sock. Return

. Consult for the documentation of these parameters.

Availability: Unix, Windows, not WASI.

Unix platforms supporting and mechanism.

Added in version 3.9.

The Python Library Reference, Release 3.13.2



® Note

Any truncated integers at the end of the list of file descriptors.





Socket objects have the following methods. Except for , these correspond to Unix system calls applicable to sockets.

Changed in version 3.2: Support for the context manager protocol was added. Exiting the context manager is equiv-

alent to calling .



Accept a connection. The socket must be bound to an address and listening for connections. The return value is

a pair where conn is a new socket object usable to send and receive data on the connection,

and address is the address bound to the socket on the other end of the connection.

The newly created socket is non-inheritable.

Changed in version 3.4: The socket is now non-inheritable.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

method now retries the system call instead of raising an exception (see PEP 475 for the

rationale).

address

Bind the socket to address. The socket must not already be bound. (The format of address depends on the

address family — see above.)

Raises an auditing event with arguments , .

Availability: not WASI.



Mark the socket closed. The underlying system resource (e.g. a file descriptor) is also closed when all file

objects from are closed. Once that happens, all future operations on the socket object will fail.

The remote end will receive no more data (after queued data is flushed).

Sockets are automatically closed when they are garbage-collected, but it is recommended to them

explicitly, or to use a statement around them.

Changed in version 3.6: is now raised if an error occurs when the underlying call is made.



® Note

releases the resource associated with a connection but does not necessarily close the connection

immediately. If you want to close the connection in a timely fashion, call before .



address

Connect to a remote socket at address. (The format of address depends on the address family — see above.)

If the connection is interrupted by a signal, the method waits until the connection completes, or raise a

on timeout, if the signal handler doesn’t raise an exception and the socket is blocking or has

a timeout. For non-blocking sockets, the method raises an exception if the connection

is interrupted by a signal (or the exception raised by the signal handler).

Raises an auditing event with arguments , .

Changed in version 3.5: The method now waits until the connection completes instead of raising an

exception if the connection is interrupted by a signal, the signal handler doesn’t raise an

exception and the socket is blocking or has a timeout (see the PEP 475 for the rationale).

Availability: not WASI.

The Python Library Reference, Release 3.13.2



address

Like , but return an error indicator instead of raising an exception for errors returned by

the C-level call (other problems, such as “host not found,” can still raise exceptions). The error

indicator is if the operation succeeded, otherwise the value of the variable. This is useful to support,

for example, asynchronous connects.

Raises an auditing event with arguments , .

Availability: not WASI.



Put the socket object into closed state without actually closing the underlying file descriptor. The file descriptor

is returned, and can be reused for other purposes.

Added in version 3.2.



Duplicate the socket.

The newly created socket is non-inheritable.

Changed in version 3.4: The socket is now non-inheritable.

Availability: not WASI.



Return the socket’s file descriptor (a small integer), or -1 on failure. This is useful with .

Under Windows the small integer returned by this method cannot be used where a file descriptor can be used

(such as ). Unix does not have this limitation.



Get the inheritable flag of the socket’s file descriptor or socket’s handle: if the socket can be inherited in

child processes, if it cannot.

Added in version 3.4.



Return the remote address to which the socket is connected. This is useful to find out the port number of a

remote IPv4/v6 socket, for instance. (The format of the address returned depends on the address family —

see above.) On some systems this function is not supported.



Return the socket’s own address. This is useful to find out the port number of an IPv4/v6 socket, for instance.

(The format of the address returned depends on the address family — see above.)

level, optname , buflen

Return the value of the given socket option (see the Unix man page ). The needed symbolic

constants (SO_* etc.) are defined in this module. If buflen is absent, an integer option is assumed and its integer

value is returned by the function. If buflen is present, it specifies the maximum length of the buffer used to

receive the option in, and this buffer is returned as a bytes object. It is up to the caller to decode the contents of

the buffer (see the optional built-in module for a way to decode C structures encoded as byte strings).

Availability: not WASI.



Return if socket is in blocking mode, if in non-blocking.

This is equivalent to checking .

Added in version 3.7.



Return the timeout in seconds (float) associated with socket operations, or if no timeout is set. This

reflects the last call to or .

The Python Library Reference, Release 3.13.2



control, option

Platform

Windows

The method is a limited interface to the WSAIoctl system interface. Please refer to the Win32

documentation for more information.

On other platforms, the generic and functions may be used; they accept

a socket object as their first argument.

Currently only the following control codes are supported: , , and

.

Changed in version 3.6: was added.

backlog

Enable a server to accept connections. If backlog is specified, it must be at least 0 (if it is lower, it is set to 0);

it specifies the number of unaccepted connections that the system will allow before refusing new connections.

If not specified, a default reasonable value is chosen.

Availability: not WASI.

Changed in version 3.5: The backlog parameter is now optional.

mode=’r’, buffering=None, *, encoding=None, errors=None, newline=None

Return a file object associated with the socket. The exact returned type depends on the arguments given to

. These arguments are interpreted the same way as by the built-in function, except the

only supported mode values are (default), , , or a combination of those.

The socket must be in blocking mode; it can have a timeout, but the file object’s internal buffer may end up in

an inconsistent state if a timeout occurs.

Closing the file object returned by won’t close the original socket unless all other file objects

have been closed and has been called on the socket object.



® Note

On Windows, the file-like object created by cannot be used where a file object with a file

descriptor is expected, such as the stream arguments of .



bufsize, flags

Receive data from the socket. The return value is a bytes object representing the data received. The maximum

amount of data to be received at once is specified by bufsize. A returned empty bytes object indicates that the

client has disconnected. See the Unix manual page for the meaning of the optional argument flags;

it defaults to zero.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

method now retries the system call instead of raising an exception (see PEP 475 for the

rationale).

bufsize , flags

Receive data from the socket. The return value is a pair where bytes is a bytes object

representing the data received and address is the address of the socket sending the data. See the Unix manual

page for the meaning of the optional argument flags; it defaults to zero. (The format of address

depends on the address family — see above.)

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

method now retries the system call instead of raising an exception (see PEP 475 for the

rationale).

Changed in version 3.7: For multicast IPv6 address, first item of address does not contain part

anymore. In order to get full IPv6 address use .

The Python Library Reference, Release 3.13.2



bufsize , ancbufsize, flags

Receive normal data (up to bufsize bytes) and ancillary data from the socket. The ancbufsize argument sets the

size in bytes of the internal buffer used to receive the ancillary data; it defaults to 0, meaning that no ancillary

data will be received. Appropriate buffer sizes for ancillary data can be calculated using or

, and items which do not fit into the buffer might be truncated or discarded. The flags argument

defaults to 0 and has the same meaning as for .

The return value is a 4-tuple: . The data item is a ob-

ject holding the non-ancillary data received. The ancdata item is a list of zero or more tuples

representing the ancillary data (control messages) received: cmsg_level and

cmsg_type are integers specifying the protocol level and protocol-specific type respectively, and cmsg_data

is a object holding the associated data. The msg_flags item is the bitwise OR of various flags indicat-

ing conditions on the received message; see your system documentation for details. If the receiving socket is

unconnected, address is the address of the sending socket, if available; otherwise, its value is unspecified.

On some systems, and can be used to pass file descriptors between processes over

an socket. When this facility is used (it is often restricted to sockets),

will return, in its ancillary data, items of the form ,

where fds is a object representing the new file descriptors as a binary array of the native C type. If

raises an exception after the system call returns, it will first attempt to close any file descriptors

received via this mechanism.

Some systems do not indicate the truncated length of ancillary data items which have been only partially re-

ceived. If an item appears to extend beyond the end of the buffer, will issue a ,

and will return the part of it which is inside the buffer provided it has not been truncated before the start of its

associated data.

On systems which support the mechanism, the following function will receive up to maxfds

file descriptors, returning the message data and a list containing the descriptors (while ignoring unexpected

conditions such as unrelated control messages being received). See also .





Availability: Unix.

Most Unix platforms.

Added in version 3.3.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

method now retries the system call instead of raising an exception (see PEP 475 for the

rationale).

buffers , ancbufsize, flags

Receive normal data and ancillary data from the socket, behaving as would, but scatter the non-

ancillary data into a series of buffers instead of returning a new bytes object. The buffers argument must be an

iterable of objects that export writable buffers (e.g. objects); these will be filled with successive

chunks of the non-ancillary data until it has all been written or there are no more buffers. The operating system

may set a limit ( value ) on the number of buffers that can be used. The ancbufsize

and flags arguments have the same meaning as for .

The Python Library Reference, Release 3.13.2



The return value is a 4-tuple: , where nbytes is the total

number of bytes of non-ancillary data written into the buffers, and ancdata, msg_flags and address are the

same as for .

Example:





Availability: Unix.

Most Unix platforms.

Added in version 3.3.

buffer , nbytes, flags

Receive data from the socket, writing it into buffer instead of creating a new bytestring. The return value is

a pair where nbytes is the number of bytes received and address is the address of the

socket sending the data. See the Unix manual page for the meaning of the optional argument flags;

it defaults to zero. (The format of address depends on the address family — see above.)

buffer , nbytes, flags

Receive up to nbytes bytes from the socket, storing the data into a buffer rather than creating a new bytestring.

If nbytes is not specified (or 0), receive up to the size available in the given buffer. Returns the number of bytes

received. See the Unix manual page for the meaning of the optional argument flags; it defaults to

zero.

bytes, flags

Send data to the socket. The socket must be connected to a remote socket. The optional flags argument has

the same meaning as for above. Returns the number of bytes sent. Applications are responsible for

checking that all data has been sent; if only some of the data was transmitted, the application needs to attempt

delivery of the remaining data. For further information on this topic, consult the socket-howto.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

method now retries the system call instead of raising an exception (see PEP 475 for the

rationale).

bytes, flags

Send data to the socket. The socket must be connected to a remote socket. The optional flags argument has

the same meaning as for above. Unlike , this method continues to send data from bytes until

either all data has been sent or an error occurs. is returned on success. On error, an exception is raised,

and there is no way to determine how much data, if any, was successfully sent.

Changed in version 3.5: The socket timeout is no longer reset each time data is sent successfully. The socket

timeout is now the maximum total duration to send all data.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

method now retries the system call instead of raising an exception (see PEP 475 for the

rationale).

bytes, address

bytes, flags, address

Send data to the socket. The socket should not be connected to a remote socket, since the destination socket The Python Library Reference, Release 3.13.2



is specified by address. The optional flags argument has the same meaning as for above. Return the

number of bytes sent. (The format of address depends on the address family — see above.)

Raises an auditing event with arguments , .

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

method now retries the system call instead of raising an exception (see PEP 475 for the

rationale).

buffers, ancdata, flags, address

Send normal and ancillary data to the socket, gathering the non-ancillary data from a series of buffers and

concatenating it into a single message. The buffers argument specifies the non-ancillary data as an iterable of

bytes-like objects (e.g. objects); the operating system may set a limit ( value )

on the number of buffers that can be used. The ancdata argument specifies the ancillary data (control messages)

as an iterable of zero or more tuples , where cmsg_level and

cmsg_type are integers specifying the protocol level and protocol-specific type respectively, and cmsg_data

is a bytes-like object holding the associated data. Note that some systems (in particular, systems without

) might support sending only one control message per call. The flags argument defaults to 0

and has the same meaning as for . If address is supplied and not , it sets a destination address for

the message. The return value is the number of bytes of non-ancillary data sent.

The following function sends the list of file descriptors fds over an socket, on systems which support

the mechanism. See also .





Availability: Unix, not WASI.

Most Unix platforms.

Raises an auditing event with arguments , .

Added in version 3.3.

Changed in version 3.5: If the system call is interrupted and the signal handler does not raise an exception, the

method now retries the system call instead of raising an exception (see PEP 475 for the

rationale).

msg , *, op, iv, assoclen, flags

Specialized version of for socket. Set mode, IV, AEAD associated data length and flags

for socket.

Availability: Linux >= 2.6.38.

Added in version 3.6.

file, offset=0, count=None

Send a file until EOF is reached by using high-performance and return the total number of bytes

which were sent. file must be a regular file object opened in binary mode. If is not available

(e.g. Windows) or file is not a regular file will be used instead. offset tells from where to start reading

the file. If specified, count is the total number of bytes to transmit as opposed to sending the file until EOF is

reached. File position is updated on return or also in case of error in which case can be used

to figure out the number of bytes which were sent. The socket must be of type. Non-blocking

sockets are not supported.

Added in version 3.5.

inheritable

Set the inheritable flag of the socket’s file descriptor or socket’s handle.

Added in version 3.4.

The Python Library Reference, Release 3.13.2



flag

Set blocking or non-blocking mode of the socket: if flag is false, the socket is set to non-blocking, else to

blocking mode.

This method is a shorthand for certain calls:

• is equivalent to

• is equivalent to

Changed in version 3.7: The method no longer applies flag on .

value

Set a timeout on blocking socket operations. The value argument can be a nonnegative floating-point number

expressing seconds, or . If a non-zero value is given, subsequent socket operations will raise a

exception if the timeout period value has elapsed before the operation has completed. If zero is given, the

socket is put in non-blocking mode. If is given, the socket is put in blocking mode.

For further information, please consult the notes on socket timeouts.

Changed in version 3.7: The method no longer toggles flag on .

level, optname, value: int

level, optname, value: buffer

level, optname, None, optlen: int

Set the value of the given socket option (see the Unix manual page ). The needed symbolic

constants are defined in this module (SO_* etc. ). The value can be an integer, or

a bytes-like object representing a buffer. In the later case it is up to the caller to ensure that the bytestring contains

the proper bits (see the optional built-in module for a way to encode C structures as bytestrings).

When value is set to , optlen argument is required. It’s equivalent to call C function with

and .

Changed in version 3.5: Writable bytes-like object is now accepted.

Changed in version 3.6: setsockopt(level, optname, None, optlen: int) form added.

Availability: not WASI.

how

Shut down one or both halves of the connection. If how is , further receives are disallowed. If how

is , further sends are disallowed. If how is , further sends and receives are disallowed.

Availability: not WASI.

process_id

Duplicate a socket and prepare it for sharing with a target process. The target process must be provided with

process_id. The resulting bytes object can then be passed to the target process using some form of interprocess

communication and the socket can be recreated there using . Once this method has been called,

it is safe to close the socket since the operating system has already duplicated it for the target process.

Availability: Windows.

Added in version 3.3.

Note that there are no methods or ; use and without flags argument instead.

Socket objects also have these (read-only) attributes that correspond to the values given to the constructor.



The socket family.



The socket type.



The socket protocol.

The Python Library Reference, Release 3.13.2





A socket object can be in one of three modes: blocking, non-blocking, or timeout. Sockets are by default always

created in blocking mode, but this can be changed by calling .

• In blocking mode, operations block until complete or the system returns an error (such as connection timed

out).

• In non-blocking mode, operations fail (with an error that is unfortunately system-dependent) if they cannot be

completed immediately: functions from the module can be used to know when and whether a socket

is available for reading or writing.

• In timeout mode, operations fail if they cannot be completed within the timeout specified for the socket (they

raise a exception) or if the system returns an error.



® Note

At the operating system level, sockets in timeout mode are internally set in non-blocking mode. Also, the blocking

and timeout modes are shared between file descriptors and socket objects that refer to the same network endpoint.

This implementation detail can have visible consequences if e.g. you decide to use the of a socket.



Timeouts and the method

The operation is also subject to the timeout setting, and in general it is recommended to call

before calling or pass a timeout parameter to . However, the system network stack may also return a connection timeout error of its own regardless of any Python socket timeout setting.



Timeouts and the method

If is not , sockets returned by the method inherit that timeout. Otherwise, the behaviour depends on settings of the listening socket:

• if the listening socket is in blocking mode or in timeout mode, the socket returned by is in blocking

mode;

• if the listening socket is in non-blocking mode, whether the socket returned by is in blocking or

non-blocking mode is operating system-dependent. If you want to ensure cross-platform behaviour, it is rec-

ommended you manually override this setting.





Here are four minimal example programs using the TCP/IP protocol: a server that echoes all data that it receives

back (servicing only one client), and a client using it. Note that a server must perform the sequence ,

, , (possibly repeating the to service more than one client), while a client

only needs the sequence , . Also note that the server does not / on the

socket it is listening on but on the new socket returned by .

The first two examples support IPv4 only.





The Python Library Reference, Release 3.13.2





The next two examples are identical to the above two, but support both IPv4 and IPv6. The server side will listen to the first address family available (it should listen to both instead). On most of IPv6-ready systems, IPv6 will take precedence and the server may not accept IPv4 traffic. The client side will try to connect to all the addresses returned as a result of the name resolution, and sends traffic to the first one connected successfully.





The Python Library Reference, Release 3.13.2





The next example shows how to write a very simple network sniffer with raw sockets on Windows. The example requires administrator privileges to modify the interface:





The next example shows how to use the socket interface to communicate to a CAN network using the raw socket protocol. To use CAN with the broadcast manager protocol instead, open a socket with:



The Python Library Reference, Release 3.13.2



After binding () or connecting ( ) the socket, you can use the and

operations (and their counterparts) on the socket object as usual.

This last example might require special privileges:





Running an example several times with too small delay between executions, could lead to this error:





This is because the previous execution has left the socket in a state, and can’t be immediately reused.

There is a flag to set, in order to prevent this, :





the flag tells the kernel to reuse a local socket in state, without waiting for its natural timeout to expire.



The Python Library Reference, Release 3.13.2



µ See also

For an introduction to socket programming (in C), see the following papers:

• An Introductory 4.3BSD Interprocess Communication Tutorial, by Stuart Sechrest

• An Advanced 4.3BSD Interprocess Communication Tutorial, by Samuel J. Leffler et al,

both in the UNIX Programmer’s Manual, Supplementary Documents 1 (sections PS1:7 and PS1:8). The platform-

specific reference material for the various socket-related system calls are also a valuable source of information on

the details of socket semantics. For Unix, refer to the manual pages; for Windows, see the WinSock (or Winsock

2) specification. For IPv6-ready APIs, readers may want to refer to RFC 3493 titled Basic Socket Interface

Extensions for IPv6.





Source code: Lib/ssl.py



This module provides access to Transport Layer Security (often known as “Secure Sockets Layer”) encryption and peer authentication facilities for network sockets, both client-side and server-side. This module uses the OpenSSL library. It is available on all modern Unix systems, Windows, macOS, and probably additional platforms, as long as OpenSSL is installed on that platform.



® Note

Some behavior may be platform dependent, since calls are made to the operating system socket APIs. The

installed version of OpenSSL may also cause variations in behavior. For example, TLSv1.3 comes with OpenSSL

version 1.1.1.



Á Warning

Don’t use this module without reading the Security considerations. Doing so may lead to a false sense of security,

as the default settings of the ssl module are not necessarily appropriate for your application.



Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.

This section documents the objects and functions in the module; for more general information about TLS, SSL, and certificates, the reader is referred to the documents in the “See Also” section at the bottom.

This module provides a class, , which is derived from the type, and pro-vides a socket-like wrapper that also encrypts and decrypts the data going over the socket with SSL. It supports additional methods such as , which retrieves the certificate of the other side of the connec-tion, , which retrieves the cipher being used for the secure connection or , which retrieves certificate chain.

For more sophisticated applications, the class helps manage settings and certificates, which can

then be inherited by SSL sockets created through the method.

Changed in version 3.5.3: Updated to support linking with OpenSSL 1.1.0

Changed in version 3.6: OpenSSL 0.9.8, 1.0.0 and 1.0.1 are deprecated and no longer supported. In the future the ssl module will require at least OpenSSL 1.0.2 or 1.1.0.

Changed in version 3.10: PEP 644 has been implemented. The ssl module requires OpenSSL 1.1.1 or newer.

Use of deprecated constants and functions result in deprecation warnings.

The Python Library Reference, Release 3.13.2





Socket creation

Instances of must be created using the method. The helper function

returns a new context with secure default settings.

Client socket example with default context and IPv4/IPv6 dual stack:





Client socket example with custom context and IPv4:





Server socket example listening on localhost IPv4:





Context creation

A convenience function helps create objects for common purposes.

purpose=Purpose.SERVER_AUTH, cafile=None, capath=None, cadata=None

Return a new object with default settings for the given purpose. The settings are chosen by

the module, and usually represent a higher security level than when calling the constructor

directly.

cafile, capath, cadata represent optional CA certificates to trust for certificate verification, as in

. If all three are , this function can choose to trust the system’s default

CA certificates instead.

The settings are: or , , and

with high encryption cipher suites without RC4 and without unauthenticated cipher suites.

as purpose sets to and either loads CA certificates (when

at least one of cafile, capath or cadata is given) or uses to load

default CA certificates.

The Python Library Reference, Release 3.13.2



When is supported and the environment variable is set,

enables key logging.

The default settings for this context include and .

These make the underlying OpenSSL implementation behave more like a conforming implementation of RFC

5280, in exchange for a small amount of incompatibility with older X.509 certificates.



® Note

The protocol, options, cipher and other settings may change to more restrictive values anytime without prior deprecation. The values represent a fair balance between compatibility and security.

If your application needs specific settings, you should create a and apply the settings yourself.



® Note

If you find that when certain older clients or servers attempt to connect with a created by this function that they get an error stating “Protocol or cipher suite mismatch”, it may be that they only

support SSL3.0 which this function excludes using the . SSL3.0 is widely considered to be

completely broken. If you still wish to continue to use this function but still allow SSL 3.0 connections you can re-enable them using:





® Note

This context enables by default, which may reject pre-RFC 5280 or malformed certificates that the underlying OpenSSL implementation otherwise would accept. While disabling this is not recommended, you can do so using:





Added in version 3.4.

Changed in version 3.4.4: RC4 was dropped from the default cipher string.

Changed in version 3.6: ChaCha20/Poly1305 was added to the default cipher string.

3DES was dropped from the default cipher string.

Changed in version 3.8: Support for key logging to was added.

Changed in version 3.10: The context now uses or pro-

tocol instead of generic .

Changed in version 3.13: The context now uses and

in its default verify flags.



Exceptions



Raised to signal an error from the underlying SSL implementation (currently provided by the OpenSSL library).

This signifies some problem in the higher-level encryption and authentication layer that’s superimposed on the

underlying network connection. This error is a subtype of . The error code and message of

instances are provided by the OpenSSL library.

Changed in version 3.3: used to be a subtype of .

The Python Library Reference, Release 3.13.2





A string mnemonic designating the OpenSSL submodule in which the error occurred, such as , or . The range of possible values depends on the OpenSSL version.

Added in version 3.3.



A string mnemonic designating the reason this error occurred, for example

. The range of possible values depends on the OpenSSL version.

Added in version 3.3.



A subclass of raised when trying to read or write and the SSL connection has been closed cleanly.

Note that this doesn’t mean that the underlying transport (read TCP) has been closed.

Added in version 3.3.



A subclass of raised by a non-blocking SSL socket when trying to read or write data, but more data

needs to be received on the underlying TCP transport before the request can be fulfilled.

Added in version 3.3.



A subclass of raised by a non-blocking SSL socket when trying to read or write data, but more data

needs to be sent on the underlying TCP transport before the request can be fulfilled.

Added in version 3.3.



A subclass of raised when a system error was encountered while trying to fulfill an operation on a

SSL socket. Unfortunately, there is no easy way to inspect the original errno number.

Added in version 3.3.



A subclass of raised when the SSL connection has been terminated abruptly. Generally, you

shouldn’t try to reuse the underlying transport when this error is encountered.

Added in version 3.3.



A subclass of raised when certificate validation has failed.

Added in version 3.7.



A numeric error number that denotes the verification error.



A human readable string of the verification error.



An alias for .

Changed in version 3.7: The exception is now an alias for .



Random generation

num

Return num cryptographically strong pseudo-random bytes. Raises an if the PRNG has not been

seeded with enough data or if the operation is not supported by the current RAND method.

can be used to check the status of the PRNG and can be used to seed the PRNG.

For almost all applications is preferable.

The Python Library Reference, Release 3.13.2



Read the Wikipedia article, Cryptographically secure pseudorandom number generator (CSPRNG), to get the

requirements of a cryptographically strong generator.

Added in version 3.3.



Return if the SSL pseudo-random number generator has been seeded with ‘enough’ randomness, and

otherwise. You can use and to increase the randomness of the

pseudo-random number generator.

bytes, entropy

Mix the given bytes into the SSL pseudo-random number generator. The parameter entropy (a float) is a lower

bound on the entropy contained in string (so you can always use ). See RFC 1750 for more information

on sources of entropy.

Changed in version 3.5: Writable bytes-like object is now accepted.



Certificate handling

cert_time

Return the time in seconds since the Epoch, given the string representing the “notBefore” or

“notAfter” date from a certificate in strptime format (C locale).

Here’s an example:





“notBefore” or “notAfter” dates must use GMT (RFC 5280).

Changed in version 3.5: Interpret the input time as a time in UTC as specified by ‘GMT’ timezone in the input

string. Local timezone was used previously. Return an integer (no fractions of a second in the input format)

addr, ssl_version=PROTOCOL_TLS_CLIENT, ca_certs=None, timeout

Given the address of an SSL-protected server, as a (hostname, port-number) pair, fetches the server’s

certificate, and returns it as a PEM-encoded string. If is specified, uses that version of the SSL

protocol to attempt to connect to the server. If ca_certs is specified, it should be a file containing a list of root

certificates, the same format as used for the cafile parameter in .

The call will attempt to validate the server certificate against that set of root certificates, and will fail if the

validation attempt fails. A timeout can be specified with the parameter.

Changed in version 3.3: This function is now IPv6-compatible.

Changed in version 3.5: The default ssl_version is changed from to for

maximum compatibility with modern servers.

Changed in version 3.10: The timeout parameter was added.

DER_cert_bytes

Given a certificate as a DER-encoded blob of bytes, returns a PEM-encoded string version of the same certifi-

cate.

PEM_cert_string

Given a certificate as an ASCII PEM string, returns a DER-encoded sequence of bytes for that same certificate.



Returns a named tuple with paths to OpenSSL’s default cafile and capath.

same as used by . The return value is a named tuple

:

The Python Library Reference, Release 3.13.2



• - resolved path to cafile or if the file doesn’t exist,

• - resolved path to capath or if the directory doesn’t exist,

• - OpenSSL’s environment key that points to a cafile,

• - hard coded path to a cafile,

• - OpenSSL’s environment key that points to a capath,

• - hard coded path to a capath directory

Added in version 3.4.

store_name

Retrieve certificates from Windows’ system cert store. store_name may be one of , or . Windows

may provide additional cert stores, too.

The function returns a list of (cert_bytes, encoding_type, trust) tuples. The encoding_type specifies the en-

coding of cert_bytes. It is either for X.509 ASN.1 data or for PKCS#7 ASN.1 data.

Trust specifies the purpose of the certificate as a set of OIDS or exactly if the certificate is trustworthy

for all purposes.

Example:





Availability: Windows.

Added in version 3.4.

store_name

Retrieve CRLs from Windows’ system cert store. store_name may be one of , or . Windows may

provide additional cert stores, too.

The function returns a list of (cert_bytes, encoding_type, trust) tuples. The encoding_type specifies the en-

coding of cert_bytes. It is either for X.509 ASN.1 data or for PKCS#7 ASN.1 data.

Availability: Windows.

Added in version 3.4.



Constants

All constants are now or collections.

Added in version 3.6.



Possible value for . Except for , it is the default mode.

With client-side sockets, just about any cert is accepted. Validation errors, such as untrusted or expired cert,

are ignored and do not abort the TLS/SSL handshake.

In server mode, no certificate is requested from the client, so the client does not send any for client cert

authentication.

See the discussion of Security considerations below.



Possible value for . In client mode, has the same meaning as

. It is recommended to use for client-side sockets instead.

In server mode, a client certificate request is sent to the client. The client may either ignore the request or send

a certificate in order perform TLS client cert authentication. If the client chooses to send a certificate, it is

verified. Any verification error immediately aborts the TLS handshake.

The Python Library Reference, Release 3.13.2



Use of this setting requires a valid set of CA certificates to be passed to

.



Possible value for . In this mode, certificates are required from the other side of

the socket connection; an will be raised if no certificate is provided, or if its validation fails. This

mode is not sufficient to verify a certificate in client mode as it does not match hostnames.

must be enabled as well to verify the authenticity of a cert. uses

and enables by default.

With server socket, this mode provides mandatory TLS client cert authentication. A client certificate request

is sent to the client and the client must provide a valid and trusted certificate.

Use of this setting requires a valid set of CA certificates to be passed to

.



collection of CERT_* constants.

Added in version 3.6.



Possible value for . In this mode, certificate revocation lists (CRLs) are not

checked. By default OpenSSL does neither require nor verify CRLs.

Added in version 3.4.



Possible value for . In this mode, only the peer cert is checked but none of the

intermediate CA certificates. The mode requires a valid CRL that is signed by the peer cert’s issuer (its direct

ancestor CA). If no proper CRL has been loaded with , validation

will fail.

Added in version 3.4.



Possible value for . In this mode, CRLs of all certificates in the peer cert chain

are checked.

Added in version 3.4.



Possible value for to disable workarounds for broken X.509 certificates.

Added in version 3.4.



Possible value for to enables proxy certificate verification.

Added in version 3.10.



Possible value for . It instructs OpenSSL to prefer trusted certificates when

building the trust chain to validate a certificate. This flag is enabled by default.

Added in version 3.4.4.



Possible value for . It instructs OpenSSL to accept intermediate CAs in the

trust store to be treated as trust-anchors, in the same way as the self-signed root CA certificates. This makes it

possible to trust certificates issued by an intermediate CA without having to trust its ancestor root CA.

Added in version 3.10.



The Python Library Reference, Release 3.13.2





collection of VERIFY_* constants.

Added in version 3.6.



Selects the highest protocol version that both the client and server support. Despite the name, this option can

select both “SSL” and “TLS” protocols.

Added in version 3.6.

Deprecated since version 3.10: TLS clients and servers require different default settings for secure com-

munication. The generic TLS protocol constant is deprecated in favor of and

.



Auto-negotiate the highest protocol version that both the client and server support, and configure the context

client-side connections. The protocol enables and by default.

Added in version 3.6.



Auto-negotiate the highest protocol version that both the client and server support, and configure the context

server-side connections.

Added in version 3.6.



Alias for .

Deprecated since version 3.6: Use instead.



Selects SSL version 3 as the channel encryption protocol.

This protocol is not available if OpenSSL is compiled with the option.



Á Warning

SSL version 3 is insecure. Its use is highly discouraged.



Deprecated since version 3.6: OpenSSL has deprecated all version specific protocols. Use the default pro-

tocol or with and

instead.



Selects TLS version 1.0 as the channel encryption protocol.

Deprecated since version 3.6: OpenSSL has deprecated all version specific protocols.



Selects TLS version 1.1 as the channel encryption protocol. Available only with openssl version 1.0.1+.

Added in version 3.4.

Deprecated since version 3.6: OpenSSL has deprecated all version specific protocols.



Selects TLS version 1.2 as the channel encryption protocol. Available only with openssl version 1.0.1+.

Added in version 3.4.

Deprecated since version 3.6: OpenSSL has deprecated all version specific protocols.

The Python Library Reference, Release 3.13.2





Enables workarounds for various bugs present in other SSL implementations. This option is set by default. It

does not necessarily set the same flags as OpenSSL’s constant.

Added in version 3.2.



Prevents an SSLv2 connection. This option is only applicable in conjunction with . It prevents

the peers from choosing SSLv2 as the protocol version.

Added in version 3.2.

Deprecated since version 3.6: SSLv2 is deprecated



Prevents an SSLv3 connection. This option is only applicable in conjunction with . It prevents

the peers from choosing SSLv3 as the protocol version.

Added in version 3.2.

Deprecated since version 3.6: SSLv3 is deprecated



Prevents a TLSv1 connection. This option is only applicable in conjunction with . It prevents

the peers from choosing TLSv1 as the protocol version.

Added in version 3.2.

Deprecated since version 3.7: The option is deprecated since OpenSSL 1.1.0, use the new

and instead.



Prevents a TLSv1.1 connection. This option is only applicable in conjunction with . It prevents

the peers from choosing TLSv1.1 as the protocol version. Available only with openssl version 1.0.1+.

Added in version 3.4.

Deprecated since version 3.7: The option is deprecated since OpenSSL 1.1.0.



Prevents a TLSv1.2 connection. This option is only applicable in conjunction with . It prevents

the peers from choosing TLSv1.2 as the protocol version. Available only with openssl version 1.0.1+.

Added in version 3.4.

Deprecated since version 3.7: The option is deprecated since OpenSSL 1.1.0.



Prevents a TLSv1.3 connection. This option is only applicable in conjunction with . It prevents

the peers from choosing TLSv1.3 as the protocol version. TLS 1.3 is available with OpenSSL 1.1.1 or later.

When Python has been compiled against an older version of OpenSSL, the flag defaults to 0.

Added in version 3.6.3.

Deprecated since version 3.7: The option is deprecated since OpenSSL 1.1.0. It was added to 2.7.15 and 3.6.3

for backwards compatibility with OpenSSL 1.0.2.



Disable all renegotiation in TLSv1.2 and earlier. Do not send HelloRequest messages, and ignore renegotiation

requests via ClientHello.

This option is only available with OpenSSL 1.1.0h and later.

Added in version 3.7.



The Python Library Reference, Release 3.13.2





Use the server’s cipher ordering preference, rather than the client’s. This option has no effect on client sockets

and SSLv2 server sockets.

Added in version 3.3.



Prevents reuse of the same DH key for distinct SSL sessions. This improves forward secrecy but requires more

computational resources. This option only applies to server sockets.

Added in version 3.3.



Prevents reuse of the same ECDH key for distinct SSL sessions. This improves forward secrecy but requires

more computational resources. This option only applies to server sockets.

Added in version 3.3.



Send dummy Change Cipher Spec (CCS) messages in TLS 1.3 handshake to make a TLS 1.3 connection look

more like a TLS 1.2 connection.

This option is only available with OpenSSL 1.1.1 and later.

Added in version 3.8.



Disable compression on the SSL channel. This is useful if the application protocol supports its own compression

scheme.

Added in version 3.3.



collection of OP_* constants.



Prevent client side from requesting a session ticket.

Added in version 3.6.



Ignore unexpected shutdown of TLS connections.

This option is only available with OpenSSL 3.0.0 and later.

Added in version 3.10.



Enable the use of the kernel TLS. To benefit from the feature, OpenSSL must have been compiled with support

for it, and the negotiated cipher suites and extensions must be supported by it (a list of supported ones may

vary by platform and kernel version).

Note that with enabled kernel TLS some cryptographic operations are performed by the kernel directly and

not via any available OpenSSL Providers. This might be undesirable if, for example, the application requires

all cryptographic operations to be performed by the FIPS provider.

This option is only available with OpenSSL 3.0.0 and later.

Added in version 3.12.



Allow legacy insecure renegotiation between OpenSSL and unpatched servers only.

Added in version 3.12.



The Python Library Reference, Release 3.13.2





Whether the OpenSSL library has built-in support for the Application-Layer Protocol Negotiation TLS extension

as described in RFC 7301.

Added in version 3.5.



Whether the OpenSSL library has built-in support not checking subject common name and

is writeable.

Added in version 3.7.



Whether the OpenSSL library has built-in support for the Elliptic Curve-based Diffie-Hellman key exchange.

This should be true unless the feature was explicitly disabled by the distributor.

Added in version 3.3.



Whether the OpenSSL library has built-in support for the Server Name Indication extension (as defined in RFC

6066).

Added in version 3.2.



Whether the OpenSSL library has built-in support for the Next Protocol Negotiation as described in the Ap-

plication Layer Protocol Negotiation. When true, you can use the

method to advertise which protocols you want to support.

Added in version 3.3.



Whether the OpenSSL library has built-in support for the SSL 2.0 protocol.

Added in version 3.7.



Whether the OpenSSL library has built-in support for the SSL 3.0 protocol.

Added in version 3.7.



Whether the OpenSSL library has built-in support for the TLS 1.0 protocol.

Added in version 3.7.



Whether the OpenSSL library has built-in support for the TLS 1.1 protocol.

Added in version 3.7.



Whether the OpenSSL library has built-in support for the TLS 1.2 protocol.

Added in version 3.7.



Whether the OpenSSL library has built-in support for the TLS 1.3 protocol.

Added in version 3.7.



Whether the OpenSSL library has built-in support for TLS-PSK.

Added in version 3.13.

The Python Library Reference, Release 3.13.2





List of supported TLS channel binding types. Strings in this list can be used as arguments to

.

Added in version 3.3.



The version string of the OpenSSL library loaded by the interpreter:





Added in version 3.2.



A tuple of five integers representing version information about the OpenSSL library:





Added in version 3.2.



The raw version number of the OpenSSL library, as a single integer:





Added in version 3.2.





Alert Descriptions from RFC 5246 and others. The IANA TLS Alert Registry contains this list and references

to the RFCs where their meaning is defined.

Used as the return value of the callback function in .

Added in version 3.4.



collection of ALERT_DESCRIPTION_* constants.

Added in version 3.6.



Option for and . This value indi-

cates that the context may be used to authenticate web servers (therefore, it will be used to create client-side

sockets).

Added in version 3.4.



Option for and . This value indi-

cates that the context may be used to authenticate web clients (therefore, it will be used to create server-side

sockets).

Added in version 3.4.



The Python Library Reference, Release 3.13.2





collection of SSL_ERROR_* constants.

Added in version 3.6.



collection of SSL and TLS versions for and

.

Added in version 3.7.





The minimum or maximum supported SSL or TLS version. These are magic constants. Their values don’t

reflect the lowest and highest available TLS/SSL versions.





SSL 3.0 to TLS 1.3.

Deprecated since version 3.10: All members except and

are deprecated.





socket.socket

SSL sockets provide the following methods of Socket Objects:

•

•

•

•

•

•

• ,

• ,

• , ,

•

•

• , (but passing a non-zero argument is not allowed)

• , (with the same limitation)

• (but will be used for plain-text sockets only, else will be used)

•



The Python Library Reference, Release 3.13.2



However, since the SSL (and TLS) protocol has its own framing atop of TCP, the SSL sockets abstraction

can, in certain respects, diverge from the specification of normal, OS-level sockets. See especially the notes on

non-blocking sockets.

Instances of must be created using the method.

Changed in version 3.5: The method was added.

Changed in version 3.5: The does not reset the socket timeout each time bytes are received or

sent. The socket timeout is now the maximum total duration of the shutdown.

Deprecated since version 3.6: It is deprecated to create a instance directly, use

to wrap a socket.

Changed in version 3.7: instances must to created with . In earlier versions, it

was possible to create instances directly. This was never documented or officially supported.

Changed in version 3.10: Python now uses and internally. The functions

support reading and writing of data larger than 2 GB. Writing zero-length data no longer fails with a protocol

violation error.

SSL sockets also have the following additional methods and attributes:

len=1024, buffer=None

Read up to len bytes of data from the SSL socket and return the result as a instance. If buffer is specified,

then read into the buffer instead, and return the number of bytes read.

Raise or if the socket is non-blocking and the read would block.

As at any time a re-negotiation is possible, a call to can also cause write operations.

Changed in version 3.5: The socket timeout is no longer reset each time bytes are received or sent. The socket

timeout is now the maximum total duration to read up to len bytes.

Deprecated since version 3.6: Use instead of .

buf

Write buf to the SSL socket and return the number of bytes written. The buf argument must be an object

supporting the buffer interface.

Raise or if the socket is non-blocking and the write would block.

As at any time a re-negotiation is possible, a call to can also cause read operations.

Changed in version 3.5: The socket timeout is no longer reset each time bytes are received or sent. The socket

timeout is now the maximum total duration to write buf.

Deprecated since version 3.6: Use instead of .



® Note

The and methods are the low-level methods that read and write unencrypted, application-level

data and decrypt/encrypt it to encrypted, wire-level data. These methods require an active SSL connection, i.e.

the handshake was completed and was not called.

Normally you should use the socket API methods like and instead of these methods.





Perform the SSL setup handshake.

Changed in version 3.4: The handshake method also performs when the

attribute of the socket’s is true.

Changed in version 3.5: The socket timeout is no longer reset each time bytes are received or sent. The socket

timeout is now the maximum total duration of the handshake.

The Python Library Reference, Release 3.13.2



Changed in version 3.7: Hostname or IP address is matched by OpenSSL during handshake. The function

is no longer used. In case OpenSSL refuses a hostname or IP address, the handshake is

aborted early and a TLS alert message is sent to the peer.

binary_form=False

If there is no certificate for the peer on the other end of the connection, return . If the SSL handshake

hasn’t been done yet, raise .

If the parameter is , and a certificate was received from the peer, this method returns

a instance. If the certificate was not validated, the dict is empty. If the certificate was validated, it

returns a dict with several keys, amongst them (the principal for which the certificate was issued)

and (the principal issuing the certificate). If a certificate contains an instance of the Subject Alternative

Name extension (see RFC 3280), there will also be a key in the dictionary.

The and fields are tuples containing the sequence of relative distinguished names (RDNs)

given in the certificate’s data structure for the respective fields, and each RDN is a sequence of name-value

pairs. Here is a real-world example:





If the parameter is , and a certificate was provided, this method returns the DER-encoded

form of the entire certificate as a sequence of bytes, or if the peer did not provide a certificate. Whether

the peer provides a certificate depends on the SSL socket’s role:

• for a client SSL socket, the server will always provide a certificate, regardless of whether validation was

required;

• for a server SSL socket, the client will only provide a certificate when requested by the server; there-

fore will return if you used (rather than or

).

See also .

Changed in version 3.2: The returned dictionary includes additional items such as and .

Changed in version 3.4: is raised when the handshake isn’t done. The returned dictionary in-

cludes additional X509v3 extension items such as , and URIs.

Changed in version 3.9: IPv6 address strings no longer have a trailing new line.



Returns verified certificate chain provided by the other end of the SSL channel as a list of DER-encoded bytes.

If certificate verification was disabled method acts the same as .

Added in version 3.13.

The Python Library Reference, Release 3.13.2





Returns raw certificate chain provided by the other end of the SSL channel as a list of DER-encoded bytes.

Added in version 3.13.



Returns a three-value tuple containing the name of the cipher being used, the version of the SSL protocol that

defines its use, and the number of secret bits being used. If no connection has been established, returns .



Return the list of ciphers available in both the client and server. Each entry of the returned list is a three-value

tuple containing the name of the cipher, the version of the SSL protocol that defines its use, and the number

of secret bits the cipher uses. returns if no connection has been established or the

socket is a client socket.

Added in version 3.5.



Return the compression algorithm being used as a string, or if the connection isn’t compressed.

If the higher-level protocol supports its own compression mechanism, you can use to

disable SSL-level compression.

Added in version 3.3.

cb_type=’tls-unique’

Get channel binding data for current connection, as a bytes object. Returns if not connected or the

handshake has not been completed.

The cb_type parameter allow selection of the desired channel binding type. Valid channel binding types are

listed in the list. Currently only the ‘tls-unique’ channel binding, defined by RFC

5929, is supported. will be raised if an unsupported channel binding type is requested.

Added in version 3.3.



Return the protocol that was selected during the TLS handshake. If

was not called, if the other party does not support ALPN, if this socket does not support any of the client’s

proposed protocols, or if the handshake has not happened yet, is returned.

Added in version 3.5.



Return the higher-level protocol that was selected during the TLS/SSL handshake. If

was not called, or if the other party does not support NPN, or if the handshake

has not yet happened, this will return .

Added in version 3.3.

Deprecated since version 3.10: NPN has been superseded by ALPN



Performs the SSL shutdown handshake, which removes the TLS layer from the underlying socket, and returns

the underlying socket object. This can be used to go from encrypted operation over a connection to unen-

crypted. The returned socket should always be used for further communication with the other side of the

connection, rather than the original socket.



Requests post-handshake authentication (PHA) from a TLS 1.3 client. PHA can only be initiated for a TLS

1.3 connection from a server-side socket, after the initial TLS handshake and with PHA enabled on both sides,

see .

The method does not perform a cert exchange immediately. The server-side sends a CertificateRequest during

the next write event and expects the client to respond with a certificate on the next read event.

If any precondition isn’t met (e.g. not TLS 1.3, PHA not enabled), an is raised.

The Python Library Reference, Release 3.13.2



® Note

Only available with OpenSSL 1.1.1 and TLS 1.3 enabled. Without TLS 1.3 support, the method raises

.



Added in version 3.8.



Return the actual SSL protocol version negotiated by the connection as a string, or if no secure connection

is established. As of this writing, possible return values include , , ,

and . Recent OpenSSL versions may define more return values.

Added in version 3.5.



Returns the number of already decrypted bytes available for read, pending on the connection.



The object this SSL socket is tied to.

Added in version 3.2.



A boolean which is for server-side sockets and for client-side sockets.

Added in version 3.2.



Hostname of the server: type, or for server-side socket or if the hostname was not specified in the

constructor.

Added in version 3.2.

Changed in version 3.7: The attribute is now always ASCII text. When is an internation-

alized domain name (IDN), this attribute now stores the A-label form (), rather than

the U-label form ().



The for this SSL connection. The session is available for client and server side sockets after the

TLS handshake has been performed. For client sockets the session can be set before has

been called to reuse a session.

Added in version 3.6.



Added in version 3.6.





Added in version 3.2.

An SSL context holds various data longer-lived than single SSL connections, such as SSL configuration options, certificate(s) and private key(s). It also manages a cache of SSL sessions for server-side sockets, in order to speed up repeated connections from the same clients.

protocol=None

Create a new SSL context. You may pass protocol which must be one of the constants defined in

this module. The parameter specifies which version of the SSL protocol to use. Typically, the server chooses

a particular protocol version, and the client must adapt to the server’s choice. Most of the versions are not

interoperable with the other versions. If not specified, the default is ; it provides the most

compatibility with other versions.

Here’s a table showing which versions in a client (down the side) can connect to which versions in a server

(along the top):

The Python Library Reference, Release 3.13.2



client / server SSLv2 SSLv3 TLS TLSv1 TLSv1.1 TLSv1.2

SSLv2 yes no no no no no

SSLv3 no yes no no no no

TLS ( SSLv23 ) no no yes yes yes yes

TLSv1 no no yes yes no no

TLSv1.1 no no yes no yes no

TLSv1.2 no no yes no no yes



µ See also

lets the module choose security settings for a given purpose.



Changed in version 3.6: The context is created with secure default values. The options ,

, , , , and

(except for ) are set by default. The initial cipher suite list contains only

ciphers, no ciphers and no ciphers.

Deprecated since version 3.10: without protocol argument is deprecated. The context class will

either require or protocol in the future.

Changed in version 3.10: The default cipher suites now include only secure AES and ChaCha20 ciphers with

forward secrecy and security level 2. RSA and DH keys with less than 2048 bits and ECC keys with less than

224 bits are prohibited. , , and use TLS

1.2 as minimum TLS version.



® Note

only supports limited mutation once it has been used by a connection. Adding new certifi-cates to the internal trust store is allowed, but changing ciphers, verification settings, or mTLS certificates may result in surprising behavior.



® Note

is designed to be shared and used by multiple connections. Thus, it is thread-safe as long as it is not reconfigured after being used by a connection.



objects have the following methods and attributes:



Get statistics about quantities of loaded X.509 certificates, count of X.509 certificates flagged as CA certificates

and certificate revocation lists as dictionary.

Example for a context with one CA cert and one other cert:





Added in version 3.4.





The Python Library Reference, Release 3.13.2



certfile, keyfile=None, password=None

Load a private key and the corresponding certificate. The certfile string must be the path to a single file in PEM

format containing the certificate as well as any number of CA certificates needed to establish the certificate’s

authenticity. The keyfile string, if present, must point to a file containing the private key. Otherwise the private

key will be taken from certfile as well. See the discussion of Certificates for more information on how the

certificate is stored in the certfile.

The password argument may be a function to call to get the password for decrypting the private key. It will

only be called if the private key is encrypted and a password is necessary. It will be called with no arguments,

and it should return a string, bytes, or bytearray. If the return value is a string it will be encoded as UTF-8

before using it to decrypt the key. Alternatively a string, bytes, or bytearray value may be supplied directly as

the password argument. It will be ignored if the private key is not encrypted and no password is needed.

If the password argument is not specified and a password is required, OpenSSL’s built-in password prompting

mechanism will be used to interactively prompt the user for a password.

An is raised if the private key doesn’t match with the certificate.

Changed in version 3.3: New optional argument password.

purpose=Purpose.SERVER_AUTH

Load a set of default “certification authority” (CA) certificates from default locations.

it loads CA certs from the and system stores. On all systems it calls

. In the future the method may load CA certificates from other locations,

too.

The purpose flag specifies what kind of CA certificates are loaded. The default settings

loads certificates, that are flagged and trusted for TLS web server authentication (client side

sockets). loads CA certificates for client certificate verification on the server side.

Added in version 3.4.

cafile=None, capath=None, cadata=None

Load a set of “certification authority” (CA) certificates used to validate other peers’ certificates when

is other than . At least one of cafile or capath must be specified.

This method can also load certification revocation lists (CRLs) in PEM or DER format. In order to make use

of CRLs, must be configured properly.

The cafile string, if present, is the path to a file of concatenated CA certificates in PEM format. See the

discussion of Certificates for more information about how to arrange the certificates in this file.

The capath string, if present, is the path to a directory containing several CA certificates in PEM format,

following an OpenSSL specific layout.

The cadata object, if present, is either an ASCII string of one or more PEM-encoded certificates or a bytes-like

object of DER-encoded certificates. Like with capath extra lines around PEM-encoded certificates are ignored

but at least one certificate must be present.

Changed in version 3.4: New optional argument cadata

binary_form=False

Get a list of loaded “certification authority” (CA) certificates. If the parameter is each

list entry is a dict like the output of . Otherwise the method returns a list of

DER-encoded certificates. The returned list does not contain certificates from capath unless a certificate was

requested and loaded by a SSL connection.



® Note

Certificates in a capath directory aren’t loaded unless they have been used at least once.



Added in version 3.4.

The Python Library Reference, Release 3.13.2





Get a list of enabled ciphers. The list is in order of cipher priority. See .

Example:





Added in version 3.6.



Load a set of default “certification authority” (CA) certificates from a filesystem path defined when building

the OpenSSL library. Unfortunately, there’s no easy way to know whether this method succeeds: no error is

returned if no certificates are to be found. When the OpenSSL library is provided as part of the operating

system, though, it is likely to be configured properly.

ciphers

Set the available ciphers for sockets created with this context. It should be a string in the OpenSSL cipher list

format. If no cipher can be selected (because compile-time options or other configuration forbids use of all

the specified ciphers), an will be raised.



® Note

when connected, the method of SSL sockets will give the currently selected ci-pher.

TLS 1.3 cipher suites cannot be disabled with .



protocols

Specify which protocols the socket should advertise during the SSL/TLS handshake. It should be a list of

ASCII strings, like , ordered by preference. The selection of a protocol will

happen during the handshake, and will play out according to RFC 7301. After a successful handshake, the

method will return the agreed-upon protocol.

The Python Library Reference, Release 3.13.2



This method will raise if is .

Added in version 3.5.

protocols

Specify which protocols the socket should advertise during the SSL/TLS handshake. It should be a list of

strings, like , ordered by preference. The selection of a protocol will happen

during the handshake, and will play out according to the Application Layer Protocol Negotiation. After a

successful handshake, the method will return the agreed-upon

protocol.

This method will raise if is .

Added in version 3.3.

Deprecated since version 3.10: NPN has been superseded by ALPN



Register a callback function that will be called after the TLS Client Hello handshake message has been received

by the SSL/TLS server when the TLS client specifies a server name indication. The server name indication

mechanism is specified in RFC 6066 section 3 - Server Name Indication.

Only one callback can be set per . If sni_callback is set to then the callback is disabled.

Calling this function a subsequent time will disable the previously registered callback.

The callback function will be called with three arguments; the first being the , the second is

a string that represents the server name that the client is intending to communicate (or if the TLS Client

Hello does not contain a server name) and the third argument is the original . The server name

argument is text. For internationalized domain name, the server name is an IDN A-label (

).

A typical use of this callback is to change the ’s attribute to a new

object of type representing a certificate chain that matches the server name.

Due to the early negotiation phase of the TLS connection, only limited methods and attributes are us-

able like and . The

, ,

and methods require that the TLS connection has

progressed beyond the TLS Client Hello and therefore will not return meaningful values nor can they be called

safely.

The sni_callback function must return to allow the TLS negotiation to continue. If a TLS failure is

required, a constant can be returned. Other return values will result in a TLS fatal

error with .

If an exception is raised from the sni_callback function the TLS connection will terminate with a fatal TLS

alert message .

This method will raise if the OpenSSL library had OPENSSL_NO_TLSEXT de-

fined when it was built.

Added in version 3.7.

server_name_callback

This is a legacy API retained for backwards compatibility. When possible, you should use

instead. The given server_name_callback is similar to sni_callback, except that when the server hostname

is an IDN-encoded internationalized domain name, the server_name_callback receives a decoded U-label

().

If there is a decoding error on the server name, the TLS connection will terminate with an

fatal TLS alert message to the client.

Added in version 3.4.



The Python Library Reference, Release 3.13.2



dhfile

Load the key generation parameters for Diffie-Hellman (DH) key exchange. Using DH key exchange improves

forward secrecy at the expense of computational resources (both on the server and on the client). The dhfile

parameter should be the path to a file containing DH parameters in PEM format.

This setting doesn’t apply to client sockets. You can also use the option to further

improve security.

Added in version 3.3.

curve_name

Set the curve name for Elliptic Curve-based Diffie-Hellman (ECDH) key exchange. ECDH is significantly

faster than regular DH while arguably as secure. The curve_name parameter should be a string describing a

well-known elliptic curve, for example for a widely supported curve.

This setting doesn’t apply to client sockets. You can also use the option to further

improve security.

This method is not available if is .

Added in version 3.3.



µ See also



SSL/TLS & Perfect Forward Secrecy

Vincent Bernat.



sock, server_side=False, do_handshake_on_connect=True,

suppress_ragged_eofs=True, server_hostname=None, session=None

Wrap an existing Python socket sock and return an instance of (default

). The returned SSL socket is tied to the context, its settings and certificates. sock must be a

socket; other socket types are unsupported.

The parameter is a boolean which identifies whether server-side or client-side behavior is de-

sired from this socket.

For client-side sockets, the context construction is lazy; if the underlying socket isn’t connected yet, the context

construction will be performed after is called on the socket. For server-side sockets, if the socket

has no remote peer, it is assumed to be a listening socket, and the server-side SSL wrapping is automatically

performed on client connections accepted via the method. The method may raise .

On client connections, the optional parameter server_hostname specifies the hostname of the service which

we are connecting to. This allows a single server to host multiple SSL-based services with distinct certificates,

quite similarly to HTTP virtual hosts. Specifying server_hostname will raise a if server_side is

true.

The parameter specifies whether to do the SSL handshake automatically af-

ter doing a , or whether the application program will call it explicitly, by invoking the

method. Calling explicitly gives the pro-

gram control over the blocking behavior of the socket I/O involved in the handshake.

The parameter specifies how the method should signal un-

expected EOF from the other end of the connection. If specified as (the default), it returns a normal EOF

(an empty bytes object) in response to unexpected EOF errors raised from the underlying socket; if , it

will raise the exceptions back to the caller.

session, see .

To wrap an in another , use .

Changed in version 3.5: Always allow a server_hostname to be passed, even if OpenSSL does not have SNI.

Changed in version 3.6: session argument was added.

The Python Library Reference, Release 3.13.2



Changed in version 3.7: The method returns an instance of instead of

hard-coded .



The return type of , defaults to . The attribute can be overridden

on instance of class in order to return a custom subclass of .

Added in version 3.7.

incoming, outgoing, server_side=False, server_hostname=None, session=None

Wrap the BIO objects incoming and outgoing and return an instance of

(default ). The SSL routines will read input data from the incoming BIO and write data to the

outgoing BIO.

The server_side, server_hostname and session parameters have the same meaning as in

.

Changed in version 3.6: session argument was added.

Changed in version 3.7: The method returns an instance of instead of

hard-coded .



The return type of , defaults to . The attribute can be overridden on

instance of class in order to return a custom subclass of .

Added in version 3.7.



Get statistics about the SSL sessions created or managed by this context. A dictionary is returned which maps

the names of each piece of information to their numeric values. For example, here is the total number of hits

and misses in the session cache since the context was created:





Whether to match the peer cert’s hostname in . The context’s

must be set to or , and you must pass server_hostname to

in order to match the hostname. Enabling hostname checking automatically sets from

to . It cannot be set back to as long as hostname checking is en-

abled. The protocol enables hostname checking by default. With other protocols,

hostname checking must be enabled explicitly.

Example:





Added in version 3.4.

Changed in version 3.7: is now automatically changed to when hostname

checking is enabled and is . Previously the same operation would have failed with

a .

The Python Library Reference, Release 3.13.2





Write TLS keys to a keylog file, whenever key material is generated or received. The keylog file is designed

for debugging purposes only. The file format is specified by NSS and used by many traffic analyzers such as

Wireshark. The log file is opened in append-only mode. Writes are synchronized between threads, but not

between processes.

Added in version 3.8.



A enum member representing the highest supported TLS version. The value defaults to

. The attribute is read-only for protocols other than ,

, and .

The attributes , and all affect the supported

SSL and TLS versions of the context. The implementation does not prevent invalid combination. For example

a context with in and set to will not

be able to establish a TLS 1.2 connection.

Added in version 3.7.



Like except it is the lowest supported version or

.

Added in version 3.7.



Control the number of TLS 1.3 session tickets of a context. The setting has no

impact on TLS 1.0 to 1.2 connections.

Added in version 3.8.



An integer representing the set of SSL options enabled on this context. The default value is , but you

can specify other options such as by ORing them together.

Changed in version 3.6: returns flags:





Deprecated since version 3.7: All and options have been deprecated since Python

3.7. Use and instead.



Enable TLS 1.3 post-handshake client authentication. Post-handshake auth is disabled by default and a server

can only request a TLS client certificate during the initial handshake. When enabled, a server may request a

TLS client certificate at any time after the handshake.

When enabled on client-side sockets, the client signals the server that it supports post-handshake authentication.

When enabled on server-side sockets, must be set to

or , too. The actual client cert exchange is delayed until

is called and some I/O is performed.

Added in version 3.8.



The protocol version chosen when constructing the context. This attribute is read-only.



Whether falls back to verify the cert’s subject common name in the absence of a subject

alternative name extension (default: true).

Added in version 3.7.

The Python Library Reference, Release 3.13.2



Changed in version 3.10: The flag had no effect with OpenSSL before version 1.1.1l. Python 3.8.9, 3.9.3, and

3.10 include workarounds for previous versions.



An integer representing the security level for the context. This attribute is read-only.

Added in version 3.10.



The flags for certificate verification operations. You can set flags like by ORing

them together. By default OpenSSL does neither require nor verify certificate revocation lists (CRLs).

Added in version 3.4.

Changed in version 3.6: returns flags:





Whether to try to verify other peers’ certificates and how to behave if verification fails. This attribute must be

one of , or .

Changed in version 3.6: returns enum:





callback

Enables TLS-PSK (pre-shared key) authentication on a client-side connection.

In general, certificate based authentication should be preferred over this method.

The parameter is a callable object with the signature:

. The parameter is an optional identity hint sent by the server. The

return value is a tuple in the form (client-identity, psk). Client-identity is an optional string which may be used

by the server to select a corresponding PSK for the client. The string must be less than or equal to octets

when UTF-8 encoded. PSK is a bytes-like object representing the pre-shared key. Return a zero length PSK to

reject the connection.

Setting to removes any existing callback.



® Note

When using TLS 1.3:

• the parameter is always .

• client-identity must be a non-empty string.



Example usage:





The Python Library Reference, Release 3.13.2





This method will raise if is .

Added in version 3.13.

callback, identity_hint=None

Enables TLS-PSK (pre-shared key) authentication on a server-side connection.

In general, certificate based authentication should be preferred over this method.

The parameter is a callable object with the signature:

. The parameter is an optional identity sent by the client which can be used

to select a corresponding PSK. The return value is a bytes-like object representing the pre-shared key. Return

a zero length PSK to reject the connection.

Setting to removes any existing callback.

The parameter is an optional identity hint string sent to the client. The string must be less

than or equal to octets when UTF-8 encoded.



® Note

When using TLS 1.3 the parameter is not sent to the client.



Example usage:





This method will raise if is .

Added in version 3.13.





Certificates in general are part of a public-key / private-key system. In this system, each principal, (which may be a machine, or a person, or an organization) is assigned a unique two-part encryption key. One part of the key is public, and is called the public key; the other part is kept secret, and is called the private key. The two parts are related, in The Python Library Reference, Release 3.13.2



that if you encrypt a message with one of the parts, you can decrypt it with the other part, and only with the other part.

A certificate contains information about two principals. It contains the name of a subject, and the subject’s public key. It also contains a statement by a second principal, the issuer, that the subject is who they claim to be, and that this is indeed the subject’s public key. The issuer’s statement is signed with the issuer’s private key, which only the issuer knows. However, anyone can verify the issuer’s statement by finding the issuer’s public key, decrypting the statement with it, and comparing it to the other information in the certificate. The certificate also contains information about the time period over which it is valid. This is expressed as two fields, called “notBefore” and “notAfter”.

In the Python use of certificates, a client or server can use a certificate to prove who they are. The other side of a network connection can also be required to produce a certificate, and that certificate can be validated to the satisfaction of the client or server that requires such validation. The connection attempt can be set to raise an exception if the validation fails. Validation is done automatically, by the underlying OpenSSL framework; the application need not concern itself with its mechanics. But the application does usually need to provide sets of certificates to allow this process to take place.

Python uses files to contain certificates. They should be formatted as “PEM” (see RFC 1422), which is a base-64 encoded form wrapped with a header line and a footer line:





Certificate chains

The Python files which contain certificates can contain a sequence of certificates, sometimes called a certificate chain. This chain should start with the specific certificate for the principal who “is” the client or server, and then the certificate for the issuer of that certificate, and then the certificate for the issuer of that certificate, and so on up the chain till you get to a certificate which is self-signed, that is, a certificate which has the same subject and issuer, sometimes called a root certificate. The certificates should just be concatenated together in the certificate file. For example, suppose we had a three certificate chain, from our server certificate to the certificate of the certification authority that signed our server certificate, to the root certificate of the agency which issued the certification authority’s certificate:





CA certificates

If you are going to require validation of the other side of the connection’s certificate, you need to provide a “CA certs” file, filled with the certificate chains for each issuer you are willing to trust. Again, this file just contains these chains concatenated together. For validation, Python will use the first chain it finds in the file which matches. The platform’s

certificates file can be used by calling , this is done automatically with

.



Combined key and certificate

Often the private key is stored in the same file as the certificate; in this case, only the parameter to

needs to be passed. If the private key is stored with the certificate, it should come before the first certificate in the certificate chain:



The Python Library Reference, Release 3.13.2





Self-signed certificates

If you are going to create a server that provides SSL-encrypted connection services, you will need to acquire a certificate for that service. There are many ways of acquiring appropriate certificates, such as buying one from a certification authority. Another common practice is to generate a self-signed certificate. The simplest way to do this is with the OpenSSL package, using something like the following:





The disadvantage of a self-signed certificate is that it is its own root certificate, and no one else will have it in their cache of known (and trusted) root certificates.





Testing for SSL support

To test for the presence of SSL support in a Python installation, user code should use the following idiom:





Client-side operation

This example creates a SSL context with the recommended security settings for client sockets, including automatic certificate verification:

The Python Library Reference, Release 3.13.2





If you prefer to tune security settings yourself, you might create a context from scratch (but beware that you might not get the settings right):





(this snippet assumes your operating system places a bundle of all CA certificates in ; if not, you’ll get an error and have to adjust the location)

The protocol configures the context for cert validation and hostname verification.

is set to and is set to . All other protocols create SSL contexts with insecure defaults.

When you use the context to connect to a server, and validate the server cer-tificate: it ensures that the server certificate was signed with one of the CA certificates, checks the signature for correctness, and verifies other properties like validity and identity of the hostname:





You may then fetch the certificate:





Visual inspection shows that the certificate does identify the desired service (that is, the HTTPS host ):





The Python Library Reference, Release 3.13.2





Now the SSL channel is established and the certificate verified, you can proceed to talk with the server:





See the discussion of Security considerations below.



Server-side operation

For server operation, typically you’ll need to have a server certificate, and private key, each in a file. You’ll first create a context holding the key and the certificate, so that clients can check your authenticity. Then you’ll open a socket, bind it to a port, call on it, and start waiting for clients to connect:





When a client connects, you’ll call on the socket to get the new socket from the other end, and use the

context’s method to create a server-side SSL socket for the connection:





The Python Library Reference, Release 3.13.2





Then you’ll read data from the and do something with it till you are finished with the client (or the client is finished with you):





And go back to listening for new client connections (of course, a real server would probably handle each client

connection in a separate thread, or put the sockets in non-blocking mode and use an event loop).





SSL sockets behave slightly different than regular sockets in non-blocking mode. When working with non-blocking sockets, there are thus several things you need to be aware of:

• Most methods will raise either or instead of

if an I/O operation would block. will be raised if a read opera-

tion on the underlying socket is necessary, and for a write operation on the underlying

socket. Note that attempts to write to an SSL socket may require reading from the underlying socket first, and

attempts to read from the SSL socket may require a prior write to the underlying socket.

Changed in version 3.5: In earlier Python versions, the method returned zero instead of

raising or .

• Calling tells you that the OS-level socket can be read from (or written to), but it does not imply

that there is sufficient data at the upper SSL layer. For example, only part of an SSL frame might have arrived.

Therefore, you must be ready to handle and failures, and retry

after another call to .

• Conversely, since the SSL layer has its own framing, a SSL socket may still have data available for reading

without being aware of it. Therefore, you should first call to drain any

potentially available data, and then only block on a call if still necessary.

(of course, similar provisions apply when using other primitives such as , or those in the

module)

• The SSL handshake itself will be non-blocking: the method has to be retried

until it returns successfully. Here is a synopsis using to wait for the socket’s readiness:





The Python Library Reference, Release 3.13.2



µ See also

The module supports non-blocking SSL sockets and provides a higher level Streams API. It polls

for events using the module and handles , and

exceptions. It runs the SSL handshake asynchronously as well.





Added in version 3.5.

Ever since the SSL module was introduced in Python 2.6, the class has provided two related but distinct areas of functionality:

• SSL protocol handling

• Network IO

The network IO API is identical to that provided by , from which also inherits. This allows an SSL socket to be used as a drop-in replacement for a regular socket, making it very easy to add SSL support to an existing application.

Combining SSL protocol handling and network IO usually works well, but there are some cases where it doesn’t. An example is async IO frameworks that want to use a different IO multiplexing model than the “select/poll on a file

descriptor” (readiness based) model that is assumed by and by the internal OpenSSL socket IO routines. This is mostly relevant for platforms like Windows where this model is not efficient. For this purpose, a

reduced scope variant of called is provided.



A reduced-scope variant of representing an SSL protocol instance that does not contain any net-

work IO methods. This class is typically used by framework authors that want to implement asynchronous IO

for SSL through memory buffers.

This class implements an interface on top of a low-level SSL object as implemented by OpenSSL. This object

captures the state of an SSL connection but does not provide any network IO itself. IO needs to be performed

through separate “BIO” objects which are OpenSSL’s IO abstraction layer.

This class has no public constructor. An instance must be created using the method.

This method will create the instance and bind it to a pair of BIOs. The incoming BIO is used to

pass data from Python to the SSL protocol instance, while the outgoing BIO is used to pass data the other way

around.

The following methods are available:

•

•

•

•

•

•

•

•

•

•

•

•

•

The Python Library Reference, Release 3.13.2



•

•

•

•

•

•

•

•

When compared to , this object lacks the following features:

• Any form of network IO; and read and write only to the underlying buffers.

• There is no do_handshake_on_connect machinery. You must always manually call

to start the handshake.

• There is no handling of suppress_ragged_eofs. All end-of-file conditions that are in violation of the

protocol are reported via the exception.

• The method call does not return anything, unlike for an SSL socket where it returns the

underlying socket.

• The server_name_callback callback passed to will get

an instance instead of a instance as its first parameter.

Some notes related to the use of :

• All IO on an is non-blocking. This means that for example will raise an

if it needs more data than the incoming BIO has available.

Changed in version 3.7: instances must be created with . In earlier versions, it was

possible to create instances directly. This was never documented or officially supported.

An SSLObject communicates with the outside world using memory buffers. The class provides a mem-ory buffer that can be used for this purpose. It wraps an OpenSSL memory BIO (Basic IO) object:



A memory buffer that can be used to pass data between Python and an SSL protocol instance.



Return the number of bytes currently in the memory buffer.



A boolean indicating whether the memory BIO is current at the end-of-file position.

n=-1

Read up to n bytes from the memory buffer. If n is not specified or negative, all bytes are returned.

buf

Write the bytes from buf to the memory BIO. The buf argument must be an object supporting the buffer protocol.

The return value is the number of bytes written, which is always equal to the length of buf.



Write an EOF marker to the memory BIO. After this method has been called, it is illegal to call .

The attribute will become true after all data currently in the buffer has been read.



The Python Library Reference, Release 3.13.2





Added in version 3.6.



Session object used by .





Best defaults

For client use, if you don’t have any special requirements for your security policy, it is highly recommended that you

use the function to create your SSL context. It will load the system’s trusted CA certificates, enable certificate validation and hostname checking, and try to choose reasonably secure protocol and cipher settings.

For example, here is how you would use the class to create a trusted, secure connection to a SMTP server:





If a client certificate is needed for the connection, it can be added with .

By contrast, if you create the SSL context by calling the constructor yourself, it will not have certificate validation nor hostname checking enabled by default. If you do so, please read the paragraphs below to achieve a good security level.



Manual settings

Verifying certificates

When calling the constructor directly, is the default. Since it does not authenticate the other peer, it can be insecure, especially in client mode where most of the time you would like to ensure the authentic-

ity of the server you’re talking to. Therefore, when in client mode, it is highly recommended to use . However, it is in itself not sufficient; you also have to check that the server certificate, which can be obtained by calling

, matches the desired service. For many protocols and applications, the service can be

identified by the hostname. This common check is automatically performed when is enabled.

Changed in version 3.7:

.

In server mode, if you want to authenticate your clients using the SSL layer (rather than using a higher-level authen-

tication mechanism), you’ll also have to specify and similarly check the client certificate.



The Python Library Reference, Release 3.13.2



Protocol versions

SSL versions 2 and 3 are considered insecure and are therefore dangerous to use. If you want maximum compatibility

between clients and servers, it is recommended to use or as the protocol version. SSLv2 and SSLv3 are disabled by default.





The SSL context created above will only allow TLSv1.3 and later (if supported by your system) connections to a

server. implies certificate validation and hostname checks by default. You have to load certificates into the context.



Cipher selection

If you have advanced security requirements, fine-tuning of the ciphers enabled when negotiating a SSL session is

possible through the method. Starting from Python 3.2.3, the ssl module disables certain weak ciphers by default, but you may want to further restrict the cipher choice. Be sure to read OpenSSL’s

documentation about the cipher list format. If you want to check which ciphers are enabled by a given cipher list,

use or the command on your system.



Multi-processing

If using this module as part of a multi-processed application (using, for example the or

modules), be aware that OpenSSL’s internal random number generator does not properly handle forked processes. Applications must change the PRNG state of the parent process if they use any SSL feature

with . Any successful call of or is sufficient.





Added in version 3.7.

The TLS 1.3 protocol behaves slightly differently than previous version of TLS/SSL. Some new TLS 1.3 features are not yet available.

• TLS 1.3 uses a disjunct set of cipher suites. All AES-GCM and ChaCha20 cipher suites are enabled by

default. The method cannot enable or disable any TLS 1.3 ciphers yet, but

returns them.

• Session tickets are no longer sent as part of the initial handshake and are handled differently.

and are not compatible with TLS 1.3.

• Client-side certificates are also no longer verified during the initial handshake. A server can request a certificate

at any time. Clients process certificate requests while they send or receive application data from the server.

• TLS 1.3 features like early data, deferred TLS client cert request, signature algorithm configuration, and rekey-

ing are not supported yet.



µ See also

Class

Documentation of underlying class

SSL/TLS Strong Encryption: An Introduction

Intro from the Apache HTTP Server documentation

RFC 1422: Privacy Enhancement for Internet Electronic Mail: Part II: Certificate-Based Key

Management

Steve Kent

The Python Library Reference, Release 3.13.2



RFC 4086: Randomness Requirements for Security

Donald E., Jeffrey I. Schiller

RFC 5280: Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL)

Profile

D. Cooper

RFC 5246: The Transport Layer Security (TLS) Protocol Version 1.2

T. Dierks et. al.

RFC 6066: Transport Layer Security (TLS) Extensions

D. Eastlake

IANA TLS: Transport Layer Security (TLS) Parameters

IANA

RFC 7525: Recommendations for Secure Use of Transport Layer Security (TLS) and Datagram

Transport Layer Security (DTLS)

IETF

Mozilla’s Server Side TLS recommendations

Mozilla





This module provides access to the and functions available in most operating systems, available on Solaris and derivatives, available on Linux 2.5+ and available on most BSD. Note that on Windows, it only works for sockets; on other operating systems, it also works for other file types (in particular, on Unix, it works on pipes). It cannot be used on regular files to determine whether a file has grown since it was last read.



® Note

The module allows high-level and efficient I/O multiplexing, built upon the module prim-

itives. Users are encouraged to use the module instead, unless they want precise control over the

OS-level primitives used.



Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.

The module defines the following:



A deprecated alias of .

Changed in version 3.3: Following PEP 3151, this class was made an alias of .



(Only supported on Solaris and derivatives.) Returns a polling object; see section /dev/poll Polling

Objects below for the methods supported by devpoll objects.

objects are linked to the number of file descriptors allowed at the time of instantiation. If your

program reduces this value, will fail. If your program increases this value, may return

an incomplete list of active file descriptors.

The new file descriptor is non-inheritable.

Added in version 3.3.

Changed in version 3.4: The new file descriptor is now non-inheritable.

The Python Library Reference, Release 3.13.2



sizehint=-1, flags=0

(Only supported on Linux 2.5.44 and newer.) Return an edge polling object, which can be used as Edge or

Level Triggered interface for I/O events.

sizehint informs epoll about the expected number of events to be registered. It must be positive, or to use

the default. It is only used on older systems where is not available; otherwise it has no

effect (though its value is still checked).

flags is deprecated and completely ignored. However, when supplied, its value must be or

, otherwise is raised.

See the Edge and Level Trigger Polling (epoll) Objects section below for the methods supported by epolling

objects.

objects support the context management protocol: when used in a statement, the new file de-

scriptor is automatically closed at the end of the block.

The new file descriptor is non-inheritable.

Changed in version 3.3: Added the flags parameter.

Changed in version 3.4: Support for the statement was added. The new file descriptor is now non-

inheritable.

Deprecated since version 3.4: The flags parameter. is used by default now. Use

to make the file descriptor inheritable.



(Not supported by all operating systems.) Returns a polling object, which supports registering and unregister-

ing file descriptors, and then polling them for I/O events; see section Polling Objects below for the methods

supported by polling objects.



(Only supported on BSD.) Returns a kernel queue object; see section Kqueue Objects below for the methods

supported by kqueue objects.

The new file descriptor is non-inheritable.

Changed in version 3.4: The new file descriptor is now non-inheritable.

ident, filter=KQ_FILTER_READ, flags=KQ_EV_ADD, fflags=0, data=0, udata=0

(Only supported on BSD.) Returns a kernel event object; see section Kevent Objects below for the methods

supported by kevent objects.

rlist, wlist, xlist, timeout

This is a straightforward interface to the Unix system call. The first three arguments are iterables of

‘waitable objects’: either integers representing file descriptors or objects with a parameterless method named

returning such an integer:

• rlist: wait until ready for reading

• wlist: wait until ready for writing

• xlist: wait for an “exceptional condition” (see the manual page for what your system considers such a

condition)

Empty iterables are allowed, but acceptance of three empty iterables is platform-dependent. (It is known to

work on Unix but not on Windows.) The optional timeout argument specifies a time-out as a floating-point

number in seconds. When the timeout argument is omitted the function blocks until at least one file descriptor

is ready. A time-out value of zero specifies a poll and never blocks.

The return value is a triple of lists of objects that are ready: subsets of the first three arguments. When the

time-out is reached without a file descriptor becoming ready, three empty lists are returned.

Among the acceptable object types in the iterables are Python file objects (e.g. , or objects returned

by or ), socket objects returned by . You may also define a wrapper

The Python Library Reference, Release 3.13.2



class yourself, as long as it has an appropriate method (that really returns a file descriptor, not just

a random integer).



® Note

File objects on Windows are not acceptable, but sockets are. On Windows, the underlying function is provided by the WinSock library, and does not handle file descriptors that don’t originate from WinSock.



Changed in version 3.5: The function is now retried with a recomputed timeout when interrupted by a

signal, except if the signal handler raises an exception (see PEP 475 for the rationale), instead of raising

.



The minimum number of bytes which can be written without blocking to a pipe when the pipe has been

reported as ready for writing by , or another interface in this module. This doesn’t apply

to other kind of file-like objects such as sockets.

This value is guaranteed by POSIX to be at least 512.

Availability: Unix

Added in version 3.2.





Solaris and derivatives have . While is O(highest file descriptor) and is O(number of file descriptors), is O(active file descriptors).

behaviour is very close to the standard object.



Close the file descriptor of the polling object.

Added in version 3.4.



if the polling object is closed.

Added in version 3.4.



Return the file descriptor number of the polling object.

Added in version 3.4.

fd, eventmask

Register a file descriptor with the polling object. Future calls to the method will then check whether

the file descriptor has any pending I/O events. fd can be either an integer, or an object with a

method that returns an integer. File objects implement , so they can also be used as the argument.

eventmask is an optional bitmask describing the type of events you want to check for. The constants are the

same that with object. The default value is a combination of the constants , , and

.



Á Warning

Registering a file descriptor that’s already registered is not an error, but the result is undefined. The appro-priate action is to unregister or modify it first. This is an important difference compared with .



The Python Library Reference, Release 3.13.2



fd, eventmask

This method does an followed by a . It is (a bit) more efficient that doing the

same explicitly.

fd

Remove a file descriptor being tracked by a polling object. Just like the method, fd can be an

integer or an object with a method that returns an integer.

Attempting to remove a file descriptor that was never registered is safely ignored.

timeout

Polls the set of registered file descriptors, and returns a possibly empty list containing 2-tuples

for the descriptors that have events or errors to report. fd is the file descriptor, and event is a bitmask with

bits set for the reported events for that descriptor — for waiting input, to indicate that the

descriptor can be written to, and so forth. An empty list indicates that the call timed out and no file descriptors

had any events to report. If timeout is given, it specifies the length of time in milliseconds which the system

will wait for events before returning. If timeout is omitted, -1, or , the call will block until there is an

event for this poll object.

Changed in version 3.5: The function is now retried with a recomputed timeout when interrupted by a

signal, except if the signal handler raises an exception (see PEP 475 for the rationale), instead of raising

.





https://linux.die.net/man/4/epoll

eventmask



Constant Meaning

Available for read

Available for write

Urgent data for read

Error condition happened on the assoc. fd

Hang up happened on the assoc. fd

Set Edge Trigger behavior, the default is Level Trigger behavior Set one-shot behavior. After one event is pulled out, the fd is internally disabled Wake only one epoll object when the associated fd has an event. The default (if this

flag is not set) is to wake all epoll objects polling on a fd.

Stream socket peer closed connection or shut down writing half of connection. Equivalent to

Priority data band can be read.

Equivalent to

Priority data may be written.

Ignored.



Added in version 3.6: was added. It’s only supported by Linux Kernel 4.5 or later.



Close the control file descriptor of the epoll object.



if the epoll object is closed.



Return the file descriptor number of the control fd.

fd

Create an epoll object from a given file descriptor.

The Python Library Reference, Release 3.13.2



fd, eventmask

Register a fd descriptor with the epoll object.

fd, eventmask

Modify a registered file descriptor.

fd

Remove a registered file descriptor from the epoll object.

Changed in version 3.9: The method no longer ignores the error.

timeout=None, maxevents=-1

Wait for events. timeout in seconds (float)

Changed in version 3.5: The function is now retried with a recomputed timeout when interrupted by a

signal, except if the signal handler raises an exception (see PEP 475 for the rationale), instead of raising

.





The system call, supported on most Unix systems, provides better scalability for network servers that service many, many clients at the same time. scales better because the system call only requires listing the file descriptors of interest, while builds a bitmap, turns on bits for the fds of interest, and then afterward the whole bitmap has to be linearly scanned again. is O(highest file descriptor), while is O(number of file descriptors).

fd, eventmask

Register a file descriptor with the polling object. Future calls to the method will then check whether

the file descriptor has any pending I/O events. fd can be either an integer, or an object with a

method that returns an integer. File objects implement , so they can also be used as the argument.

eventmask is an optional bitmask describing the type of events you want to check for, and can be a combination

of the constants , , and , described in the table below. If not specified, the default

value used will check for all 3 types of events.



Constant Meaning

There is data to read

There is urgent data to read

Ready for output: writing will not block

Error condition of some sort

Hung up

Stream socket peer closed connection, or shut down writing half of connection Invalid request: descriptor not open



Registering a file descriptor that’s already registered is not an error, and has the same effect as registering the

descriptor exactly once.

fd, eventmask

Modifies an already registered fd. This has the same effect as . Attempting

to modify a file descriptor that was never registered causes an exception with errno to be

raised.

fd

Remove a file descriptor being tracked by a polling object. Just like the method, fd can be an

integer or an object with a method that returns an integer.

Attempting to remove a file descriptor that was never registered causes a exception to be raised.



The Python Library Reference, Release 3.13.2



timeout

Polls the set of registered file descriptors, and returns a possibly empty list containing 2-tuples

for the descriptors that have events or errors to report. fd is the file descriptor, and event is a bitmask with

bits set for the reported events for that descriptor — for waiting input, to indicate that the

descriptor can be written to, and so forth. An empty list indicates that the call timed out and no file descriptors

had any events to report. If timeout is given, it specifies the length of time in milliseconds which the system

will wait for events before returning. If timeout is omitted, negative, or , the call will block until there is

an event for this poll object.

Changed in version 3.5: The function is now retried with a recomputed timeout when interrupted by a

signal, except if the signal handler raises an exception (see PEP 475 for the rationale), instead of raising

.





Close the control file descriptor of the kqueue object.



if the kqueue object is closed.



Return the file descriptor number of the control fd.

fd

Create a kqueue object from a given file descriptor.

changelist, max_events, timeout → eventlist

Low level interface to kevent

• changelist must be an iterable of kevent objects or

• max_events must be 0 or a positive integer

• timeout in seconds (floats possible); the default is , to wait forever

Changed in version 3.5: The function is now retried with a recomputed timeout when interrupted by a

signal, except if the signal handler raises an exception (see PEP 475 for the rationale), instead of raising

.





https://man.freebsd.org/cgi/man.cgi?query=kqueue&sektion=2



Value used to identify the event. The interpretation depends on the filter but it’s usually the file descriptor.

In the constructor ident can either be an int or an object with a method. kevent stores the integer

internally.



Name of the kernel filter.



Constant Meaning

Takes a descriptor and returns whenever there is data available to read Takes a descriptor and returns whenever there is data available to write AIO requests

Returns when one or more of the requested events watched in fflag occurs Watch for events on a process id

Watch for events on a network device [not available on macOS] Returns whenever the watched signal is delivered to the process Establishes an arbitrary timer

The Python Library Reference, Release 3.13.2





Filter action.



Constant Meaning

Adds or modifies an event

Removes an event from the queue

Permitscontrol() to returns the event

Disablesevent

Removes event after first occurrence

Reset the state after an event is retrieved

internal event

internal event

Filter specific EOF condition

See return values





Filter specific flags.

and filter flags:



Constant Meaning

low water mark of a socket buffer



filter flags:



Constant Meaning

unlink() was called

a write occurred

the file was extended

an attribute was changed

the link count has changed

the file was renamed

access to the file was revoked



filter flags:



Constant Meaning

the process has exited

the process has called fork()

the process has executed a new process

internal filter flag

internal filter flag

follow a process across fork()

returned on the child process for NOTE_TRACK

unable to attach to a child



filter flags (not available on macOS):



Constant Meaning

link is up

link is down

link state is invalid

The Python Library Reference, Release 3.13.2





Filter specific data.



User defined value.





Added in version 3.4.

Source code: Lib/selectors.py





This module allows high-level and efficient I/O multiplexing, built upon the module primitives. Users are encouraged to use this module instead, unless they want precise control over the OS-level primitives used.

It defines a abstract base class, along with several concrete implementations (,

…), that can be used to wait for I/O readiness notification on multiple file objects. In the following,

“file object” refers to any object with a method, or a raw file descriptor. See file object.

is an alias to the most efficient implementation available on the current platform: this should be the default choice for most users.



® Note

The type of file objects supported depends on the platform: on Windows, sockets are supported, but not pipes,

whereas on Unix, both are supported (some other types may be supported as well, such as fifos or special file

devices).



µ See also



Low-level I/O multiplexing module.



Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.





Classes hierarchy:





In the following, events is a bitwise mask indicating which I/O events should be waited for on a given file object. It can be a combination of the modules constants below:



The Python Library Reference, Release 3.13.2



Constant Meaning

Available for read





Available for write





A is a used to associate a file object to its underlying file descriptor, selected

event mask and attached data. It is returned by several methods.



File object registered.



Underlying file descriptor.



Events that must be waited for on this file object.



Optional opaque data associated to this file object: for example, this could be used to store a per-client session ID.



A is used to wait for I/O event readiness on multiple file objects. It supports file stream regis-

tration, unregistration, and a method to wait for I/O events on those streams, with an optional timeout. It’s an

abstract base class, so cannot be instantiated. Use instead, or one of ,

etc. if you want to specifically use an implementation, and your platform supports it.

and its concrete implementations support the context manager protocol.

fileobj, events, data=None

Register a file object for selection, monitoring it for I/O events.

fileobj is the file object to monitor. It may either be an integer file descriptor or an object with a method. events is a bitwise mask of events to monitor. data is an opaque object.

This returns a new instance, or raises a in case of invalid event mask or file

descriptor, or if the file object is already registered.

fileobj

Unregister a file object from selection, removing it from monitoring. A file object shall be unregistered prior to being closed.

fileobj must be a file object previously registered.

This returns the associated instance, or raises a if fileobj is not registered. It

will raise if fileobj is invalid (e.g. it has no method or its method has an invalid return value).

fileobj, events, data=None

Change a registered file object’s monitored events or attached data.

This is equivalent to followed by , except that it can be implemented more efficiently.

This returns a new instance, or raises a in case of invalid event mask or file

descriptor, or if the file object is not registered.

The Python Library Reference, Release 3.13.2



timeout=None

Wait until some registered file objects become ready, or the timeout expires.

If , this specifies the maximum wait time, in seconds. If , the call won’t block, and will report the currently ready file objects. If timeout is , the call will block until a monitored file object becomes ready.

This returns a list of tuples, one for each ready file object.

key is the instance corresponding to a ready file object. events is a bitmask of events ready on this file object.



® Note

This method can return before any file object becomes ready or the timeout has elapsed if the current process receives a signal: in this case, an empty list will be returned.



Changed in version 3.5: The selector is now retried with a recomputed timeout when interrupted by a

signal if the signal handler did not raise an exception (see PEP 475 for the rationale), instead of returning an empty list of events before the timeout.



Close the selector.

This must be called to make sure that any underlying resource is freed. The selector shall not be used once it has been closed.

fileobj

Return the key associated with a registered file object.

This returns the instance associated to this file object, or raises if the file object is not registered.



Return a mapping of file objects to selector keys.

This returns a instance mapping registered file objects to their associated in-stance.



The default selector class, using the most efficient implementation available on the current platform. This

should be the default choice for most users.



-based selector.



-based selector.



-based selector.



This returns the file descriptor used by the underlying object.



-based selector.



This returns the file descriptor used by the underlying object.

Added in version 3.5.

The Python Library Reference, Release 3.13.2





-based selector.



This returns the file descriptor used by the underlying object.





Here is a simple echo server implementation:





Source code: Lib/signal.py



This module provides mechanisms to use signal handlers in Python.





The function allows defining custom handlers to be executed when a signal is received. A small

number of default handlers are installed: is ignored (so write errors on pipes and sockets can be reported as

ordinary Python exceptions) and is translated into a exception if the parent process has not changed it.

The Python Library Reference, Release 3.13.2



A handler for a particular signal, once set, remains installed until it is explicitly reset (Python emulates the BSD style

interface regardless of the underlying implementation), with the exception of the handler for , which follows the underlying implementation.

On WebAssembly platforms, signals are emulated and therefore behave differently. Several functions and signals are not available on these platforms.



Execution of Python signal handlers

A Python signal handler does not get executed inside the low-level (C) signal handler. Instead, the low-level signal

handler sets a flag which tells the virtual machine to execute the corresponding Python signal handler at a later

point(for example at the next bytecode instruction). This has consequences:

• It makes little sense to catch synchronous errors like or that are caused by an invalid op-

eration in C code. Python will return from the signal handler to the C code, which is likely to raise the same

signal again, causing Python to apparently hang. From Python 3.3 onwards, you can use the

module to report on synchronous errors.

• A long-running calculation implemented purely in C (such as regular expression matching on a large body of

text) may run uninterrupted for an arbitrary amount of time, regardless of any signals received. The Python

signal handlers will be called when the calculation finishes.

• If the handler raises an exception, it will be raised “out of thin air” in the main thread. See the note below for

a discussion.



Signals and threads

Python signal handlers are always executed in the main Python thread of the main interpreter, even if the signal was received in another thread. This means that signals can’t be used as a means of inter-thread communication. You can

use the synchronization primitives from the module instead.

Besides, only the main thread of the main interpreter is allowed to set a new signal handler.





Changed in version 3.5: signal (SIG*), handler (, ) and sigmask (, ,

) related constants listed below were turned into (, and respec-

tively). , , and functions return human-readable

as objects.

The signal module defines three enums:



collection of SIG* constants and the CTRL_* constants.

Added in version 3.5.



collection the constants and .

Added in version 3.5.



collection the constants , and .

Availability: Unix.

See the man page and for further information.

Added in version 3.5.

The variables defined in the module are:



The Python Library Reference, Release 3.13.2





This is one of two standard signal handling options; it will simply perform the default function for the signal.

For example, on most systems the default action for is to dump core and exit, while the default action

for is to simply ignore it.



This is another standard signal handler, which will simply ignore the given signal.



Abort signal from .



Timer signal from .

Availability: Unix.



Interrupt from keyboard (CTRL + BREAK).

Availability: Windows.



Bus error (bad memory access).

Availability: Unix.



Child process stopped or terminated.

Availability: Unix.



Alias to .

Availability: not macOS.



Continue the process if it is currently stopped

Availability: Unix.



Floating-point exception. For example, division by zero.



µ See also

is raised when the second argument of a division or modulo operation is zero.





Hangup detected on controlling terminal or death of controlling process.

Availability: Unix.



Illegal instruction.



Interrupt from keyboard (CTRL + C).

Default action is to raise .



The Python Library Reference, Release 3.13.2





Kill signal.

It cannot be caught, blocked, or ignored.

Availability: Unix.



Broken pipe: write to pipe with no readers.

Default action is to ignore the signal.

Availability: Unix.



Segmentation fault: invalid memory reference.



Stack fault on coprocessor. The Linux kernel does not raise this signal: it can only be raised in user space.

Availability: Linux.

On architectures where the signal is available. See the man page for further information.

Added in version 3.11.



Termination signal.



User-defined signal 1.

Availability: Unix.



User-defined signal 2.

Availability: Unix.



Window resize signal.

Availability: Unix.



All the signal numbers are defined symbolically. For example, the hangup signal is defined as ;

the variable names are identical to the names used in C programs, as found in . The Unix man

page for ‘’ lists the existing signals (on some systems this is , on others the list is in

). Note that not all systems define the same set of signal names; only those names defined by the

system are defined by this module.



The signal corresponding to the keystroke event. This signal can only be used with .

Availability: Windows.

Added in version 3.2.



The signal corresponding to the keystroke event. This signal can only be used with .

Availability: Windows.

Added in version 3.2.

The Python Library Reference, Release 3.13.2





One more than the number of the highest signal number. Use to get valid signal numbers.



Decrements interval timer in real time, and delivers upon expiration.



Decrements interval timer only when the process is executing, and delivers SIGVTALRM upon expiration.



Decrements interval timer both when the process executes and when the system is executing on behalf of

the process. Coupled with ITIMER_VIRTUAL, this timer is usually used to profile the time spent by the

application in user and kernel space. SIGPROF is delivered upon expiration.



A possible value for the how parameter to indicating that signals are to be blocked.

Added in version 3.3.



A possible value for the how parameter to indicating that signals are to be unblocked.

Added in version 3.3.



A possible value for the how parameter to indicating that the signal mask is to be

replaced.

Added in version 3.3.

The module defines one exception:



Raised to signal an error from the underlying or implementation. Expect this

error if an invalid interval timer or a negative time is passed to . This error is a subtype of

.

Added in version 3.3: This error used to be a subtype of , which is now an alias of .

The module defines the following functions:

time

If time is non-zero, this function requests that a signal be sent to the process in time seconds. Any

previously scheduled alarm is canceled (only one alarm can be scheduled at any time). The returned value is

then the number of seconds before any previously set alarm was to have been delivered. If time is zero, no

alarm is scheduled, and any scheduled alarm is canceled. If the return value is zero, no alarm is currently

scheduled.

Availability: Unix.

See the man page for further information.

signalnum

Return the current signal handler for the signal signalnum. The returned value may be a callable Python object,

or one of the special values , or . Here, means

that the signal was previously ignored, means that the default way of handling the signal

was previously in use, and means that the previous signal handler was not installed from Python.

signalnum

Returns the description of signal signalnum, such as “Interrupt” for . Returns if signalnum has

no description. Raises if signalnum is invalid.

Added in version 3.8.

The Python Library Reference, Release 3.13.2





Return the set of valid signal numbers on this platform. This can be less than if some

signals are reserved by the system for internal use.

Added in version 3.8.



Cause the process to sleep until a signal is received; the appropriate handler will then be called. Returns

nothing.

Availability: Unix.

See the man page for further information.

See also , , and .

signum

Sends a signal to the calling process. Returns nothing.

Added in version 3.8.

pidfd, sig, siginfo=None, flags=0

Send signal sig to the process referred to by file descriptor pidfd. Python does not currently support the siginfo

parameter; it must be . The flags argument is provided for future extensions; no flag values are currently

defined.

See the man page for more information.

Availability: Linux >= 5.1, Android >= API level 31

Added in version 3.9.

thread_id, signalnum

Send the signal signalnum to the thread thread_id, another thread in the same process as the caller. The target

thread can be executing any code (Python or not). However, if the target thread is executing the Python

interpreter, the Python signal handlers will be executed by the main thread of the main interpreter. Therefore,

the only point of sending a signal to a particular Python thread would be to force a running system call to fail

with .

Use or the attribute of objects to get a suitable

value for thread_id.

If signalnum is 0, then no signal is sent, but error checking is still performed; this can be used to check if the

target thread is still running.

Raises an auditing event with arguments , .

Availability: Unix.

See the man page for further information.

See also .

Added in version 3.3.

how, mask

Fetch and/or change the signal mask of the calling thread. The signal mask is the set of signals whose delivery

is currently blocked for the caller. Return the old signal mask as a set of signals.

The behavior of the call is dependent on the value of how, as follows.

• : The set of blocked signals is the union of the current set and the mask argument.

• : The signals in mask are removed from the current set of blocked signals. It is permissible

to attempt to unblock a signal which is not blocked.

• : The set of blocked signals is set to the mask argument.

The Python Library Reference, Release 3.13.2



mask is a set of signal numbers (e.g. {, }). Use for

a full mask including all signals.

For example, reads the signal mask of the calling

thread.

and cannot be blocked.

Availability: Unix.

See the man page and for further information.

See also , and .

Added in version 3.3.

which, seconds, interval=0.0

Sets given interval timer (one of , or

) specified by which to fire after seconds (float is accepted, different from ) and after

that every interval seconds (if interval is non-zero). The interval timer specified by which can be cleared by

setting seconds to zero.

When an interval timer fires, a signal is sent to the process. The signal sent is dependent on the timer being

used; will deliver , sends , and

will deliver .

The old values are returned as a tuple: (delay, interval).

Attempting to pass an invalid interval timer will cause an .

Availability: Unix.

which

Returns current value of a given interval timer specified by which.

Availability: Unix.

fd, *, warn_on_full_buffer=True

Set the wakeup file descriptor to fd. When a signal is received, the signal number is written as a single byte into

the fd. This can be used by a library to wakeup a poll or select call, allowing the signal to be fully processed.

The old wakeup fd is returned (or -1 if file descriptor wakeup was not enabled). If fd is -1, file descriptor

wakeup is disabled. If not -1, fd must be non-blocking. It is up to the library to remove any bytes from fd

before calling poll or select again.

When threads are enabled, this function can only be called from the main thread of the main interpreter;

attempting to call it from other threads will cause a exception to be raised.

There are two common ways to use this function. In both approaches, you use the fd to wake up when a signal

arrives, but then they differ in how they determine which signal or signals have arrived.

In the first approach, we read the data out of the fd’s buffer, and the byte values give you the signal numbers.

This is simple, but in rare cases it can run into a problem: generally the fd will have a limited amount of buffer

space, and if too many signals arrive too quickly, then the buffer may become full, and some signals may be

lost. If you use this approach, then you should set , which will at least cause

a warning to be printed to stderr when signals are lost.

In the second approach, we use the wakeup fd only for wakeups, and ignore the actual byte values. In this case,

all we care about is whether the fd’s buffer is empty or non-empty; a full buffer doesn’t indicate a problem at

all. If you use this approach, then you should set , so that your users are not

confused by spurious warning messages.

Changed in version 3.5: On Windows, the function now also supports socket handles.

Changed in version 3.7: Added parameter.



The Python Library Reference, Release 3.13.2



signalnum, flag

Change system call restart behaviour: if flag is , system calls will be restarted when interrupted by signal

signalnum, otherwise system calls will be interrupted. Returns nothing.

Availability: Unix.

See the man page for further information.

Note that installing a signal handler with will reset the restart behaviour to interruptible by implicitly

calling with a true flag value for the given signal.

signalnum, handler

Set the handler for signal signalnum to the function handler. handler can be a callable Python object taking

two arguments (see below), or one of the special values or . The pre-

vious signal handler will be returned (see the description of above). (See the Unix man page

for further information.)

When threads are enabled, this function can only be called from the main thread of the main interpreter;

attempting to call it from other threads will cause a exception to be raised.

The handler is called with two arguments: the signal number and the current stack frame ( or a frame ob-

ject; for a description of frame objects, see the description in the type hierarchy or see the attribute descriptions

in the module).

On Windows, can only be called with , , , , , ,

or . A will be raised in any other case. Note that not all systems define the same set

of signal names; an will be raised if a signal name is not defined as module level

constant.



Examine the set of signals that are pending for delivery to the calling thread (i.e., the signals which have been

raised while blocked). Return the set of the pending signals.

Availability: Unix.

See the man page for further information.

See also , and .

Added in version 3.3.

sigset

Suspend execution of the calling thread until the delivery of one of the signals specified in the signal set sigset.

The function accepts the signal (removes it from the pending list of signals), and returns the signal number.

Availability: Unix.

See the man page for further information.

See also , , , and .

Added in version 3.3.

sigset

Suspend execution of the calling thread until the delivery of one of the signals specified in the signal set sigset.

The function accepts the signal and removes it from the pending list of signals. If one of the signals in sigset is

already pending for the calling thread, the function will return immediately with information about that signal.

The signal handler is not called for the delivered signal. The function raises an if it is

interrupted by a signal that is not in sigset.

The return value is an object representing the data contained in the structure, namely: ,

, , , , , .

Availability: Unix.

See the man page for further information.

See also , and .

The Python Library Reference, Release 3.13.2



Added in version 3.3.

Changed in version 3.5: The function is now retried if interrupted by a signal not in sigset and the signal handler

does not raise an exception (see PEP 475 for the rationale).

sigset, timeout

Like , but takes an additional timeout argument specifying a timeout. If timeout is specified

as , a poll is performed. Returns if a timeout occurs.

Availability: Unix.

See the man page for further information.

See also , and .

Added in version 3.3.

Changed in version 3.5: The function is now retried with the recomputed timeout if interrupted by a signal not

in sigset and the signal handler does not raise an exception (see PEP 475 for the rationale).





Here is a minimal example program. It uses the function to limit the time spent waiting to open a file; this

is useful if the file is for a serial device that may not be turned on, which would normally cause the to hang indefinitely. The solution is to set a 5-second alarm before opening the file; if the operation takes too long, the alarm signal will be sent, and the handler raises an exception.





Piping output of your program to tools like will cause a signal to be sent to your process when the receiver of its standard output closes early. This results in an exception like . To handle this case, wrap your entry point to catch this exception as follows:





The Python Library Reference, Release 3.13.2





Do not set ’s disposition to in order to avoid . Doing that would cause your program to exit unexpectedly whenever any socket connection is interrupted while your program is still writing to it.





If a signal handler raises an exception, the exception will be propagated to the main thread and may be raised after

any bytecode instruction. Most notably, a may appear at any point during execution. Most

Python code, including the standard library, cannot be made robust against this, and so a (or any other exception resulting from a signal handler) may on rare occasions put the program in an unexpected state.

To illustrate this issue, consider the following code:





For many programs, especially those that merely want to exit on , this is not a problem, but applications that are complex or require high reliability should avoid raising exceptions from signal handlers. They

should also avoid catching as a means of gracefully shutting down. Instead, they should install

their own handler. Below is an example of an HTTP server that avoids :





The Python Library Reference, Release 3.13.2





Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.

Memory-mapped file objects behave like both and like file objects. You can use mmap objects in most

places where are expected; for example, you can use the module to search through a memory-mapped file. You can also change a single byte by doing , or change a subsequence by assigning to a slice: . You can also read and write data starting at the current file position, and through the file to different positions.

A memory-mapped file is created by the constructor, which is different on Unix and on Windows. In either case you must provide a file descriptor for a file opened for update. If you wish to map an existing Python file object,

use its method to obtain the correct value for the fileno parameter. Otherwise, you can open the file using

the function, which returns a file descriptor directly (the file still needs to be closed when done).



® Note

If you want to create a memory-mapping for a writable, buffered file, you should the file first. This is

necessary to ensure that local modifications to the buffers are actually available to the mapping.



For both the Unix and Windows versions of the constructor, access may be specified as an optional keyword parameter. access accepts one of four values: , , or to specify read-only, write-through or copy-on-write memory respectively, or to defer to prot. access can be used on both Unix and Windows. If access is not specified, Windows mmap returns a write-through mapping. The initial memory values for all three access types are taken from the specified file. Assignment to an memory map raises

a exception. Assignment to an memory map affects both memory and the underlying file. Assignment to an memory map affects memory but does not update the underlying file.

Changed in version 3.7: Added constant.

To map anonymous memory, -1 should be passed as the fileno along with the length.

fileno, length, tagname=None, access=ACCESS_DEFAULT , offset=0

(Windows version) Maps length bytes from the file specified by the file handle fileno, and creates a mmap

object. If length is larger than the current size of the file, the file is extended to contain length bytes. If length

is , the maximum length of the map is the current size of the file, except that if the file is empty Windows

raises an exception (you cannot create an empty mapping on Windows).

tagname, if specified and not , is a string giving a tag name for the mapping. Windows allows you to have

many different mappings against the same file. If you specify the name of an existing tag, that tag is opened, The Python Library Reference, Release 3.13.2



otherwise a new tag of this name is created. If this parameter is omitted or , the mapping is created

without a name. Avoiding the use of the tagname parameter will assist in keeping your code portable between

Unix and Windows.

offset may be specified as a non-negative integer offset. mmap references will be relative to the offset from the

beginning of the file. offset defaults to 0. offset must be a multiple of the .

Raises an auditing event with arguments , , , .

fileno, length, flags=MAP_SHARED, prot=PROT_WRITE | PROT_READ,

access=ACCESS_DEFAULT , offset=0, *, trackfd=True

(Unix version) Maps length bytes from the file specified by the file descriptor fileno, and returns a mmap

object. If length is , the maximum length of the map will be the current size of the file when is called.

flags specifies the nature of the mapping. creates a private copy-on-write mapping, so changes

to the contents of the mmap object will be private to this process, and creates a mapping that’s

shared with all other processes mapping the same areas of the file. The default value is . Some

systems have additional possible flags with the full list specified in MAP_* constants.

prot, if specified, gives the desired memory protection; the two most useful values are and

, to specify that the pages may be read or written. prot defaults to .

access may be specified in lieu of flags and prot as an optional keyword parameter. It is an error to specify

both flags, prot and access. See the description of access above for information on how to use this parameter.

offset may be specified as a non-negative integer offset. mmap references will be relative to the offset from the

beginning of the file. offset defaults to 0. offset must be a multiple of which is

equal to on Unix systems.

If trackfd is , the file descriptor specified by fileno will not be duplicated, and the resulting object

will not be associated with the map’s underlying file. This means that the and methods

will fail. This mode is useful to limit the number of open file descriptors.

To ensure validity of the created memory mapping the file specified by the descriptor fileno is internally auto-

matically synchronized with the physical backing store on macOS.

Changed in version 3.13: The trackfd parameter was added.

This example shows a simple way of using :





can also be used as a context manager in a statement:

The Python Library Reference, Release 3.13.2





Added in version 3.2: Context manager support.

The next example demonstrates how to create an anonymous map and exchange data between the parent and

child processes:





Raises an auditing event with arguments , , , .

Memory-mapped file objects support the following methods:



Closes the mmap. Subsequent calls to other methods of the object will result in a ValueError exception being raised. This will not close the open file.



if the file is closed.

Added in version 3.2.

sub , start, end

Returns the lowest index in the object where the subsequence sub is found, such that sub is contained in the range [start, end]. Optional arguments start and end are interpreted as in slice notation. Returns on failure.

Changed in version 3.5: Writable bytes-like object is now accepted.

offset , size

Flushes changes made to the in-memory copy of a file back to disk. Without use of this call there is no guarantee that changes are written back before the object is destroyed. If offset and size are specified, only changes to the given range of bytes will be flushed to disk; otherwise, the whole extent of the mapping is flushed. offset must be a multiple of the or .

is returned to indicate success. An exception is raised when the call failed.

Changed in version 3.8: Previously, a nonzero value was returned on success; zero was returned on error under Windows. A zero value was returned on success; an exception was raised on error under Unix.

option, start, length

Send advice option to the kernel about the memory region beginning at start and extending length bytes.

option must be one of the MADV_* constants available on the system. If start and length are omitted, the entire mapping is spanned. On some systems (including Linux), start must be a multiple of the .

Availability: Systems with the system call.

The Python Library Reference, Release 3.13.2



Added in version 3.8.

dest, src, count

Copy the count bytes starting at offset src to the destination index dest. If the mmap was created with

, then calls to move will raise a exception.

n

Return a containing up to n bytes starting from the current file position. If the argument is omitted, or negative, return all bytes from the current file position to the end of the mapping. The file position is updated to point after the bytes that were returned.

Changed in version 3.3: Argument can be omitted or .



Returns a byte at the current file position as an integer, and advances the file position by 1.



Returns a single line, starting at the current file position and up to the next newline. The file position is updated to point after the bytes that were returned.

newsize

Resizes the map and the underlying file, if any.

Resizing a map created with access of or , will raise a excep-

tion. Resizing a map created with with trackfd set to , will raise a exception.

On Windows: Resizing the map will raise an if there are other maps against the same named file. Resizing an anonymous map (ie against the pagefile) will silently create a new map with the original data copied over up to the length of the new size.

Changed in version 3.11: Correctly fails if attempting to resize when another map is held Allows resize against an anonymous map on Windows

sub , start, end

Returns the highest index in the object where the subsequence sub is found, such that sub is contained in the range [start, end]. Optional arguments start and end are interpreted as in slice notation. Returns on failure.

Changed in version 3.5: Writable bytes-like object is now accepted.

pos, whence

Set the file’s current position. whence argument is optional and defaults to or (absolute file positioning); other values are or (seek relative to the current position) and or (seek relative to the file’s end).

Changed in version 3.13: Return the new absolute position instead of .



Return whether the file supports seeking, and the return value is always .

Added in version 3.13.



Return the length of the file, which can be larger than the size of the memory-mapped area.



Returns the current position of the file pointer.

bytes

Write the bytes in bytes into memory at the current position of the file pointer and return the number

of bytes written (never less than , since if the write fails, a will be raised). The file position is updated to point after the bytes that were written. If the mmap was created with

, then writing to it will raise a exception.

Changed in version 3.5: Writable bytes-like object is now accepted.

The Python Library Reference, Release 3.13.2



Changed in version 3.6: The number of bytes written is now returned.

byte

Write the integer byte into memory at the current position of the file pointer; the file position is advanced

by . If the mmap was created with , then writing to it will raise a exception.





These options can be passed to . Not every option will be present on every system.

Availability: Systems with the madvise() system call.

Added in version 3.8.





The Python Library Reference, Release 3.13.2





These are the various flags that can be passed to . is only available at

FreeBSD and is only available at OpenBSD. Note that some options might not be present on

some systems.

Changed in version 3.10: Added constant.

Added in version 3.11: Added constant.

Added in version 3.12: Added and constants.

Added in version 3.13: Added , , , ,

, , , , ,

, and constants.





CHAPTER





This chapter describes modules which support handling data formats commonly used on the internet.





Source code: Lib/email/__init__.py



The package is a library for managing email messages. It is specifically not designed to do any sending of

email messages to SMTP (RFC 2821), NNTP, or other servers; those are functions of modules such as .

The package attempts to be as RFC-compliant as possible, supporting RFC 5322 and RFC 6532, as well as

such MIME-related RFCs as RFC 2045, RFC 2046, RFC 2047, RFC 2183, and RFC 2231.

The overall structure of the email package can be divided into three major components, plus a fourth component that controls the behavior of the other components.

The central component of the package is an “object model” that represents email messages. An application interacts

with the package primarily through the object model interface defined in the sub-module. The application can use this API to ask questions about an existing email, to construct a new email, or to add or remove email sub-components that themselves use the same object model interface. That is, following the nature of email messages and

their MIME subcomponents, the email object model is a tree structure of objects that all provide the API.

The other two major components of the package are the and the . The parser takes the serialized

version of an email message (a stream of bytes) and converts it into a tree of objects. The generator

takes an and turns it back into a serialized byte stream. (The parser and generator also handle streams of text characters, but this usage is discouraged as it is too easy to end up with messages that are not valid in one way or another.)

The control component is the module. Every , every , and every has

an associated object that controls its behavior. Usually an application only needs to specify the policy when

an is created, either by directly instantiating an to create a new email, or by parsing

an input stream using a . But the policy can be changed when the message is serialized using a . This allows, for example, a generic email message to be parsed from disk, but to serialize it using standard SMTP settings when sending it to an email server.

The email package does its best to hide the details of the various governing RFCs from the application. Conceptually the application should be able to treat the email message as a structured tree of unicode text and binary attachments, without having to worry about how these are represented when serialized. In practice, however, it is often necessary to be aware of at least some of the rules governing MIME messages and their structure, specifically the names and nature of the MIME “content types” and how they identify multipart documents. For the most part this knowledge should only be required for more complex applications, and even then it should only be the high level structure in question, and not the details of how those structures are represented. Since MIME content types are used widely in modern internet software (not just email), this will be a familiar concept to many programmers.

The following sections describe the functionality of the package. We start with the object model,

which is the primary interface an application will use, and follow that with the and components.

Then we cover the controls, which completes the treatment of the main components of the library.

The Python Library Reference, Release 3.13.2



The next three sections cover the exceptions the package may raise and the defects (non-compliance with the RFCs)

that the may detect. Then we cover the and the sub-components, which provide tools for doing more detailed manipulation of headers and payloads, respectively. Both of these components contain features relevant to consuming and producing non-trivial messages, but also document their extensibility APIs, which will be of interest to advanced applications.

Following those is a set of examples of using the fundamental parts of the APIs covered in the preceding sections.

The foregoing represent the modern (unicode friendly) API of the email package. The remaining sections, starting

with the class, cover the legacy API that deals much more directly with the details of how

email messages are represented. The API does not hide the details of the RFCs from the application, but for applications that need to operate at that level, they can be useful tools. This documentation is also relevant for

applications that are still using the API for backward compatibility reasons.

Changed in version 3.6: Docs reorganized and rewritten to promote the new / API.

Contents of the package documentation:





Source code: Lib/email/message.py



Added in version 3.6:

The central class in the package is the class, imported from the module. It

is the base class for the object model. provides the core functionality for setting and querying header fields, for accessing message bodies, and for creating or modifying structured messages.

An email message consists of headers and a payload (which is also referred to as the content). Headers are RFC

5322 or RFC 6532 style field names and values, where the field name and value are separated by a colon. The colon is not part of either the field name or the field value. The payload may be a simple text message, or a binary object, or a structured sequence of sub-messages each with their own set of headers and their own payload. The latter type of payload is indicated by the message having a MIME type such as or .

The conceptual model provided by an object is that of an ordered dictionary of headers coupled

with a payload that represents the RFC 5322 body of the message, which might be a list of sub- objects. In addition to the normal dictionary methods for accessing the header names and values, there are methods for accessing specialized information from the headers (for example the MIME content type), for operating on the payload, for generating a serialized version of the message, and for recursively walking over the object tree.

The dictionary-like interface is indexed by the header names, which must be ASCII values. The values of the dictionary are strings with some extra methods. Headers are stored and returned in case-preserving form, but field names are matched case-insensitively. The keys are ordered, but unlike a real dict, there can be duplicates. Additional methods are provided for working with headers that have duplicate keys.

The payload is either a string or bytes object, in the case of simple message objects, or a list of objects, for MIME container documents such as and message objects.

policy=default

If policy is specified use the rules it specifies to update and serialize the representation of the message. If

policy is not set, use the policy, which follows the rules of the email RFCs except for line endings

(instead of the RFC mandated , it uses the Python standard line endings). For more information see

the documentation.

unixfrom=False, maxheaderlen=None, policy=None

Return the entire message flattened as a string. When optional unixfrom is true, the envelope header is included in the returned string. unixfrom defaults to . For backward compatibility with the

base class maxheaderlen is accepted, but defaults to , which means that by default the

line length is controlled by the of the policy. The policy argument may be used to





The Python Library Reference, Release 3.13.2



override the default policy obtained from the message instance. This can be used to control some of the

formatting produced by the method, since the specified policy will be passed to the .

Flattening the message may trigger changes to the if defaults need to be filled in to complete the transformation to a string (for example, MIME boundaries may be generated or modified).

Note that this method is provided as a convenience and may not be the most useful way to serialize mes-

sages in your application, especially if you are dealing with multiple messages. See

for a more flexible API for serializing messages. Note also that this method is restricted to

producing messages serialized as “7 bit clean” when is , which is the default.

Changed in version 3.6: the default behavior when maxheaderlen is not specified was changed from defaulting to 0 to defaulting to the value of max_line_length from the policy.



Equivalent to . Allows to produce a string containing the serialized message in a readable format.

Changed in version 3.4: the method was changed to use , thus producing an RFC 6531-like

message representation, instead of being a direct alias for .

unixfrom=False, policy=None

Return the entire message flattened as a bytes object. When optional unixfrom is true, the envelope header is included in the returned string. unixfrom defaults to . The policy argument may be used to override the default policy obtained from the message instance. This can be used to control some of the

formatting produced by the method, since the specified policy will be passed to the .

Flattening the message may trigger changes to the if defaults need to be filled in to complete the transformation to a string (for example, MIME boundaries may be generated or modified).

Note that this method is provided as a convenience and may not be the most useful way to serialize mes-

sages in your application, especially if you are dealing with multiple messages. See

for a more flexible API for serializing messages.



Equivalent to . Allows to produce a bytes object containing the serialized message.



Return if the message’s payload is a list of sub- objects, otherwise return .

When returns , the payload should be a string object (which might be a CTE

encoded binary payload). Note that returning does not necessarily mean that “msg.get_content_maintype() == ‘multipart’” will return the . For example, will

return when the is of type .

unixfrom

Set the message’s envelope header to unixfrom, which should be a string. (See for a brief description of this header.)



Return the message’s envelope header. Defaults to if the envelope header was never set.

The following methods implement the mapping-like interface for accessing the message’s headers. Note that

there are some semantic differences between these methods and a normal mapping (i.e. dictionary) interface.

For example, in a dictionary there are no duplicate keys, but here there may be duplicate message headers.

Also, in dictionaries there is no guaranteed order to the keys returned by , but in an

object, headers are always returned in the order they appeared in the original message, or in which they were

added to the message later. Any header deleted and then re-added is always appended to the end of the header

list.

These semantic differences are intentional and are biased toward convenience in the most common use cases.

Note that in all cases, any envelope header present in the message is not included in the mapping interface.

The Python Library Reference, Release 3.13.2





Return the total number of headers, including duplicates.

name

Return if the message object has a field named name. Matching is done without regard to case and name does not include the trailing colon. Used for the operator. For example:





name

Return the value of the named header field. name does not include the colon field separator. If the header

is missing, is returned; a is never raised.

Note that if the named field appears more than once in the message’s headers, exactly which of those

field values will be returned is undefined. Use the method to get the values of all the extant headers named name.

Using the standard (non-) policies, the returned value is an instance of a subclass of

.

name, val

Add a header to the message with field name name and value val. The field is appended to the end of the message’s existing headers.

Note that this does not overwrite or delete any existing header with the same name. If you want to ensure that the new header is the only one present in the message with field name name, delete the field first, e.g.:





If the defines certain headers to be unique (as the standard policies do), this method may raise a

when an attempt is made to assign a value to such a header when one already exists. This behavior is intentional for consistency’s sake, but do not depend on it as we may choose to make such assignments do an automatic deletion of the existing header in the future.

name

Delete all occurrences of the field with name name from the message’s headers. No exception is raised if the named field isn’t present in the headers.



Return a list of all the message’s header field names.



Return a list of all the message’s field values.



Return a list of 2-tuples containing all the message’s field headers and values.

name, failobj=None

Return the value of the named header field. This is identical to except that optional failobj is returned if the named header is missing (failobj defaults to ).

Here are some additional useful header related methods:

name, failobj=None

Return a list of all the values for the field named name. If there are no such named headers in the message, failobj is returned (defaults to ).



The Python Library Reference, Release 3.13.2



_name, _value, **_params

Extended header setting. This method is similar to except that additional header pa-rameters can be provided as keyword arguments. _name is the header field to add and _value is the primary value for the header.

For each item in the keyword argument dictionary _params, the key is taken as the parameter name, with underscores converted to dashes (since dashes are illegal in Python identifiers). Normally, the parameter will be added as unless the value is , in which case only the key will be added.

If the value contains non-ASCII characters, the charset and language may be explicitly controlled by specifying the value as a three tuple in the format , where is a string naming the charset to be used to encode the value, can usually be set to or the

empty string (see RFC 2231 for other possibilities), and is the string value containing non-ASCII code points. If a three tuple is not passed and the value contains non-ASCII characters, it is automatically

encoded in RFC 2231 format using a of and a of .

Here is an example:





This will add a header that looks like





An example of the extended interface with non-ASCII characters:





_name, _value

Replace a header. Replace the first header found in the message that matches _name, retaining header

order and field name case of the original header. If no matching header is found, raise a .



Return the message’s content type, coerced to lower case of the form . If there is

no header in the message return the value returned by . If the header is invalid, return .

(According to RFC 2045, messages always have a default type, will always

return a value. RFC 2045 defines a message’s default type to be unless it appears inside a container, in which case it would be . If the

header has an invalid type specification, RFC 2045 mandates that the default type be .)



Return the message’s main content type. This is the part of the string returned by

.



Return the message’s sub-content type. This is the part of the string returned by

.



Return the default content type. Most messages have a default content type of , except for messages that are subparts of containers. Such subparts have a default content type of .

ctype

Set the default content type. ctype should either be or , although this is not enforced. The default content type is not stored in the header, so it only affects the return value of the methods when no header is present in the message.

The Python Library Reference, Release 3.13.2



param, value, header=’Content-Type’, requote=True, charset=None, language=”, replace=False

Set a parameter in the header. If the parameter already exists in the header, replace its value with value. When header is (the default) and the header does not yet exist in the message, add it, set its value to , and append the new parameter value. Optional header specifies an alternative header to .

If the value contains non-ASCII characters, the charset and language may be explicitly specified using

the optional charset and language parameters. Optional language specifies the RFC 2231 language, defaulting to the empty string. Both charset and language should be strings. The default is to use the charset and for the language.

If replace is (the default) the header is moved to the end of the list of headers. If replace is , the header will be updated in place.

Use of the requote parameter with objects is deprecated.

Note that existing parameter values of headers may be accessed through the attribute of the header value (for example, ).

Changed in version 3.4: keyword was added.

param, header=’content-type’, requote=True

Remove the given parameter completely from the header. The header will be re-written in place without the parameter or its value. Optional header specifies an alternative to .

Use of the requote parameter with objects is deprecated.

failobj=None

Return the value of the parameter of the header of the message. If the header does not have a parameter, this method falls back to looking for the parameter on the header. If neither is found, or the header is missing, then failobj is

returned. The returned string will always be unquoted as per .

failobj=None

Return the value of the parameter of the header of the message, or failobj if either the header is missing, or has no parameter. The returned string will always be unquoted

as per .

boundary

Set the parameter of the header to boundary. will al-

ways quote boundary if necessary. A is raised if the message object has no header.

Note that using this method is subtly different from deleting the old header and adding

a new one with the new boundary via , because preserves the order of the header in the list of headers.

failobj=None

Return the parameter of the header, coerced to lower case. If there is no header, or if that header has no parameter, failobj is returned.

failobj=None

Return a list containing the character set names in the message. If the message is a , then the list will contain one element for each subpart in the payload, otherwise, it will be a list of length 1.

Each item in the list will be a string which is the value of the parameter in the header for the represented subpart. If the subpart has no header, no parameter, or is not of the main MIME type, then that item in the returned list will be failobj.



Return if there is a header and its (case insensitive) value is , otherwise.

Changed in version 3.4.2: is_attachment is now a method instead of a property, for consistency with

.

The Python Library Reference, Release 3.13.2





Return the lowercased value (without parameters) of the message’s header if it has one, or . The possible values for this method are inline, attachment or if the message

follows RFC 2183.

Added in version 3.5.

The following methods relate to interrogating and manipulating the content (payload) of the message.



The method is an all-purpose generator which can be used to iterate over all the parts and

subparts of a message object tree, in depth-first traversal order. You will typically use as the iterator in a loop; each iteration returns the next subpart.

Here’s an example that prints the MIME type of every part of a multipart message structure:





iterates over the subparts of any part where returns , even though may return . We can see this in our example by making use of the debug helper function:





Here the parts are not , but they do contain subparts. returns and descends into the subparts.

preferencelist=(’related’, ’html’, ’plain’)

Return the MIME part that is the best candidate to be the “body” of the message.

preferencelist must be a sequence of strings from the set , , and , and indicates the order of preference for the content type of the part returned.

Start looking for candidate matches with the object on which the method is called.

The Python Library Reference, Release 3.13.2



If is not included in preferencelist, consider the root part (or subpart of the root part) of any related encountered as a candidate if the (sub-)part matches a preference.

When encountering a , check the parameter and if a part with a matching is found, consider only it when looking for candidate matches. Otherwise consider only the first (default root) part of the .

If a part has a header, only consider the part a candidate match if the value of the header is .

If none of the candidates matches any of the preferences in preferencelist, return .

Notes: (1) For most applications the only preferencelist combinations that really make sense are , , and the default . (2) Be-cause matching starts with the object on which is called, calling on a will return the object itself unless preferencelist has a non-default value. (3) Messages (or message parts) that do not specify a or whose header is invalid will be treated as if they are of type , which may occasionally cause to return unex-pected results.



Return an iterator over all of the immediate sub-parts of the message that are not candidate “body” parts. That is, skip the first occurrence of each of , , , or (unless they are explicitly marked as attachments via ), and return all remaining parts. When applied directly to a , return an iterator over the all the related parts except the root part (ie: the part pointed to by the parameter, or the first part if there is no parameter or the parameter doesn’t match the of any of the parts). When applied directly to a or a non-, return an empty iterator.



Return an iterator over all of the immediate sub-parts of the message, which will be empty for a non-

. (See also .)

*args, content_manager=None, **kw

Call the method of the content_manager, passing self as the message object, and pass-ing along any other arguments or keywords as additional arguments. If content_manager is not specified,

use the specified by the current .

*args, content_manager=None, **kw

Call the method of the content_manager, passing self as the message object, and pass-ing along any other arguments or keywords as additional arguments. If content_manager is not specified,

use the specified by the current .

boundary=None

Convert a non- message into a message, moving any existing headers and payload into a (new) first part of the . If boundary is specified, use it as the boundary string in the multipart, otherwise leave the boundary to be automatically created when it is needed (for example, when the message is serialized).

boundary=None

Convert a non- or a into a , moving any existing headers and payload into a (new) first part of the . If boundary is spec-ified, use it as the boundary string in the multipart, otherwise leave the boundary to be automatically created when it is needed (for example, when the message is serialized).

boundary=None

Convert a non-, a , or a into a , moving any existing headers and payload into a (new) first part of the . If boundary is specified, use it as the boundary string in the multipart, otherwise leave the boundary to be automatically created when it is needed (for example, when the message is serialized).

The Python Library Reference, Release 3.13.2



*args, content_manager=None, **kw

If the message is a , create a new message object, pass all of the arguments to its

method, and it to the . If the message is a non-,

call and then proceed as above. If the message is any other type of , raise

a . If content_manager is not specified, use the specified by the current

. If the added part has no header, add one with the value .

*args, content_manager=None, **kw

If the message is a , create a new message object, pass all of the arguments to

its method, and it to the . If the message is a non-

or , call and then proceed as above. If the message

is any other type of , raise a . If content_manager is not specified, use the

specified by the current .

*args, content_manager=None, **kw

If the message is a , create a new message object, pass all of the arguments

to its method, and it to the . If the message is a non-

, , or , call and then proceed as above. If content_manager is not specified, use the specified by the

current . If the added part has no header, add one with the value . This method can be used both for explicit attachments ( ) and attachments (), by passing appropriate options to the .



Remove the payload and all of the headers.



Remove the payload and all of the headers, leaving all other headers intact and in their original order.

objects have the following instance attributes:



The format of a MIME document allows for some text between the blank line following the headers, and the first multipart boundary string. Normally, this text is never visible in a MIME-aware mail reader because it falls outside the standard MIME armor. However, when viewing the raw text of the message, or when viewing the message in a non-MIME aware reader, this text can become visible.

The preamble attribute contains this leading extra-armor text for MIME documents. When the discovers some text after the headers but before the first boundary string, it assigns this text to the mes-

sage’s preamble attribute. When the is writing out the plain text representation of a MIME message, and it finds the message has a preamble attribute, it will write this text in the area between the

headers and the first boundary. See and for details.

Note that if the message object has no preamble, the preamble attribute will be .





The epilogue attribute acts the same way as the preamble attribute, except that it contains text that appears

between the last boundary and the end of the message. As with the , if there is no epilog text this attribute will be .



The defects attribute contains a list of all the problems found when parsing this message. See

for a detailed description of the possible parsing defects.

policy=default

This class represents a subpart of a MIME message. It is identical to , except that no

headers are added when is called, since sub-parts do not need their own

headers.

The Python Library Reference, Release 3.13.2





Source code: Lib/email/parser.py



Message object structures can be created in one of two ways: they can be created from whole cloth by creating an

object, adding headers using the dictionary interface, and adding payload(s) using and related methods, or they can be created by parsing a serialized representation of the email message.

The package provides a standard parser that understands most email document structures, including MIME documents. You can pass the parser a bytes, string or file object, and the parser will return to you the root

instance of the object structure. For simple, non-MIME messages the payload of this root ob-ject will likely be a string containing the text of the message. For MIME messages, the root object will return

from its method, and the subparts can be accessed via the payload manipulation methods, such

as , , and .

There are actually two parser interfaces available for use, the API and the incremental API.

The API is most useful if you have the entire text of the message in memory, or if the entire message lives

in a file on the file system. is more appropriate when you are reading the message from a stream

which might block waiting for more input (such as reading an email message from a socket). The can consume and parse the message incrementally, and only returns the root object when you close the parser.

Note that the parser can be extended in limited ways, and of course you can implement your own parser completely

from scratch. All of the logic that connects the package’s bundled parser and the class is

embodied in the class, so a custom parser can create message object trees any way it finds necessary by implementing custom versions of the appropriate methods.



FeedParser API

The , imported from the module, provides an API that is conducive to incremental parsing of email messages, such as would be necessary when reading the text of an email message from

a source that can block (such as a socket). The can of course be used to parse an email message

fully contained in a bytes-like object, string, or file, but the API may be more convenient for such use cases. The semantics and results of the two parser APIs are identical.

The ’s API is simple; you create an instance, feed it a bunch of bytes until there’s no more to feed

it, then close the parser to retrieve the root message object. The is extremely accurate when parsing standards-compliant messages, and it does a very good job of parsing non-compliant messages, providing

information about how a message was deemed broken. It will populate a message object’s attribute with a

list of any problems it found in a message. See the module for the list of defects that it can find.

Here is the API for the :

_factory=None, *, policy=policy.compat32

Create a instance. Optional _factory is a no-argument callable; if not specified use the

from the policy. Call _factory whenever a new message object is needed.

If policy is specified use the rules it specifies to update the representation of the message. If policy is not set,

use the policy, which maintains backward compatibility with the Python 3.2 version of the email

package and provides as the default factory. All other policies provide as the default

_factory. For more information on what else policy controls, see the documentation.

Note: The policy keyword should always be specified; The default will change to

in a future version of Python.

Added in version 3.2.

Changed in version 3.3: Added the policy keyword.

Changed in version 3.6: _factory defaults to the policy .

data

Feed the parser some more data. data should be a bytes-like object containing one or more lines. The lines can be partial and the parser will stitch such partial lines together properly. The lines can have any

The Python Library Reference, Release 3.13.2



of the three common line endings: carriage return, newline, or carriage return and newline (they can even be mixed).



Complete the parsing of all previously fed data and return the root message object. It is undefined what

happens if is called after this method has been called.

_factory=None, *, policy=policy.compat32

Works like except that the input to the method must be a string. This is of

limited utility, since the only way for such a message to be valid is for it to contain only ASCII text or, if

is , no binary attachments.

Changed in version 3.3: Added the policy keyword.



Parser API

The class, imported from the module, provides an API that can be used to parse

a message when the complete contents of the message are available in a bytes-like object or file. The

module also provides for parsing strings, and header-only parsers, and

, which can be used if you’re only interested in the headers of the message.

and can be much faster in these situations, since they do not attempt to parse the message body, instead setting the payload to the raw body.

_class=None, *, policy=policy.compat32

Create a instance. The _class and policy arguments have the same meaning and semantics as

the _factory and policy arguments of .

Note: The policy keyword should always be specified; The default will change to

in a future version of Python.

Changed in version 3.3: Removed the strict argument that was deprecated in 2.4. Added the policy keyword.

Changed in version 3.6: _class defaults to the policy .

fp, headersonly=False

Read all the data from the binary file-like object fp, parse the resulting bytes, and return the message

object. fp must support both the and the methods.

The bytes contained in fp must be formatted as a block of RFC 5322 (or, if is , RFC

6532) style headers and header continuation lines, optionally preceded by an envelope header. The header block is terminated either by the end of the data or by a blank line. Following the header block is the body of the message (which may contain MIME-encoded subparts, including subparts with a of ).

Optional headersonly is a flag specifying whether to stop parsing after reading the headers or not. The default is , meaning it parses the entire contents of the file.

bytes, headersonly=False

Similar to the method, except it takes a bytes-like object instead of a file-like object. Calling

this method on a bytes-like object is equivalent to wrapping bytes in a instance first and calling

.

Optional headersonly is as with the method.

Added in version 3.2.

_class=None, *, policy=policy.compat32

Exactly like , except that headersonly defaults to .

Added in version 3.3.

_class=None, *, policy=policy.compat32

This class is parallel to , but handles string input.

Changed in version 3.3: Removed the strict argument. Added the policy keyword.

The Python Library Reference, Release 3.13.2



Changed in version 3.6: _class defaults to the policy .

fp, headersonly=False

Read all the data from the text-mode file-like object fp, parse the resulting text, and return the root

message object. fp must support both the and the methods on file-like objects.

Other than the text mode requirement, this method operates like .

text, headersonly=False

Similar to the method, except it takes a string object instead of a file-like object. Calling this

method on a string is equivalent to wrapping text in a instance first and calling .

Optional headersonly is as with the method.

_class=None, *, policy=policy.compat32

Exactly like , except that headersonly defaults to .

Since creating a message object structure from a string or a file object is such a common task, four functions are

provided as a convenience. They are available in the top-level package namespace.

s, _class=None, *, policy=policy.compat32

Return a message object structure from a bytes-like object. This is equivalent to

. Optional _class and policy are interpreted as with the class constructor.

Added in version 3.2.

Changed in version 3.3: Removed the strict argument. Added the policy keyword.

fp, _class=None, *, policy=policy.compat32

Return a message object structure tree from an open binary file object. This is equivalent to

. _class and policy are interpreted as with the class constructor.

Added in version 3.2.

Changed in version 3.3: Removed the strict argument. Added the policy keyword.

s, _class=None, *, policy=policy.compat32

Return a message object structure from a string. This is equivalent to . _class and

policy are interpreted as with the class constructor.

Changed in version 3.3: Removed the strict argument. Added the policy keyword.

fp, _class=None, *, policy=policy.compat32

Return a message object structure tree from an open file object. This is equivalent to .

_class and policy are interpreted as with the class constructor.

Changed in version 3.3: Removed the strict argument. Added the policy keyword.

Changed in version 3.6: _class defaults to the policy .

Here’s an example of how you might use at an interactive Python prompt:





Additional notes

Here are some notes on the parsing semantics:

• Most non- type messages are parsed as a single message object with a string payload. These objects

will return for , and will yield an empty list.

• All type messages will be parsed as a container message object with a list of sub-message objects

for their payload. The outer container message will return for , and

will yield a list of subparts.

The Python Library Reference, Release 3.13.2



• Most messages with a content type of (such as and

) will also be parsed as container object containing a list payload of length 1. Their

method will return . The single element yielded by will be a sub-message object.

• Some non-standards-compliant messages may not be internally consistent about their -edness.

Such messages may have a header of type , but their method

may return . If such messages were parsed with the , they will have an instance of the

class in their defects attribute list. See for de-

tails.





Source code: Lib/email/generator.py



One of the most common tasks is to generate the flat (serialized) version of the email message represented by a mes-

sage object structure. You will need to do this if you want to send your message via , or print the message on the console. Taking a message object structure and producing a serialized representation is the job of the generator classes.

As with the module, you aren’t limited to the functionality of the bundled generator; you could write one from scratch yourself. However the bundled generator knows how to generate most email in a standards-compliant way, should handle MIME and non-MIME email messages just fine, and is designed so that the bytes-

oriented parsing and generation operations are inverses, assuming the same non-transforming is used for

both. That is, parsing the serialized byte stream via the class and then regenerating the serialized

byte stream using should produce output identical to the input. (On the other hand, using the

generator on an constructed by program may result in changes to the object as defaults are filled in.)

The class can be used to flatten a message into a text (as opposed to binary) serialized representation, but since Unicode cannot represent binary data directly, the message is of necessity transformed into something that contains only ASCII characters, using the standard email RFC Content Transfer Encoding techniques for encoding email messages for transport over channels that are not “8 bit clean”.

To accommodate reproducible processing of SMIME-signed messages disables header folding for mes-sage parts of type and all subparts.

outfp, mangle_from_=None, maxheaderlen=None, *,

policy=None

Return a object that will write any message provided to the method, or any

surrogateescape encoded text provided to the method, to the file-like object outfp. outfp must support

a method that accepts binary data.

If optional mangle_from_ is , put a character in front of any line in the body that starts with the exact

string , that is followed by a space at the beginning of a line. mangle_from_ defaults to the

value of the setting of the policy (which is for the policy and for all

others). mangle_from_ is intended for use when messages are stored in Unix mbox format (see and

WHY THE CONTENT-LENGTH FORMAT IS BAD).

If maxheaderlen is not , refold any header lines that are longer than maxheaderlen, or if , do not rewrap

any headers. If manheaderlen is (the default), wrap headers and other message lines according to the

policy settings.

If policy is specified, use that policy to control message generation. If policy is (the default), use the

policy associated with the or object passed to to control the message

generation. See for details on what policy controls.

Added in version 3.2.





The Python Library Reference, Release 3.13.2



Changed in version 3.3: Added the policy keyword.

Changed in version 3.6: The default behavior of the mangle_from_ and maxheaderlen parameters is to follow

the policy.

msg, unixfrom=False, linesep=None

Print the textual representation of the message object structure rooted at msg to the output file specified

when the instance was created.

If the option is (the default), copy any headers in the original parsed mes-sage that have not been modified to the output with any bytes with the high bit set reproduced as in the original, and preserve the non-ASCII of any body parts that have them. If is , convert the bytes with the high bit set as needed using an ASCII-compatible . That is, transform parts with non-ASCII () to an ASCII compati-ble , and encode RFC-invalid non-ASCII bytes in headers using the MIME character set, thus rendering them RFC-compliant.

If unixfrom is , print the envelope header delimiter used by the Unix mailbox format (see )

before the first of the RFC 5322 headers of the root message object. If the root object has no envelope header, craft a standard one. The default is . Note that for subparts, no envelope header is ever printed.

If linesep is not , use it as the separator character between all the lines of the flattened message. If linesep is (the default), use the value specified in the policy.

fp

Return an independent clone of this instance with the exact same option settings, and fp as the new outfp.

s

Encode s using the codec and the error handler, and pass it to the write

method of the outfp passed to the ’s constructor.

As a convenience, provides the methods and (a.k.a.

), which simplify the generation of a serialized binary representation of a message object. For more

detail, see .

Because strings cannot represent binary data, the class must convert any binary data in any message it flat-tens to an ASCII compatible format, by converting them to an ASCII compatible .

Using the terminology of the email RFCs, you can think of this as serializing to an I/O stream that is

not “8 bit clean”. In other words, most applications will want to be using , and not .

outfp, mangle_from_=None, maxheaderlen=None, *, policy=None

Return a object that will write any message provided to the method, or any text

provided to the method, to the file-like object outfp. outfp must support a method that accepts

string data.

If optional mangle_from_ is , put a character in front of any line in the body that starts with the exact

string , that is followed by a space at the beginning of a line. mangle_from_ defaults to the

value of the setting of the policy (which is for the policy and for all

others). mangle_from_ is intended for use when messages are stored in Unix mbox format (see and

WHY THE CONTENT-LENGTH FORMAT IS BAD).

If maxheaderlen is not , refold any header lines that are longer than maxheaderlen, or if , do not rewrap

any headers. If manheaderlen is (the default), wrap headers and other message lines according to the

policy settings.

If policy is specified, use that policy to control message generation. If policy is (the default), use the

policy associated with the or object passed to to control the message

generation. See for details on what policy controls.

Changed in version 3.3: Added the policy keyword.

The Python Library Reference, Release 3.13.2



Changed in version 3.6: The default behavior of the mangle_from_ and maxheaderlen parameters is to follow

the policy.

msg, unixfrom=False, linesep=None

Print the textual representation of the message object structure rooted at msg to the output file specified

when the instance was created.

If the option is , generate the message as if the option were set to . (This is required because strings cannot represent non-ASCII bytes.) Convert any bytes with the high bit set as needed using an ASCII-compatible . That is, transform parts with non-ASCII () to an ASCII compatible , and encode RFC-invalid non-ASCII bytes in headers us-ing the MIME character set, thus rendering them RFC-compliant.

If unixfrom is , print the envelope header delimiter used by the Unix mailbox format (see )

before the first of the RFC 5322 headers of the root message object. If the root object has no envelope header, craft a standard one. The default is . Note that for subparts, no envelope header is ever printed.

If linesep is not , use it as the separator character between all the lines of the flattened message. If linesep is (the default), use the value specified in the policy.

Changed in version 3.2: Added support for re-encoding message bodies, and the linesep argument.

fp

Return an independent clone of this instance with the exact same options, and fp as the new outfp.

s

Write s to the write method of the outfp passed to the ’s constructor. This provides just

enough file-like API for instances to be used in the function.

As a convenience, provides the methods and (a.k.a. ),

which simplify the generation of a formatted string representation of a message object. For more detail, see

.

The module also provides a derived class, , which is like the base class, except that non- parts are not serialized, but are instead represented in the output stream by a string derived from a template filled in with information about the part.

outfp, mangle_from_=None, maxheaderlen=None, fmt=None,

*, policy=None

Act like , except that for any subpart of the message passed to , if the

subpart is of main type , print the decoded payload of the subpart, and if the main type is not ,

instead of printing it fill in the string fmt using information from the part and print the resulting filled-in string.

To fill in fmt, execute , where is a dictionary composed of the following keys

and values:

• – Full MIME type of the non- part

• – Main MIME type of the non- part

• – Sub-MIME type of the non- part

• – Filename of the non- part

• – Description associated with the non- part

• – Content transfer encoding of the non- part

If fmt is , use the following default fmt:

“[Non-text (%(type)s) part of message omitted, filename %(filename)s]”

Optional _mangle_from_ and maxheaderlen are as with the base class.

The Python Library Reference, Release 3.13.2





Added in version 3.3.

Source code: Lib/email/policy.py



The package’s prime focus is the handling of email messages as described by the various email and MIME RFCs. However, the general format of email messages (a block of header fields each consisting of a name followed by a colon followed by a value, the whole block followed by a blank line and an arbitrary ‘body’), is a format that has found utility outside of the realm of email. Some of these uses conform fairly closely to the main email RFCs, some do not. Even when working with email, there are times when it is desirable to break strict compliance with the RFCs, such as generating emails that interoperate with email servers that do not themselves follow the standards, or that implement extensions you want to use in ways that violate the standards.

Policy objects give the email package the flexibility to handle all these disparate use cases.

A object encapsulates a set of attributes and methods that control the behavior of various components of

the email package during use. instances can be passed to various classes and methods in the email package to alter the default behavior. The settable values and their defaults are described below.

There is a default policy used by all classes in the email package. For all of the classes and the related conve-

nience functions, and for the class, this is the policy, via its corresponding pre-defined instance

. This policy provides for complete backward compatibility (in some cases, including bug compatibility) with the pre-Python3.3 version of the email package.

This default value for the policy keyword to is the policy, via its pre-defined instance

.

When a or object is created, it acquires a policy. If the message is created by a , a policy passed to the parser will be the policy used by the message it creates. If the message is created by the program,

then the policy can be specified when it is created. When a message is passed to a , the generator uses the policy from the message by default, but you can also pass a specific policy to the generator that will override the one stored on the message object.

The default value for the policy keyword for the classes and the parser convenience functions will be changing in a future version of Python. Therefore you should always specify explicitly which policy you want

to use when calling any of the classes and functions described in the module.

The first part of this documentation covers the features of , an abstract base class that defines the features that

are common to all policy objects, including . This includes certain hook methods that are called internally by the email package, which a custom policy could override to obtain different behavior. The second part describes

the concrete classes and , which implement the hooks that provide the standard behavior and the backward compatible behavior and features, respectively.

instances are immutable, but they can be cloned, accepting the same keyword arguments as the class con-

structor and returning a new instance that is a copy of the original but with the specified attributes values changed.

As an example, the following code could be used to read an email message from a file on disk and pass it to the system program on a Unix system:





The Python Library Reference, Release 3.13.2





Here we are telling to use the RFC correct line separator characters when creating the binary string to feed into , where the default policy would use line separators.

Some email package methods accept a policy keyword argument, allowing the policy to be overridden for that method.

For example, the following code uses the method of the msg object from the previous example and writes the message to a file using the native line separators for the platform on which it is running:





Policy objects can also be combined using the addition operator, producing a policy object whose settings are a combination of the non-default values of the summed objects:





This operation is not commutative; that is, the order in which the objects are added matters. To illustrate:





**kw

This is the abstract base class for all policy classes. It provides default implementations for a couple of trivial

methods, as well as the implementation of the immutability property, the method, and the constructor

semantics.

The constructor of a policy class can be passed various keyword arguments. The arguments that may be spec-

ified are any non-method properties on this class, plus any additional non-method properties on the concrete

class. A value specified in the constructor will override the default value for the corresponding attribute.

This class defines the following properties, and thus values for the following may be passed in the constructor

of any policy class:



The maximum length of any line in the serialized output, not counting the end of line character(s). Default

is 78, per RFC 5322. A value of or indicates that no line wrapping should be done at all.



The string to be used to terminate lines in serialized output. The default is because that’s the internal end-of-line discipline used by Python, though is required by the RFCs.



Controls the type of Content Transfer Encodings that may be or are required to be used. The possible values are:



The Python Library Reference, Release 3.13.2





encoded using either quoted-printable or base64 encoding.



and so will be encoded (see and below for exceptions), but body parts may use the CTE.



A value of only works with , not , because strings cannot contain binary data. If a is operating under a policy that specifies , it will act as if is .



If , any defects encountered will be raised as errors. If (the default), defects will be passed

to the method.



If , lines starting with “From “ in the body are escaped by putting a in front of them. This parameter

is used when the message is being serialized by a generator. Default: .

Added in version 3.5.



A factory function for constructing a new empty message object. Used by the parser when building

messages. Defaults to , in which case is used.

Added in version 3.6.



If (the default), the generator will raise instead of writing a header that is improperly folded or delimited, such that it would be parsed as multiple headers or joined with adjacent data. Such headers can be generated by custom header classes or bugs in the module.

As it’s a security feature, this defaults to even in the policy. For backwards compatible, but unsafe, behavior, it must be set to explicitly.

Added in version 3.13.

The following method is intended to be called by code using the email library to create policy instances

with custom settings:

**kw

Return a new instance whose attributes have the same values as the current instance, except where those attributes are given new values by the keyword arguments.

The remaining methods are called by the email package code, and are not intended to be called by an

application using the email package. A custom policy must implement all of these methods.

obj, defect

Handle a defect found on obj. When the email package calls this method, defect will always be a subclass

of .

The default implementation checks the flag. If it is , defect is raised as an

exception. If it is (the default), obj and defect are passed to .

obj, defect

Register a defect on obj. In the email package, defect will always be a subclass of .

The default implementation calls the method of the attribute of obj. When the email

package calls , obj will normally have a attribute that has an method. Custom object types used with the email package (for example, custom objects) should also provide such an attribute, otherwise defects in parsed messages will raise unexpected errors.



The Python Library Reference, Release 3.13.2



name

Return the maximum allowed number of headers named name.

Called when a header is added to an or object. If the returned value is not or , and there are already a number of headers with the name name greater than or equal to the

value returned, a is raised.

Because the default behavior of is to append the value to the list of headers, it is easy to create duplicate headers without realizing it. This method allows certain headers to be limited in the number of instances of that header that may be added to a programmatically. (The limit is not observed by the parser, which will faithfully produce as many headers as exist in the message being parsed.)

The default implementation returns for all header names.

sourcelines

The email package calls this method with a list of strings, each string ending with the line separation characters found in the source being parsed. The first line includes the field header name and separator. All whitespace in the source is preserved. The method should return the tuple that is to be stored in the to represent the parsed header.

If an implementation wishes to retain compatibility with the existing email package policies, name should be the case preserved name (all characters up to the ‘’ separator), while value should be the unfolded value (all line separator characters removed, but whitespace kept intact), stripped of leading whitespace.

sourcelines may contain surrogateescaped binary data.

There is no default implementation

name, value

The email package calls this method with the name and value provided by the application program when the application program is modifying a programmatically (as opposed to a created by a parser). The method should return the tuple that is to be stored in the to represent the header.

If an implementation wishes to retain compatibility with the existing email package policies, the name and value should be strings or string subclasses that do not change the content of the passed in arguments.

There is no default implementation

name, value

The email package calls this method with the name and value currently stored in the when that header is requested by the application program, and whatever the method returns is what is passed back to the application as the value of the header being retrieved. Note that there may be more than one header with the same name stored in the ; the method is passed the specific name and value of the header destined to be returned to the application.

value may contain surrogateescaped binary data. There should be no surrogateescaped binary data in the value returned by the method.

There is no default implementation

name, value

The email package calls this method with the name and value currently stored in the for a given header. The method should return a string that represents that header “folded” correctly (according

to the policy settings) by composing the name with the value and inserting characters at the

appropriate places. See RFC 5322 for a discussion of the rules for folding email headers.

value may contain surrogateescaped binary data. There should be no surrogateescaped binary data in the string returned by the method.

name, value

The same as , except that the returned value should be a bytes object rather than a string.

value may contain surrogateescaped binary data. These could be converted back into binary data in the returned bytes object.

The Python Library Reference, Release 3.13.2



**kw

This concrete provides behavior that is intended to be fully compliant with the current email RFCs.

These include (but are not limited to) RFC 5322, RFC 2047, and the current MIME RFCs.

This policy adds new header parsing and folding algorithms. Instead of simple strings, headers are sub-

classes with attributes that depend on the type of the field. The parsing and folding algorithm fully implement

RFC 2047 and RFC 5322.

The default value for the attribute is .

In addition to the settable attributes listed above that apply to all policies, this policy adds the following addi-

tional attributes:

Added in version 3.6:



If , follow RFC 5322, supporting non-ASCII characters in headers by encoding them as “encoded

words”. If , follow RFC 6532 and use encoding for headers. Messages formatted in this

way may be passed to SMTP servers that support the extension (RFC 6531).



If the value for a header in the object originated from a (as opposed to being set by a program), this attribute indicates whether or not a generator should refold that value when transforming the message back into serialized form. The possible values are:



all source values use original folding

source values that have any line that is longer than will be refolded all values are refolded.



The default is .



A callable that takes two arguments, and , where is a header field name and is an unfolded header field value, and returns a string subclass that represents that header. A default

(see ) is provided that supports custom parsing for the various

address and date RFC 5322 header field types, and the major MIME header field stypes. Support for additional custom parsing will be added in the future.



An object with at least two methods: get_content and set_content. When the or

method of an object is called, it calls the corresponding method of this object, passing it the message object as its first argument, and any arguments or keywords that were

passed to it as additional arguments. By default is set to .

Added in version 3.4.

The class provides the following concrete implementations of the abstract methods of :

name

Returns the value of the attribute of the specialized class used to represent the header with the given name.

sourcelines

The name is parsed as everything up to the ‘’ and returned unmodified. The value is determined by stripping leading whitespace off the remainder of the first line, joining all subsequent lines together, and stripping any trailing carriage return or linefeed characters.





The Python Library Reference, Release 3.13.2



name, value

The name is returned unchanged. If the input value has a attribute and it matches name ignoring case, the value is returned unchanged. Otherwise the name and value are passed to , and the resulting header object is returned as the value. In this case a is raised if the input value contains CR or LF characters.

name, value

If the value has a attribute, it is returned to unmodified. Otherwise the name, and the value with any CR or LF characters removed, are passed to the , and the resulting header object is returned. Any surrogateescaped bytes get turned into the unicode unknown-character glyph.

name, value

Header folding is controlled by the policy setting. A value is considered to be a ‘source value’ if and only if it does not have a attribute (having a attribute means it is a header object of some sort). If a source value needs to be refolded according to the policy, it is converted into a header object by passing the name and the value with any CR and LF characters removed to the . Folding of a header object is done by calling its method with the current policy.

Source values are split into lines using . If the value is not to be refolded, the lines are rejoined using the from the policy and returned. The exception is lines containing non-ascii binary data. In that case the value is refolded regardless of the setting, which causes the binary data to be CTE encoded using the charset.

name, value

The same as if is , except that the returned value is bytes.

If is , non-ASCII binary data is converted back into bytes. Headers with binary data are not refolded, regardless of the setting, since there is no way to know whether the binary data consists of single byte characters or multibyte characters.

The following instances of provide defaults suitable for specific application domains. Note that in the future the behavior of these instances (in particular the instance) may be adjusted to conform even more closely to the RFCs relevant to their domains.



An instance of with all defaults unchanged. This policy uses the standard Python line

endings rather than the RFC-correct .



Suitable for serializing messages in conformance with the email RFCs. Like , but with set

to , which is RFC compliant.



The same as except that is . Useful for serializing messages to a message store without using

encoded words in the headers. Should only be used for SMTP transmission if the sender or recipient addresses

have non-ASCII characters (the method handles this automatically).



Suitable for serializing headers with for use in HTTP traffic. Like except that is set

to (unlimited).



Convenience instance. The same as except that is set to . This allows any

policy to be made strict by writing:





With all of these , the effective API of the email package is changed from the Python 3.2 API in the following ways:

• Setting a header on a results in that header being parsed and a header object created.

The Python Library Reference, Release 3.13.2



• Fetching a header value from a results in that header being parsed and a header object created and

returned.

• Any header object, or any header that is refolded due to the policy settings, is folded using an algorithm that fully

implements the RFC folding algorithms, including knowing where encoded words are required and allowed.

From the application view, this means that any header obtained through the is a header object with extra attributes, whose string value is the fully decoded unicode value of the header. Likewise, a header may be assigned a new value, or a new header created, using a unicode string, and the policy will take care of converting the unicode string into the correct RFC encoded form.

The header objects and their attributes are described in .

**kw

This concrete is the backward compatibility policy. It replicates the behavior of the email package in

Python 3.2. The module also defines an instance of this class, , that is used as the default

policy. Thus the default behavior of the email package is to maintain compatibility with Python 3.2.

The following attributes have values that are different from the default:



The default is .

The class provides the following concrete implementations of the abstract methods of :

sourcelines

The name is parsed as everything up to the ‘’ and returned unmodified. The value is determined by stripping leading whitespace off the remainder of the first line, joining all subsequent lines together, and stripping any trailing carriage return or linefeed characters.

name, value

The name and value are returned unmodified.

name, value

If the value contains binary data, it is converted into a object using the charset. Otherwise it is returned unmodified.

name, value

Headers are folded using the folding algorithm, which preserves existing line breaks in the value, and wraps each resulting line to the . Non-ASCII binary data are CTE encoded using the charset.

name, value

Headers are folded using the folding algorithm, which preserves existing line breaks in the value, and wraps each resulting line to the . If is , non-ascii binary data is CTE encoded using the charset. Otherwise the original source header is used, with its existing line breaks and any (RFC invalid) binary data it may contain.



An instance of , providing backward compatibility with the behavior of the email package in Python

3.2.





Source code: Lib/email/errors.py



The following exception classes are defined in the module:



This is the base class for all exceptions that the package can raise. It is derived from the standard

class and defines no additional methods.

The Python Library Reference, Release 3.13.2





This is the base class for exceptions raised by the class. It is derived from . This class

is also used internally by the parser used by .



Raised under some error conditions when parsing the RFC 5322 headers of a message, this class is derived from

. The method will raise this error if the content type is unknown

when the method is called. may raise this error for certain base64 decoding errors, and when an

attempt is made to create a header that appears to contain an embedded header (that is, there is what is supposed

to be a continuation line that has no leading whitespace and looks like a header).



Deprecated and no longer used.



Raised when a payload is added to a object using , but the payload is

already a scalar and the message’s main type is not either or missing.

multiply inherits from and the built-in .

Since is deprecated, this exception is rarely raised in practice. However the

exception may also be raised if the method is called on an instance of a class derived from

(e.g. ).



Raised when an error occurs when the outputs headers.



This is the base class for all defects found when parsing email messages. It is derived from .



This is the base class for all defects found when parsing email headers. It is derived from .

Here is the list of the defects that the can find while parsing messages. Note that the defects are added to the message where the problem was found, so for example, if a message nested inside a had a malformed header, that nested message object would have a defect, but the containing messages would not.

All defect classes are subclassed from .

• – A message claimed to be a multipart, but had no parameter.

• – The start boundary claimed in the header was never

found.

• – A start boundary was found, but no corresponding close boundary was

ever found.

Added in version 3.3.

• – The message had a continuation line as its first header line.

• - A “Unix From” header was found in the middle of a header block.

• - A line was found while parsing headers that had no leading white

space but contained no ‘:’. Parsing continues assuming that the line represents the first line of the body.

Added in version 3.3.

• – A header was found that was missing a colon, or was otherwise malformed.

Deprecated since version 3.3: This defect has not been used for several Python versions.

• – A message claimed to be a , but no subparts were

found. Note that when a message has this defect, its method may return even though

its content type claims to be .

• – When decoding a block of base64 encoded bytes, the padding was not

correct. Enough padding is added to perform the decode, but the resulting decoded bytes may be invalid.

The Python Library Reference, Release 3.13.2



• – When decoding a block of base64 encoded bytes, characters outside

the base64 alphabet were encountered. The characters are ignored, but the resulting decoded bytes may be

invalid.

• – When decoding a block of base64 encoded bytes, the number of non-

padding base64 characters was invalid (1 more than a multiple of 4). The encoded block was kept as-is.

• – When decoding an invalid or unparsable date field. The original value is kept as-is.





Source code: Lib/email/headerregistry.py



Added in version 3.6:

Headers are represented by customized subclasses of . The particular class used to represent a given header is

determined by the of the in effect when the headers are created. This section documents

the particular implemented by the email package for handling RFC 5322 compliant email mes-sages, which not only provides customized header objects for various header types, but also provides an extension mechanism for applications to add their own custom header types.

When using any of the policy objects derived from , all headers are produced by

and have as their last base class. Each header class has an additional base class that is determined by

the type of the header. For example, many headers have the class as their other base class. The specialized second class for a header is determined by the name of the header, using a lookup table stored in

the . All of this is managed transparently for the typical application program, but interfaces are provided for modifying the default behavior for use by more complex applications.

The sections below first document the header base classes and their attributes, followed by the API for modifying

the behavior of , and finally the support classes used to represent the data parsed from structured headers.

name, value

name and value are passed to from the call. The string value of any header

object is the value fully decoded to unicode.

This base class defines the following read-only properties:



The name of the header (the portion of the field before the ‘:’). This is exactly the value passed in the

call for name; that is, case is preserved.



A tuple of instances reporting any RFC compliance problems found during parsing.

The email package tries to be complete about detecting compliance issues. See the module for a discussion of the types of defects that may be reported.



The maximum number of headers of this type that can have the same . A value of means unlimited. The value for this attribute is ; it is expected that specialized header classes will override this value as needed.

also provides the following method, which is called by the email library code and should not in

general be called by application programs:

*, policy

Return a string containing characters as required to correctly fold the header according to

policy. A of will be treated as if it were , since headers may not contain arbitrary

binary data. If is , non-ASCII data will be RFC 2047 encoded.



The Python Library Reference, Release 3.13.2



by itself cannot be used to create a header object. It defines a protocol that each specialized

header cooperates with in order to produce the header object. Specifically, requires that the

specialized class provide a named . This method is called as follows:





is a dictionary containing one pre-initialized key, . is an empty list. The parse method

should append any detected defects to this list. On return, the dictionary must contain values for at least

the keys and . should be the string value for the header (that is, the header value

fully decoded to unicode). The parse method should assume that string may contain content-transfer-encoded

parts, but should correctly handle all valid unicode characters as well so that it can parse un-encoded header

values.

’s then creates the header instance, and calls its method. The specialized class

only needs to provide an method if it wishes to set additional attributes beyond those provided by

itself. Such an method should look like this:





That is, anything extra that the specialized class puts in to the dictionary should be removed and handled,

and the remaining contents of (and ) passed to the method.



An “unstructured” header is the default type of header in RFC 5322. Any header that does not have a specified

syntax is treated as unstructured. The classic example of an unstructured header is the header.

In RFC 5322, an unstructured header is a run of arbitrary text in the ASCII character set. RFC 2047, however,

has an RFC 5322 compatible mechanism for encoding non-ASCII text as ASCII characters within a header

value. When a value containing encoded words is passed to the constructor, the parser

converts such encoded words into unicode, following the RFC 2047 rules for unstructured text. The parser

uses heuristics to attempt to decode certain non-compliant encoded words. Defects are registered in such cases,

as well as defects for issues such as invalid characters within the encoded words or the non-encoded text.

This header type provides no additional attributes.



RFC 5322 specifies a very specific format for dates within email headers. The parser recognizes

that date format, as well as recognizing a number of variant forms that are sometimes found “in the wild”.

This header type provides the following additional attributes:



If the header value can be recognized as a valid date of one form or another, this attribute will contain

a instance representing that date. If the timezone of the input date is specified as

(indicating it is in UTC but contains no information about the source timezone), then will be

a naive . If a specific timezone offset is found (including ), then will contain

an aware that uses to record the timezone offset.

The value of the header is determined by formatting the according to the RFC 5322

rules; that is, it is set to:





When creating a , value may be instance. This means, for example, that the following

code is valid and does what one would expect:





Because this is a naive it will be interpreted as a UTC timestamp, and the resulting value will have

a timezone of. Much more useful is to use the function from the module:

The Python Library Reference, Release 3.13.2





This example sets the date header to the current time and date using the current timezone offset.



Address headers are one of the most complex structured header types. The class provides a

generic interface to any address header.

This header type provides the following additional attributes:



A tuple of objects encoding the addresses and groups found in the header value. Addresses that

are not part of a group are represented in this list as single-address whose is .



A tuple of objects encoding all of the individual addresses from the header value. If the header value contains any groups, the individual addresses from the group are included in the list at the point where the group occurs in the value (that is, the list of addresses is “flattened” into a one dimensional list).

The value of the header will have all encoded words decoded to unicode. encoded domain

names are also decoded to unicode. The value is set by joining the value of the elements of the

attribute with .

A list of and objects in any combination may be used to set the value of an address header.

objects whose is will be interpreted as single addresses, which allows an address

list to be copied with groups intact by using the list obtained from the attribute of the source header.



A subclass of that adds one additional attribute:



The single address encoded by the header value. If the header value actually contains more than one

address (which would be a violation of the RFC under the default ), accessing this attribute will

result in a .

Many of the above classes also have a variant (for example, ). The only

difference is that in the variant, is set to 1.



There is really only one valid value for the header, and that is . For future proofing, this

header class supports other valid version numbers. If a version number has a valid value per RFC 2045, then

the header object will have non- values for the following attributes:



The version number as a string, with any whitespace and/or comments removed.



The major version number as an integer



The minor version number as an integer



MIME headers all start with the prefix ‘Content-’. Each specific header has a certain value, described under

the class for that header. Some can also take a list of supplemental parameters, which have a common format.

This class serves as a base for all the MIME headers that take parameters.



A dictionary mapping parameter names to parameter values.

The Python Library Reference, Release 3.13.2





A class that handles the header.



The content type string, in the form .





A class that handles the header.



and are the only valid values in common use.



Handles the header.



Valid values are , , , and . See RFC 2045 for more information.

base_class=BaseHeader,

default_class=UnstructuredHeader,

use_default_map=True

This is the factory used by by default. builds the class used to create a

header instance dynamically, using base_class and a specialized class retrieved from a registry that it holds.

When a given header name does not appear in the registry, the class specified by default_class is used as the

specialized class. When use_default_map is (the default), the standard mapping of header names to

classes is copied in to the registry during initialization. base_class is always the last class in the generated

class’s list.

The default mappings are:

subject

UniqueUnstructuredHeader

date

UniqueDateHeader

resent-date

DateHeader

orig-date

UniqueDateHeader

sender

UniqueSingleAddressHeader

resent-sender

SingleAddressHeader

to

UniqueAddressHeader

resent-to

AddressHeader

cc

UniqueAddressHeader

resent-cc

AddressHeader

bcc

UniqueAddressHeader

The Python Library Reference, Release 3.13.2



resent-bcc

AddressHeader

from

UniqueAddressHeader

resent-from

AddressHeader

reply-to

UniqueAddressHeader

mime-version

MIMEVersionHeader

content-type

ContentTypeHeader

content-disposition

ContentDispositionHeader

content-transfer-encoding

ContentTransferEncodingHeader

message-id

MessageIDHeader

has the following methods:

self, name, cls

name is the name of the header to be mapped. It will be converted to lower case in the registry. cls is the specialized class to be used, along with base_class, to create the class used to instantiate headers that match name.

name

Construct and return a class to handle creating a name header.

name, value

Retrieves the specialized header associated with name from the registry (using default_class if name does not appear in the registry) and composes it with base_class to produce a class, calls the constructed class’s constructor, passing it the same argument list, and finally returns the class instance created thereby.

The following classes are the classes used to represent data parsed from structured headers and can, in general, be used by an application program to construct structured values to assign to specific headers.

display_name=” , username=” , domain=” , addr_spec=None

The class used to represent an email address. The general form of an address is:





or:





where each part must conform to specific syntax rules spelled out in RFC 5322.

As a convenience addr_spec can be specified instead of username and domain, in which case username and

domain will be parsed from the addr_spec. An addr_spec must be a properly RFC quoted string; if it is not

will raise an error. Unicode characters are allowed and will be property encoded when serialized.

However, per the RFCs, unicode is not allowed in the username portion of the address.



The display name portion of the address, if any, with all quoting removed. If the address does not have a display name, this attribute will be an empty string.

The Python Library Reference, Release 3.13.2





The portion of the address, with all quoting removed.



The portion of the address.



The portion of the address, correctly quoted for use as a bare address (the second form shown above). This attribute is not mutable.



The value of the object is the address quoted according to RFC 5322 rules, but with no Content Transfer Encoding of any non-ASCII characters.

To support SMTP (RFC 5321), handles one special case: if and are both the

empty string (or ), then the string value of the is .

display_name=None, addresses=None

The class used to represent an address group. The general form of an address group is:





As a convenience for processing lists of addresses that consist of a mixture of groups and single addresses, a

may also be used to represent single addresses that are not part of a group by setting display_name to

and providing a list of the single address as addresses.



The of the group. If it is and there is exactly one in , then the represents a single address that is not in a group.



A possibly empty tuple of objects representing the addresses in the group.



The value of a is formatted according to RFC 5322, but with no Content Transfer En-coding of any non-ASCII characters. If is none and there is a single in the list, the value will be the same as the of that single .





Source code: Lib/email/contentmanager.py



Added in version 3.6:



Base class for content managers. Provides the standard registry mechanisms to register converters between

MIME content and other representations, as well as the and dispatch methods.



msg, *args, **kw

Look up a handler function based on the of msg (see next paragraph), call it, passing through all arguments, and return the result of the call. The expectation is that the handler will extract the payload from msg and return an object that encodes information about the extracted data.

To find the handler, look for the following keys in the registry, stopping with the first one found:

• the string representing the full MIME type ()

• the string representing the



The Python Library Reference, Release 3.13.2



• the empty string

If none of these keys produce a handler, raise a for the full MIME type.

msg, obj, *args, **kw

If the is , raise a ; otherwise look up a handler function based on

the type of obj (see next paragraph), call on the msg, and call the handler function, passing through all arguments. The expectation is that the handler will transform and store obj into msg, possibly making other changes to msg as well, such as adding various MIME headers to encode information needed to interpret the stored data.

To find the handler, obtain the type of obj (), and look for the following keys in the registry, stopping with the first one found:

• the type itself ()

• the type’s fully qualified name ().

• the type’s ()

• the type’s ().

If none of the above match, repeat all of the checks above for each of the types in the MRO ( ). Finally, if no other key yields a handler, check for a handler for the key . If there is no

handler for , raise a for the fully qualified name of the type.

Also add a header if one is not present (see also ).

key, handler

Record the function handler as the handler for key. For the possible values of key, see .

typekey, handler

Record handler as the function to call when an object of a type matching typekey is passed to

. For the possible values of typekey, see .



Content Manager Instances

Currently the email package provides only one concrete content manager, , although more

may be added in the future. is the provided by and its derivatives.



This content manager provides only a minimum interface beyond that provided by itself: it deals only

with text, raw byte strings, and objects. Nevertheless, it provides significant advantages compared

to the base API: on a text part will return a unicode string without the application needing to

manually decode it, provides a rich set of options for controlling the headers added to a part

and controlling the content transfer encoding, and it enables the use of the various methods, thereby

simplifying the creation of multipart messages.

msg, errors=’replace’

Return the payload of the part as either a string (for parts), an object (for

parts), or a object (for all other non-multipart types). Raise a if called on a . If the part is a part and errors is specified, use it as the error handler when decoding the payload to unicode. The default error handler is .

msg, <’str’>, subtype=”plain”, charset=’utf-8’, cte=None,

disposition=None, filename=None, cid=None, params=None,

headers=None

msg, <’bytes’>, maintype, subtype, cte=”base64”,

disposition=None, filename=None, cid=None, params=None,

headers=None



The Python Library Reference, Release 3.13.2



msg, <’EmailMessage’>, cte=None, disposition=None,

filename=None, cid=None, params=None, headers=None

Add headers and payload to msg:

Add a header with a value.

• For , set the MIME to , and set the subtype to subtype if it is specified, or

if it is not.

• For , use the specified maintype and subtype, or raise a if they are not specified.

• For objects, set the maintype to , and set the subtype to subtype if it is

specified or if it is not. If subtype is , raise an error ( objects must be used to construct parts).

If charset is provided (which is valid only for ), encode the string to bytes using the specified character set. The default is . If the specified charset is a known alias for a standard MIME charset name, use the standard charset instead.

If cte is set, encode the payload using the specified content transfer encoding, and set the header to that value. Possible values for cte are , , , , and . If the input cannot be encoded in the specified encoding (for exam-

ple, specifying a cte of for an input that contains non-ASCII values), raise a .

• For objects, if cte is not set use heuristics to determine the most compact encoding. Prior to

encoding, is used to normalize all line boundaries, ensuring that each line of

the payload is terminated by the current policy’s property (even if the original string did not end with one).

• For objects, cte is taken to be base64 if not set, and the aforementioned newline translation

is not performed.

• For , per RFC 2046, raise an error if a cte of or is

requested for subtype , and for any cte other than for subtype . For , use if cte is not specified. For all other values of subtype, use .



® Note

A cte of does not actually work correctly yet. The object as modified by

is correct, but does not serialize it correctly.



If disposition is set, use it as the value of the header. If not specified, and filename is specified, add the header with the value . If disposition is not specified and filename is also not specified, do not add the header. The only valid values for disposition are and .

If filename is specified, use it as the value of the parameter of the header.

If cid is specified, add a header with cid as its value.

If params is specified, iterate its method and use the resulting pairs to set addi-tional parameters on the header.

If headers is specified and is a list of strings of the form or a list of objects (distinguished from strings by having a attribute), add the headers to msg.





Here are a few examples of how to use the package to read, write, and send simple email messages, as well as more complex MIME messages.

First, let’s see how to create and send a simple text message (both the text content and the addresses may contain unicode characters):

The Python Library Reference, Release 3.13.2





Parsing RFC 822 headers can easily be done by the using the classes from the module:





Here’s an example of how to send a MIME message containing a bunch of family pictures that may be residing in a directory:





The Python Library Reference, Release 3.13.2





Here’s an example of how to send the entire contents of a directory as an email message:





The Python Library Reference, Release 3.13.2





Here’s an example of how to unpack a MIME message like the one above, into a directory of files:





The Python Library Reference, Release 3.13.2





Here’s an example of how to create an HTML message with an alternative plain text version. To make things a bit more interesting, we include a related image in the html part, and we save a copy of what we are going to send to disk, as well as sending it.





The Python Library Reference, Release 3.13.2





Salut!





Cette



recette

sera sûrement un très bon repas.





{asparagus_cid}" />





""".format(asparagus_cid=asparagus_cid[1:-1]), subtype='html') # note that we needed to peel the <> off the msgid for use in the html.

# Now add the related image to the html part.

with open("roasted-asparagus.jpg", 'rb') as img:

msg.get_payload()[1].add_related(img.read(), 'image', 'jpeg',

cid=asparagus_cid)

# Make a local copy of what we are going to send.

with open('outgoing.msg', 'wb') as f:

f.write(bytes(msg))

# Send the message via local SMTP server.

with smtplib.SMTP('localhost') as s:

s.send_message(msg)



If we were sent the message from the last example, here is one way we could process it:

The Python Library Reference, Release 3.13.2



import os

import sys

import tempfile

import mimetypes

import webbrowser

# Import the email modules we'll need

from email import policy

from email.parser import BytesParser



def magic_html_parser(html_text, partfiles):

"""Return safety-sanitized html linked to partfiles.

Rewrite the href="cid:...." attributes to point to the filenames in partfiles.

Though not trivial, this should be possible using html.parser.

"""

raise NotImplementedError("Add the magic needed")



# In a real program you'd get the filename from the arguments. with open('outgoing.msg', 'rb') as fp:

msg = BytesParser(policy=policy.default).parse(fp)

# Now the header items can be accessed as a dictionary, and any non-ASCII will # be converted to unicode:

print('To:', msg['to'])

print('From:', msg['from'])

print('Subject:', msg['subject'])

# If we want to print a preview of the message content, we can extract whatever # the least formatted payload is and print the first three lines. Of course, # if the message has no plain text part printing the first three lines of html # is probably useless, but this is just a conceptual example. simplest = msg.get_body(preferencelist=('plain', 'html')) print()

print(''.join(simplest.get_content().splitlines(keepends=True)[:3]))

ans = input("View full message?")

if ans.lower()[0] == 'n':

sys.exit()

# We can extract the richest alternative in order to display it: richest = msg.get_body()

partfiles = {}

if richest['content-type'].maintype == 'text':

if richest['content-type'].subtype == 'plain':

for line in richest.get_content().splitlines():

print(line)

sys.exit()

elif richest['content-type'].subtype == 'html':

body = richest

else:

print("Don't know how to display {}".format(richest.get_content_type())) sys.exit()

elif richest['content-type'].content_type == 'multipart/related':

body = richest.get_body(preferencelist=('html'))

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

for part in richest.iter_attachments():

fn = part.get_filename()

if fn:

extension = os.path.splitext(part.get_filename())[1]

else:

extension = mimetypes.guess_extension(part.get_content_type())

with tempfile.NamedTemporaryFile(suffix=extension, delete=False) as f:

f.write(part.get_content())

# again strip the <> to go from email form of cid to html form. partfiles[part['content-id'][1:-1]] = f.name

else:

print("Don't know how to display {}".format(richest.get_content_type()))

sys.exit()

with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:

f.write(magic_html_parser(body.get_content(), partfiles))

webbrowser.open(f.name)

os.remove(f.name)

for fn in partfiles.values():

os.remove(fn)

# Of course, there are lots of email messages that could break this simple # minded program, but it will handle the most common ones.



Up to the prompt, the output from the above is:

To: Penelope Pussycat , Fabrette Pussycat

, →com>

From: Pepé Le Pew

Subject: Pourquoi pas des asperges pour ce midi ?

Salut!

Cette recette [1] sera sûrement un très bon repas.



Legacy API:



20.1.9 email.message.Message: Representing an email message using the

compat32 API

The Message class is very similar to the EmailMessage class, without the methods added by that class, and with the default behavior of certain other methods being slightly different. We also document here some methods that,

while supported by the EmailMessage class, are not recommended unless you are dealing with legacy code.

The philosophy and structure of the two classes is otherwise the same.

This document describes the behavior under the default (for Message) policy Compat32. If you are going to use

another policy, you should be using the EmailMessage class instead.

An email message consists of headers and a payload. Headers must be RFC 5322 style names and values, where the field name and value are separated by a colon. The colon is not part of either the field name or the field value. The payload may be a simple text message, or a binary object, or a structured sequence of sub-messages each with their own set of headers and their own payload. The latter type of payload is indicated by the message having a MIME type such as multipart/* or message/rfc822.

The conceptual model provided by a Message object is that of an ordered dictionary of headers with additional methods for accessing both specialized information from the headers, for accessing the payload, for generating a serialized version of the message, and for recursively walking over the object tree. Note that duplicate headers are supported but special methods must be used to access them.

The Python Library Reference, Release 3.13.2



The Message pseudo-dictionary is indexed by the header names, which must be ASCII values. The values of the dictionary are strings that are supposed to contain only ASCII characters; there is some special handling for non-ASCII input, but it doesn’t always produce the correct results. Headers are stored and returned in case-preserving form, but field names are matched case-insensitively. There may also be a single envelope header, also known as the Unix-From header or the From_ header. The payload is either a string or bytes, in the case of simple message

objects, or a list of Message objects, for MIME container documents (e.g. multipart/* and message/rfc822).

Here are the methods of the Message class:

class email.message.Message(policy=compat32)

If policy is specified (it must be an instance of a policy class) use the rules it specifies to update and serialize

the representation of the message. If policy is not set, use the compat32 policy, which maintains backward

compatibility with the Python 3.2 version of the email package. For more information see the policy docu-

mentation.

Changed in version 3.3: The policy keyword argument was added.

as_string(unixfrom=False, maxheaderlen=0, policy=None)

Return the entire message flattened as a string. When optional unixfrom is true, the envelope header is included in the returned string. unixfrom defaults to False. For backward compatibility reasons, maxheaderlen defaults to 0, so if you want a different value you must override it explicitly (the value specified for max_line_length in the policy will be ignored by this method). The policy argument may be used to override the default policy obtained from the message instance. This can be used to control some of the formatting produced by the method, since the specified policy will be passed to the Generator.

Flattening the message may trigger changes to the Message if defaults need to be filled in to complete the transformation to a string (for example, MIME boundaries may be generated or modified).

Note that this method is provided as a convenience and may not always format the message the way you want. For example, by default it does not do the mangling of lines that begin with From that is required

by the Unix mbox format. For more flexibility, instantiate a Generator instance and use its flatten() method directly. For example:

from io import StringIO

from email.generator import Generator

fp = StringIO()

g = Generator(fp, mangle_from_=True, maxheaderlen=60) g.flatten(msg)

text = fp.getvalue()



If the message object contains binary data that is not encoded according to RFC standards, the non-

compliant data will be replaced by unicode “unknown character” code points. (See also as_bytes()

and BytesGenerator.)

Changed in version 3.4: the policy keyword argument was added.

__str__()

Equivalent to as_string(). Allows str(msg) to produce a string containing the formatted message.

as_bytes(unixfrom=False, policy=None)

Return the entire message flattened as a bytes object. When optional unixfrom is true, the envelope header is included in the returned string. unixfrom defaults to False. The policy argument may be used to override the default policy obtained from the message instance. This can be used to control some of the formatting produced by the method, since the specified policy will be passed to the BytesGenerator.

Flattening the message may trigger changes to the Message if defaults need to be filled in to complete the transformation to a string (for example, MIME boundaries may be generated or modified).

Note that this method is provided as a convenience and may not always format the message the way you want. For example, by default it does not do the mangling of lines that begin with From that is required

by the Unix mbox format. For more flexibility, instantiate a BytesGenerator instance and use its

flatten() method directly. For example:

The Python Library Reference, Release 3.13.2



from io import BytesIO

from email.generator import BytesGenerator

fp = BytesIO()

g = BytesGenerator(fp, mangle_from_=True, maxheaderlen=60) g.flatten(msg)

text = fp.getvalue()



Added in version 3.4.

__bytes__()

Equivalent to as_bytes(). Allows bytes(msg) to produce a bytes object containing the formatted message.

Added in version 3.4.

is_multipart()

Return True if the message’s payload is a list of sub-Message objects, otherwise return False. When

is_multipart() returns False, the payload should be a string object (which might be a CTE en-

coded binary payload). (Note that is_multipart() returning True does not necessarily mean that “msg.get_content_maintype() == ‘multipart’” will return the True. For example, is_multipart will

return True when the Message is of type message/rfc822.)

set_unixfrom(unixfrom)

Set the message’s envelope header to unixfrom, which should be a string.

get_unixfrom()

Return the message’s envelope header. Defaults to None if the envelope header was never set.

attach(payload)

Add the given payload to the current payload, which must be None or a list of Message objects before

the call. After the call, the payload will always be a list of Message objects. If you want to set the

payload to a scalar object (e.g. a string), use set_payload() instead.

This is a legacy method. On the EmailMessage class its functionality is replaced by set_content() and the related make and add methods.

get_payload(i=None, decode=False)

Return the current payload, which will be a list of Message objects when is_multipart() is True,

or a string when is_multipart() is False. If the payload is a list and you mutate the list object, you modify the message’s payload in place.

With optional argument i, get_payload() will return the i-th element of the payload, counting from

zero, if is_multipart() is True. An IndexError will be raised if i is less than 0 or greater than or

equal to the number of items in the payload. If the payload is a string (i.e. is_multipart() is False)

and i is given, a TypeError is raised.

Optional decode is a flag indicating whether the payload should be decoded or not, according to the Content-Transfer-Encoding header. When True and the message is not a multipart, the payload will be decoded if this header’s value is quoted-printable or base64. If some other encoding is used, or Content-Transfer-Encoding header is missing, the payload is returned as-is (undecoded). In all cases the returned value is binary data. If the message is a multipart and the decode flag is True, then None is returned. If the payload is base64 and it was not perfectly formed (missing padding, characters outside the base64 alphabet), then an appropriate defect will be added to the message’s defect property (InvalidBase64PaddingDefect or InvalidBase64CharactersDefect, respectively).

When decode is False (the default) the body is returned as a string without decoding the Content-Transfer-Encoding. However, for a Content-Transfer-Encoding of 8bit, an at-tempt is made to decode the original bytes using the charset specified by the Content-Type header, using the replace error handler. If no charset is specified, or if the charset given is not recognized by the email package, the body is decoded using the default ASCII charset.

The Python Library Reference, Release 3.13.2



This is a legacy method. On the EmailMessage class its functionality is replaced by get_content()

and iter_parts().

set_payload(payload, charset=None)

Set the entire message object’s payload to payload. It is the client’s responsibility to ensure the payload

invariants. Optional charset sets the message’s default character set; see set_charset() for details.

This is a legacy method. On the EmailMessage class its functionality is replaced by set_content().

set_charset(charset)

Set the character set of the payload to charset, which can either be a Charset instance (see email.

charset ), a string naming a character set, or None. If it is a string, it will be converted to a Charset instance. If charset is None, the charset parameter will be removed from the Content-Type header

(the message will not be otherwise modified). Anything else will generate a TypeError.

If there is no existing MIME-Version header one will be added. If there is no existing Content-Type header, one will be added with a value of text/plain. Whether the Content-Type header already exists or not, its charset parameter will be set to charset.output_charset. If charset.input_charset and charset.output_charset differ, the payload will be re-encoded to the output_charset. If there is no existing Content-Transfer-Encoding header, then the payload will be transfer-encoded, if

needed, using the specified Charset, and a header with the appropriate value will be added. If a Content-Transfer-Encoding header already exists, the payload is assumed to already be correctly encoded using that Content-Transfer-Encoding and is not modified.

This is a legacy method. On the EmailMessage class its functionality is replaced by the charset param-eter of the email.emailmessage.EmailMessage.set_content() method.

get_charset()

Return the Charset instance associated with the message’s payload.

This is a legacy method. On the EmailMessage class it always returns None.

The following methods implement a mapping-like interface for accessing the message’s RFC 2822 headers.

Note that there are some semantic differences between these methods and a normal mapping (i.e. dictionary)

interface. For example, in a dictionary there are no duplicate keys, but here there may be duplicate message

headers. Also, in dictionaries there is no guaranteed order to the keys returned by keys(), but in a Message

object, headers are always returned in the order they appeared in the original message, or were added to the

message later. Any header deleted and then re-added are always appended to the end of the header list.

These semantic differences are intentional and are biased toward maximal convenience.

Note that in all cases, any envelope header present in the message is not included in the mapping interface.

In a model generated from bytes, any header values that (in contravention of the RFCs) contain non-

ASCII bytes will, when retrieved through this interface, be represented as Header objects with a charset

of unknown-8bit.

__len__()

Return the total number of headers, including duplicates.

__contains__(name)

Return True if the message object has a field named name. Matching is done case-insensitively and name should not include the trailing colon. Used for the in operator, e.g.:

if 'message-id' in myMessage:

print('Message-ID:', myMessage['message-id'])



__getitem__(name)

Return the value of the named header field. name should not include the colon field separator. If the

header is missing, None is returned; a KeyError is never raised.

Note that if the named field appears more than once in the message’s headers, exactly which of those

field values will be returned is undefined. Use the get_all() method to get the values of all the extant named headers.

The Python Library Reference, Release 3.13.2



__setitem__(name, val)

Add a header to the message with field name name and value val. The field is appended to the end of the message’s existing fields.

Note that this does not overwrite or delete any existing header with the same name. If you want to ensure that the new header is the only one present in the message with field name name, delete the field first, e.g.:

del msg['subject']

msg['subject'] = 'Python roolz!'



__delitem__(name)

Delete all occurrences of the field with name name from the message’s headers. No exception is raised if the named field isn’t present in the headers.

keys()

Return a list of all the message’s header field names.

values()

Return a list of all the message’s field values.

items()

Return a list of 2-tuples containing all the message’s field headers and values.

get(name, failobj=None)

Return the value of the named header field. This is identical to __getitem__() except that optional failobj is returned if the named header is missing (defaults to None).

Here are some additional useful methods:

get_all(name, failobj=None)

Return a list of all the values for the field named name. If there are no such named headers in the message, failobj is returned (defaults to None).

add_header(_name, _value, **_params)

Extended header setting. This method is similar to __setitem__() except that additional header pa-rameters can be provided as keyword arguments. _name is the header field to add and _value is the primary value for the header.

For each item in the keyword argument dictionary _params, the key is taken as the parameter name, with underscores converted to dashes (since dashes are illegal in Python identifiers). Normally, the parameter will be added as key="value" unless the value is None, in which case only the key will be added. If the value contains non-ASCII characters, it can be specified as a three tuple in the format (CHARSET, LANGUAGE, VALUE), where CHARSET is a string naming the charset to be used to encode the value,

LANGUAGE can usually be set to None or the empty string (see RFC 2231 for other possibilities), and VALUE is the string value containing non-ASCII code points. If a three tuple is not passed and the value

contains non-ASCII characters, it is automatically encoded in RFC 2231 format using a CHARSET of utf-8 and a LANGUAGE of None.

Here’s an example:

msg.add_header('Content-Disposition', 'attachment', filename='bud.gif')



This will add a header that looks like

Content-Disposition: attachment; filename="bud.gif"



An example with non-ASCII characters:

msg.add_header('Content-Disposition', 'attachment',

filename=('iso-8859-1', '', 'Fußballer.ppt'))

The Python Library Reference, Release 3.13.2



Which produces

Content-Disposition: attachment; filename*="iso-8859-1''Fu%DFballer.ppt"



replace_header(_name, _value)

Replace a header. Replace the first header found in the message that matches _name, retaining header

order and field name case. If no matching header was found, a KeyError is raised.

get_content_type()

Return the message’s content type. The returned string is coerced to lower case of the form maintype/ subtype . If there was no Content-Type header in the message the default type as given by

get_default_type() will be returned. Since according to RFC 2045, messages always have a default

type, get_content_type() will always return a value.

RFC 2045 defines a message’s default type to be text/plain unless it appears inside a multipart/ digest container, in which case it would be message/rfc822. If the Content-Type header has an

invalid type specification, RFC 2045 mandates that the default type be text/plain.

get_content_maintype()

Return the message’s main content type. This is the maintype part of the string returned by

get_content_type().

get_content_subtype()

Return the message’s sub-content type. This is the subtype part of the string returned by

get_content_type().

get_default_type()

Return the default content type. Most messages have a default content type of text/plain, except for messages that are subparts of multipart/digest containers. Such subparts have a default content type of message/rfc822.

set_default_type( ctype)

Set the default content type. ctype should either be text/plain or message/rfc822, although this is not enforced. The default content type is not stored in the Content-Type header.

get_params(failobj=None, header=’content-type’, unquote=True)

Return the message’s Content-Type parameters, as a list. The elements of the returned list are 2-tuples of key/value pairs, as split on the '=' sign. The left hand side of the '=' is the key, while the right hand side is the value. If there is no '=' sign in the parameter the value is the empty string, otherwise the

value is as described in get_param() and is unquoted if optional unquote is True (the default).

Optional failobj is the object to return if there is no Content-Type header. Optional header is the header to search instead of Content-Type.

This is a legacy method. On the EmailMessage class its functionality is replaced by the params property of the individual header objects returned by the header access methods.

get_param(param, failobj=None, header=’content-type’, unquote=True)

Return the value of the Content-Type header’s parameter param as a string. If the message has no Content-Type header or if there is no such parameter, then failobj is returned (defaults to None).

Optional header if given, specifies the message header to use instead of Content-Type.

Parameter keys are always compared case insensitively. The return value can either be a string, or a

3-tuple if the parameter was RFC 2231 encoded. When it’s a 3-tuple, the elements of the value are of the form (CHARSET, LANGUAGE, VALUE). Note that both CHARSET and LANGUAGE can be None, in which case you should consider VALUE to be encoded in the us-ascii charset. You can usually ignore LANGUAGE.

If your application doesn’t care whether the parameter was encoded as in RFC 2231, you can collapse

the parameter value by calling email.utils.collapse_rfc2231_value(), passing in the return

value from get_param(). This will return a suitably decoded Unicode string when the value is a tuple, or the original string unquoted if it isn’t. For example:

The Python Library Reference, Release 3.13.2



rawparam = msg.get_param('foo')

param = email.utils.collapse_rfc2231_value(rawparam)



In any case, the parameter value (either the returned string, or the VALUE item in the 3-tuple) is always unquoted, unless unquote is set to False.

This is a legacy method. On the EmailMessage class its functionality is replaced by the params property of the individual header objects returned by the header access methods.

set_param(param, value, header=’Content-Type’, requote=True, charset=None, language=”, replace=False)

Set a parameter in the Content-Type header. If the parameter already exists in the header, its value will be replaced with value. If the Content-Type header as not yet been defined for this message, it

will be set to text/plain and the new parameter value will be appended as per RFC 2045.

Optional header specifies an alternative header to Content-Type, and all parameters will be quoted as necessary unless optional requote is False (the default is True).

If optional charset is specified, the parameter will be encoded according to RFC 2231. Optional language specifies the RFC 2231 language, defaulting to the empty string. Both charset and language should be strings.

If replace is False (the default) the header is moved to the end of the list of headers. If replace is True, the header will be updated in place.

Changed in version 3.4: replace keyword was added.

del_param(param, header=’content-type’, requote=True)

Remove the given parameter completely from the Content-Type header. The header will be re-written in place without the parameter or its value. All values will be quoted as necessary unless requote is False (the default is True). Optional header specifies an alternative to Content-Type.

set_type(type, header=’Content-Type’, requote=True)

Set the main type and subtype for the Content-Type header. type must be a string in the form

maintype/subtype, otherwise a ValueError is raised.

This method replaces the Content-Type header, keeping all the parameters in place. If requote is False , this leaves the existing header’s quoting as is, otherwise the parameters will be quoted (the de-fault).

An alternative header can be specified in the header argument. When the Content-Type header is set a MIME-Version header is also added.

This is a legacy method. On the EmailMessage class its functionality is replaced by the make_ and add_ methods.

get_filename(failobj=None)

Return the value of the filename parameter of the Content-Disposition header of the message. If the header does not have a filename parameter, this method falls back to looking for the name parameter on the Content-Type header. If neither is found, or the header is missing, then failobj is

returned. The returned string will always be unquoted as per email.utils.unquote().

get_boundary(failobj=None)

Return the value of the boundary parameter of the Content-Type header of the message, or failobj if either the header is missing, or has no boundary parameter. The returned string will always be unquoted

as per email.utils.unquote().

set_boundary(boundary)

Set the boundary parameter of the Content-Type header to boundary. set_boundary() will al-

ways quote boundary if necessary. A HeaderParseError is raised if the message object has no Content-Type header.

Note that using this method is subtly different than deleting the old Content-Type header and adding a

new one with the new boundary via add_header(), because set_boundary() preserves the order of

The Python Library Reference, Release 3.13.2



the Content-Type header in the list of headers. However, it does not preserve any continuation lines which may have been present in the original Content-Type header.

get_content_charset(failobj=None)

Return the charset parameter of the Content-Type header, coerced to lower case. If there is no Content-Type header, or if that header has no charset parameter, failobj is returned.

Note that this method differs from get_charset() which returns the Charset instance for the default encoding of the message body.

get_charsets(failobj=None)

Return a list containing the character set names in the message. If the message is a multipart, then the list will contain one element for each subpart in the payload, otherwise, it will be a list of length 1.

Each item in the list will be a string which is the value of the charset parameter in the Content-Type header for the represented subpart. However, if the subpart has no Content-Type header, no charset parameter, or is not of the text main MIME type, then that item in the returned list will be failobj.

get_content_disposition()

Return the lowercased value (without parameters) of the message’s Content-Disposition header if it has one, or None. The possible values for this method are inline, attachment or None if the message

follows RFC 2183.

Added in version 3.5.

walk()

The walk() method is an all-purpose generator which can be used to iterate over all the parts and

subparts of a message object tree, in depth-first traversal order. You will typically use walk() as the iterator in a for loop; each iteration returns the next subpart.

Here’s an example that prints the MIME type of every part of a multipart message structure:

>>> for part in msg.walk():

... print(part.get_content_type())

multipart/report

text/plain

message/delivery-status

text/plain

text/plain

message/rfc822

text/plain



walk iterates over the subparts of any part where is_multipart() returns True, even though msg. get_content_maintype() == 'multipart' may return False. We can see this in our example by making use of the _structure debug helper function:

>>> for part in msg.walk():

... print(part.get_content_maintype() == 'multipart', ... part.is_multipart())

True True

False False

False True

False False

False False

False True

False False

>>> _structure(msg)

multipart/report

text/plain

message/delivery-status

text/plain

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

text/plain

message/rfc822

text/plain



Here the message parts are not multiparts, but they do contain subparts. is_multipart() returns True and walk descends into the subparts.

Message objects can also optionally contain two instance attributes, which can be used when generating the

plain text of a MIME message.

preamble

The format of a MIME document allows for some text between the blank line following the headers, and the first multipart boundary string. Normally, this text is never visible in a MIME-aware mail reader because it falls outside the standard MIME armor. However, when viewing the raw text of the message, or when viewing the message in a non-MIME aware reader, this text can become visible.

The preamble attribute contains this leading extra-armor text for MIME documents. When the Parser discovers some text after the headers but before the first boundary string, it assigns this text to the mes-

sage’s preamble attribute. When the Generator is writing out the plain text representation of a MIME message, and it finds the message has a preamble attribute, it will write this text in the area between the

headers and the first boundary. See email.parser and email.generator for details.

Note that if the message object has no preamble, the preamble attribute will be None.





epilogue


The epilogue attribute acts the same way as the preamble attribute, except that it contains text that appears between the last boundary and the end of the message.

You do not need to set the epilogue to the empty string in order for the Generator to print a newline at the end of the file.

defects

The defects attribute contains a list of all the problems found when parsing this message. See email.

errors for a detailed description of the possible parsing defects.



20.1.10 email.mime: Creating email and MIME objects from scratch

Source code: Lib/email/mime/



This module is part of the legacy (Compat32) email API. Its functionality is partially replaced by the

contentmanager in the new API, but in certain applications these classes may still be useful, even in non-legacy code.

Ordinarily, you get a message object structure by passing a file or some text to a parser, which parses the text and returns the root message object. However you can also build a complete message structure from scratch, or even

individual Message objects by hand. In fact, you can also take an existing structure and add new Message objects, move them around, etc. This makes a very convenient interface for slicing-and-dicing MIME messages.

You can create a new object structure by creating Message instances, adding attachments and all the appropriate

headers manually. For MIME messages though, the email package provides some convenient subclasses to make things easier.

Here are the classes:

class email.mime.base.MIMEBase(_maintype, _subtype, *, policy=compat32, **_params)

Module: email.mime.base

This is the base class for all the MIME-specific subclasses of Message. Ordinarily you won’t create instances

specifically of MIMEBase, although you could. MIMEBase is provided primarily as a convenient base class for

more specific MIME-aware subclasses.

The Python Library Reference, Release 3.13.2



_maintype is the Content-Type major type (e.g. text or image), and _subtype is the Content-Type minor

type (e.g. plain or gif). _params is a parameter key/value dictionary and is passed directly to Message.

add_header.

If policy is specified, (defaults to the compat32 policy) it will be passed to Message.

The MIMEBase class always adds a Content-Type header (based on _maintype, _subtype, and _params), and

a MIME-Version header (always set to 1.0).

Changed in version 3.6: Added policy keyword-only parameter.

class email.mime.nonmultipart.MIMENonMultipart

Module: email.mime.nonmultipart

A subclass of MIMEBase, this is an intermediate base class for MIME messages that are not multipart.

The primary purpose of this class is to prevent the use of the attach() method, which only makes sense for

multipart messages. If attach() is called, a MultipartConversionError exception is raised.

class email.mime.multipart.MIMEMultipart(_subtype=’mixed’, boundary=None, _subparts=None, *,

policy=compat32, **_params)

Module: email.mime.multipart

A subclass of MIMEBase, this is an intermediate base class for MIME messages that are multipart. Optional

_subtype defaults to mixed, but can be used to specify the subtype of the message. A Content-Type header

of multipart/_subtype will be added to the message object. A MIME-Version header will also be added.

Optional boundary is the multipart boundary string. When None (the default), the boundary is calculated when

needed (for example, when the message is serialized).

_subparts is a sequence of initial subparts for the payload. It must be possible to convert this sequence to a list.

You can always attach new subparts to the message by using the Message.attach method.

Optional policy argument defaults to compat32.

Additional parameters for the Content-Type header are taken from the keyword arguments, or passed into

the _params argument, which is a keyword dictionary.

Changed in version 3.6: Added policy keyword-only parameter.

class email.mime.application.MIMEApplication(_data, _subtype=’octet-stream’,

_encoder=email.encoders.encode_base64, *,

policy=compat32, **_params)

Module: email.mime.application

A subclass of MIMENonMultipart, the MIMEApplication class is used to represent MIME message objects

of major type application. _data contains the bytes for the raw application data. Optional _subtype specifies

the MIME subtype and defaults to octet-stream.

Optional _encoder is a callable (i.e. function) which will perform the actual encoding of the data for

transport. This callable takes one argument, which is the MIMEApplication instance. It should use

get_payload() and set_payload() to change the payload to encoded form. It should also add any

Content-Transfer-Encoding or other headers to the message object as necessary. The default encoding

is base64. See the email.encoders module for a list of the built-in encoders.

Optional policy argument defaults to compat32.

_params are passed straight through to the base class constructor.

Changed in version 3.6: Added policy keyword-only parameter.

class email.mime.audio.MIMEAudio(_audiodata, _subtype=None,

_encoder=email.encoders.encode_base64, *, policy=compat32,

**_params)

Module: email.mime.audio

A subclass of MIMENonMultipart, the MIMEAudio class is used to create MIME message objects of major

type audio. _audiodata contains the bytes for the raw audio data. If this data can be decoded as au, wav, The Python Library Reference, Release 3.13.2



aiff, or aifc, then the subtype will be automatically included in the Content-Type header. Otherwise you can

explicitly specify the audio subtype via the _subtype argument. If the minor type could not be guessed and

_subtype was not given, then TypeError is raised.

Optional _encoder is a callable (i.e. function) which will perform the actual encoding of the audio

data for transport. This callable takes one argument, which is the MIMEAudio instance. It should use

get_payload() and set_payload() to change the payload to encoded form. It should also add any

Content-Transfer-Encoding or other headers to the message object as necessary. The default encoding

is base64. See the email.encoders module for a list of the built-in encoders.

Optional policy argument defaults to compat32.

_params are passed straight through to the base class constructor.

Changed in version 3.6: Added policy keyword-only parameter.

class email.mime.image.MIMEImage(_imagedata, _subtype=None,

_encoder=email.encoders.encode_base64, *, policy=compat32,

**_params)

Module: email.mime.image

A subclass of MIMENonMultipart, the MIMEImage class is used to create MIME message objects of major

type image. _imagedata contains the bytes for the raw image data. If this data type can be detected (jpeg,

png, gif, tiff, rgb, pbm, pgm, ppm, rast, xbm, bmp, webp, and exr attempted), then the subtype will be auto-

matically included in the Content-Type header. Otherwise you can explicitly specify the image subtype via

the _subtype argument. If the minor type could not be guessed and _subtype was not given, then TypeError

is raised.

Optional _encoder is a callable (i.e. function) which will perform the actual encoding of the image

data for transport. This callable takes one argument, which is the MIMEImage instance. It should use

get_payload() and set_payload() to change the payload to encoded form. It should also add any

Content-Transfer-Encoding or other headers to the message object as necessary. The default encoding

is base64. See the email.encoders module for a list of the built-in encoders.

Optional policy argument defaults to compat32.

_params are passed straight through to the MIMEBase constructor.

Changed in version 3.6: Added policy keyword-only parameter.

class email.mime.message.MIMEMessage(_msg, _subtype=’rfc822’, *, policy=compat32)

Module: email.mime.message

A subclass of MIMENonMultipart, the MIMEMessage class is used to create MIME objects of main type

message . _msg is used as the payload, and must be an instance of class Message (or a subclass thereof),

otherwise a TypeError is raised.

Optional _subtype sets the subtype of the message; it defaults to rfc822.

Optional policy argument defaults to compat32.

Changed in version 3.6: Added policy keyword-only parameter.

class email.mime.text.MIMEText(_text, _subtype=’plain’ , _charset=None, *, policy=compat32)

Module: email.mime.text

A subclass of MIMENonMultipart, the MIMEText class is used to create MIME objects of major type text.

_text is the string for the payload. _subtype is the minor type and defaults to plain. _charset is the character

set of the text and is passed as an argument to the MIMENonMultipart constructor; it defaults to us-ascii

if the string contains only ascii code points, and utf-8 otherwise. The _charset parameter accepts either a

string or a Charset instance.

Unless the _charset argument is explicitly set to None, the MIMEText object created will have both a

Content-Type header with a charset parameter, and a Content-Transfer-Encoding header. This

means that a subsequent set_payload call will not result in an encoded payload, even if a charset is passed in

the set_payload command. You can “reset” this behavior by deleting the Content-Transfer-Encoding

The Python Library Reference, Release 3.13.2



header, after which a set_payload call will automatically encode the new payload (and add a new

Content-Transfer-Encoding header).

Optional policy argument defaults to compat32.

Changed in version 3.5: _charset also accepts Charset instances.

Changed in version 3.6: Added policy keyword-only parameter.



20.1.11 email.header: Internationalized headers

Source code: Lib/email/header.py



This module is part of the legacy (Compat32) email API. In the current API encoding and decoding of headers is

handled transparently by the dictionary-like API of the EmailMessage class. In addition to uses in legacy code, this module can be useful in applications that need to completely control the character sets used when encoding headers.

The remaining text in this section is the original documentation of the module.

RFC 2822 is the base standard that describes the format of email messages. It derives from the older RFC 822

standard which came into widespread use at a time when most email was composed of ASCII characters only. RFC

2822 is a specification written assuming email contains only 7-bit ASCII characters.

Of course, as email has been deployed worldwide, it has become internationalized, such that language specific char-acter sets can now be used in email messages. The base standard still requires email messages to be transferred using only 7-bit ASCII characters, so a slew of RFCs have been written describing how to encode email containing

non-ASCII characters into RFC 2822-compliant format. These RFCs include RFC 2045, RFC 2046, RFC 2047,

and RFC 2231. The email package supports these standards in its email.header and email.charset modules.

If you want to include non-ASCII characters in your email headers, say in the Subject or To fields, you should use

the Header class and assign the field in the Message object to an instance of Header instead of using a string for

the header value. Import the Header class from the email.header module. For example:

>>> from email.message import Message

>>> from email.header import Header

>>> msg = Message()

>>> h = Header('p\xf6stal', 'iso-8859-1')

>>> msg['Subject'] = h

>>> msg.as_string()

'Subject: =?iso-8859-1?q?p=F6stal?=\n\n'



Notice here how we wanted the Subject field to contain a non-ASCII character? We did this by creating a Header

instance and passing in the character set that the byte string was encoded in. When the subsequent Message instance

was flattened, the Subject field was properly RFC 2047 encoded. MIME-aware mail readers would show this header using the embedded ISO-8859-1 character.

Here is the Header class description:

class email.header.Header(s=None, charset=None, maxlinelen=None, header_name=None,

continuation_ws=’ ’, errors=’strict’)

Create a MIME-compliant header that can contain strings in different character sets.

Optional s is the initial header value. If None (the default), the initial header value is not set. You can later

append to the header with append() method calls. s may be an instance of bytes or str, but see the

append() documentation for semantics.

Optional charset serves two purposes: it has the same meaning as the charset argument to the append()

method. It also sets the default character set for all subsequent append() calls that omit the charset argument.

If charset is not provided in the constructor (the default), the us-ascii character set is used both as s’s initial

charset and as the default for subsequent append() calls.

The maximum line length can be specified explicitly via maxlinelen. For splitting the first line to a shorter

value (to account for the field header which isn’t included in s, e.g. Subject) pass in the name of the field in The Python Library Reference, Release 3.13.2



header_name. The default maxlinelen is 78, and the default value for header_name is None, meaning it is not

taken into account for the first line of a long, split header.

Optional continuation_ws must be RFC 2822-compliant folding whitespace, and is usually either a space or a

hard tab character. This character will be prepended to continuation lines. continuation_ws defaults to a single

space character.

Optional errors is passed straight through to the append() method.

append(s, charset=None, errors=’strict’)

Append the string s to the MIME header.

Optional charset, if given, should be a Charset instance (see email.charset) or the name of a char-

acter set, which will be converted to a Charset instance. A value of None (the default) means that the charset given in the constructor is used.

s may be an instance of bytes or str. If it is an instance of bytes, then charset is the encoding of that

byte string, and a UnicodeError will be raised if the string cannot be decoded with that character set.

If s is an instance of str, then charset is a hint specifying the character set of the characters in the string.

In either case, when producing an RFC 2822-compliant header using RFC 2047 rules, the string will be encoded using the output codec of the charset. If the string cannot be encoded using the output codec, a UnicodeError will be raised.

Optional errors is passed as the errors argument to the decode call if s is a byte string.

encode(splitchars=’;, \t’, maxlinelen=None, linesep=’\n’)

Encode a message header into an RFC-compliant format, possibly wrapping long lines and encapsulating non-ASCII parts in base64 or quoted-printable encodings.

Optional splitchars is a string containing characters which should be given extra weight by the splitting

algorithm during normal header wrapping. This is in very rough support of RFC 2822’s ‘higher level syntactic breaks’: split points preceded by a splitchar are preferred during line splitting, with the char-acters preferred in the order in which they appear in the string. Space and tab may be included in the string to indicate whether preference should be given to one over the other as a split point when other

split chars do not appear in the line being split. Splitchars does not affect RFC 2047 encoded lines.

maxlinelen, if given, overrides the instance’s value for the maximum line length.

linesep specifies the characters used to separate the lines of the folded header. It defaults to the most useful value for Python application code (\n), but \r\n can be specified in order to produce headers with RFC-compliant line separators.

Changed in version 3.2: Added the linesep argument.

The Header class also provides a number of methods to support standard operators and built-in functions.

__str__()

Returns an approximation of the Header as a string, using an unlimited line length. All pieces are converted to unicode using the specified encoding and joined together appropriately. Any pieces with a charset of 'unknown-8bit' are decoded as ASCII using the 'replace' error handler.

Changed in version 3.2: Added handling for the 'unknown-8bit' charset.

__eq__(other)

This method allows you to compare two Header instances for equality.

__ne__(other)

This method allows you to compare two Header instances for inequality.

The email.header module also provides the following convenient functions.

email.header.decode_header(header)

Decode a message header value without converting the character set. The header value is in header.

The Python Library Reference, Release 3.13.2



This function returns a list of (decoded_string, charset) pairs containing each of the decoded parts of

the header. charset is None for non-encoded parts of the header, otherwise a lower case string containing the

name of the character set specified in the encoded string.

Here’s an example:

>>> from email.header import decode_header

>>> decode_header('=?iso-8859-1?q?p=F6stal?=')

[(b'p\xf6stal', 'iso-8859-1')]



email.header.make_header(decoded_seq, maxlinelen=None, header_name=None, continuation_ws=’ ’)

Create a Header instance from a sequence of pairs as returned by decode_header().

decode_header() takes a header value string and returns a sequence of pairs of the format

(decoded_string, charset) where charset is the name of the character set.

This function takes one of those sequence of pairs and returns a Header instance. Optional maxlinelen,

header_name, and continuation_ws are as in the Header constructor.



20.1.12 email.charset: Representing character sets

Source code: Lib/email/charset.py



This module is part of the legacy (Compat32) email API. In the new API only the aliases table is used.

The remaining text in this section is the original documentation of the module.

This module provides a class Charset for representing character sets and character set conversions in email mes-sages, as well as a character set registry and several convenience methods for manipulating this registry. Instances of

Charset are used in several other modules within the email package.

Import this class from the email.charset module.

class email.charset.Charset(input_charset=DEFAULT_CHARSET)

Map character sets to their email properties.

This class provides information about the requirements imposed on email for a specific character set. It also

provides convenience routines for converting between character sets, given the availability of the applicable

codecs. Given a character set, it will do its best to provide information on how to use that character set in an

email message in an RFC-compliant way.

Certain character sets must be encoded with quoted-printable or base64 when used in email headers or bodies.

Certain character sets must be converted outright, and are not allowed in email.

Optional input_charset is as described below; it is always coerced to lower case. After being alias normalized

it is also used as a lookup into the registry of character sets to find out the header encoding, body encoding,

and output conversion codec to be used for the character set. For example, if input_charset is iso-8859-1,

then headers and bodies will be encoded using quoted-printable and no output conversion codec is necessary.

If input_charset is euc-jp, then headers will be encoded with base64, bodies will not be encoded, but output

text will be converted from the euc-jp character set to the iso-2022-jp character set.

Charset instances have the following data attributes:

input_charset

The initial character set specified. Common aliases are converted to their official email names (e.g. latin_1 is converted to iso-8859-1). Defaults to 7-bit us-ascii.

header_encoding

If the character set must be encoded before it can be used in an email header, this attribute will be set to charset.QP (for quoted-printable), charset.BASE64 (for base64 encoding), or charset. SHORTEST for the shortest of QP or BASE64 encoding. Otherwise, it will be None.

The Python Library Reference, Release 3.13.2



body_encoding

Same as header_encoding, but describes the encoding for the mail message’s body, which indeed may be different than the header encoding. charset.SHORTEST is not allowed for body_encoding.

output_charset

Some character sets must be converted before they can be used in email headers or bodies. If the in-put_charset is one of them, this attribute will contain the name of the character set output will be con-verted to. Otherwise, it will be None.

input_codec

The name of the Python codec used to convert the input_charset to Unicode. If no conversion codec is necessary, this attribute will be None.

output_codec

The name of the Python codec used to convert Unicode to the output_charset. If no conversion codec is necessary, this attribute will have the same value as the input_codec.

Charset instances also have the following methods:

get_body_encoding()

Return the content transfer encoding used for body encoding.

This is either the string quoted-printable or base64 depending on the encoding used, or it is a function, in which case you should call the function with a single argument, the Message object being encoded. The function should then set the Content-Transfer-Encoding header itself to whatever is appropriate.

Returns the string quoted-printable if body_encoding is QP, returns the string base64 if body_encoding is BASE64, and returns the string 7bit otherwise.

get_output_charset()

Return the output character set.

This is the output_charset attribute if that is not None, otherwise it is input_charset.

header_encode(string)

Header-encode the string string.

The type of encoding (base64 or quoted-printable) will be based on the header_encoding attribute.

header_encode_lines(string, maxlengths)

Header-encode a string by converting it first to bytes.

This is similar to header_encode() except that the string is fit into maximum line lengths as given by the argument maxlengths, which must be an iterator: each element returned from this iterator will provide the next maximum line length.

body_encode(string)

Body-encode the string string.

The type of encoding (base64 or quoted-printable) will be based on the body_encoding attribute.

The Charset class also provides a number of methods to support standard operations and built-in functions.

__str__()

Returns input_charset as a string coerced to lower case. __repr__() is an alias for __str__().

__eq__(other)

This method allows you to compare two Charset instances for equality.

__ne__(other)

This method allows you to compare two Charset instances for inequality.

The email.charset module also provides the following functions for adding new entries to the global character set, alias, and codec registries:

The Python Library Reference, Release 3.13.2



email.charset.add_charset(charset, header_enc=None, body_enc=None, output_charset=None)

Add character properties to the global registry.

charset is the input character set, and must be the canonical name of a character set.

Optional header_enc and body_enc is either charset.QP for quoted-printable, charset.BASE64 for base64

encoding, charset.SHORTEST for the shortest of quoted-printable or base64 encoding, or None for no en-

coding. SHORTEST is only valid for header_enc. The default is None for no encoding.

Optional output_charset is the character set that the output should be in. Conversions will proceed from input

charset, to Unicode, to the output charset when the method Charset.convert() is called. The default is to

output in the same character set as the input.

Both input_charset and output_charset must have Unicode codec entries in the module’s character set-to-codec

mapping; use add_codec() to add codecs the module does not know about. See the codecs module’s

documentation for more information.

The global character set registry is kept in the module global dictionary CHARSETS.

email.charset.add_alias(alias, canonical)

Add a character set alias. alias is the alias name, e.g. latin-1. canonical is the character set’s canonical

name, e.g. iso-8859-1.

The global charset alias registry is kept in the module global dictionary ALIASES.

email.charset.add_codec(charset, codecname)

Add a codec that map characters in the given character set to and from Unicode.

charset is the canonical name of a character set. codecname is the name of a Python codec, as appropriate for

the second argument to the str’s encode() method.



20.1.13 email.encoders: Encoders

Source code: Lib/email/encoders.py



This module is part of the legacy (Compat32) email API. In the new API the functionality is provided by the cte

parameter of the set_content() method.

This module is deprecated in Python 3. The functions provided here should not be called explicitly since the

MIMEText class sets the content type and CTE header using the _subtype and _charset values passed during the instantiation of that class.

The remaining text in this section is the original documentation of the module.

When creating Message objects from scratch, you often need to encode the payloads for transport through compliant mail servers. This is especially true for image/* and text/* type messages containing binary data.

The email package provides some convenient encoders in its encoders module. These encoders are actually

used by the MIMEAudio and MIMEImage class constructors to provide default encodings. All encoder functions take exactly one argument, the message object to encode. They usually extract the payload, encode it, and reset the payload to this newly encoded value. They should also set the Content-Transfer-Encoding header as appropriate.

Note that these functions are not meaningful for a multipart message. They must be applied to individual subparts

instead, and will raise a TypeError if passed a message whose type is multipart.

Here are the encoding functions provided:

email.encoders.encode_quopri(msg)

Encodes the payload into quoted-printable form and sets the Content-Transfer-Encoding header to

quoted-printable1 . This is a good encoding to use when most of your payload is normal printable data,

but contains a few unprintable characters.

1 Note that encoding with encode_quopri() also encodes all tabs and space characters in the data.

The Python Library Reference, Release 3.13.2



email.encoders.encode_base64(msg)

Encodes the payload into base64 form and sets the Content-Transfer-Encoding header to base64. This

is a good encoding to use when most of your payload is unprintable data since it is a more compact form than

quoted-printable. The drawback of base64 encoding is that it renders the text non-human readable.

email.encoders.encode_7or8bit(msg)

This doesn’t actually modify the message’s payload, but it does set the Content-Transfer-Encoding

header to either 7bit or 8bit as appropriate, based on the payload data.

email.encoders.encode_noop(msg)

This does nothing; it doesn’t even set the Content-Transfer-Encoding header.



20.1.14 email.utils: Miscellaneous utilities

Source code: Lib/email/utils.py



There are a couple of useful utilities provided in the email.utils module:

email.utils.localtime( dt=None)

Return local time as an aware datetime object. If called without arguments, return current time. Otherwise dt

argument should be a datetime instance, and it is converted to the local time zone according to the system

time zone database. If dt is naive (that is, dt.tzinfo is None), it is assumed to be in local time. The isdst

parameter is ignored.

Added in version 3.3.

Deprecated since version 3.12, will be removed in version 3.14: The isdst parameter.

email.utils.make_msgid(idstring=None, domain=None)

Returns a string suitable for an RFC 2822-compliant Message-ID header. Optional idstring if given, is a

string used to strengthen the uniqueness of the message id. Optional domain if given provides the portion of

the msgid after the ‘@’. The default is the local hostname. It is not normally necessary to override this default,

but may be useful certain cases, such as a constructing distributed system that uses a consistent domain name

across multiple hosts.

Changed in version 3.2: Added the domain keyword.

The remaining functions are part of the legacy (Compat32) email API. There is no need to directly use these with the new API, since the parsing and formatting they provide is done automatically by the header parsing machinery of the new API.

email.utils.quote(str)

Return a new string with backslashes in str replaced by two backslashes, and double quotes replaced by

backslash-double quote.

email.utils.unquote(str)

Return a new string which is an unquoted version of str. If str ends and begins with double quotes, they are

stripped off. Likewise if str ends and begins with angle brackets, they are stripped off.

email.utils.parseaddr( address, *, strict=True)

Parse address – which should be the value of some address-containing field such as To or Cc – into its con-

stituent realname and email address parts. Returns a tuple of that information, unless the parse fails, in which

case a 2-tuple of ('', '') is returned.

If strict is true, use a strict parser which rejects malformed inputs.

Changed in version 3.13: Add strict optional parameter and reject malformed inputs by default.



The Python Library Reference, Release 3.13.2



email.utils.formataddr(pair, charset=’utf-8’)

The inverse of parseaddr(), this takes a 2-tuple of the form (realname, email_address) and returns

the string value suitable for a To or Cc header. If the first element of pair is false, then the second element is

returned unmodified.

Optional charset is the character set that will be used in the RFC 2047 encoding of the realname if the

realname contains non-ASCII characters. Can be an instance of str or a Charset. Defaults to utf-8.

Changed in version 3.3: Added the charset option.

email.utils.getaddresses(fieldvalues, *, strict=True)

This method returns a list of 2-tuples of the form returned by parseaddr(). fieldvalues is a sequence of

header field values as might be returned by Message.get_all.

If strict is true, use a strict parser which rejects malformed inputs.

Here’s a simple example that gets all the recipients of a message:

from email.utils import getaddresses

tos = msg.get_all('to', [])

ccs = msg.get_all('cc', [])

resent_tos = msg.get_all('resent-to', [])

resent_ccs = msg.get_all('resent-cc', [])

all_recipients = getaddresses(tos + ccs + resent_tos + resent_ccs)



Changed in version 3.13: Add strict optional parameter and reject malformed inputs by default.

email.utils.parsedate( date)

Attempts to parse a date according to the rules in RFC 2822. however, some mailers don’t follow that format

as specified, so parsedate() tries to guess correctly in such cases. date is a string containing an RFC 2822

date, such as "Mon, 20 Nov 1995 19:12:08 -0500". If it succeeds in parsing the date, parsedate()

returns a 9-tuple that can be passed directly to time.mktime(); otherwise None will be returned. Note that

indexes 6, 7, and 8 of the result tuple are not usable.

email.utils.parsedate_tz(date)

Performs the same function as parsedate(), but returns either None or a 10-tuple; the first 9 elements make

up a tuple that can be passed directly to time.mktime(), and the tenth is the offset of the date’s timezone

from UTC (which is the official term for Greenwich Mean Time) 1. If the input string has no timezone, the last

element of the tuple returned is 0, which represents UTC. Note that indexes 6, 7, and 8 of the result tuple are

not usable.

email.utils.parsedate_to_datetime(date)

The inverse of format_datetime(). Performs the same function as parsedate(), but on success returns

a datetime; otherwise ValueError is raised if date contains an invalid value such as an hour greater than 23

or a timezone offset not between -24 and 24 hours. If the input date has a timezone of-0000, the datetime

will be a naive datetime, and if the date is conforming to the RFCs it will represent a time in UTC but with

no indication of the actual source timezone of the message the date comes from. If the input date has any

other valid timezone offset, the datetime will be an aware datetime with the corresponding a timezone

tzinfo .

Added in version 3.3.

email.utils.mktime_tz( tuple)

Turn a 10-tuple as returned by parsedate_tz() into a UTC timestamp (seconds since the Epoch). If the

timezone item in the tuple is None, assume local time.

email.utils.formatdate(timeval=None, localtime=False, usegmt=False)

Returns a date string as per RFC 2822, e.g.:

1 Note that the sign of the timezone offset is the opposite of the sign of the time.timezone variable for the same timezone; the latter variable

follows the POSIX standard while this module follows RFC 2822.

The Python Library Reference, Release 3.13.2



Fri, 09 Nov 2001 01:08:47-0000



Optional timeval if given is a floating-point time value as accepted by time.gmtime() and time.

localtime(), otherwise the current time is used.

Optional localtime is a flag that when True, interprets timeval, and returns a date relative to the local timezone

instead of UTC, properly taking daylight savings time into account. The default is False meaning UTC is

used.

Optional usegmt is a flag that when True, outputs a date string with the timezone as an ascii string GMT, rather

than a numeric-0000. This is needed for some protocols (such as HTTP). This only applies when localtime

is False. The default is False.

email.utils.format_datetime(dt, usegmt=False)

Like formatdate, but the input is a datetime instance. If it is a naive datetime, it is assumed to be “UTC

with no information about the source timezone”, and the conventional-0000 is used for the timezone. If it

is an aware datetime, then the numeric timezone offset is used. If it is an aware timezone with offset zero,

then usegmt may be set to True, in which case the string GMT is used instead of the numeric timezone offset.

This provides a way to generate standards conformant HTTP date headers.

Added in version 3.3.

email.utils.decode_rfc2231(s)

Decode the string s according to RFC 2231.

email.utils.encode_rfc2231(s, charset=None, language=None)

Encode the string s according to RFC 2231. Optional charset and language, if given is the character set name

and language name to use. If neither is given, s is returned as-is. If charset is given but language is not, the

string is encoded using the empty string for language.

email.utils.collapse_rfc2231_value(value, errors=’replace’, fallback_charset=’us-ascii’ )

When a header parameter is encoded in RFC 2231 format, Message.get_param may return a 3-tuple con-

taining the character set, language, and value. collapse_rfc2231_value() turns this into a unicode string.

Optional errors is passed to the errors argument of str’s encode() method; it defaults to 'replace'. Op-

tional fallback_charset specifies the character set to use if the one in the RFC 2231 header is not known by

Python; it defaults to 'us-ascii'.

For convenience, if the value passed to collapse_rfc2231_value() is not a tuple, it should be a string

and it is returned unquoted.

email.utils.decode_params(params)

Decode parameters list according to RFC 2231. params is a sequence of 2-tuples containing elements of the

form (content-type, string-value).



20.1.15 email.iterators: Iterators

Source code: Lib/email/iterators.py



Iterating over a message object tree is fairly easy with the Message.walk method. The email.iterators module provides some useful higher level iterations over message object trees.

email.iterators.body_line_iterator(msg, decode=False)

This iterates over all the payloads in all the subparts of msg, returning the string payloads line-by-line. It skips

over all the subpart headers, and it skips over any subpart with a payload that isn’t a Python string. This is

somewhat equivalent to reading the flat text representation of the message from a file using readline(),

skipping over all the intervening headers.

Optional decode is passed through to Message.get_payload.



The Python Library Reference, Release 3.13.2



email.iterators.typed_subpart_iterator(msg, maintype=’text’, subtype=None)

This iterates over all the subparts of msg, returning only those subparts that match the MIME type specified

by maintype and subtype.

Note that subtype is optional; if omitted, then subpart MIME type matching is done only with the main type.

maintype is optional too; it defaults to text.

Thus, by default typed_subpart_iterator() returns each subpart that has a MIME type of text/*.

The following function has been added as a useful debugging tool. It should not be considered part of the supported public interface for the package.

email.iterators._structure(msg, fp=None, level=0, include_default=False)

Prints an indented representation of the content types of the message object structure. For example:

>>> msg = email.message_from_file(somefile)

>>> _structure(msg)

multipart/mixed

text/plain

text/plain

multipart/digest

message/rfc822

text/plain

message/rfc822

text/plain

message/rfc822

text/plain

message/rfc822

text/plain

message/rfc822

text/plain

text/plain



Optional fp is a file-like object to print the output to. It must be suitable for Python’s print() function. level

is used internally. include_default, if true, prints the default type as well.



µ See also

Module smtplib

SMTP (Simple Mail Transport Protocol) client

Module poplib

POP (Post Office Protocol) client

Module imaplib

IMAP (Internet Message Access Protocol) client

Module mailbox

Tools for creating, reading, and managing collections of messages on disk using a variety standard formats.



20.2 json — JSON encoder and decoder

Source code: Lib/json/__init__.py



JSON (JavaScript Object Notation), specified by RFC 7159 (which obsoletes RFC 4627) and by ECMA-404, is a

lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of

JavaScript1 ).

1 As noted in the errata for RFC 7159, JSON permits literal U+2028 (LINE SEPARATOR) and U+2029 (PARAGRAPH SEPARATOR)

characters in strings, whereas JavaScript (as of ECMAScript Edition 5.1) does not.

The Python Library Reference, Release 3.13.2



Á Warning

Be cautious when parsing JSON data from untrusted sources. A malicious JSON string may cause the decoder

to consume considerable CPU and memory resources. Limiting the size of data to be parsed is recommended.



json exposes an API familiar to users of the standard library marshal and pickle modules.

Encoding basic Python object hierarchies:

>>> import json

>>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}]) '["foo", {"bar": ["baz", null, 1.0, 2]}]'

>>> print(json.dumps("\"foo\bar"))

"\"foo\bar"

>>> print(json.dumps('\u1234'))

"\u1234"

>>> print(json.dumps('\\'))

"\\"

>>> print(json.dumps({"c": 0, "b": 0, "a": 0}, sort_keys=True)) {"a": 0, "b": 0, "c": 0}

>>> from io import StringIO

>>> io = StringIO()

>>> json.dump(['streaming API'], io)

>>> io.getvalue()

'["streaming API"]'



Compact encoding:

>>> import json

>>> json.dumps([1, 2, 3, {'4': 5, '6': 7}], separators=(',', ':')) '[1,2,3,{"4":5,"6":7}]'



Pretty printing:

>>> import json

>>> print(json.dumps({'6': 7, '4': 5}, sort_keys=True, indent=4)) {

"4": 5,

"6": 7

}



Specializing JSON object encoding:

>>> import json

>>> def custom_json(obj):

... if isinstance(obj, complex):

... return {'__complex__': True, 'real': obj.real, 'imag': obj.imag} ... raise TypeError(f'Cannot serialize object of {type(obj)}') ...

>>> json.dumps(1 + 2j, default=custom_json)

'{"__complex__": true, "real": 1.0, "imag": 2.0}'



Decoding JSON:

>>> import json

>>> json.loads('["foo", {"bar":["baz", null, 1.0, 2]}]') ['foo', {'bar': ['baz', None, 1.0, 2]}]

>>> json.loads('"\\"foo\\bar"')

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

'"foo\x08ar'

>>> from io import StringIO

>>> io = StringIO('["streaming API"]')

>>> json.load(io)

['streaming API']



Specializing JSON object decoding:

>>> import json

>>> def as_complex(dct):

... if '__complex__' in dct:

... return complex(dct['real'], dct['imag'])

... return dct

...

>>> json.loads('{"__complex__": true, "real": 1, "imag": 2}', ... object_hook=as_complex)

(1+2j)

>>> import decimal

>>> json.loads('1.1', parse_float=decimal.Decimal)

Decimal('1.1')



Extending JSONEncoder:

>>> import json

>>> class ComplexEncoder(json.JSONEncoder):

... def default(self, obj):

... if isinstance(obj, complex):

... return [obj.real, obj.imag]

... # Let the base class default method raise the TypeError ... return super().default(obj)

...

>>> json.dumps(2 + 1j, cls=ComplexEncoder)

'[2.0, 1.0]'

>>> ComplexEncoder().encode(2 + 1j)

'[2.0, 1.0]'

>>> list(ComplexEncoder().iterencode(2 + 1j))

['[2.0', ', 1.0', ']']



Using json.tool from the shell to validate and pretty-print:

$ echo '{"json":"obj"}' | python -m json.tool

{

"json": "obj"

}

$ echo '{1.2:3.4}' | python -m json.tool

Expecting property name enclosed in double quotes: line 1 column 2 (char 1)



See Command Line Interface for detailed documentation.



® Note

JSON is a subset of YAML 1.2. The JSON produced by this module’s default settings (in particular, the default

separators value) is also a subset of YAML 1.0 and 1.1. This module can thus also be used as a YAML serializer.



The Python Library Reference, Release 3.13.2



® Note

This module’s encoders and decoders preserve input and output order by default. Order is only lost if the under-

lying containers are unordered.



20.2.1 Basic Usage

json.dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,

indent=None, separators=None, default=None, sort_keys=False, **kw)

Serialize obj as a JSON formatted stream to fp (a .write()-supporting file-like object) using this Python-to-

JSON conversion table.



® Note

Unlike pickle and marshal, JSON is not a framed protocol, so trying to serialize multiple objects with

repeated calls to dump() using the same fp will result in an invalid JSON file.



Parameters

• obj (object) – The Python object to be serialized.

• fp (file-like object) – The file-like object obj will be serialized to. The json module always

produces str objects, not bytes objects, therefore fp.write() must support str input.

• skipkeys (bool) – If True, keys that are not of a basic type (str, int, float, bool,

None) will be skipped instead of raising a TypeError. Default False.

• ensure_ascii (bool) – If True (the default), the output is guaranteed to have all in-

coming non-ASCII characters escaped. If False, these characters will be outputted as-is.

• check_circular (bool) – If False, the circular reference check for container types

is skipped and a circular reference will result in a RecursionError (or worse). Default True.

• allow_nan (bool) – If False, serialization of out-of-range float values (nan, inf,

-inf) will result in a ValueError, in strict compliance with the JSON specification. If True (the default), their JavaScript equivalents (NaN, Infinity,-Infinity) are used.

• cls (a JSONEncoder subclass) – If set, a custom JSON encoder with the default()

method overridden, for serializing into custom datatypes. If None (the default), JSONEncoder is used.

• indent (int | str | None) – If a positive integer or string, JSON array elements and

object members will be pretty-printed with that indent level. A positive integer indents that many spaces per level; a string (such as "\t") is used to indent each level. If zero, negative, or "" (the empty string), only newlines are inserted. If None (the default), the most compact representation is used.

• separators (tuple | None) – A two-tuple: (item_separator,

key_separator). If None (the default), separators defaults to (', ', ': ') if indent is None, and (',', ': ') otherwise. For the most compact JSON, specify (',', ':') to eliminate whitespace.

• default (callable | None) – A function that is called for objects that can’t otherwise be

serialized. It should return a JSON encodable version of the object or raise a TypeError. If None (the default), TypeError is raised.

• sort_keys (bool) – If True, dictionaries will be outputted sorted by key. Default

False.

Changed in version 3.2: Allow strings for indent in addition to integers.

The Python Library Reference, Release 3.13.2



Changed in version 3.4: Use (',', ': ') as default if indent is not None.

Changed in version 3.6: All optional parameters are now keyword-only.

json.dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,

indent=None, separators=None, default=None, sort_keys=False, **kw)

Serialize obj to a JSON formatted str using this conversion table. The arguments have the same meaning as

in dump().



® Note

Keys in key/value pairs of JSON are always of the type str. When a dictionary is converted into JSON, all the keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON and then back into a dictionary, the dictionary may not equal the original one. That is, loads(dumps(x)) != x if x has non-string keys.



json.load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,

object_pairs_hook=None, **kw)

Deserialize fp to a Python object using the JSON-to-Python conversion table.

Parameters

• fp (file-like object) – A .read()-supporting text file or binary file containing the JSON

document to be deserialized.

• cls (a JSONDecoder subclass) – If set, a custom JSON decoder. Additional keyword

arguments to load() will be passed to the constructor of cls. If None (the default), JSONDecoder is used.

• object_hook (callable | None) – If set, a function that is called with the result of any

object literal decoded (a dict). The return value of this function will be used instead of

the dict. This feature can be used to implement custom decoders, for example JSON-

RPC class hinting. Default None.

• object_pairs_hook (callable | None) – If set, a function that is called with the result of

any object literal decoded with an ordered list of pairs. The return value of this function

will be used instead of the dict. This feature can be used to implement custom decoders. If object_hook is also set, object_pairs_hook takes priority. Default None.

• parse_float (callable | None) – If set, a function that is called with the string of every

JSON float to be decoded. If None (the default), it is equivalent to float(num_str).

This can be used to parse JSON floats into custom datatypes, for example decimal.

Decimal.

• parse_int (callable | None) – If set, a function that is called with the string of every

JSON int to be decoded. If None (the default), it is equivalent to int(num_str). This

can be used to parse JSON integers into custom datatypes, for example float.

• parse_constant (callable | None) – If set, a function that is called with one of the

following strings: '-Infinity', 'Infinity', or 'NaN'. This can be used to raise an exception if invalid JSON numbers are encountered. Default None.

Raises

• JSONDecodeError – When the data being deserialized is not a valid JSON document.

• UnicodeDecodeError – When the data being deserialized does not contain UTF-8,

UTF-16 or UTF-32 encoded data.

Changed in version 3.1:

• Added the optional object_pairs_hook parameter.

• parse_constant doesn’t get called on ‘null’, ‘true’, ‘false’ anymore.

The Python Library Reference, Release 3.13.2



Changed in version 3.6:

• All optional parameters are now keyword-only.

• fp can now be a binary file. The input encoding should be UTF-8, UTF-16 or UTF-32.

Changed in version 3.11: The default parse_int of int() now limits the maximum length of the integer string

via the interpreter’s integer string conversion length limitation to help avoid denial of service attacks.

json.loads(s, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,

object_pairs_hook=None, **kw)

Identical to load(), but instead of a file-like object, deserialize s (a str, bytes or bytearray instance

containing a JSON document) to a Python object using this conversion table.

Changed in version 3.6: s can now be of type bytes or bytearray. The input encoding should be UTF-8,

UTF-16 or UTF-32.

Changed in version 3.9: The keyword argument encoding has been removed.



20.2.2 Encoders and Decoders

class json.JSONDecoder(*, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,

strict=True, object_pairs_hook=None)

Simple JSON decoder.

Performs the following translations in decoding by default:



JSON Python

object dict

array list

string str

number (int) int

number (real) float

true True

false False

null None



It also understands NaN, Infinity, and-Infinity as their corresponding float values, which is outside

the JSON spec.

object_hook is an optional function that will be called with the result of every JSON object decoded and its

return value will be used in place of the given dict. This can be used to provide custom deserializations (e.g.

to support JSON-RPC class hinting).

object_pairs_hook is an optional function that will be called with the result of every JSON object decoded with

an ordered list of pairs. The return value of object_pairs_hook will be used instead of the dict. This feature

can be used to implement custom decoders. If object_hook is also defined, the object_pairs_hook takes priority.

Changed in version 3.1: Added support for object_pairs_hook.

parse_float is an optional function that will be called with the string of every JSON float to be decoded. By

default, this is equivalent to float(num_str). This can be used to use another datatype or parser for JSON

floats (e.g. decimal.Decimal).

parse_int is an optional function that will be called with the string of every JSON int to be decoded. By default,

this is equivalent to int(num_str). This can be used to use another datatype or parser for JSON integers

(e.g. float).

parse_constant is an optional function that will be called with one of the following strings: '-Infinity',

'Infinity', 'NaN'. This can be used to raise an exception if invalid JSON numbers are encountered.

If strict is false (True is the default), then control characters will be allowed inside strings. Control characters

in this context are those with character codes in the 0–31 range, including '\t' (tab), '\n', '\r' and '\0'.

The Python Library Reference, Release 3.13.2



If the data being deserialized is not a valid JSON document, a JSONDecodeError will be raised.

Changed in version 3.6: All parameters are now keyword-only.

decode(s)

Return the Python representation of s (a str instance containing a JSON document).

JSONDecodeError will be raised if the given JSON document is not valid.

raw_decode(s)

Decode a JSON document from s (a str beginning with a JSON document) and return a 2-tuple of the Python representation and the index in s where the document ended.

This can be used to decode a JSON document from a string that may have extraneous data at the end.

class json.JSONEncoder(*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True,

sort_keys=False, indent=None, separators=None, default=None)

Extensible JSON encoder for Python data structures.

Supports the following objects and types by default:



Python JSON

dict object

list, tuple array

str string

int, float, int- & float-derived Enums number

True true

False false

None null



Changed in version 3.4: Added support for int- and float-derived Enum classes.

To extend this to recognize other objects, subclass and implement a default() method with another method

that returns a serializable object for o if possible, otherwise it should call the superclass implementation (to

raise TypeError).

If skipkeys is false (the default), a TypeError will be raised when trying to encode keys that are not str, int,

float or None. If skipkeys is true, such items are simply skipped.

If ensure_ascii is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped.

If ensure_ascii is false, these characters will be output as-is.

If check_circular is true (the default), then lists, dicts, and custom encoded objects will be checked for cir-

cular references during encoding to prevent an infinite recursion (which would cause a RecursionError).

Otherwise, no such check takes place.

If allow_nan is true (the default), then NaN, Infinity, and-Infinity will be encoded as such. This behav-

ior is not JSON specification compliant, but is consistent with most JavaScript based encoders and decoders.

Otherwise, it will be a ValueError to encode such floats.

If sort_keys is true (default: False), then the output of dictionaries will be sorted by key; this is useful for

regression tests to ensure that JSON serializations can be compared on a day-to-day basis.

If indent is a non-negative integer or string, then JSON array elements and object members will be pretty-

printed with that indent level. An indent level of 0, negative, or "" will only insert newlines. None (the

default) selects the most compact representation. Using a positive integer indent indents that many spaces per

level. If indent is a string (such as "\t"), that string is used to indent each level.

Changed in version 3.2: Allow strings for indent in addition to integers.

If specified, separators should be an (item_separator, key_separator) tuple. The default is (', ',

': ') if indent is None and (',', ': ') otherwise. To get the most compact JSON representation, you

should specify (',', ':') to eliminate whitespace.

The Python Library Reference, Release 3.13.2



Changed in version 3.4: Use (',', ': ') as default if indent is not None.

If specified, default should be a function that gets called for objects that can’t otherwise be serialized. It should

return a JSON encodable version of the object or raise a TypeError. If not specified, TypeError is raised.

Changed in version 3.6: All parameters are now keyword-only.

default(o)

Implement this method in a subclass such that it returns a serializable object for o, or calls the base

implementation (to raise a TypeError).

For example, to support arbitrary iterators, you could implement default() like this:

def default(self, o):

try:

iterable = iter(o)

except TypeError:

pass

else:

return list(iterable)

# Let the base class default method raise the TypeError return super().default(o)



encode(o)

Return a JSON string representation of a Python data structure, o. For example:

>>> json.JSONEncoder().encode({"foo": ["bar", "baz"]}) '{"foo": ["bar", "baz"]}'



iterencode(o)

Encode the given object, o, and yield each string representation as available. For example:

for chunk in json.JSONEncoder().iterencode(bigobject):

mysocket.write(chunk)



20.2.3 Exceptions

exception json.JSONDecodeError(msg, doc, pos)

Subclass of ValueError with the following additional attributes:

msg

The unformatted error message.

doc

The JSON document being parsed.

pos

The start index of doc where parsing failed.

lineno

The line corresponding to pos.

colno

The column corresponding to pos.

Added in version 3.5.



The Python Library Reference, Release 3.13.2



20.2.4 Standard Compliance and Interoperability

The JSON format is specified by RFC 7159 and by ECMA-404. This section details this module’s level of compli-

ance with the RFC. For simplicity, JSONEncoder and JSONDecoder subclasses, and parameters other than those explicitly mentioned, are not considered.

This module does not comply with the RFC in a strict fashion, implementing some extensions that are valid JavaScript but not valid JSON. In particular:

• Infinite and NaN number values are accepted and output;

• Repeated names within an object are accepted, and only the value of the last name-value pair is used.

Since the RFC permits RFC-compliant parsers to accept input texts that are not RFC-compliant, this module’s de-serializer is technically RFC-compliant under default settings.



Character Encodings

The RFC requires that JSON be represented using either UTF-8, UTF-16, or UTF-32, with UTF-8 being the rec-ommended default for maximum interoperability.

As permitted, though not required, by the RFC, this module’s serializer sets ensure_ascii=True by default, thus es-caping the output so that the resulting strings only contain ASCII characters.

Other than the ensure_ascii parameter, this module is defined strictly in terms of conversion between Python objects

and Unicode strings, and thus does not otherwise directly address the issue of character encodings.

The RFC prohibits adding a byte order mark (BOM) to the start of a JSON text, and this module’s serializer does not add a BOM to its output. The RFC permits, but does not require, JSON deserializers to ignore an initial BOM

in their input. This module’s deserializer raises a ValueError when an initial BOM is present.

The RFC does not explicitly forbid JSON strings which contain byte sequences that don’t correspond to valid Unicode characters (e.g. unpaired UTF-16 surrogates), but it does note that they may cause interoperability problems. By

default, this module accepts and outputs (when present in the original str) code points for such sequences.



Infinite and NaN Number Values

The RFC does not permit the representation of infinite or NaN number values. Despite that, by default, this module accepts and outputs Infinity,-Infinity, and NaN as if they were valid JSON number literal values:

>>> # Neither of these calls raises an exception, but the results are not valid␣

, →JSON

>>> json.dumps(float('-inf'))

'-Infinity'

>>> json.dumps(float('nan'))

'NaN'

>>> # Same when deserializing

>>> json.loads('-Infinity')

-inf

>>> json.loads('NaN')

nan



In the serializer, the allow_nan parameter can be used to alter this behavior. In the deserializer, the parse_constant parameter can be used to alter this behavior.



Repeated Names Within an Object

The RFC specifies that the names within a JSON object should be unique, but does not mandate how repeated names in JSON objects should be handled. By default, this module does not raise an exception; instead, it ignores all but the last name-value pair for a given name:



The Python Library Reference, Release 3.13.2



>>> weird_json = '{"x": 1, "x": 2, "x": 3}'

>>> json.loads(weird_json)

{'x': 3}



The object_pairs_hook parameter can be used to alter this behavior.



Top-level Non-Object, Non-Array Values

The old version of JSON specified by the obsolete RFC 4627 required that the top-level value of a JSON text must

be either a JSON object or array (Python dict or list), and could not be a JSON null, boolean, number, or string

value. RFC 7159 removed that restriction, and this module does not and has never implemented that restriction in either its serializer or its deserializer.

Regardless, for maximum interoperability, you may wish to voluntarily adhere to the restriction yourself.



Implementation Limitations

Some JSON deserializer implementations may set limits on:

• the size of accepted JSON texts

• the maximum level of nesting of JSON objects and arrays

• the range and precision of JSON numbers

• the content and maximum length of JSON strings

This module does not impose any such limits beyond those of the relevant Python datatypes themselves or the Python interpreter itself.

When serializing to JSON, beware any such limitations in applications that may consume your JSON. In particular, it is common for JSON numbers to be deserialized into IEEE 754 double precision numbers and thus subject to that

representation’s range and precision limitations. This is especially relevant when serializing Python int values of

extremely large magnitude, or when serializing instances of “exotic” numerical types such as decimal.Decimal.



20.2.5 Command Line Interface

Source code: Lib/json/tool.py



The json.tool module provides a simple command line interface to validate and pretty-print JSON objects.

If the optional infile and outfile arguments are not specified, sys.stdin and sys.stdout will be used respectively:

$ echo '{"json": "obj"}' | python -m json.tool

{

"json": "obj"

}

$ echo '{1.2:3.4}' | python -m json.tool

Expecting property name enclosed in double quotes: line 1 column 2 (char 1)



Changed in version 3.5: The output is now in the same order as the input. Use the--sort-keys option to sort the output of dictionaries alphabetically by key.



Command line options

infile

The JSON file to be validated or pretty-printed:



The Python Library Reference, Release 3.13.2



$ python -m json.tool mp_films.json

[

{

"title": "And Now for Something Completely Different", "year": 1971

},

{

"title": "Monty Python and the Holy Grail",

"year": 1975

}

]



If infile is not specified, read from sys.stdin.

outfile

Write the output of the infile to the given outfile. Otherwise, write it to sys.stdout.

--sort-keys

Sort the output of dictionaries alphabetically by key.

Added in version 3.5.

--no-ensure-ascii

Disable escaping of non-ascii characters, see json.dumps() for more information.

Added in version 3.9.

--json-lines

Parse every input line as separate JSON object.

Added in version 3.8.

--indent,--tab,--no-indent,--compact

Mutually exclusive options for whitespace control.

Added in version 3.9.

-h,--help

Show the help message.



20.3 mailbox — Manipulate mailboxes in various formats

Source code: Lib/mailbox.py



This module defines two classes, Mailbox and Message, for accessing and manipulating on-disk mailboxes and the messages they contain. Mailbox offers a dictionary-like mapping from keys to messages. Message extends the

email.message module’s Message class with format-specific state and behavior. Supported mailbox formats are Maildir, mbox, MH, Babyl, and MMDF.



µ See also

Module email

Represent and manipulate messages.



The Python Library Reference, Release 3.13.2



20.3.1 Mailbox objects

class mailbox.Mailbox

A mailbox, which may be inspected and modified.

The Mailbox class defines an interface and is not intended to be instantiated. Instead, format-specific sub-

classes should inherit from Mailbox and your code should instantiate a particular subclass.

The Mailbox interface is dictionary-like, with small keys corresponding to messages. Keys are issued by the

Mailbox instance with which they will be used and are only meaningful to that Mailbox instance. A key

continues to identify a message even if the corresponding message is modified, such as by replacing it with

another message.

Messages may be added to a Mailbox instance using the set-like method add() and removed using a del

statement or the set-like methods remove() and discard().

Mailbox interface semantics differ from dictionary semantics in some noteworthy ways. Each time a message

is requested, a new representation (typically a Message instance) is generated based upon the current state of

the mailbox. Similarly, when a message is added to a Mailbox instance, the provided message representation’s

contents are copied. In neither case is a reference to the message representation kept by the Mailbox instance.

The default Mailbox iterator iterates over message representations, not keys as the default dictionary

iterator does. Moreover, modification of a mailbox during iteration is safe and well-defined. Messages added

to the mailbox after an iterator is created will not be seen by the iterator. Messages removed from the mailbox

before the iterator yields them will be silently skipped, though using a key from an iterator may result in a

KeyError exception if the corresponding message is subsequently removed.



Á Warning

Be very cautious when modifying mailboxes that might be simultaneously changed by some other process.

The safest mailbox format to use for such tasks is Maildir; try to avoid using single-file formats such as

mbox for concurrent writing. If you’re modifying a mailbox, you must lock it by calling the lock() and

unlock() methods before reading any messages in the file or making any changes by adding or deleting a message. Failing to lock the mailbox runs the risk of losing messages or corrupting the entire mailbox.



Mailbox instances have the following methods:

add(message)

Add message to the mailbox and return the key that has been assigned to it.

Parameter message may be a Message instance, an email.message.Message instance, a string, a byte string, or a file-like object (which should be open in binary mode). If message is an instance of

the appropriate format-specific Message subclass (e.g., if it’s an mboxMessage instance and this is an

mbox instance), its format-specific information is used. Otherwise, reasonable defaults for format-specific information are used.

Changed in version 3.2: Support for binary input was added.

remove(key)

__delitem__(key)

discard(key)

Delete the message corresponding to key from the mailbox.

If no such message exists, a KeyError exception is raised if the method was called as remove() or

__delitem__() but no exception is raised if the method was called as discard(). The behavior

of discard() may be preferred if the underlying mailbox format supports concurrent modification by other processes.

__setitem__(key, message)

Replace the message corresponding to key with message. Raise a KeyError exception if no message already corresponds to key.

The Python Library Reference, Release 3.13.2



As with add(), parameter message may be a Message instance, an email.message.Message in-stance, a string, a byte string, or a file-like object (which should be open in binary mode). If message is

an instance of the appropriate format-specific Message subclass (e.g., if it’s an mboxMessage instance

and this is an mbox instance), its format-specific information is used. Otherwise, the format-specific information of the message that currently corresponds to key is left unchanged.

iterkeys()

Return an iterator over all keys

keys()

The same as iterkeys(), except that a list is returned rather than an iterator

itervalues()

__iter__()

Return an iterator over representations of all messages. The messages are represented as instances of the

appropriate format-specific Message subclass unless a custom message factory was specified when the Mailbox instance was initialized.



® Note

The behavior of __iter__() is unlike that of dictionaries, which iterate over keys.



values()

The same as itervalues(), except that a list is returned rather than an iterator

iteritems()

Return an iterator over (key, message) pairs, where key is a key and message is a message representation.

The messages are represented as instances of the appropriate format-specific Message subclass unless a custom message factory was specified when the Mailbox instance was initialized.

items()

The same as iteritems(), except that a list of pairs is returned rather than an iterator of pairs.

get(key, default=None)

__getitem__(key)

Return a representation of the message corresponding to key. If no such message exists, default is returned

if the method was called as get() and a KeyError exception is raised if the method was called as

__getitem__(). The message is represented as an instance of the appropriate format-specific Message subclass unless a custom message factory was specified when the Mailbox instance was initialized.

get_message(key)

Return a representation of the message corresponding to key as an instance of the appropriate format-

specific Message subclass, or raise a KeyError exception if no such message exists.

get_bytes(key)

Return a byte representation of the message corresponding to key, or raise a KeyError exception if no such message exists.

Added in version 3.2.

get_string(key)

Return a string representation of the message corresponding to key, or raise a KeyError exception if no

such message exists. The message is processed through email.message.Message to convert it to a 7bit clean representation.

get_file(key)

Return a file-like representation of the message corresponding to key, or raise a KeyError exception if no such message exists. The file-like object behaves as if open in binary mode. This file should be closed once it is no longer needed.

The Python Library Reference, Release 3.13.2



Changed in version 3.2: The file object really is a binary file; previously it was incorrectly returned in text

mode. Also, the file-like object now supports the context manager protocol: you can use a with statement to automatically close it.



® Note

Unlike other representations of messages, file-like representations are not necessarily independent of the Mailbox instance that created them or of the underlying mailbox. More specific documentation is provided by each subclass.



__contains__(key)

Return True if key corresponds to a message, False otherwise.

__len__()

Return a count of messages in the mailbox.

clear()

Delete all messages from the mailbox.

pop(key, default=None)

Return a representation of the message corresponding to key and delete the message. If no such mes-sage exists, return default. The message is represented as an instance of the appropriate format-specific

Message subclass unless a custom message factory was specified when the Mailbox instance was ini-tialized.

popitem()

Return an arbitrary (key, message) pair, where key is a key and message is a message representation, and

delete the corresponding message. If the mailbox is empty, raise a KeyError exception. The message is

represented as an instance of the appropriate format-specific Message subclass unless a custom message factory was specified when the Mailbox instance was initialized.

update(arg)

Parameter arg should be a key-to-message mapping or an iterable of (key, message) pairs. Updates the mailbox so that, for each given key and message, the message corresponding to key is set to message as if

by using __setitem__(). As with __setitem__(), each key must already correspond to a message

in the mailbox or else a KeyError exception will be raised, so in general it is incorrect for arg to be a Mailbox instance.



® Note

Unlike with dictionaries, keyword arguments are not supported.



flush()

Write any pending changes to the filesystem. For some Mailbox subclasses, changes are always written immediately and flush() does nothing, but you should still make a habit of calling this method.

lock()

Acquire an exclusive advisory lock on the mailbox so that other processes know not to modify it. An

ExternalClashError is raised if the lock is not available. The particular locking mechanisms used depend upon the mailbox format. You should always lock the mailbox before making any modifications to its contents.

unlock()

Release the lock on the mailbox, if any.

close()

Flush the mailbox, unlock it if necessary, and close any open files. For some Mailbox subclasses, this method does nothing.

The Python Library Reference, Release 3.13.2



Maildir objects

class mailbox.Maildir( dirname, factory=None, create=True)

A subclass of Mailbox for mailboxes in Maildir format. Parameter factory is a callable object that accepts a

file-like message representation (which behaves as if opened in binary mode) and returns a custom represen-

tation. If factory is None, MaildirMessage is used as the default message representation. If create is True,

the mailbox is created if it does not exist.

If create is True and the dirname path exists, it will be treated as an existing maildir without attempting to

verify its directory layout.

It is for historical reasons that dirname is named as such rather than path.

Maildir is a directory-based mailbox format invented for the qmail mail transfer agent and now widely sup-

ported by other programs. Messages in a Maildir mailbox are stored in separate files within a common directory

structure. This design allows Maildir mailboxes to be accessed and modified by multiple unrelated programs

without data corruption, so file locking is unnecessary.

Maildir mailboxes contain three subdirectories, namely: tmp, new, and cur. Messages are created momentar-

ily in the tmp subdirectory and then moved to the new subdirectory to finalize delivery. A mail user agent may

subsequently move the message to the cur subdirectory and store information about the state of the message

in a special “info” section appended to its file name.

Folders of the style introduced by the Courier mail transfer agent are also supported. Any subdirectory of the

main mailbox is considered a folder if '.' is the first character in its name. Folder names are represented by

Maildir without the leading '.'. Each folder is itself a Maildir mailbox but should not contain other folders.

Instead, a logical nesting is indicated using '.' to delimit levels, e.g., “Archived.2005.07”.

colon

The Maildir specification requires the use of a colon (':') in certain message file names. However, some operating systems do not permit this character in file names, If you wish to use a Maildir-like format on such an operating system, you should specify another character to use instead. The exclamation point ('!') is a popular choice. For example:

import mailbox

mailbox.Maildir.colon = '!'



The colon attribute may also be set on a per-instance basis.

Changed in version 3.13: Maildir now ignores files with a leading dot.

Maildir instances have all of the methods of Mailbox in addition to the following:

list_folders()

Return a list of the names of all folders.

get_folder(folder)

Return a Maildir instance representing the folder whose name is folder. A NoSuchMailboxError exception is raised if the folder does not exist.

add_folder(folder)

Create a folder whose name is folder and return a Maildir instance representing it.

remove_folder(folder)

Delete the folder whose name is folder. If the folder contains any messages, a NotEmptyError exception will be raised and the folder will not be deleted.

clean()

Delete temporary files from the mailbox that have not been accessed in the last 36 hours. The Maildir specification says that mail-reading programs should do this occasionally.



The Python Library Reference, Release 3.13.2



get_flags(key)

Return as a string the flags that are set on the message corresponding to key. This is the same as get_message(key).get_flags() but much faster, because it does not open the message file. Use this method when iterating over the keys to determine which messages are interesting to get.

If you do have a MaildirMessage object, use its get_flags() method instead, because changes

made by the message’s set_flags(), add_flag() and remove_flag() methods are not reflected

here until the mailbox’s __setitem__() method is called.

Added in version 3.13.

set_flags(key, flags)

On the message corresponding to key, set the flags specified by flags and unset all others. Calling some_mailbox.set_flags(key, flags) is similar to

one_message = some_mailbox.get_message(key)

one_message.set_flags(flags)

some_mailbox[key] = one_message



but faster, because it does not open the message file.

If you do have a MaildirMessage object, use its set_flags() method instead, because changes made

with this mailbox method will not be visible to the message object’s method, get_flags().

Added in version 3.13.

add_flag(key, flag)

On the message corresponding to key, set the flags specified by flag without changing other flags. To add more than one flag at a time, flag may be a string of more than one character.

Considerations for using this method versus the message object’s add_flag() method are similar to

those for set_flags(); see the discussion there.

Added in version 3.13.

remove_flag(key, flag)

On the message corresponding to key, unset the flags specified by flag without changing other flags. To remove more than one flag at a time, flag may be a string of more than one character.

Considerations for using this method versus the message object’s remove_flag() method are similar

to those for set_flags(); see the discussion there.

Added in version 3.13.

get_info(key)

Return a string containing the info for the message corresponding to key. This is the same as

get_message(key).get_info() but much faster, because it does not open the message file. Use this method when iterating over the keys to determine which messages are interesting to get.

If you do have a MaildirMessage object, use its get_info() method instead, because changes

made by the message’s set_info() method are not reflected here until the mailbox’s __setitem__() method is called.

Added in version 3.13.

set_info(key, info)

Set the info of the message corresponding to key to info. Calling some_mailbox.set_info(key, flags) is similar to

one_message = some_mailbox.get_message(key)

one_message.set_info(info)

some_mailbox[key] = one_message



The Python Library Reference, Release 3.13.2



but faster, because it does not open the message file.

If you do have a MaildirMessage object, use its set_info() method instead, because changes made

with this mailbox method will not be visible to the message object’s method, get_info().

Added in version 3.13.

Some Mailbox methods implemented by Maildir deserve special remarks:

add(message)

__setitem__(key, message)

update(arg)



Á Warning

These methods generate unique file names based upon the current process ID. When using multiple threads, undetected name clashes may occur and cause corruption of the mailbox unless threads are coordinated to avoid using these methods to manipulate the same mailbox simultaneously.



flush()

All changes to Maildir mailboxes are immediately applied, so this method does nothing.

lock()

unlock()

Maildir mailboxes do not support (or require) locking, so these methods do nothing.

close()

Maildir instances do not keep any open files and the underlying mailboxes do not support locking, so this method does nothing.

get_file(key)

Depending upon the host platform, it may not be possible to modify or remove the underlying message while the returned file remains open.



µ See also

maildir man page from Courier

A specification of the format. Describes a common extension for supporting folders.

Using maildir format

Notes on Maildir by its inventor. Includes an updated name-creation scheme and details on “info” seman-tics.



mbox objects

class mailbox.mbox(path, factory=None, create=True)

A subclass of Mailbox for mailboxes in mbox format. Parameter factory is a callable object that accepts a file-

like message representation (which behaves as if opened in binary mode) and returns a custom representation.

If factory is None, mboxMessage is used as the default message representation. If create is True, the mailbox

is created if it does not exist.

The mbox format is the classic format for storing mail on Unix systems. All messages in an mbox mailbox

are stored in a single file with the beginning of each message indicated by a line whose first five characters are

“From “.

Several variations of the mbox format exist to address perceived shortcomings in the original. In the interest

of compatibility, mbox implements the original format, which is sometimes referred to as mboxo. This means

that the Content-Length header, if present, is ignored and that any occurrences of “From “ at the beginning The Python Library Reference, Release 3.13.2



of a line in a message body are transformed to “>From “ when storing the message, although occurrences of

“>From “ are not transformed to “From “ when reading the message.

Some Mailbox methods implemented by mbox deserve special remarks:

get_file(key)

Using the file after calling flush() or close() on the mbox instance may yield unpredictable results or raise an exception.

lock()

unlock()

Three locking mechanisms are used—dot locking and, if available, the flock() and lockf() system calls.



µ See also

mbox man page from tin

A specification of the format, with details on locking.

Configuring Netscape Mail on Unix: Why The Content-Length Format is Bad

An argument for using the original mbox format rather than a variation.

“mbox” is a family of several mutually incompatible mailbox formats

A history of mbox variations.



MH objects

class mailbox.MH(path, factory=None, create=True)

A subclass of Mailbox for mailboxes in MH format. Parameter factory is a callable object that accepts a file-

like message representation (which behaves as if opened in binary mode) and returns a custom representation.

If factory is None, MHMessage is used as the default message representation. If create is True, the mailbox

is created if it does not exist.

MH is a directory-based mailbox format invented for the MH Message Handling System, a mail user agent.

Each message in an MH mailbox resides in its own file. An MH mailbox may contain other MH mailboxes

(called folders) in addition to messages. Folders may be nested indefinitely. MH mailboxes also support

sequences, which are named lists used to logically group messages without moving them to sub-folders. Se-

quences are defined in a file called .mh_sequences in each folder.

The MH class manipulates MH mailboxes, but it does not attempt to emulate all of mh’s behaviors. In particular,

it does not modify and is not affected by the context or .mh_profile files that are used by mh to store its

state and configuration.

MH instances have all of the methods of Mailbox in addition to the following:

Changed in version 3.13: Supported folders that don’t contain a .mh_sequences file.

list_folders()

Return a list of the names of all folders.

get_folder(folder)

Return an MH instance representing the folder whose name is folder. A NoSuchMailboxError exception is raised if the folder does not exist.

add_folder(folder)

Create a folder whose name is folder and return an MH instance representing it.

remove_folder(folder)

Delete the folder whose name is folder. If the folder contains any messages, a NotEmptyError exception will be raised and the folder will not be deleted.

The Python Library Reference, Release 3.13.2



get_sequences()

Return a dictionary of sequence names mapped to key lists. If there are no sequences, the empty dictio-nary is returned.

set_sequences(sequences)

Re-define the sequences that exist in the mailbox based upon sequences, a dictionary of names mapped

to key lists, like returned by get_sequences().

pack()

Rename messages in the mailbox as necessary to eliminate gaps in numbering. Entries in the sequences list are updated correspondingly.



® Note

Already-issued keys are invalidated by this operation and should not be subsequently used.



Some Mailbox methods implemented by MH deserve special remarks:

remove(key)

__delitem__(key)

discard(key)

These methods immediately delete the message. The MH convention of marking a message for deletion by prepending a comma to its name is not used.

lock()

unlock()

Three locking mechanisms are used—dot locking and, if available, the flock() and lockf() system calls. For MH mailboxes, locking the mailbox means locking the .mh_sequences file and, only for the duration of any operations that affect them, locking individual message files.

get_file(key)

Depending upon the host platform, it may not be possible to remove the underlying message while the returned file remains open.

flush()

All changes to MH mailboxes are immediately applied, so this method does nothing.

close()

MH instances do not keep any open files, so this method is equivalent to unlock().



µ See also

nmh - Message Handling System

Home page of nmh, an updated version of the original mh.

MH & nmh: Email for Users & Programmers

A GPL-licensed book on mh and nmh, with some information on the mailbox format.



Babyl objects

class mailbox.Babyl(path, factory=None, create=True)

A subclass of Mailbox for mailboxes in Babyl format. Parameter factory is a callable object that accepts a file-

like message representation (which behaves as if opened in binary mode) and returns a custom representation.

If factory is None, BabylMessage is used as the default message representation. If create is True, the mailbox

is created if it does not exist.

Babyl is a single-file mailbox format used by the Rmail mail user agent included with Emacs. The beginning

of a message is indicated by a line containing the two characters Control-Underscore ('\037') and Control-L

The Python Library Reference, Release 3.13.2



('\014'). The end of a message is indicated by the start of the next message or, in the case of the last message,

a line containing a Control-Underscore ('\037') character.

Messages in a Babyl mailbox have two sets of headers, original headers and so-called visible headers. Visible

headers are typically a subset of the original headers that have been reformatted or abridged to be more at-

tractive. Each message in a Babyl mailbox also has an accompanying list of labels, or short strings that record

extra information about the message, and a list of all user-defined labels found in the mailbox is kept in the

Babyl options section.

Babyl instances have all of the methods of Mailbox in addition to the following:

get_labels()

Return a list of the names of all user-defined labels used in the mailbox.



® Note

The actual messages are inspected to determine which labels exist in the mailbox rather than con-sulting the list of labels in the Babyl options section, but the Babyl section is updated whenever the mailbox is modified.



Some Mailbox methods implemented by Babyl deserve special remarks:

get_file(key)

In Babyl mailboxes, the headers of a message are not stored contiguously with the body of the message.

To generate a file-like representation, the headers and body are copied together into an io.BytesIO instance, which has an API identical to that of a file. As a result, the file-like object is truly independent of the underlying mailbox but does not save memory compared to a string representation.

lock()

unlock()

Three locking mechanisms are used—dot locking and, if available, the flock() and lockf() system calls.



µ See also

Format of Version 5 Babyl Files

A specification of the Babyl format.

Reading Mail with Rmail

The Rmail manual, with some information on Babyl semantics.



MMDF objects

class mailbox.MMDF(path, factory=None, create=True)

A subclass of Mailbox for mailboxes in MMDF format. Parameter factory is a callable object that accepts a

file-like message representation (which behaves as if opened in binary mode) and returns a custom represen-

tation. If factory is None, MMDFMessage is used as the default message representation. If create is True, the

mailbox is created if it does not exist.

MMDF is a single-file mailbox format invented for the Multichannel Memorandum Distribution Facility, a

mail transfer agent. Each message is in the same form as an mbox message but is bracketed before and after

by lines containing four Control-A ('\001') characters. As with the mbox format, the beginning of each

message is indicated by a line whose first five characters are “From “, but additional occurrences of “From

“ are not transformed to “>From “ when storing messages because the extra message separator lines prevent

mistaking such occurrences for the starts of subsequent messages.

Some Mailbox methods implemented by MMDF deserve special remarks:

The Python Library Reference, Release 3.13.2



get_file(key)

Using the file after calling flush() or close() on the MMDF instance may yield unpredictable results or raise an exception.

lock()

unlock()

Three locking mechanisms are used—dot locking and, if available, the flock() and lockf() system calls.



µ See also

mmdf man page from tin

A specification of MMDF format from the documentation of tin, a newsreader.

MMDF

A Wikipedia article describing the Multichannel Memorandum Distribution Facility.



20.3.2 Message objects

class mailbox.Message( message=None)

A subclass of the email.message module’s Message. Subclasses of mailbox.Message add mailbox-

format-specific state and behavior.

If message is omitted, the new instance is created in a default, empty state. If message is an email.message.

Message instance, its contents are copied; furthermore, any format-specific information is converted insofar

as possible if message is a Message instance. If message is a string, a byte string, or a file, it should contain an

RFC 2822-compliant message, which is read and parsed. Files should be open in binary mode, but text mode

files are accepted for backward compatibility.

The format-specific state and behaviors offered by subclasses vary, but in general it is only the properties that

are not specific to a particular mailbox that are supported (although presumably the properties are specific

to a particular mailbox format). For example, file offsets for single-file mailbox formats and file names for

directory-based mailbox formats are not retained, because they are only applicable to the original mailbox.

But state such as whether a message has been read by the user or marked as important is retained, because it

applies to the message itself.

There is no requirement that Message instances be used to represent messages retrieved using Mailbox

instances. In some situations, the time and memory required to generate Message representations might not

be acceptable. For such situations, Mailbox instances also offer string and file-like representations, and a

custom message factory may be specified when a Mailbox instance is initialized.



MaildirMessage objects

class mailbox.MaildirMessage(message=None)

A message with Maildir-specific behaviors. Parameter message has the same meaning as with the Message

constructor.

Typically, a mail user agent application moves all of the messages in the new subdirectory to the cur subdi-

rectory after the first time the user opens and closes the mailbox, recording that the messages are old whether

or not they’ve actually been read. Each message in cur has an “info” section added to its file name to store

information about its state. (Some mail readers may also add an “info” section to messages in new.) The “info”

section may take one of two forms: it may contain “2,” followed by a list of standardized flags (e.g., “2,FR”)

or it may contain “1,” followed by so-called experimental information. Standard flags for Maildir messages are

as follows:



The Python Library Reference, Release 3.13.2



Flag Meaning Explanation

D Draft Under composition

F Flagged Marked as important

P Passed Forwarded, resent, or bounced

R Replied Replied to

S Seen Read

T Trashed Marked for subsequent deletion



MaildirMessage instances offer the following methods:

get_subdir()

Return either “new” (if the message should be stored in the new subdirectory) or “cur” (if the message should be stored in the cur subdirectory).



® Note

A message is typically moved from new to cur after its mailbox has been accessed, whether or not the message has been read. A message msg has been read if "S" in msg.get_flags() is True.



set_subdir(subdir)

Set the subdirectory the message should be stored in. Parameter subdir must be either “new” or “cur”.

get_flags()

Return a string specifying the flags that are currently set. If the message complies with the standard Maildir format, the result is the concatenation in alphabetical order of zero or one occurrence of each of 'D', 'F', 'P', 'R', 'S', and 'T'. The empty string is returned if no flags are set or if “info” contains experimental semantics.

set_flags(flags)

Set the flags specified by flags and unset all others.

add_flag(flag)

Set the flag(s) specified by flag without changing other flags. To add more than one flag at a time, flag may be a string of more than one character. The current “info” is overwritten whether or not it contains experimental information rather than flags.

remove_flag(flag)

Unset the flag(s) specified by flag without changing other flags. To remove more than one flag at a time, flag maybe a string of more than one character. If “info” contains experimental information rather than flags, the current “info” is not modified.

get_date()

Return the delivery date of the message as a floating-point number representing seconds since the epoch.

set_date(date)

Set the delivery date of the message to date, a floating-point number representing seconds since the epoch.

get_info()

Return a string containing the “info” for a message. This is useful for accessing and modifying “info” that is experimental (i.e., not a list of flags).

set_info(info)

Set “info” to info, which should be a string.

When a MaildirMessage instance is created based upon an mboxMessage or MMDFMessage instance, the Status and X-Status headers are omitted and the following conversions take place:

The Python Library Reference, Release 3.13.2



Resulting state mboxMessage or MMDFMessage state

“cur” subdirectory O flag

F flag F flag

R flag A flag

S flag R flag

T flag D flag



When a MaildirMessage instance is created based upon an MHMessage instance, the following conversions take place:



Resulting state MHMessage state

“cur” subdirectory “unseen” sequence

“cur” subdirectory and S flag no “unseen” sequence

F flag “flagged” sequence

R flag “replied” sequence



When a MaildirMessage instance is created based upon a BabylMessage instance, the following conversions take place:



Resulting state BabylMessage state

“cur” subdirectory “unseen” label

“cur” subdirectory and S flag no “unseen” label

P flag “forwarded” or “resent” label

R flag “answered” label

T flag “deleted” label



mboxMessage objects

class mailbox.mboxMessage(message=None)

A message with mbox-specific behaviors. Parameter message has the same meaning as with the Message

constructor.

Messages in an mbox mailbox are stored together in a single file. The sender’s envelope address and the time

of delivery are typically stored in a line beginning with “From “ that is used to indicate the start of a message,

though there is considerable variation in the exact format of this data among mbox implementations. Flags

that indicate the state of the message, such as whether it has been read or marked as important, are typically

stored in Status and X-Status headers.

Conventional flags for mbox messages are as follows:



Flag Meaning Explanation

R Read Read

O Old Previously detected by MUA

D Deleted Marked for subsequent deletion

F Flagged Marked as important

A Answered Replied to



The “R” and “O” flags are stored in the Status header, and the “D”, “F”, and “A” flags are stored in the

X-Status header. The flags and headers typically appear in the order mentioned.

mboxMessage instances offer the following methods:



The Python Library Reference, Release 3.13.2



get_from()

Return a string representing the “From “ line that marks the start of the message in an mbox mailbox. The leading “From “ and the trailing newline are excluded.

set_from(from_, time_=None)

Set the “From “ line to from_, which should be specified without a leading “From “ or trailing newline. For convenience, time_ may be specified and will be formatted appropriately and appended to from_. If

time_ is specified, it should be a time.struct_time instance, a tuple suitable for passing to time.

strftime(), or True (to use time.gmtime()).

get_flags()

Return a string specifying the flags that are currently set. If the message complies with the conventional format, the result is the concatenation in the following order of zero or one occurrence of each of 'R', 'O', 'D', 'F', and 'A'.

set_flags(flags)

Set the flags specified by flags and unset all others. Parameter flags should be the concatenation in any order of zero or more occurrences of each of 'R', 'O', 'D', 'F', and 'A'.

add_flag(flag)

Set the flag(s) specified by flag without changing other flags. To add more than one flag at a time, flag may be a string of more than one character.

remove_flag(flag)

Unset the flag(s) specified by flag without changing other flags. To remove more than one flag at a time, flag maybe a string of more than one character.

When an mboxMessage instance is created based upon a MaildirMessage instance, a “From “ line is generated

based upon the MaildirMessage instance’s delivery date, and the following conversions take place:



Resulting state MaildirMessage state

R flag S flag

O flag “cur” subdirectory

D flag T flag

F flag F flag

A flag R flag



When an mboxMessage instance is created based upon an MHMessage instance, the following conversions take place:



Resulting state MHMessage state

R flag and O flag no “unseen” sequence

O flag “unseen” sequence

F flag “flagged” sequence

A flag “replied” sequence



When an mboxMessage instance is created based upon a BabylMessage instance, the following conversions take place:



Resulting state BabylMessage state

R flag and O flag no “unseen” label

O flag “unseen” label

D flag “deleted” label

A flag “answered” label

The Python Library Reference, Release 3.13.2



When a mboxMessage instance is created based upon an MMDFMessage instance, the “From “ line is copied and all flags directly correspond:



Resulting state MMDFMessage state

R flag R flag

O flag O flag

D flag D flag

F flag F flag

A flag A flag



MHMessage objects

class mailbox.MHMessage(message=None)

A message with MH-specific behaviors. Parameter message has the same meaning as with the Message

constructor.

MH messages do not support marks or flags in the traditional sense, but they do support sequences, which are

logical groupings of arbitrary messages. Some mail reading programs (although not the standard mh and nmh)

use sequences in much the same way flags are used with other formats, as follows:



Sequence Explanation

unseen Not read, but previously detected by MUA

replied Replied to

flagged Marked as important



MHMessage instances offer the following methods:

get_sequences()

Return a list of the names of sequences that include this message.

set_sequences(sequences)

Set the list of sequences that include this message.

add_sequence(sequence)

Add sequence to the list of sequences that include this message.

remove_sequence(sequence)

Remove sequence from the list of sequences that include this message.

When an MHMessage instance is created based upon a MaildirMessage instance, the following conversions take place:



Resulting state MaildirMessage state

“unseen” sequence no S flag

“replied” sequence R flag

“flagged” sequence F flag



When an MHMessage instance is created based upon an mboxMessage or MMDFMessage instance, the Status and X-Status headers are omitted and the following conversions take place:



Resulting state mboxMessage or MMDFMessage state

“unseen” sequence no R flag

“replied” sequence A flag

“flagged” sequence F flag

The Python Library Reference, Release 3.13.2



When an MHMessage instance is created based upon a BabylMessage instance, the following conversions take place:



Resulting state BabylMessage state

“unseen” sequence “unseen” label

“replied” sequence “answered” label



BabylMessage objects

class mailbox.BabylMessage(message=None)

A message with Babyl-specific behaviors. Parameter message has the same meaning as with the Message

constructor.

Certain message labels, called attributes, are defined by convention to have special meanings. The attributes

are as follows:



Label Explanation

unseen Not read, but previously detected by MUA

deleted Marked for subsequent deletion

filed Copied to another file or mailbox

answered Replied to

forwarded Forwarded

edited Modified by the user

resent Resent



By default, Rmail displays only visible headers. The BabylMessage class, though, uses the original headers

because they are more complete. Visible headers may be accessed explicitly if desired.

BabylMessage instances offer the following methods:

get_labels()

Return a list of labels on the message.

set_labels(labels)

Set the list of labels on the message to labels.

add_label(label)

Add label to the list of labels on the message.

remove_label(label)

Remove label from the list of labels on the message.

get_visible()

Return a Message instance whose headers are the message’s visible headers and whose body is empty.

set_visible(visible)

Set the message’s visible headers to be the same as the headers in message. Parameter visible should be a

Message instance, an email.message.Message instance, a string, or a file-like object (which should be open in text mode).

update_visible()

When a BabylMessage instance’s original headers are modified, the visible headers are not automatically modified to correspond. This method updates the visible headers as follows: each visible header with a corresponding original header is set to the value of the original header, each visible header without a corresponding original header is removed, and any of Date, From, Reply-To, To, CC, and Subject that are present in the original headers but not the visible headers are added to the visible headers.

The Python Library Reference, Release 3.13.2



When a BabylMessage instance is created based upon a MaildirMessage instance, the following conversions take place:



Resulting state MaildirMessage state

“unseen” label no S flag

“deleted” label T flag

“answered” label R flag

“forwarded” label P flag



When a BabylMessage instance is created based upon an mboxMessage or MMDFMessage instance, the Status and X-Status headers are omitted and the following conversions take place:



Resulting state mboxMessage or MMDFMessage state

“unseen” label no R flag

“deleted” label D flag

“answered” label A flag



When a BabylMessage instance is created based upon an MHMessage instance, the following conversions take place:



Resulting state MHMessage state

“unseen” label “unseen” sequence

“answered” label “replied” sequence



MMDFMessage objects

class mailbox.MMDFMessage(message=None)

A message with MMDF-specific behaviors. Parameter message has the same meaning as with the Message

constructor.

As with message in an mbox mailbox, MMDF messages are stored with the sender’s address and the delivery

date in an initial line beginning with “From “. Likewise, flags that indicate the state of the message are typically

stored in Status and X-Status headers.

Conventional flags for MMDF messages are identical to those of mbox message and are as follows:



Flag Meaning Explanation

R Read Read

O Old Previously detected by MUA

D Deleted Marked for subsequent deletion

F Flagged Marked as important

A Answered Replied to



The “R” and “O” flags are stored in the Status header, and the “D”, “F”, and “A” flags are stored in the

X-Status header. The flags and headers typically appear in the order mentioned.

MMDFMessage instances offer the following methods, which are identical to those offered by mboxMessage:

get_from()

Return a string representing the “From “ line that marks the start of the message in an mbox mailbox. The leading “From “ and the trailing newline are excluded.



The Python Library Reference, Release 3.13.2



set_from(from_, time_=None)

Set the “From “ line to from_, which should be specified without a leading “From “ or trailing newline. For convenience, time_ may be specified and will be formatted appropriately and appended to from_. If

time_ is specified, it should be a time.struct_time instance, a tuple suitable for passing to time.

strftime(), or True (to use time.gmtime()).

get_flags()

Return a string specifying the flags that are currently set. If the message complies with the conventional format, the result is the concatenation in the following order of zero or one occurrence of each of 'R', 'O', 'D', 'F', and 'A'.

set_flags(flags)

Set the flags specified by flags and unset all others. Parameter flags should be the concatenation in any order of zero or more occurrences of each of 'R', 'O', 'D', 'F', and 'A'.

add_flag(flag)

Set the flag(s) specified by flag without changing other flags. To add more than one flag at a time, flag may be a string of more than one character.

remove_flag(flag)

Unset the flag(s) specified by flag without changing other flags. To remove more than one flag at a time, flag maybe a string of more than one character.

When an MMDFMessage instance is created based upon a MaildirMessage instance, a “From “ line is generated

based upon the MaildirMessage instance’s delivery date, and the following conversions take place:



Resulting state MaildirMessage state

R flag S flag

O flag “cur” subdirectory

D flag T flag

F flag F flag

A flag R flag



When an MMDFMessage instance is created based upon an MHMessage instance, the following conversions take place:



Resulting state MHMessage state

R flag and O flag no “unseen” sequence

O flag “unseen” sequence

F flag “flagged” sequence

A flag “replied” sequence



When an MMDFMessage instance is created based upon a BabylMessage instance, the following conversions take place:



Resulting state BabylMessage state

R flag and O flag no “unseen” label

O flag “unseen” label

D flag “deleted” label

A flag “answered” label



When an MMDFMessage instance is created based upon an mboxMessage instance, the “From “ line is copied and all flags directly correspond:

The Python Library Reference, Release 3.13.2



Resulting state mboxMessage state

R flag R flag

O flag O flag

D flag D flag

F flag F flag

A flag A flag



20.3.3 Exceptions

The following exception classes are defined in the mailbox module:

exception mailbox.Error

The based class for all other module-specific exceptions.

exception mailbox.NoSuchMailboxError

Raised when a mailbox is expected but is not found, such as when instantiating a Mailbox subclass with a

path that does not exist (and with the create parameter set to False), or when opening a folder that does not

exist.

exception mailbox.NotEmptyError

Raised when a mailbox is not empty but is expected to be, such as when deleting a folder that contains messages.

exception mailbox.ExternalClashError

Raised when some mailbox-related condition beyond the control of the program causes it to be unable to

proceed, such as when failing to acquire a lock that another program already holds a lock, or when a uniquely

generated file name already exists.

exception mailbox.FormatError

Raised when the data in a file cannot be parsed, such as when an MH instance attempts to read a corrupted

.mh_sequences file.



20.3.4 Examples

A simple example of printing the subjects of all messages in a mailbox that seem interesting:

import mailbox

for message in mailbox.mbox('~/mbox'):

subject = message['subject'] # Could possibly be None.

if subject and 'python' in subject.lower():

print(subject)



To copy all mail from a Babyl mailbox to an MH mailbox, converting all of the format-specific information that can be converted:

import mailbox

destination = mailbox.MH('~/Mail')

destination.lock()

for message in mailbox.Babyl('~/RMAIL'):

destination.add(mailbox.MHMessage(message))

destination.flush()

destination.unlock()



This example sorts mail from several mailing lists into different mailboxes, being careful to avoid mail corruption due to concurrent modification by other programs, mail loss due to interruption of the program, or premature termination due to malformed messages in the mailbox:



The Python Library Reference, Release 3.13.2



import mailbox

import email.errors

list_names = ('python-list', 'python-dev', 'python-bugs')

boxes = {name: mailbox.mbox('~/email/%s' % name) for name in list_names} inbox = mailbox.Maildir('~/Maildir', factory=None)

for key in inbox.iterkeys():

try:

message = inbox[key]

except email.errors.MessageParseError:

continue # The message is malformed. Just leave it.

for name in list_names:

list_id = message['list-id']

if list_id and name in list_id:

# Get mailbox to use

box = boxes[name]

# Write copy to disk before removing original.

# If there's a crash, you might duplicate a message, but # that's better than losing a message completely.

box.lock()

box.add(message)

box.flush()

box.unlock()

# Remove original message

inbox.lock()

inbox.discard(key)

inbox.flush()

inbox.unlock()

break # Found destination, so stop looking.

for box in boxes.itervalues():

box.close()



20.4 mimetypes — Map filenames to MIME types

Source code: Lib/mimetypes.py



The mimetypes module converts between a filename or URL and the MIME type associated with the filename extension. Conversions are provided from filename to MIME type and from MIME type to filename extension; encodings are not supported for the latter conversion.

The module provides one class and a number of convenience functions. The functions are the normal interface to this module, but some applications may be interested in the class as well.

The functions described below provide the primary interface for this module. If the module has not been initialized,

they will call init() if they rely on the information init() sets up.

mimetypes.guess_type(url, strict=True)

Guess the type of a file based on its filename, path or URL, given by url. URL can be a string or a path-like

object.

The Python Library Reference, Release 3.13.2



The return value is a tuple (type, encoding) where type is None if the type can’t be guessed (missing or

unknown suffix) or a string of the form 'type/subtype', usable for a MIME content-type header.

encoding is None for no encoding or the name of the program used to encode (e.g. compress or gzip).

The encoding is suitable for use as a Content-Encoding header, not as a Content-Transfer-Encoding

header. The mappings are table driven. Encoding suffixes are case sensitive; type suffixes are first tried case

sensitively, then case insensitively.

The optional strict argument is a flag specifying whether the list of known MIME types is limited to only the

official types registered with IANA. When strict is True (the default), only the IANA types are supported;

when strict is False, some additional non-standard but commonly used MIME types are also recognized.

Changed in version 3.8: Added support for url being a path-like object.

Deprecated since version 3.13: Passing a file path instead of URL is soft deprecated. Use

guess_file_type() for this.

mimetypes.guess_file_type(path, *, strict=True)

Guess the type of a file based on its path, given by path. Similar to the guess_type() function, but accepts

a path instead of URL. Path can be a string, a bytes object or a path-like object.

Added in version 3.13.

mimetypes.guess_all_extensions(type, strict=True)

Guess the extensions for a file based on its MIME type, given by type. The return value is a list of strings

giving all possible filename extensions, including the leading dot ('.'). The extensions are not guaranteed

to have been associated with any particular data stream, but would be mapped to the MIME type type by

guess_type() and guess_file_type().

The optional strict argument has the same meaning as with the guess_type() function.

mimetypes.guess_extension(type, strict=True)

Guess the extension for a file based on its MIME type, given by type. The return value is a string giving a

filename extension, including the leading dot ('.'). The extension is not guaranteed to have been associ-

ated with any particular data stream, but would be mapped to the MIME type type by guess_type() and

guess_file_type() . If no extension can be guessed for type, None is returned.

The optional strict argument has the same meaning as with the guess_type() function.

Some additional functions and data items are available for controlling the behavior of the module.

mimetypes.init(files=None)

Initialize the internal data structures. If given, files must be a sequence of file names which should be used to

augment the default type map. If omitted, the file names to use are taken from knownfiles; on Windows,

the current registry settings are loaded. Each file named in files or knownfiles takes precedence over those

named before it. Calling init() repeatedly is allowed.

Specifying an empty list for files will prevent the system defaults from being applied: only the well-known

values will be present from a built-in list.

If files is None the internal data structure is completely rebuilt to its initial default value. This is a stable

operation and will produce the same results when called multiple times.

Changed in version 3.2: Previously, Windows registry settings were ignored.

mimetypes.read_mime_types(filename)

Load the type map given in the file filename, if it exists. The type map is returned as a dictionary mapping

filename extensions, including the leading dot ('.'), to strings of the form 'type/subtype'. If the file

filename does not exist or cannot be read, None is returned.

mimetypes.add_type(type, ext, strict=True)

Add a mapping from the MIME type type to the extension ext. When the extension is already known, the new

type will replace the old one. When the type is already known the extension will be added to the list of known

extensions.

The Python Library Reference, Release 3.13.2



When strict is True (the default), the mapping will be added to the official MIME types, otherwise to the

non-standard ones.

mimetypes.inited

Flag indicating whether or not the global data structures have been initialized. This is set to True by init().

mimetypes.knownfiles

List of type map file names commonly installed. These files are typically named mime.types and are installed

in different locations by different packages.

mimetypes.suffix_map

Dictionary mapping suffixes to suffixes. This is used to allow recognition of encoded files for which the encoding

and the type are indicated by the same extension. For example, the .tgz extension is mapped to .tar.gz to

allow the encoding and type to be recognized separately.

mimetypes.encodings_map

Dictionary mapping filename extensions to encoding types.

mimetypes.types_map

Dictionary mapping filename extensions to MIME types.

mimetypes.common_types

Dictionary mapping filename extensions to non-standard, but commonly found MIME types.

An example usage of the module:

>>> import mimetypes

>>> mimetypes.init()

>>> mimetypes.knownfiles

['/etc/mime.types', '/etc/httpd/mime.types', ... ] >>> mimetypes.suffix_map['.tgz']

'.tar.gz'

>>> mimetypes.encodings_map['.gz']

'gzip'

>>> mimetypes.types_map['.tgz']

'application/x-tar-gz'



20.4.1 MimeTypes Objects

The MimeTypes class may be useful for applications which may want more than one MIME-type database; it provides

an interface similar to the one of the mimetypes module.

class mimetypes.MimeTypes(filenames=(), strict=True)

This class represents a MIME-types database. By default, it provides access to the same database as the rest

of this module. The initial database is a copy of that provided by the module, and may be extended by loading

additional mime.types-style files into the database using the read() or readfp() methods. The mapping

dictionaries may also be cleared before loading additional data if the default data is not desired.

The optional filenames parameter can be used to cause additional files to be loaded “on top” of the default

database.

suffix_map

Dictionary mapping suffixes to suffixes. This is used to allow recognition of encoded files for which the encoding and the type are indicated by the same extension. For example, the .tgz extension is mapped to .tar.gz to allow the encoding and type to be recognized separately. This is initially a copy of the

global suffix_map defined in the module.

encodings_map

Dictionary mapping filename extensions to encoding types. This is initially a copy of the global

encodings_map defined in the module.

The Python Library Reference, Release 3.13.2



types_map

Tuple containing two dictionaries, mapping filename extensions to MIME types: the first dictionary is for the non-standards types and the second one is for the standard types. They are initialized by

common_types and types_map.

types_map_inv

Tuple containing two dictionaries, mapping MIME types to a list of filename extensions: the first dictio-nary is for the non-standards types and the second one is for the standard types. They are initialized by

common_types and types_map.

guess_extension(type, strict=True)

Similar to the guess_extension() function, using the tables stored as part of the object.

guess_type(url, strict=True)

Similar to the guess_type() function, using the tables stored as part of the object.

guess_file_type(path, *, strict=True)

Similar to the guess_file_type() function, using the tables stored as part of the object.

Added in version 3.13.

guess_all_extensions(type, strict=True)

Similar to the guess_all_extensions() function, using the tables stored as part of the object.

read(filename, strict=True)

Load MIME information from a file named filename. This uses readfp() to parse the file.

If strict is True, information will be added to list of standard types, else to the list of non-standard types.

readfp(fp, strict=True)

Load MIME type information from an open file fp. The file must have the format of the standard mime. types files.

If strict is True, information will be added to the list of standard types, else to the list of non-standard types.

read_windows_registry(strict=True)

Load MIME type information from the Windows registry.

Availability: Windows.

If strict is True, information will be added to the list of standard types, else to the list of non-standard types.

Added in version 3.2.

add_type(type, ext, strict=True)

Add a mapping from the MIME type type to the extension ext. When the extension is already known, the new type will replace the old one. When the type is already known the extension will be added to the list of known extensions.

When strict is True (the default), the mapping will be added to the official MIME types, otherwise to the non-standard ones.



20.5 base64 — Base16, Base32, Base64, Base85 Data Encodings

Source code: Lib/base64.py



This module provides functions for encoding binary data to printable ASCII characters and decoding such encodings

back to binary data. It provides encoding and decoding functions for the encodings specified in RFC 4648, which defines the Base16, Base32, and Base64 algorithms, and for the de-facto standard Ascii85 and Base85 encodings.

The Python Library Reference, Release 3.13.2



The RFC 4648 encodings are suitable for encoding binary data so that it can be safely sent by email, used as parts of URLs, or included as part of an HTTP POST request. The encoding algorithm is not the same as the uuencode program.

There are two interfaces provided by this module. The modern interface supports encoding bytes-like objects to ASCII

bytes, and decoding bytes-like objects or strings containing ASCII to bytes. Both base-64 alphabets defined in RFC

4648 (normal, and URL- and filesystem-safe) are supported.

The legacy interface does not support decoding from strings, but it does provide functions for encoding and decoding

to and from file objects. It only supports the Base64 standard alphabet, and it adds newlines every 76 characters as

per RFC 2045. Note that if you are looking for RFC 2045 support you probably want to be looking at the email package instead.

Changed in version 3.3: ASCII-only Unicode strings are now accepted by the decoding functions of the modern interface.

Changed in version 3.4: Any bytes-like objects are now accepted by all encoding and decoding functions in this module. Ascii85/Base85 support added.

The modern interface provides:

base64.b64encode(s, altchars=None)

Encode the bytes-like object s using Base64 and return the encoded bytes.

Optional altchars must be a bytes-like object of length 2 which specifies an alternative alphabet for the + and /

characters. This allows an application to e.g. generate URL or filesystem safe Base64 strings. The default is

None , for which the standard Base64 alphabet is used.

May assert or raise a ValueError if the length of altchars is not 2. Raises a TypeError if altchars is not a

bytes-like object.

base64.b64decode(s, altchars=None, validate=False)

Decode the Base64 encoded bytes-like object or ASCII string s and return the decoded bytes.

Optional altchars must be a bytes-like object or ASCII string of length 2 which specifies the alternative alphabet

used instead of the + and / characters.

A binascii.Error exception is raised if s is incorrectly padded.

If validate is False (the default), characters that are neither in the normal base-64 alphabet nor the alternative

alphabet are discarded prior to the padding check. If validate is True, these non-alphabet characters in the

input result in a binascii.Error.

For more information about the strict base64 check, see binascii.a2b_base64()

May assert or raise a ValueError if the length of altchars is not 2.

base64.standard_b64encode(s)

Encode bytes-like object s using the standard Base64 alphabet and return the encoded bytes.

base64.standard_b64decode(s)

Decode bytes-like object or ASCII string s using the standard Base64 alphabet and return the decoded bytes.

base64.urlsafe_b64encode(s)

Encode bytes-like object s using the URL- and filesystem-safe alphabet, which substitutes-instead of + and _

instead of / in the standard Base64 alphabet, and return the encoded bytes. The result can still contain =.

base64.urlsafe_b64decode(s)

Decode bytes-like object or ASCII string s using the URL- and filesystem-safe alphabet, which substitutes-

instead of + and _ instead of / in the standard Base64 alphabet, and return the decoded bytes.

base64.b32encode(s)

Encode the bytes-like object s using Base32 and return the encoded bytes.



The Python Library Reference, Release 3.13.2



base64.b32decode(s, casefold=False, map01=None)

Decode the Base32 encoded bytes-like object or ASCII string s and return the decoded bytes.

Optional casefold is a flag specifying whether a lowercase alphabet is acceptable as input. For security purposes,

the default is False.

RFC 4648 allows for optional mapping of the digit 0 (zero) to the letter O (oh), and for optional mapping

of the digit 1 (one) to either the letter I (eye) or letter L (el). The optional argument map01 when not None,

specifies which letter the digit 1 should be mapped to (when map01 is not None, the digit 0 is always mapped

to the letter O). For security purposes the default is None, so that 0 and 1 are not allowed in the input.

A binascii.Error is raised if s is incorrectly padded or if there are non-alphabet characters present in the

input.

base64.b32hexencode(s)

Similar to b32encode() but uses the Extended Hex Alphabet, as defined in RFC 4648.

Added in version 3.10.

base64.b32hexdecode(s, casefold=False)

Similar to b32decode() but uses the Extended Hex Alphabet, as defined in RFC 4648.

This version does not allow the digit 0 (zero) to the letter O (oh) and digit 1 (one) to either the letter I (eye)

or letter L (el) mappings, all these characters are included in the Extended Hex Alphabet and are not inter-

changeable.

Added in version 3.10.

base64.b16encode(s)

Encode the bytes-like object s using Base16 and return the encoded bytes.

base64.b16decode(s, casefold=False)

Decode the Base16 encoded bytes-like object or ASCII string s and return the decoded bytes.

Optional casefold is a flag specifying whether a lowercase alphabet is acceptable as input. For security purposes,

the default is False.

A binascii.Error is raised if s is incorrectly padded or if there are non-alphabet characters present in the

input.

base64.a85encode(b, *, foldspaces=False, wrapcol=0, pad=False, adobe=False)

Encode the bytes-like object b using Ascii85 and return the encoded bytes.

foldspaces is an optional flag that uses the special short sequence ‘y’ instead of 4 consecutive spaces (ASCII

0x20) as supported by ‘btoa’. This feature is not supported by the “standard” Ascii85 encoding.

wrapcol controls whether the output should have newline (b'\n') characters added to it. If this is non-zero,

each output line will be at most this many characters long, excluding the trailing newline.

pad controls whether the input is padded to a multiple of 4 before encoding. Note that the btoa implementation

always pads.

adobe controls whether the encoded byte sequence is framed with <~ and ~>, which is used by the Adobe

implementation.

Added in version 3.4.

base64.a85decode(b, *, foldspaces=False, adobe=False, ignorechars=b’ \t\n\r\x0b’ )

Decode the Ascii85 encoded bytes-like object or ASCII string b and return the decoded bytes.

foldspaces is a flag that specifies whether the ‘y’ short sequence should be accepted as shorthand for 4 consec-

utive spaces (ASCII 0x20). This feature is not supported by the “standard” Ascii85 encoding.

adobe controls whether the input sequence is in Adobe Ascii85 format (i.e. is framed with <~ and ~>).

ignorechars should be a bytes-like object or ASCII string containing characters to ignore from the input. This

should only contain whitespace characters, and by default contains all whitespace characters in ASCII.

The Python Library Reference, Release 3.13.2



Added in version 3.4.

base64.b85encode(b, pad=False)

Encode the bytes-like object b using base85 (as used in e.g. git-style binary diffs) and return the encoded bytes.

If pad is true, the input is padded with b'\0' so its length is a multiple of 4 bytes before encoding.

Added in version 3.4.

base64.b85decode(b)

Decode the base85-encoded bytes-like object or ASCII string b and return the decoded bytes. Padding is

implicitly removed, if necessary.

Added in version 3.4.

base64.z85encode(s)

Encode the bytes-like object s using Z85 (as used in ZeroMQ) and return the encoded bytes. See Z85 speci-

fication for more information.

Added in version 3.13.

base64.z85decode(s)

Decode the Z85-encoded bytes-like object or ASCII string s and return the decoded bytes. See Z85 specifi-

cation for more information.

Added in version 3.13.

The legacy interface:

base64.decode(input, output)

Decode the contents of the binary input file and write the resulting binary data to the output file. input and

output must be file objects. input will be read until input.readline() returns an empty bytes object.

base64.decodebytes(s)

Decode the bytes-like object s, which must contain one or more lines of base64 encoded data, and return the

decoded bytes.

Added in version 3.1.

base64.encode(input, output)

Encode the contents of the binary input file and write the resulting base64 encoded data to the output file.

input and output must be file objects. input will be read until input.read() returns an empty bytes object.

encode() inserts a newline character (b'\n') after every 76 bytes of the output, as well as ensuring that the

output always ends with a newline, as per RFC 2045 (MIME).

base64.encodebytes(s)

Encode the bytes-like object s, which can contain arbitrary binary data, and return bytes containing the base64-

encoded data, with newlines (b'\n') inserted after every 76 bytes of output, and ensuring that there is a trailing

newline, as per RFC 2045 (MIME).

Added in version 3.1.

An example usage of the module:

>>> import base64

>>> encoded = base64.b64encode(b'data to be encoded') >>> encoded

b'ZGF0YSB0byBiZSBlbmNvZGVk'

>>> data = base64.b64decode(encoded)

>>> data

b'data to be encoded'



The Python Library Reference, Release 3.13.2



20.5.1 Security Considerations

A new security considerations section was added to RFC 4648 (section 12); it’s recommended to review the security section for any code deployed to production.



µ See also

Module binascii

Support module containing ASCII-to-binary and binary-to-ASCII conversions.

RFC 1521- MIME (Multipurpose Internet Mail Extensions) Part One: Mechanisms for Specifying and

Describing the Format of Internet Message Bodies

Section 5.2, “Base64 Content-Transfer-Encoding,” provides the definition of the base64 encoding.



20.6 binascii — Convert between binary and ASCII



The binascii module contains a number of methods to convert between binary and various ASCII-encoded binary

representations. Normally, you will not use these functions directly but use wrapper modules like base64 instead.

The binascii module contains low-level functions written in C for greater speed that are used by the higher-level modules.



® Note

a2b_* functions accept Unicode strings containing only ASCII characters. Other functions only accept bytes-like

objects (such as bytes, bytearray and other objects that support the buffer protocol).

Changed in version 3.3: ASCII-only unicode strings are now accepted by the a2b_* functions.



The binascii module defines the following functions:

binascii.a2b_uu(string)

Convert a single line of uuencoded data back to binary and return the binary data. Lines normally contain 45

(binary) bytes, except for the last line. Line data may be followed by whitespace.

binascii.b2a_uu(data, *, backtick=False)

Convert binary data to a line of ASCII characters, the return value is the converted line, including a newline

char. The length of data should be at most 45. If backtick is true, zeros are represented by '`' instead of

spaces.

Changed in version 3.7: Added the backtick parameter.

binascii.a2b_base64(string, / , *, strict_mode=False)

Convert a block of base64 data back to binary and return the binary data. More than one line may be passed

at a time.

If strict_mode is true, only valid base64 data will be converted. Invalid base64 data will raise binascii.

Error .

Valid base64:

• Conforms to RFC 3548.

• Contains only characters from the base64 alphabet.

• Contains no excess data after padding (including excess padding, newlines, etc.).

• Does not start with a padding.

Changed in version 3.11: Added the strict_mode parameter.

The Python Library Reference, Release 3.13.2



binascii.b2a_base64(data, *, newline=True)

Convert binary data to a line of ASCII characters in base64 coding. The return value is the converted line,

including a newline char if newline is true. The output of this function conforms to RFC 3548.

Changed in version 3.6: Added the newline parameter.

binascii.a2b_qp(data, header=False)

Convert a block of quoted-printable data back to binary and return the binary data. More than one line may be

passed at a time. If the optional argument header is present and true, underscores will be decoded as spaces.

binascii.b2a_qp(data, quotetabs=False, istext=True, header=False)

Convert binary data to a line(s) of ASCII characters in quoted-printable encoding. The return value is the

converted line(s). If the optional argument quotetabs is present and true, all tabs and spaces will be encoded.

If the optional argument istext is present and true, newlines are not encoded but trailing whitespace will be

encoded. If the optional argument header is present and true, spaces will be encoded as underscores per

RFC 1522. If the optional argument header is present and false, newline characters will be encoded as well;

otherwise linefeed conversion might corrupt the binary data stream.

binascii.crc_hqx(data, value)

Compute a 16-bit CRC value of data, starting with value as the initial CRC, and return the result. This uses

the CRC-CCITT polynomial 16 12 5 x + x + x + 1, often represented as 0x1021. This CRC is used in the binhex4

format.

binascii.crc32(data[, value ])

Compute CRC-32, the unsigned 32-bit checksum of data, starting with an initial CRC of value. The default

initial CRC is zero. The algorithm is consistent with the ZIP file checksum. Since the algorithm is designed

for use as a checksum algorithm, it is not suitable for use as a general hash algorithm. Use as follows:

print(binascii.crc32(b"hello world"))

# Or, in two pieces:

crc = binascii.crc32(b"hello")

crc = binascii.crc32(b" world", crc)

print('crc32 = {:#010x}'.format(crc))



Changed in version 3.0: The result is always unsigned.

binascii.b2a_hex(data[, sep[, bytes_per_sep=1 ]])

binascii.hexlify(data[, sep[, bytes_per_sep=1 ]])

Return the hexadecimal representation of the binary data. Every byte of data is converted into the corre-

sponding 2-digit hex representation. The returned bytes object is therefore twice as long as the length of

data.

Similar functionality (but returning a text string) is also conveniently accessible using the bytes.hex()

method.

If sep is specified, it must be a single character str or bytes object. It will be inserted in the output after every

bytes_per_sep input bytes. Separator placement is counted from the right end of the output by default, if you

wish to count from the left, supply a negative bytes_per_sep value.

>>> import binascii

>>> binascii.b2a_hex(b'\xb9\x01\xef')

b'b901ef'

>>> binascii.hexlify(b'\xb9\x01\xef', '-')

b'b9-01-ef'

>>> binascii.b2a_hex(b'\xb9\x01\xef', b'_', 2)

b'b9_01ef'

>>> binascii.b2a_hex(b'\xb9\x01\xef', b' ',-2)

b'b901 ef'



Changed in version 3.8: The sep and bytes_per_sep parameters were added.

The Python Library Reference, Release 3.13.2



binascii.a2b_hex(hexstr)

binascii.unhexlify(hexstr)

Return the binary data represented by the hexadecimal string hexstr. This function is the inverse of

b2a_hex(). hexstr must contain an even number of hexadecimal digits (which can be upper or lower case),

otherwise an Error exception is raised.

Similar functionality (accepting only text string arguments, but more liberal towards whitespace) is also ac-

cessible using the bytes.fromhex() class method.

exception binascii.Error

Exception raised on errors. These are usually programming errors.

exception binascii.Incomplete

Exception raised on incomplete data. These are usually not programming errors, but may be handled by reading

a little more data and trying again.



µ See also

Module base64

Support for RFC compliant base64-style encoding in base 16, 32, 64, and 85.

Module quopri

Support for quoted-printable encoding used in MIME email messages.



20.7 quopri — Encode and decode MIME quoted-printable data

Source code: Lib/quopri.py



This module performs quoted-printable transport encoding and decoding, as defined in RFC 1521: “MIME (Mul-tipurpose Internet Mail Extensions) Part One: Mechanisms for Specifying and Describing the Format of Internet Message Bodies”. The quoted-printable encoding is designed for data where there are relatively few nonprintable

characters; the base64 encoding scheme available via the base64 module is more compact if there are many such characters, as when sending a graphics file.

quopri.decode(input, output, header=False)

Decode the contents of the input file and write the resulting decoded binary data to the output file. input and

output must be binary file objects. If the optional argument header is present and true, underscore will be

decoded as space. This is used to decode “Q”-encoded headers as described in RFC 1522: “MIME (Multi-

purpose Internet Mail Extensions) Part Two: Message Header Extensions for Non-ASCII Text”.

quopri.encode(input, output, quotetabs, header=False)

Encode the contents of the input file and write the resulting quoted-printable data to the output file. input and

output must be binary file objects. quotetabs, a non-optional flag which controls whether to encode embedded

spaces and tabs; when true it encodes such embedded whitespace, and when false it leaves them unencoded.

Note that spaces and tabs appearing at the end of lines are always encoded, as per RFC 1521. header is a flag

which controls if spaces are encoded as underscores as per RFC 1522.

quopri.decodestring(s, header=False)

Like decode(), except that it accepts a source bytes and returns the corresponding decoded bytes.

quopri.encodestring(s, quotetabs=False, header=False)

Like encode(), except that it accepts a source bytes and returns the corresponding encoded bytes. By

default, it sends a False value to quotetabs parameter of the encode() function.



µ See also

The Python Library Reference, Release 3.13.2



Module base64

Encode and decode MIME base64 data





CHAPTER




TWENTYONE



STRUCTURED MARKUP PROCESSING TOOLS



Python supports a variety of modules to work with various forms of structured data markup. This includes modules to work with the Standard Generalized Markup Language (SGML) and the Hypertext Markup Language (HTML), and several interfaces for working with the Extensible Markup Language (XML).



21.1 html — HyperText Markup Language support

Source code: Lib/html/__init__.py



This module defines utilities to manipulate HTML.

html.escape(s, quote=True)

Convert the characters &, < and > in string s to HTML-safe sequences. Use this if you need to display text that

might contain such characters in HTML. If the optional flag quote is true, the characters (") and (') are also

translated; this helps for inclusion in an HTML attribute value delimited by quotes, as in .

Added in version 3.2.

html.unescape(s)

Convert all named and numeric character references (e.g. >, >, >) in the string s to the corre-

sponding Unicode characters. This function uses the rules defined by the HTML 5 standard for both valid and

invalid character references, and the list of HTML 5 named character references.

Added in version 3.4.



Submodules in the html package are:

• html.parser – HTML/XHTML parser with lenient parsing mode

• html.entities – HTML entity definitions



21.2 html.parser — Simple HTML and XHTML parser

Source code: Lib/html/parser.py



This module defines a class HTMLParser which serves as the basis for parsing text files formatted in HTML (Hy-perText Mark-up Language) and XHTML.

class html.parser.HTMLParser(*, convert_charrefs=True)

Create a parser instance able to parse invalid markup.

If convert_charrefs is True (the default), all character references (except the ones in script/style elements)

are automatically converted to the corresponding Unicode characters.

The Python Library Reference, Release 3.13.2



An HTMLParser instance is fed HTML data and calls handler methods when start tags, end tags, text, com-

ments, and other markup elements are encountered. The user should subclass HTMLParser and override its

methods to implement the desired behavior.

This parser does not check that end tags match start tags or call the end-tag handler for elements which are

closed implicitly by closing an outer element.

Changed in version 3.4: convert_charrefs keyword argument added.

Changed in version 3.5: The default value for argument convert_charrefs is now True.



21.2.1 Example HTML Parser Application

As a basic example, below is a simple HTML parser that uses the HTMLParser class to print out start tags, end tags, and data as they are encountered:

from html.parser import HTMLParser

class MyHTMLParser(HTMLParser):

def handle_starttag(self, tag, attrs):

print("Encountered a start tag:", tag)

def handle_endtag(self, tag):

print("Encountered an end tag :", tag)

def handle_data(self, data):

print("Encountered some data :", data)

parser = MyHTMLParser()

parser.feed(' '

'





Parse me!


')



The output will then be:

Encountered a start tag: html

Encountered a start tag: head

Encountered a start tag: title

Encountered some data : Test

Encountered an end tag : title

Encountered an end tag : head

Encountered a start tag: body

Encountered a start tag: h1

Encountered some data : Parse me!

Encountered an end tag : h1

Encountered an end tag : body

Encountered an end tag : html



21.2.2 HTMLParser Methods

HTMLParser instances have the following methods:

HTMLParser.feed(data)

Feed some text to the parser. It is processed insofar as it consists of complete elements; incomplete data is

buffered until more data is fed or close() is called. data must be str.

HTMLParser.close()

Force processing of all buffered data as if it were followed by an end-of-file mark. This method may be

redefined by a derived class to define additional processing at the end of the input, but the redefined version

should always call the HTMLParser base class method close().

The Python Library Reference, Release 3.13.2



HTMLParser.reset()

Reset the instance. Loses all unprocessed data. This is called implicitly at instantiation time.

HTMLParser.getpos()

Return current line number and offset.

HTMLParser.get_starttag_text()

Return the text of the most recently opened start tag. This should not normally be needed for structured

processing, but may be useful in dealing with HTML “as deployed” or for re-generating input with minimal

changes (whitespace between attributes can be preserved, etc.).

The following methods are called when data or markup elements are encountered and they are meant to be overridden

in a subclass. The base class implementations do nothing (except for handle_startendtag()):

HTMLParser.handle_starttag(tag, attrs)

This method is called to handle the start tag of an element (e.g.

).

The tag argument is the name of the tag converted to lower case. The attrs argument is a list of (name,

value) pairs containing the attributes found inside the tag’s <> brackets. The name will be translated to lower

case, and quotes in the value have been removed, and character and entity references have been replaced.

For instance, for the tag , this method would be called as

handle_starttag('a', [('href', 'https://www.cwi.nl/')]).

All entity references from html.entities are replaced in the attribute values.

HTMLParser.handle_endtag(tag)

This method is called to handle the end tag of an element (e.g.



).

The tag argument is the name of the tag converted to lower case.

HTMLParser.handle_startendtag(tag, attrs)

Similar to handle_starttag(), but called when the parser encounters an XHTML-style empty tag (

... /> ). This method may be overridden by subclasses which require this particular lexical information; the

default implementation simply calls handle_starttag() and handle_endtag().

HTMLParser.handle_data(data)

This method is called to process arbitrary data (e.g. text nodes and the content of

and ).

HTMLParser.handle_entityref(name)

This method is called to process a named character reference of the form &name; (e.g. >), where name is

a general entity reference (e.g. 'gt'). This method is never called if convert_charrefs is True.

HTMLParser.handle_charref(name)

This method is called to process decimal and hexadecimal numeric character references of the form &#NNN;

and &#xNNN ;. For example, the decimal equivalent for > is >, whereas the hexadecimal is >;

in this case the method will receive '62' or 'x3E'. This method is never called if convert_charrefs is True.

HTMLParser.handle_comment(data)

This method is called when a comment is encountered (e.g. ).

For example, the comment will cause this method to be called with the argument '

comment '.

The content of Internet Explorer conditional comments (condcoms) will also be sent to this method,

so, for , this method will receive '[if IE

9]>IE9-specific content .

HTMLParser.handle_decl(decl)

This method is called to handle an HTML doctype declaration (e.g. ).

The decl parameter will be the entire contents of the declaration inside the markup (e.g. 'DOCTYPE

html' ).

The Python Library Reference, Release 3.13.2



HTMLParser.handle_pi(data)

Method called when a processing instruction is encountered. The data parameter will contain the entire pro-

cessing instruction. For example, for the processing instruction , this method would

be called as handle_pi("proc color='red'"). It is intended to be overridden by a derived class; the

base class implementation does nothing.



® Note

The HTMLParser class uses the SGML syntactic rules for processing instructions. An XHTML processing instruction using the trailing '?' will cause the '?' to be included in data.



HTMLParser.unknown_decl(data)

This method is called when an unrecognized declaration is read by the parser.

The data parameter will be the entire contents of the declaration inside the markup. It is sometimes

useful to be overridden by a derived class. The base class implementation does nothing.



21.2.3 Examples

The following class implements a parser that will be used to illustrate more examples:

from html.parser import HTMLParser

from html.entities import name2codepoint

class MyHTMLParser(HTMLParser):

def handle_starttag(self, tag, attrs):

print("Start tag:", tag)

for attr in attrs:

print(" attr:", attr)

def handle_endtag(self, tag):

print("End tag :", tag)

def handle_data(self, data):

print("Data :", data)

def handle_comment(self, data):

print("Comment :", data)

def handle_entityref(self, name):

c = chr(name2codepoint[name])

print("Named ent:", c)

def handle_charref(self, name):

if name.startswith('x'):

c = chr(int(name[1:], 16))

else:

c = chr(int(name))

print("Num ent :", c)

def handle_decl(self, data):

print("Decl :", data)

parser = MyHTMLParser()



Parsing a doctype:

The Python Library Reference, Release 3.13.2



>>> parser.feed(' ... '"http://www.w3.org/TR/html4/strict.dtd">')

Decl : DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/

, →html4/strict.dtd"



Parsing an element with a few attributes and a title:

>>> parser.feed('') Start tag: img

attr: ('src', 'python-logo.png')

attr: ('alt', 'The Python logo')

>>>

>>> parser.feed('





Python


')

Start tag: h1

Data : Python

End tag : h1



The content of script and style elements is returned as is, without further parsing:

>>> parser.feed(') Start tag: style

attr: ('type', 'text/css')

Data : #python { color: green }

End tag : style

>>> parser.feed('')

Start tag: script

attr: ('type', 'text/javascript')

Data : alert("hello!");

End tag : script



Parsing comments:

>>> parser.feed(''

... '') Comment : a comment

Comment : [if IE 9]>IE-specific content



Parsing named and numeric character references and converting them to the correct char (note: these 3 references are all equivalent to '>'):

>>> parser.feed('>>>')

Named ent: >

Num ent : >

Num ent : >



Feeding incomplete chunks to feed() works, but handle_data() might be called more than once (unless con-vert_charrefs is set to True):

>>> for chunk in [', 'an>buff', 'ered ', 'text, 'pan>']: ... parser.feed(chunk)

...

Start tag: span

Data : buff

Data : ered

Data : text

End tag : span

The Python Library Reference, Release 3.13.2



Parsing invalid HTML (e.g. unquoted attributes) also works:

>>> parser.feed('

tag soup

') Start tag: p

Start tag: a

attr: ('class', 'link')

attr: ('href', '#main')

Data : tag soup

End tag : p

End tag : a



21.3 html.entities — Definitions of HTML general entities

Source code: Lib/html/entities.py



This module defines four dictionaries, html5, name2codepoint, codepoint2name, and entitydefs.

html.entities.html5

A dictionary that maps HTML5 named character references1 to the equivalent Unicode character(s), e.g.

html5['gt;'] == '>' . Note that the trailing semicolon is included in the name (e.g. 'gt;'), however

some of the names are accepted by the standard even without the semicolon: in this case the name is present

with and without the ';'. See also html.unescape().

Added in version 3.3.

html.entities.entitydefs

A dictionary mapping XHTML 1.0 entity definitions to their replacement text in ISO Latin-1.

html.entities.name2codepoint

A dictionary that maps HTML4 entity names to the Unicode code points.

html.entities.codepoint2name

A dictionary that maps Unicode code points to HTML4 entity names.



21.4 XML Processing Modules

Source code: Lib/xml/



Python’s interfaces for processing XML are grouped in the xml package.



Á Warning

The XML modules are not secure against erroneous or maliciously constructed data. If you need to parse un-

trusted or unauthenticated data see the XML vulnerabilities and The defusedxml Package sections.



It is important to note that modules in the xml package require that there be at least one SAX-compliant XML parser

available. The Expat parser is included with Python, so the xml.parsers.expat module will always be available.

The documentation for the xml.dom and xml.sax packages are the definition of the Python bindings for the DOM and SAX interfaces.

The XML handling submodules are:

• xml.etree.ElementTree: the ElementTree API, a simple and lightweight XML processor

1 See https://html.spec.whatwg.org/multipage/named-characters.html#named-character-references

The Python Library Reference, Release 3.13.2



• xml.dom: the DOM API definition

• xml.dom.minidom: a minimal DOM implementation

• xml.dom.pulldom: support for building partial DOM trees

• xml.sax: SAX2 base classes and convenience functions

• xml.parsers.expat: the Expat parser binding



21.4.1 XML vulnerabilities

The XML processing modules are not secure against maliciously constructed data. An attacker can abuse XML features to carry out denial of service attacks, access local files, generate network connections to other machines, or circumvent firewalls.

The following table gives an overview of the known attacks and whether the various modules are vulnerable to them.



kind sax etree minidom pulldom xmlrpc

billion laughs Vulnerable Vulnerable Vulnerable Vulnerable Vulnerable

(1) (1) (1) (1) (1)

quadratic blowup Vulnerable Vulnerable Vulnerable Vulnerable Vulnerable

(1) (1) (1) (1) (1)

external entity expan- Safe (5) Safe (2) Safe (3) Safe (5) Safe (4)

sion

DTD retrieval Safe (5) Safe Safe Safe (5) Safe

decompression bomb Safe Safe Safe Safe Vulnerable

large tokens Vulnerable Vulnerable Vulnerable Vulnerable Vulnerable

(6) (6) (6) (6) (6)

1. Expat 2.4.1 and newer is not vulnerable to the “billion laughs” and “quadratic blowup” vulnerabilities. Items still

listed as vulnerable due to potential reliance on system-provided libraries. Check pyexpat.EXPAT_VERSION.

2. xml.etree.ElementTree doesn’t expand external entities and raises a ParseError when an entity occurs.

3. xml.dom.minidom doesn’t expand external entities and simply returns the unexpanded entity verbatim.

4. xmlrpc.client doesn’t expand external entities and omits them.

5. Since Python 3.7.1, external general entities are no longer processed by default.

6. Expat 2.6.0 and newer is not vulnerable to denial of service through quadratic runtime caused by parsing

large tokens. Items still listed as vulnerable due to potential reliance on system-provided libraries. Check

pyexpat.EXPAT_VERSION .

billion laughs / exponential entity expansion

The Billion Laughs attack – also known as exponential entity expansion – uses multiple levels of nested entities.

Each entity refers to another entity several times, and the final entity definition contains a small string. The

exponential expansion results in several gigabytes of text and consumes lots of memory and CPU time.

quadratic blowup entity expansion

A quadratic blowup attack is similar to a Billion Laughs attack; it abuses entity expansion, too. Instead of

nested entities it repeats one large entity with a couple of thousand chars over and over again. The attack isn’t

as efficient as the exponential case but it avoids triggering parser countermeasures that forbid deeply nested

entities.

external entity expansion

Entity declarations can contain more than just text for replacement. They can also point to external resources

or local files. The XML parser accesses the resource and embeds the content into the XML document.

DTD retrieval

Some XML libraries like Python’s xml.dom.pulldom retrieve document type definitions from remote or

local locations. The feature has similar implications as the external entity expansion issue.

The Python Library Reference, Release 3.13.2



decompression bomb

Decompression bombs (aka ZIP bomb) apply to all XML libraries that can parse compressed XML streams

such as gzipped HTTP streams or LZMA-compressed files. For an attacker it can reduce the amount of

transmitted data by three magnitudes or more.

large tokens

Expat needs to re-parse unfinished tokens; without the protection introduced in Expat 2.6.0, this can lead to

quadratic runtime that can be used to cause denial of service in the application parsing XML. The issue is

known as CVE 2023-52425.

The documentation for defusedxml on PyPI has further information about all known attack vectors with examples and references.



21.4.2 The defusedxml Package

defusedxml is a pure Python package with modified subclasses of all stdlib XML parsers that prevent any potentially malicious operation. Use of this package is recommended for any server code that parses untrusted XML data. The package also ships with example exploits and extended documentation on more XML exploits such as XPath injection.



21.5 xml.etree.ElementTree — The ElementTree XML API

Source code: Lib/xml/etree/ElementTree.py



The xml.etree.ElementTree module implements a simple and efficient API for parsing and creating XML data.

Changed in version 3.3: This module will use a fast implementation whenever available.

Deprecated since version 3.3: The xml.etree.cElementTree module is deprecated.



Á Warning

The xml.etree.ElementTree module is not secure against maliciously constructed data. If you need to parse

untrusted or unauthenticated data see XML vulnerabilities.



21.5.1 Tutorial

This is a short tutorial for using xml.etree.ElementTree (ET in short). The goal is to demonstrate some of the building blocks and basic concepts of the module.



XML tree and elements

XML is an inherently hierarchical data format, and the most natural way to represent it is with a tree. ET has two

classes for this purpose -ElementTree represents the whole XML document as a tree, and Element represents a single node in this tree. Interactions with the whole document (reading and writing to/from files) are usually done

on the ElementTree level. Interactions with a single XML element and its sub-elements are done on the Element level.



Parsing XML

We’ll be using the fictive country_data.xml XML document as the sample data for this section:

<?xml version="1.0"?>

<data>

<country name="Liechtenstein">

<rank>1</rank>

<year>2008</year>

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

<gdppc>141100</gdppc>

<neighbor name="Austria" direction="E"/>

<neighbor name="Switzerland" direction="W"/>

</country>

<country name="Singapore">

<rank>4</rank>

<year>2011</year>

<gdppc>59900</gdppc>

<neighbor name="Malaysia" direction="N"/>

</country>

<country name="Panama">

<rank>68</rank>

<year>2011</year>

<gdppc>13600</gdppc>

<neighbor name="Costa Rica" direction="W"/>

<neighbor name="Colombia" direction="E"/>

</country>

</data>



We can import this data by reading from a file:

import xml.etree.ElementTree as ET

tree = ET.parse('country_data.xml')

root = tree.getroot()



Or directly from a string:

root = ET.fromstring(country_data_as_string)



fromstring() parses XML from a string directly into an Element, which is the root element of the parsed tree.

Other parsing functions may create an ElementTree. Check the documentation to be sure.

As an Element, root has a tag and a dictionary of attributes:

>>> root.tag

'data'

>>> root.attrib

{}



It also has children nodes over which we can iterate:

>>> for child in root:

... print(child.tag, child.attrib)

...

country {'name': 'Liechtenstein'}

country {'name': 'Singapore'}

country {'name': 'Panama'}



Children are nested, and we can access specific child nodes by index:

>>> root[0][1].text

'2008'



® Note

Not all elements of the XML input will end up as elements of the parsed tree. Currently, this module skips over

any XML comments, processing instructions, and document type declarations in the input. Nevertheless, trees The Python Library Reference, Release 3.13.2



built using this module’s API rather than parsing from XML text can have comments and processing instructions

in them; they will be included when generating XML output. A document type declaration may be accessed by

passing a custom TreeBuilder instance to the XMLParser constructor.



Pull API for non-blocking parsing

Most parsing functions provided by this module require the whole document to be read at once before returning

any result. It is possible to use an XMLParser and feed data into it incrementally, but it is a push API that calls methods on a callback target, which is too low-level and inconvenient for most needs. Sometimes what the user really wants is to be able to parse XML incrementally, without blocking operations, while enjoying the convenience of fully

constructed Element objects.

The most powerful tool for doing this is XMLPullParser. It does not require a blocking read to obtain the XML data,

and is instead fed with data incrementally with XMLPullParser.feed() calls. To get the parsed XML elements,

call XMLPullParser.read_events(). Here is an example:

>>> parser = ET.XMLPullParser(['start', 'end'])

>>> parser.feed('sometext')

>>> list(parser.read_events())

[('start', )]

>>> parser.feed(' more text')

>>> for event, elem in parser.read_events():

... print(event)

... print(elem.tag, 'text=', elem.text)

...

end

mytag text= sometext more text



The obvious use case is applications that operate in a non-blocking fashion where the XML data is being received from a socket or read incrementally from some storage device. In such cases, blocking reads are unacceptable.

Because it’s so flexible, XMLPullParser can be inconvenient to use for simpler use-cases. If you don’t mind your application blocking on reading XML data but would still like to have incremental parsing capabilities, take a look

at iterparse(). It can be useful when you’re reading a large XML document and don’t want to hold it wholly in memory.

Where immediate feedback through events is wanted, calling method XMLPullParser.flush() can help reduce delay; please make sure to study the related security notes.



Finding interesting elements

Element has some useful methods that help iterate recursively over all the sub-tree below it (its children, their

children, and so on). For example, Element.iter():

>>> for neighbor in root.iter('neighbor'):

... print(neighbor.attrib)

...

{'name': 'Austria', 'direction': 'E'}

{'name': 'Switzerland', 'direction': 'W'}

{'name': 'Malaysia', 'direction': 'N'}

{'name': 'Costa Rica', 'direction': 'W'}

{'name': 'Colombia', 'direction': 'E'}



Element.findall() finds only elements with a tag which are direct children of the current element. Element.

find() finds the first child with a particular tag, and Element.text accesses the element’s text content. Element.

get() accesses the element’s attributes:

>>> for country in root.findall('country'):

... rank = country.find('rank').text

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... name = country.get('name')

... print(name, rank)

...

Liechtenstein 1

Singapore 4

Panama 68



More sophisticated specification of which elements to look for is possible by using XPath.



Modifying an XML File

ElementTree provides a simple way to build XML documents and write them to files. The ElementTree.

write() method serves this purpose.

Once created, an Element object may be manipulated by directly changing its fields (such as Element.text),

adding and modifying attributes (Element.set() method), as well as adding new children (for example with

Element.append()).

Let’s say we want to add one to each country’s rank, and add an updated attribute to the rank element:

>>> for rank in root.iter('rank'):

... new_rank = int(rank.text) + 1

... rank.text = str(new_rank)

... rank.set('updated', 'yes')

...

>>> tree.write('output.xml')



Our XML now looks like this:

<?xml version="1.0"?>

<data>

<country name="Liechtenstein">

<rank updated="yes">2</rank>

<year>2008</year>

<gdppc>141100</gdppc>

<neighbor name="Austria" direction="E"/>

<neighbor name="Switzerland" direction="W"/>

</country>

<country name="Singapore">

<rank updated="yes">5</rank>

<year>2011</year>

<gdppc>59900</gdppc>

<neighbor name="Malaysia" direction="N"/>

</country>

<country name="Panama">

<rank updated="yes">69</rank>

<year>2011</year>

<gdppc>13600</gdppc>

<neighbor name="Costa Rica" direction="W"/>

<neighbor name="Colombia" direction="E"/>

</country>

</data>



We can remove elements using Element.remove(). Let’s say we want to remove all countries with a rank higher than 50:

>>> for country in root.findall('country'):

... # using root.findall() to avoid removal during traversal

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... rank = int(country.find('rank').text)

... if rank > 50:

... root.remove(country)

...

>>> tree.write('output.xml')



Note that concurrent modification while iterating can lead to problems, just like when iterating and modifying Python lists or dicts. Therefore, the example first collects all matching elements with root.findall(), and only then iterates over the list of matches.

Our XML now looks like this:

<?xml version="1.0"?>

<data>

<country name="Liechtenstein">

<rank updated="yes">2</rank>

<year>2008</year>

<gdppc>141100</gdppc>

<neighbor name="Austria" direction="E"/>

<neighbor name="Switzerland" direction="W"/>

</country>

<country name="Singapore">

<rank updated="yes">5</rank>

<year>2011</year>

<gdppc>59900</gdppc>

<neighbor name="Malaysia" direction="N"/>

</country>

</data>



Building XML documents

The SubElement() function also provides a convenient way to create new sub-elements for a given element:

>>> a = ET.Element('a')

>>> b = ET.SubElement(a, 'b')

>>> c = ET.SubElement(a, 'c')

>>> d = ET.SubElement(c, 'd')

>>> ET.dump(a)





Parsing XML with Namespaces

If the XML input has namespaces, tags and attributes with prefixes in the form prefix:sometag get expanded to

{uri}sometag where the prefix is replaced by the full URI. Also, if there is a default namespace, that full URI gets prepended to all of the non-prefixed tags.

Here is an XML example that incorporates two namespaces, one with the prefix “fictional” and the other serving as the default namespace:

<?xml version="1.0"?>

<actors xmlns:fictional="http://characters.example.com"

xmlns="http://people.example.com">

<actor>

<name>John Cleese</name>

<fictional:character>Lancelot</fictional:character> <fictional:character>Archie Leach</fictional:character>

</actor>

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

<actor>

<name>Eric Idle</name>

<fictional:character>Sir Robin</fictional:character> <fictional:character>Gunther</fictional:character> <fictional:character>Commander Clement</fictional:character>

</actor>

</actors>



One way to search and explore this XML example is to manually add the URI to every tag or attribute in the xpath

of a find() or findall():

root = fromstring(xml_text)

for actor in root.findall('{http://people.example.com}actor'):

name = actor.find('{http://people.example.com}name')

print(name.text)

for char in actor.findall('{http://characters.example.com}character'):

print(' |-->', char.text)



A better way to search the namespaced XML example is to create a dictionary with your own prefixes and use those in the search functions:

ns = {'real_person': 'http://people.example.com',

'role': 'http://characters.example.com'}

for actor in root.findall('real_person:actor', ns):

name = actor.find('real_person:name', ns)

print(name.text)

for char in actor.findall('role:character', ns):

print(' |-->', char.text)



These two approaches both output:

John Cleese

|--> Lancelot

|--> Archie Leach

Eric Idle

|--> Sir Robin

|--> Gunther

|--> Commander Clement



21.5.2 XPath support

This module provides limited support for XPath expressions for locating elements in a tree. The goal is to support a small subset of the abbreviated syntax; a full XPath engine is outside the scope of the module.



Example

Here’s an example that demonstrates some of the XPath capabilities of the module. We’ll be using the countrydata

XML document from the Parsing XML section:

import xml.etree.ElementTree as ET

root = ET.fromstring(countrydata)

# Top-level elements

root.findall(".")

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

# All 'neighbor' grand-children of 'country' children of the top-level # elements

root.findall("./country/neighbor")

# Nodes with name='Singapore' that have a 'year' child root.findall(".//year/..[@name='Singapore']")

# 'year' nodes that are children of nodes with name='Singapore' root.findall(".//*[@name='Singapore']/year")

# All 'neighbor' nodes that are the second child of their parent root.findall(".//neighbor[2]")



For XML with namespaces, use the usual qualified {namespace}tag notation:

# All dublin-core "title" tags in the document

root.findall(".//{http://purl.org/dc/elements/1.1/}title")



The Python Library Reference, Release 3.13.2



Supported XPath syntax



Syntax Meaning

tag Selects all child elements with the given tag. For example, spam selects all child

elements named spam, and spam/egg selects all grandchildren named egg in all children named spam. {namespace}* selects all tags in the given namespace, {*}spam selects tags named spam in any (or no) namespace, and {}* only selects tags that are not in a namespace.

Changed in version 3.8: Support for star-wildcards was added.

* Selects all child elements, including comments and processing instructions. For

example, */egg selects all grandchildren named egg.

. Selects the current node. This is mostly useful at the beginning of the path, to

indicate that it’s a relative path.

// Selects all subelements, on all levels beneath the current element. For example,

.//egg selects all egg elements in the entire tree.

.. Selects the parent element. Returns None if the path attempts to reach the ancestors

of the start element (the element find was called on).

[@attrib] Selects all elements that have the given attribute.

[@attrib='value'] Selects all elements for which the given attribute has the given value. The value

cannot contain quotes.

[@attrib!='value'] Selects all elements for which the given attribute does not have the given value. The

value cannot contain quotes.

Added in version 3.10.

[tag] Selects all elements that have a child named tag. Only immediate children are

supported.

[.='text'] Selects all elements whose complete text content, including descendants, equals the

given text.

Added in version 3.7.

[.!='text'] Selects all elements whose complete text content, including descendants, does not

equal the given text.

Added in version 3.10.

[tag='text'] Selects all elements that have a child named tag whose complete text content,

including descendants, equals the given text.

[tag!='text'] Selects all elements that have a child named tag whose complete text content,

including descendants, does not equal the given text.

Added in version 3.10.

[position] Selects all elements that are located at the given position. The position can be either

an integer (1 is the first position), the expression last() (for the last position), or a position relative to the last position (e.g. last()-1).



Predicates (expressions within square brackets) must be preceded by a tag name, an asterisk, or another predicate. position predicates must be preceded by a tag name.



21.5.3 Reference

Functions

xml.etree.ElementTree.canonicalize(xml_data=None, *, out=None, from_file=None, **options)

C14N 2.0 transformation function.

Canonicalization is a way to normalise XML output in a way that allows byte-by-byte comparisons and dig-

ital signatures. It reduces the freedom that XML serializers have and instead generates a more constrained

XML representation. The main restrictions regard the placement of namespace declarations, the ordering of

attributes, and ignorable whitespace.

This function takes an XML data string (xml_data) or a file path or file-like object (from_file) as input, converts

it to the canonical form, and writes it out using the out file(-like) object, if provided, or returns it as a text string

if not. The output file receives text, not bytes. It should therefore be opened in text mode with utf-8 encoding.

The Python Library Reference, Release 3.13.2



Typical uses:

xml_data = "..."

print(canonicalize(xml_data))

with open("c14n_output.xml", mode='w', encoding='utf-8') as out_file:

canonicalize(xml_data, out=out_file)

with open("c14n_output.xml", mode='w', encoding='utf-8') as out_file:

canonicalize(from_file="inputfile.xml", out=out_file)



The configuration options are as follows:

• with_comments: set to true to include comments (default: false)

• strip_text: set to true to strip whitespace before and after text content

(default: false)

• rewrite_prefixes: set to true to replace namespace prefixes by “n{number}”

(default: false)

• qname_aware_tags: a set of qname aware tag names in which prefixes

should be replaced in text content (default: empty)

• qname_aware_attrs: a set of qname aware attribute names in which prefixes

should be replaced in text content (default: empty)

• exclude_attrs: a set of attribute names that should not be serialised

• exclude_tags: a set of tag names that should not be serialised

In the option list above, “a set” refers to any collection or iterable of strings, no ordering is expected.

Added in version 3.8.

xml.etree.ElementTree.Comment(text=None)

Comment element factory. This factory function creates a special element that will be serialized as an XML

comment by the standard serializer. The comment string can be either a bytestring or a Unicode string. text is

a string containing the comment string. Returns an element instance representing a comment.

Note that XMLParser skips over comments in the input instead of creating comment objects for them. An

ElementTree will only contain comment nodes if they have been inserted into to the tree using one of the

Element methods.

xml.etree.ElementTree.dump(elem)

Writes an element tree or element structure to sys.stdout. This function should be used for debugging only.

The exact output format is implementation dependent. In this version, it’s written as an ordinary XML file.

elem is an element tree or an individual element.

Changed in version 3.8: The dump() function now preserves the attribute order specified by the user.

xml.etree.ElementTree.fromstring(text, parser=None)

Parses an XML section from a string constant. Same as XML(). text is a string containing XML data. parser

is an optional parser instance. If not given, the standard XMLParser parser is used. Returns an Element

instance.

xml.etree.ElementTree.fromstringlist(sequence, parser=None)

Parses an XML document from a sequence of string fragments. sequence is a list or other sequence containing

XML data fragments. parser is an optional parser instance. If not given, the standard XMLParser parser is

used. Returns an Element instance.

Added in version 3.2.



The Python Library Reference, Release 3.13.2



xml.etree.ElementTree.indent(tree, space=’ ’, level=0)

Appends whitespace to the subtree to indent the tree visually. This can be used to generate pretty-printed XML

output. tree can be an Element or ElementTree. space is the whitespace string that will be inserted for each

indentation level, two space characters by default. For indenting partial subtrees inside of an already indented

tree, pass the initial indentation level as level.

Added in version 3.9.

xml.etree.ElementTree.iselement(element)

Check if an object appears to be a valid element object. element is an element instance. Return True if this is

an element object.

xml.etree.ElementTree.iterparse(source, events=None, parser=None)

Parses an XML section into an element tree incrementally, and reports what’s going on to the user. source is

a filename or file object containing XML data. events is a sequence of events to report back. The supported

events are the strings "start", "end", "comment", "pi", "start-ns" and "end-ns" (the “ns” events are

used to get detailed namespace information). If events is omitted, only "end" events are reported. parser is

an optional parser instance. If not given, the standard XMLParser parser is used. parser must be a subclass of

XMLParser and can only use the default TreeBuilder as a target. Returns an iterator providing (event,

elem) pairs; it has a root attribute that references the root element of the resulting XML tree once source is

fully read. The iterator has the close() method that closes the internal file object if source is a filename.

Note that while iterparse() builds the tree incrementally, it issues blocking reads on source (or the file it

names). As such, it’s unsuitable for applications where blocking reads can’t be made. For fully non-blocking

parsing, see XMLPullParser.



® Note

iterparse() only guarantees that it has seen the “>” character of a starting tag when it emits a “start” event, so the attributes are defined, but the contents of the text and tail attributes are undefined at that point. The same applies to the element children; they may or may not be present.

If you need a fully populated element, look for “end” events instead.



Deprecated since version 3.4: The parser argument.

Changed in version 3.8: The comment and pi events were added.

Changed in version 3.13: Added the close() method.

xml.etree.ElementTree.parse(source, parser=None)

Parses an XML section into an element tree. source is a filename or file object containing XML data. parser is

an optional parser instance. If not given, the standard XMLParser parser is used. Returns an ElementTree

instance.

xml.etree.ElementTree.ProcessingInstruction(target, text=None)

PI element factory. This factory function creates a special element that will be serialized as an XML processing

instruction. target is a string containing the PI target. text is a string containing the PI contents, if given. Returns

an element instance, representing a processing instruction.

Note that XMLParser skips over processing instructions in the input instead of creating PI objects for them.

An ElementTree will only contain processing instruction nodes if they have been inserted into to the tree

using one of the Element methods.

xml.etree.ElementTree.register_namespace(prefix, uri)

Registers a namespace prefix. The registry is global, and any existing mapping for either the given prefix or

the namespace URI will be removed. prefix is a namespace prefix. uri is a namespace uri. Tags and attributes

in this namespace will be serialized with the given prefix, if at all possible.

Added in version 3.2.

The Python Library Reference, Release 3.13.2



xml.etree.ElementTree.SubElement(parent, tag, attrib={}, **extra)

Subelement factory. This function creates an element instance, and appends it to an existing element.

The element name, attribute names, and attribute values can be either bytestrings or Unicode strings. parent is

the parent element. tag is the subelement name. attrib is an optional dictionary, containing element attributes.

extra contains additional attributes, given as keyword arguments. Returns an element instance.

xml.etree.ElementTree.tostring(element, encoding=’us-ascii’, method=’xml’, *, xml_declaration=None,

default_namespace=None, short_empty_elements=True)

Generates a string representation of an XML element, including all subelements. element is an Element

instance. 1 encoding is the output encoding (default is US-ASCII). Use encoding="unicode" to generate

a Unicode string (otherwise, a bytestring is generated). method is either "xml", "html" or "text" (de-

fault is "xml"). xml_declaration, default_namespace and short_empty_elements has the same meaning as in

ElementTree.write() . Returns an (optionally) encoded string containing the XML data.

Changed in version 3.4: Added the short_empty_elements parameter.

Changed in version 3.8: Added the xml_declaration and default_namespace parameters.

Changed in version 3.8: The tostring() function now preserves the attribute order specified by the user.

xml.etree.ElementTree.tostringlist(element, encoding=’us-ascii’ , method=’xml’, *,

xml_declaration=None, default_namespace=None,

short_empty_elements=True)

Generates a string representation of an XML element, including all subelements. element is an Element

instance. 1 encoding is the output encoding (default is US-ASCII). Use encoding="unicode" to gener-

ate a Unicode string (otherwise, a bytestring is generated). method is either "xml", "html" or "text"

(default is "xml"). xml_declaration, default_namespace and short_empty_elements has the same mean-

ing as in ElementTree.write(). Returns a list of (optionally) encoded strings containing the XML

data. It does not guarantee any specific sequence, except that b"".join(tostringlist(element)) ==

tostring(element) .

Added in version 3.2.

Changed in version 3.4: Added the short_empty_elements parameter.

Changed in version 3.8: Added the xml_declaration and default_namespace parameters.

Changed in version 3.8: The tostringlist() function now preserves the attribute order specified by the

user.

xml.etree.ElementTree.XML(text, parser=None)

Parses an XML section from a string constant. This function can be used to embed “XML literals” in Python

code. text is a string containing XML data. parser is an optional parser instance. If not given, the standard

XMLParser parser is used. Returns an Element instance.

xml.etree.ElementTree.XMLID(text, parser=None)

Parses an XML section from a string constant, and also returns a dictionary which maps from element id:s to

elements. text is a string containing XML data. parser is an optional parser instance. If not given, the standard

XMLParser parser is used. Returns a tuple containing an Element instance and a dictionary.



21.5.4 XInclude support

This module provides limited support for XInclude directives, via the xml.etree.ElementInclude helper mod-ule. This module can be used to insert subtrees and text strings into element trees, based on information in the tree.

1 The encoding string included in XML output should conform to the appropriate standards. For example, “UTF-8” is valid, but “UTF8”

is not. See https://www.w3.org/TR/2006/REC-xml11-20060816/#NT-EncodingDecl and https://www.iana.org/assignments/character-sets/

character-sets.xhtml.



The Python Library Reference, Release 3.13.2



Example

Here’s an example that demonstrates use of the XInclude module. To include an XML document in the current doc-ument, use the {http://www.w3.org/2001/XInclude}include element and set the parse attribute to "xml", and use the href attribute to specify the document to include.

<?xml version="1.0"?>

<document xmlns:xi="http://www.w3.org/2001/XInclude">

<xi:include href="source.xml" parse="xml" />

</document>



By default, the href attribute is treated as a file name. You can use custom loaders to override this behaviour. Also note that the standard helper does not support XPointer syntax.

To process this file, load it as usual, and pass the root element to the xml.etree.ElementTree module:

from xml.etree import ElementTree, ElementInclude

tree = ElementTree.parse("document.xml")

root = tree.getroot()

ElementInclude.include(root)



The ElementInclude module replaces the {http://www.w3.org/2001/XInclude}include element with the root element from the source.xml document. The result might look something like this:

<document xmlns:xi="http://www.w3.org/2001/XInclude">

<para>This is a paragraph.</para>

</document>



If the parse attribute is omitted, it defaults to “xml”. The href attribute is required.

To include a text document, use the {http://www.w3.org/2001/XInclude}include element, and set the parse attribute to “text”:

<?xml version="1.0"?>

<document xmlns:xi="http://www.w3.org/2001/XInclude">

Copyright (c) <xi:include href="year.txt" parse="text" />.

</document>



The result might look something like:

<document xmlns:xi="http://www.w3.org/2001/XInclude">

Copyright (c) 2003.

</document>



21.5.5 Reference

Functions

xml.etree.ElementInclude.default_loader(href, parse, encoding=None)

Default loader. This default loader reads an included resource from disk. href is a URL. parse is for parse

mode either “xml” or “text”. encoding is an optional text encoding. If not given, encoding is utf-8. Returns

the expanded resource. If the parse mode is "xml", this is an Element instance. If the parse mode is "text",

this is a string. If the loader fails, it can return None or raise an exception.

xml.etree.ElementInclude.include(elem, loader=None, base_url=None, max_depth=6)

This function expands XInclude directives in-place in tree pointed by elem. elem is either the root Element

or an ElementTree instance to find such element. loader is an optional resource loader. If omitted, it

defaults to default_loader(). If given, it should be a callable that implements the same interface as The Python Library Reference, Release 3.13.2



default_loader(). base_url is base URL of the original file, to resolve relative include file references.

max_depth is the maximum number of recursive inclusions. Limited to reduce the risk of malicious content

explosion. Pass None to disable the limitation.

Changed in version 3.9: Added the base_url and max_depth parameters.



Element Objects

class xml.etree.ElementTree.Element( tag, attrib={}, **extra)

Element class. This class defines the Element interface, and provides a reference implementation of this in-

terface.

The element name, attribute names, and attribute values can be either bytestrings or Unicode strings. tag is

the element name. attrib is an optional dictionary, containing element attributes. extra contains additional

attributes, given as keyword arguments.

tag

A string identifying what kind of data this element represents (the element type, in other words).

text

tail

These attributes can be used to hold additional data associated with the element. Their values are usually strings but may be any application-specific object. If the element is created from an XML file, the text attribute holds either the text between the element’s start tag and its first child or end tag, or None, and the tail attribute holds either the text between the element’s end tag and the next tag, or None. For the XML data

<a><b>1<c>2<d/>3</c></b>4</a>



the a element has None for both text and tail attributes, the b element has text "1" and tail "4", the c element has text "2" and tail None, and the d element has text None and tail "3".

To collect the inner text of an element, see itertext(), for example "".join(element. itertext()).

Applications may store arbitrary objects in these attributes.

attrib

A dictionary containing the element’s attributes. Note that while the attrib value is always a real mutable Python dictionary, an ElementTree implementation may choose to use another internal representation, and create the dictionary only if someone asks for it. To take advantage of such implementations, use the dictionary methods below whenever possible.

The following dictionary-like methods work on the element attributes.

clear()

Resets an element. This function removes all subelements, clears all attributes, and sets the text and tail attributes to None.

get(key, default=None)

Gets the element attribute named key.

Returns the attribute value, or default if the attribute was not found.

items()

Returns the element attributes as a sequence of (name, value) pairs. The attributes are returned in an arbitrary order.

keys()

Returns the elements attribute names as a list. The names are returned in an arbitrary order.



The Python Library Reference, Release 3.13.2



set(key, value)

Set the attribute key on the element to value.

The following methods work on the element’s children (subelements).

append(subelement)

Adds the element subelement to the end of this element’s internal list of subelements. Raises TypeError

if subelement is not an Element.

extend(subelements)

Appends subelements from an iterable of elements. Raises TypeError if a subelement is not an

Element .

Added in version 3.2.

find(match, namespaces=None)

Finds the first subelement matching match. match may be a tag name or a path. Returns an element instance or None. namespaces is an optional mapping from namespace prefix to full name. Pass '' as prefix to move all unprefixed tag names in the expression into the given namespace.

findall(match, namespaces=None)

Finds all matching subelements, by tag name or path. Returns a list containing all matching elements in document order. namespaces is an optional mapping from namespace prefix to full name. Pass '' as prefix to move all unprefixed tag names in the expression into the given namespace.

findtext(match, default=None, namespaces=None)

Finds text for the first subelement matching match. match may be a tag name or a path. Returns the text content of the first matching element, or default if no element was found. Note that if the matching element has no text content an empty string is returned. namespaces is an optional mapping from names-pace prefix to full name. Pass '' as prefix to move all unprefixed tag names in the expression into the given namespace.

insert(index, subelement)

Inserts subelement at the given position in this element. Raises TypeError if subelement is not an

Element .

iter(tag=None)

Creates a tree iterator with the current element as the root. The iterator iterates over this element and all elements below it, in document (depth first) order. If tag is not None or '*', only elements whose tag equals tag are returned from the iterator. If the tree structure is modified during iteration, the result is undefined.

Added in version 3.2.

iterfind(match, namespaces=None)

Finds all matching subelements, by tag name or path. Returns an iterable yielding all matching elements in document order. namespaces is an optional mapping from namespace prefix to full name.

Added in version 3.2.

itertext()

Creates a text iterator. The iterator loops over this element and all subelements, in document order, and returns all inner text.

Added in version 3.2.

makeelement(tag, attrib)

Creates a new element object of the same type as this element. Do not call this method, use the

SubElement() factory function instead.

remove(subelement)

Removes subelement from the element. Unlike the find* methods this method compares elements based on the instance identity, not on tag value or contents.

The Python Library Reference, Release 3.13.2



Element objects also support the following sequence type methods for working with subelements:

__delitem__(), __getitem__(), __setitem__(), __len__().

Caution: Elements with no subelements will test as False. In a future release of Python, all elements will

test as True regardless of whether subelements exist. Instead, prefer explicit len(elem) or elem is not

None tests.:

element = root.find('foo')

if not element: # careful!

print("element not found, or element has no subelements")

if element is None:

print("element not found")



Changed in version 3.12: Testing the truth value of an Element emits DeprecationWarning.

Prior to Python 3.8, the serialisation order of the XML attributes of elements was artificially made predictable

by sorting the attributes by their name. Based on the now guaranteed ordering of dicts, this arbitrary reordering

was removed in Python 3.8 to preserve the order in which attributes were originally parsed or created by user

code.

In general, user code should try not to depend on a specific ordering of attributes, given that the XML Infor-

mation Set explicitly excludes the attribute order from conveying information. Code should be prepared to

deal with any ordering on input. In cases where deterministic XML output is required, e.g. for cryptographic

signing or test data sets, canonical serialisation is available with the canonicalize() function.

In cases where canonical output is not applicable but a specific attribute order is still desirable on output, code

should aim for creating the attributes directly in the desired order, to avoid perceptual mismatches for readers

of the code. In cases where this is difficult to achieve, a recipe like the following can be applied prior to

serialisation to enforce an order independently from the Element creation:

def reorder_attributes(root):

for el in root.iter():

attrib = el.attrib

if len(attrib) > 1:

# adjust attribute order, e.g. by sorting

attribs = sorted(attrib.items())

attrib.clear()

attrib.update(attribs)



ElementTree Objects

class xml.etree.ElementTree.ElementTree(element=None, file=None)

ElementTree wrapper class. This class represents an entire element hierarchy, and adds some extra support for

serialization to and from standard XML.

element is the root element. The tree is initialized with the contents of the XML file if given.

_setroot(element)

Replaces the root element for this tree. This discards the current contents of the tree, and replaces it with the given element. Use with care. element is an element instance.

find(match, namespaces=None)

Same as Element.find(), starting at the root of the tree.

findall(match, namespaces=None)

Same as Element.findall(), starting at the root of the tree.

findtext(match, default=None, namespaces=None)

Same as Element.findtext(), starting at the root of the tree.

The Python Library Reference, Release 3.13.2



getroot()

Returns the root element for this tree.

iter(tag=None)

Creates and returns a tree iterator for the root element. The iterator loops over all elements in this tree, in section order. tag is the tag to look for (default is to return all elements).

iterfind(match, namespaces=None)

Same as Element.iterfind(), starting at the root of the tree.

Added in version 3.2.

parse(source, parser=None)

Loads an external XML section into this element tree. source is a file name or file object. parser is an

optional parser instance. If not given, the standard XMLParser parser is used. Returns the section root element.

write(file, encoding=’us-ascii’, xml_declaration=None, default_namespace=None, method=’xml’, *,

short_empty_elements=True)

Writes the element tree to a file, as XML. file is a file name, or a file object opened for writing. encod-

ingPage 1346, 1 is the output encoding (default is US-ASCII). xml_declaration controls if an XML declara-tion should be added to the file. Use False for never, True for always, None for only if not US-ASCII or UTF-8 or Unicode (default is None). default_namespace sets the default XML namespace (for “xmlns”). method is either "xml", "html" or "text" (default is "xml"). The keyword-only short_empty_elements parameter controls the formatting of elements that contain no content. If True (the default), they are emitted as a single self-closed tag, otherwise they are emitted as a pair of start/end tags.

The output is either a string (str) or binary (bytes). This is controlled by the encoding argument. If encoding is "unicode", the output is a string; otherwise, it’s binary. Note that this may conflict with the

type of file if it’s an open file object; make sure you do not try to write a string to a binary stream and vice versa.

Changed in version 3.4: Added the short_empty_elements parameter.

Changed in version 3.8: The write() method now preserves the attribute order specified by the user.

This is the XML file that is going to be manipulated:

<html>

<head>

<title>Example pagetitle>

head>

<body>

<p>Moved to <a href="http://example.org/">example.orga> or <a href="http://example.com/">example.coma>.p>

body>

html>



Example of changing the attribute “target” of every link in first paragraph:

>>> from xml.etree.ElementTree import ElementTree

>>> tree = ElementTree()

>>> tree.parse("index.xhtml")



>>> p = tree.find("body/p") # Finds first occurrence of tag p in body >>> p



>>> links = list(p.iter("a")) # Returns list of all links >>> links

[, ] >>> for i in links: # Iterates through all found links

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... i.attrib["target"] = "blank"

...

>>> tree.write("output.xhtml")



QName Objects

class xml.etree.ElementTree.QName(text_or_uri, tag=None)

QName wrapper. This can be used to wrap a QName attribute value, in order to get proper namespace handling

on output. text_or_uri is a string containing the QName value, in the form {uri}local, or, if the tag argument is

given, the URI part of a QName. If tag is given, the first argument is interpreted as a URI, and this argument

is interpreted as a local name. QName instances are opaque.



TreeBuilder Objects

class xml.etree.ElementTree.TreeBuilder(element_factory=None, *, comment_factory=None,

pi_factory=None, insert_comments=False, insert_pis=False)

Generic element structure builder. This builder converts a sequence of start, data, end, comment and pi method

calls to a well-formed element structure. You can use this class to build an element structure using a custom

XML parser, or a parser for some other XML-like format.

element_factory, when given, must be a callable accepting two positional arguments: a tag and a dict of at-

tributes. It is expected to return a new element instance.

The comment_factory and pi_factory functions, when given, should behave like the Comment() and

ProcessingInstruction() functions to create comments and processing instructions. When not given,

the default factories will be used. When insert_comments and/or insert_pis is true, comments/pis will be in-

serted into the tree if they appear within the root element (but not outside of it).

close()

Flushes the builder buffers, and returns the toplevel document element. Returns an Element instance.

data(data)

Adds text to the current element. data is a string. This should be either a bytestring, or a Unicode string.

end(tag)

Closes the current element. tag is the element name. Returns the closed element.

start(tag, attrs)

Opens a new element. tag is the element name. attrs is a dictionary containing element attributes. Returns the opened element.

comment(text)

Creates a comment with the given text. If insert_comments is true, this will also add it to the tree.

Added in version 3.8.

pi( target, text)

Creates a process instruction with the given target name and text. If insert_pis is true, this will also add it to the tree.

Added in version 3.8.

In addition, a custom TreeBuilder object can provide the following methods:

doctype(name, pubid, system)

Handles a doctype declaration. name is the doctype name. pubid is the public identifier. system is the

system identifier. This method does not exist on the default TreeBuilder class.

Added in version 3.2.

The Python Library Reference, Release 3.13.2



start_ns(prefix, uri)

Is called whenever the parser encounters a new namespace declaration, before the start() callback for the opening element that defines it. prefix is '' for the default namespace and the declared namespace prefix name otherwise. uri is the namespace URI.

Added in version 3.8.

end_ns(prefix)

Is called after the end() callback of an element that declared a namespace prefix mapping, with the name of the prefix that went out of scope.

Added in version 3.8.

class xml.etree.ElementTree.C14NWriterTarget(write, *, with_comments=False, strip_text=False,

rewrite_prefixes=False, qname_aware_tags=None,

qname_aware_attrs=None, exclude_attrs=None,

exclude_tags=None)

A C14N 2.0 writer. Arguments are the same as for the canonicalize() function. This class does not build

a tree but translates the callback events directly into a serialised form using the write function.

Added in version 3.8.



XMLParser Objects

class xml.etree.ElementTree.XMLParser(*, target=None, encoding=None)

This class is the low-level building block of the module. It uses xml.parsers.expat for efficient, event-

based parsing of XML. It can be fed XML data incrementally with the feed() method, and parsing events

are translated to a push API - by invoking callbacks on the target object. If target is omitted, the standard

TreeBuilder Page 1346, 1 is used. If encoding is given, the value overrides the encoding specified in the XML

file.

Changed in version 3.8: Parameters are now keyword-only. The html argument is no longer supported.

close()

Finishes feeding data to the parser. Returns the result of calling the close() method of the target passed during construction; by default, this is the toplevel document element.

feed(data)

Feeds data to the parser. data is encoded data.

flush()

Triggers parsing of any previously fed unparsed data, which can be used to ensure more immediate feed-

back, in particular with Expat >=2.6.0. The implementation of flush() temporarily disables reparse de-ferral with Expat (if currently enabled) and triggers a reparse. Disabling reparse deferral has security con-

sequences; please see xml.parsers.expat.xmlparser.SetReparseDeferralEnabled() for details.

Note that flush() has been backported to some prior releases of CPython as a security fix. Check for

availability of flush() using hasattr() if used in code running across a variety of Python versions.

Added in version 3.13.

XMLParser.feed() calls target’s start(tag, attrs_dict) method for each opening tag, its end(tag)

method for each closing tag, and data is processed by method data(data). For further supported callback

methods, see the TreeBuilder class. XMLParser.close() calls target’s method close(). XMLParser

can be used not only for building a tree structure. This is an example of counting the maximum depth of an

XML file:

>>> from xml.etree.ElementTree import XMLParser

>>> class MaxDepth: # The target object of the parser

... maxDepth = 0

... depth = 0

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

... def start(self, tag, attrib): # Called for each opening tag.

... self.depth += 1

... if self.depth > self.maxDepth:

... self.maxDepth = self.depth

... def end(self, tag): # Called for each closing tag.

... self.depth-= 1

... def data(self, data):

... pass # We do not need to do anything with data.

... def close(self): # Called when all data has been parsed.

... return self.maxDepth

...

>>> target = MaxDepth()

>>> parser = XMLParser(target=target)

>>> exampleXml = """

...

...

...

...

...

...

...

...

...

... """

>>> parser.feed(exampleXml)

>>> parser.close()

4



XMLPullParser Objects

class xml.etree.ElementTree.XMLPullParser(events=None)

A pull parser suitable for non-blocking applications. Its input-side API is similar to that of XMLParser, but

instead of pushing calls to a callback target, XMLPullParser collects an internal list of parsing events and

lets the user read from it. events is a sequence of events to report back. The supported events are the strings

"start" , "end", "comment", "pi", "start-ns" and "end-ns" (the “ns” events are used to get detailed

namespace information). If events is omitted, only "end" events are reported.

feed(data)

Feed the given bytes data to the parser.

flush()

Triggers parsing of any previously fed unparsed data, which can be used to ensure more immediate feed-

back, in particular with Expat >=2.6.0. The implementation of flush() temporarily disables reparse de-ferral with Expat (if currently enabled) and triggers a reparse. Disabling reparse deferral has security con-

sequences; please see xml.parsers.expat.xmlparser.SetReparseDeferralEnabled() for details.

Note that flush() has been backported to some prior releases of CPython as a security fix. Check for

availability of flush() using hasattr() if used in code running across a variety of Python versions.

Added in version 3.13.

close()

Signal the parser that the data stream is terminated. Unlike XMLParser.close(), this method al-

ways returns None. Any events not yet retrieved when the parser is closed can still be read with

read_events().

read_events()

Return an iterator over the events which have been encountered in the data fed to the parser. The iterator

The Python Library Reference, Release 3.13.2



yields (event, elem) pairs, where event is a string representing the type of event (e.g. "end") and

elem is the encountered Element object, or other context value as follows.

• start, end: the current Element.

• comment, pi: the current comment / processing instruction

• start-ns: a tuple (prefix, uri) naming the declared namespace mapping.

• end-ns: None (this may change in a future version)

Events provided in a previous call to read_events() will not be yielded again. Events are consumed from the internal queue only when they are retrieved from the iterator, so multiple readers iterating in

parallel over iterators obtained from read_events() will have unpredictable results.



® Note

XMLPullParser only guarantees that it has seen the “>” character of a starting tag when it emits a “start” event, so the attributes are defined, but the contents of the text and tail attributes are undefined at that point. The same applies to the element children; they may or may not be present.

If you need a fully populated element, look for “end” events instead.



Added in version 3.4.

Changed in version 3.8: The comment and pi events were added.



Exceptions

class xml.etree.ElementTree.ParseError

XML parse error, raised by the various parsing methods in this module when parsing fails. The string repre-

sentation of an instance of this exception will contain a user-friendly error message. In addition, it will have

the following attributes available:

code

A numeric error code from the expat parser. See the documentation of xml.parsers.expat for the list of error codes and their meanings.

position

A tuple of line, column numbers, specifying where the error occurred.



21.6 xml.dom — The Document Object Model API

Source code: Lib/xml/dom/__init__.py



The Document Object Model, or “DOM,” is a cross-language API from the World Wide Web Consortium (W3C) for accessing and modifying XML documents. A DOM implementation presents an XML document as a tree structure, or allows client code to build such a structure from scratch. It then gives access to the structure through a set of objects which provided well-known interfaces.

The DOM is extremely useful for random-access applications. SAX only allows you a view of one bit of the document at a time. If you are looking at one SAX element, you have no access to another. If you are looking at a text node, you have no access to a containing element. When you write a SAX application, you need to keep track of your program’s position in the document somewhere in your own code. SAX does not do it for you. Also, if you need to look ahead in the XML document, you are just out of luck.

Some applications are simply impossible in an event driven model with no access to a tree. Of course you could build some sort of tree yourself in SAX events, but the DOM allows you to avoid writing that code. The DOM is a standard tree representation for XML data.

The Python Library Reference, Release 3.13.2



The Document Object Model is being defined by the W3C in stages, or “levels” in their terminology. The Python mapping of the API is substantially based on the DOM Level 2 recommendation.

DOM applications typically start by parsing some XML into a DOM. How this is accomplished is not covered at all by DOM Level 1, and Level 2 provides only limited improvements: There is a DOMImplementation object class which provides access to Document creation methods, but no way to access an XML reader/parser/Document builder in an implementation-independent way. There is also no well-defined way to access these methods without an existing

Document object. In Python, each DOM implementation will provide a function getDOMImplementation(). DOM Level 3 adds a Load/Store specification, which defines an interface to the reader, but this is not yet available in the Python standard library.

Once you have a DOM document object, you can access the parts of your XML document through its properties and methods. These properties are defined in the DOM specification; this portion of the reference manual describes the interpretation of the specification in Python.

The specification provided by the W3C defines the DOM API for Java, ECMAScript, and OMG IDL. The Python mapping defined here is based in large part on the IDL version of the specification, but strict compliance is not

required (though implementations are free to support the strict mapping from IDL). See section Conformance for a detailed discussion of mapping requirements.



µ See also

Document Object Model (DOM) Level 2 Specification

The W3C recommendation upon which the Python DOM API is based.

Document Object Model (DOM) Level 1 Specification

The W3C recommendation for the DOM supported by xml.dom.minidom.

Python Language Mapping Specification

This specifies the mapping from OMG IDL to Python.



21.6.1 Module Contents

The xml.dom contains the following functions:

xml.dom.registerDOMImplementation(name, factory)

Register the factory function with the name name. The factory function should return an object which imple-

ments the DOMImplementation interface. The factory function can return the same object every time, or

a new one for each call, as appropriate for the specific implementation (e.g. if that implementation supports

some customization).

xml.dom.getDOMImplementation(name=None, features=())

Return a suitable DOM implementation. The name is either well-known, the module name of a DOM imple-

mentation, or None. If it is not None, imports the corresponding module and returns a DOMImplementation

object if the import succeeds. If no name is given, and if the environment variable PYTHON_DOM is set, this

variable is used to find the implementation.

If name is not given, this examines the available implementations to find one with the required feature set. If

no implementation can be found, raise an ImportError. The features list must be a sequence of (feature,

version) pairs which are passed to the hasFeature() method on available DOMImplementation objects.

Some convenience constants are also provided:

xml.dom.EMPTY_NAMESPACE

The value used to indicate that no namespace is associated with a node in the DOM. This is typically found as

the namespaceURI of a node, or used as the namespaceURI parameter to a namespaces-specific method.

xml.dom.XML_NAMESPACE

The namespace URI associated with the reserved prefix xml, as defined by Namespaces in XML (section 4).



The Python Library Reference, Release 3.13.2



xml.dom.XMLNS_NAMESPACE

The namespace URI for namespace declarations, as defined by Document Object Model (DOM) Level 2 Core

Specification (section 1.1.8).

xml.dom.XHTML_NAMESPACE

The URI of the XHTML namespace as defined by XHTML 1.0: The Extensible HyperText Markup Language

(section 3.1.1).

In addition, xml.dom contains a base Node class and the DOM exception classes. The Node class provided by this module does not implement any of the methods or attributes defined by the DOM specification; concrete DOM implementations must provide those. The Node class provided as part of this module does provide the constants used for the nodeType attribute on concrete Node objects; they are located within the class rather than at the module level to conform with the DOM specifications.



21.6.2 Objects in the DOM

The definitive documentation for the DOM is the DOM specification from the W3C.

Note that DOM attributes may also be manipulated as nodes instead of as simple strings. It is fairly rare that you must do this, however, so this usage is not yet documented.



Interface Section Purpose

DOMImplementation DOMImplementation Ob- Interface to the underlying implementation.

jects

Node Node Objects Base interface for most objects in a document.

NodeList NodeList Objects Interface for a sequence of nodes.

DocumentType DocumentType Objects Information about the declarations needed to process a

document.

Document Document Objects Object which represents an entire document.

Element Element Objects Element nodes in the document hierarchy.

Attr Attr Objects Attribute value nodes on element nodes.

Comment Comment Objects Representation of comments in the source document.

Text Text and CDATASection Nodes containing textual content from the document.

Objects

ProcessingInstruction ProcessingInstruction Ob- Processing instruction representation.

jects



An additional section describes the exceptions defined for working with the DOM in Python.



DOMImplementation Objects

The DOMImplementation interface provides a way for applications to determine the availability of particular fea-tures in the DOM they are using. DOM Level 2 added the ability to create new Document and DocumentType objects using the DOMImplementation as well.

DOMImplementation.hasFeature(feature, version)

Return True if the feature identified by the pair of strings feature and version is implemented.

DOMImplementation.createDocument(namespaceUri, qualifiedName, doctype)

Return a new Document object (the root of the DOM), with a child Element object having the

given namespaceUri and qualifiedName. The doctype must be a DocumentType object created by

createDocumentType() , or None. In the Python DOM API, the first two arguments can also be None

in order to indicate that no Element child is to be created.

DOMImplementation.createDocumentType(qualifiedName, publicId, systemId)

Return a new DocumentType object that encapsulates the given qualifiedName, publicId, and systemId strings,

representing the information contained in an XML document type declaration.

The Python Library Reference, Release 3.13.2



Node Objects

All of the components of an XML document are subclasses of Node.

Node.nodeType

An integer representing the node type. Symbolic constants for the types are on the Node ob-

ject: ELEMENT_NODE, ATTRIBUTE_NODE, TEXT_NODE, CDATA_SECTION_NODE, ENTITY_NODE,

PROCESSING_INSTRUCTION_NODE, COMMENT_NODE, DOCUMENT_NODE, DOCUMENT_TYPE_NODE,

NOTATION_NODE. This is a read-only attribute.

Node.parentNode

The parent of the current node, or None for the document node. The value is always a Node object or None.

For Element nodes, this will be the parent element, except for the root element, in which case it will be the

Document object. For Attr nodes, this is always None. This is a read-only attribute.

Node.attributes

A NamedNodeMap of attribute objects. Only elements have actual values for this; others provide None for this

attribute. This is a read-only attribute.

Node.previousSibling

The node that immediately precedes this one with the same parent. For instance the element with an end-tag

that comes just before the self element’s start-tag. Of course, XML documents are made up of more than just

elements so the previous sibling could be text, a comment, or something else. If this node is the first child of

the parent, this attribute will be None. This is a read-only attribute.

Node.nextSibling

The node that immediately follows this one with the same parent. See also previousSibling. If this is the

last child of the parent, this attribute will be None. This is a read-only attribute.

Node.childNodes

A list of nodes contained within this node. This is a read-only attribute.

Node.firstChild

The first child of the node, if there are any, or None. This is a read-only attribute.

Node.lastChild

The last child of the node, if there are any, or None. This is a read-only attribute.

Node.localName

The part of the tagName following the colon if there is one, else the entire tagName. The value is a string.

Node.prefix

The part of the tagName preceding the colon if there is one, else the empty string. The value is a string, or

None .

Node.namespaceURI

The namespace associated with the element name. This will be a string or None. This is a read-only attribute.

Node.nodeName

This has a different meaning for each node type; see the DOM specification for details. You can always get

the information you would get here from another property such as the tagName property for elements or the

name property for attributes. For all node types, the value of this attribute will be either a string or None. This

is a read-only attribute.

Node.nodeValue

This has a different meaning for each node type; see the DOM specification for details. The situation is similar

to that with nodeName. The value is a string or None.

Node.hasAttributes()

Return True if the node has any attributes.

The Python Library Reference, Release 3.13.2



Node.hasChildNodes()

Return True if the node has any child nodes.

Node.isSameNode(other)

Return True if other refers to the same node as this node. This is especially useful for DOM implementations

which use any sort of proxy architecture (because more than one object can refer to the same node).



® Note

This is based on a proposed DOM Level 3 API which is still in the “working draft” stage, but this particular interface appears uncontroversial. Changes from the W3C will not necessarily affect this method in the Python DOM interface (though any new W3C API for this would also be supported).



Node.appendChild(newChild)

Add a new child node to this node at the end of the list of children, returning newChild. If the node was already

in the tree, it is removed first.

Node.insertBefore(newChild, refChild)

Insert a new child node before an existing child. It must be the case that refChild is a child of this node; if

not, ValueError is raised. newChild is returned. If refChild is None, it inserts newChild at the end of the

children’s list.

Node.removeChild(oldChild)

Remove a child node. oldChild must be a child of this node; if not, ValueError is raised. oldChild is returned

on success. If oldChild will not be used further, its unlink() method should be called.

Node.replaceChild(newChild, oldChild)

Replace an existing node with a new node. It must be the case that oldChild is a child of this node; if not,

ValueError is raised.

Node.normalize()

Join adjacent text nodes so that all stretches of text are stored as single Text instances. This simplifies pro-

cessing text from a DOM tree for many applications.

Node.cloneNode(deep)

Clone this node. Setting deep means to clone all child nodes as well. This returns the clone.



NodeList Objects

A NodeList represents a sequence of nodes. These objects are used in two ways in the DOM Core recom-mendation: an Element object provides one as its list of child nodes, and the getElementsByTagName() and getElementsByTagNameNS() methods of Node return objects with this interface to represent query results.

The DOM Level 2 recommendation defines one method and one attribute for these objects:

NodeList.item(i)

Return the i’th item from the sequence, if there is one, or None. The index i is not allowed to be less than zero

or greater than or equal to the length of the sequence.

NodeList.length

The number of nodes in the sequence.

In addition, the Python DOM interface requires that some additional support is provided to allow NodeList ob-jects to be used as Python sequences. All NodeList implementations must include support for __len__() and

__getitem__(); this allows iteration over the NodeList in for statements and proper support for the len() built-in function.

If a DOM implementation supports modification of the document, the NodeList implementation must also support the __setitem__() and __delitem__() methods.

The Python Library Reference, Release 3.13.2



DocumentType Objects

Information about the notations and entities declared by a document (including the external subset if the parser uses it and can provide the information) is available from a DocumentType object. The DocumentType for a document is available from the Document object’s doctype attribute; if there is no DOCTYPE declaration for the document, the document’s doctype attribute will be set to None instead of an instance of this interface.

DocumentType is a specialization of Node, and adds the following attributes:

DocumentType.publicId

The public identifier for the external subset of the document type definition. This will be a string or None.

DocumentType.systemId

The system identifier for the external subset of the document type definition. This will be a URI as a string, or

None .

DocumentType.internalSubset

A string giving the complete internal subset from the document. This does not include the brackets which

enclose the subset. If the document has no internal subset, this should be None.

DocumentType.name

The name of the root element as given in the DOCTYPE declaration, if present.

DocumentType.entities

This is a NamedNodeMap giving the definitions of external entities. For entity names defined more than once,

only the first definition is provided (others are ignored as required by the XML recommendation). This may

be None if the information is not provided by the parser, or if no entities are defined.

DocumentType.notations

This is a NamedNodeMap giving the definitions of notations. For notation names defined more than once, only

the first definition is provided (others are ignored as required by the XML recommendation). This may be

None if the information is not provided by the parser, or if no notations are defined.



Document Objects

A Document represents an entire XML document, including its constituent elements, attributes, processing instruc-tions, comments etc. Remember that it inherits properties from Node.

Document.documentElement

The one and only root element of the document.

Document.createElement(tagName)

Create and return a new element node. The element is not inserted into the document when it is created. You

need to explicitly insert it with one of the other methods such as insertBefore() or appendChild().

Document.createElementNS(namespaceURI, tagName)

Create and return a new element with a namespace. The tagName may have a prefix. The element is not

inserted into the document when it is created. You need to explicitly insert it with one of the other methods

such as insertBefore() or appendChild().

Document.createTextNode(data)

Create and return a text node containing the data passed as a parameter. As with the other creation methods,

this one does not insert the node into the tree.

Document.createComment(data)

Create and return a comment node containing the data passed as a parameter. As with the other creation

methods, this one does not insert the node into the tree.

Document.createProcessingInstruction(target, data)

Create and return a processing instruction node containing the target and data passed as parameters. As with

the other creation methods, this one does not insert the node into the tree.

The Python Library Reference, Release 3.13.2



Document.createAttribute(name)

Create and return an attribute node. This method does not associate the attribute node with any particular

element. You must use setAttributeNode() on the appropriate Element object to use the newly created

attribute instance.

Document.createAttributeNS(namespaceURI, qualifiedName)

Create and return an attribute node with a namespace. The tagName may have a prefix. This method does

not associate the attribute node with any particular element. You must use setAttributeNode() on the

appropriate Element object to use the newly created attribute instance.

Document.getElementsByTagName(tagName)

Search for all descendants (direct children, children’s children, etc.) with a particular element type name.

Document.getElementsByTagNameNS(namespaceURI, localName)

Search for all descendants (direct children, children’s children, etc.) with a particular namespace URI and

localname. The localname is the part of the namespace after the prefix.



Element Objects

Element is a subclass of Node, so inherits all the attributes of that class.

Element.tagName

The element type name. In a namespace-using document it may have colons in it. The value is a string.

Element.getElementsByTagName(tagName)

Same as equivalent method in the Document class.

Element.getElementsByTagNameNS(namespaceURI, localName)

Same as equivalent method in the Document class.

Element.hasAttribute(name)

Return True if the element has an attribute named by name.

Element.hasAttributeNS(namespaceURI, localName)

Return True if the element has an attribute named by namespaceURI and localName.

Element.getAttribute(name)

Return the value of the attribute named by name as a string. If no such attribute exists, an empty string is

returned, as if the attribute had no value.

Element.getAttributeNode(attrname)

Return the Attr node for the attribute named by attrname.

Element.getAttributeNS(namespaceURI, localName)

Return the value of the attribute named by namespaceURI and localName as a string. If no such attribute

exists, an empty string is returned, as if the attribute had no value.

Element.getAttributeNodeNS(namespaceURI, localName)

Return an attribute value as a node, given a namespaceURI and localName.

Element.removeAttribute(name)

Remove an attribute by name. If there is no matching attribute, a NotFoundErr is raised.

Element.removeAttributeNode(oldAttr)

Remove and return oldAttr from the attribute list, if present. If oldAttr is not present, NotFoundErr is raised.

Element.removeAttributeNS(namespaceURI, localName)

Remove an attribute by name. Note that it uses a localName, not a qname. No exception is raised if there is

no matching attribute.

Element.setAttribute(name, value)

Set an attribute value from a string.

The Python Library Reference, Release 3.13.2



Element.setAttributeNode(newAttr)

Add a new attribute node to the element, replacing an existing attribute if necessary if the name attribute

matches. If a replacement occurs, the old attribute node will be returned. If newAttr is already in use,

InuseAttributeErr will be raised.

Element.setAttributeNodeNS(newAttr)

Add a new attribute node to the element, replacing an existing attribute if necessary if the namespaceURI

and localName attributes match. If a replacement occurs, the old attribute node will be returned. If newAttr

is already in use, InuseAttributeErr will be raised.

Element.setAttributeNS(namespaceURI, qname, value)

Set an attribute value from a string, given a namespaceURI and a qname. Note that a qname is the whole

attribute name. This is different than above.



Attr Objects

Attr inherits from Node, so inherits all its attributes.

Attr.name

The attribute name. In a namespace-using document it may include a colon.

Attr.localName

The part of the name following the colon if there is one, else the entire name. This is a read-only attribute.

Attr.prefix

The part of the name preceding the colon if there is one, else the empty string.

Attr.value

The text value of the attribute. This is a synonym for the nodeValue attribute.



NamedNodeMap Objects

NamedNodeMap does not inherit from Node.

NamedNodeMap.length

The length of the attribute list.

NamedNodeMap.item(index)

Return an attribute with a particular index. The order you get the attributes in is arbitrary but will be consistent

for the life of a DOM. Each item is an attribute node. Get its value with the value attribute.

There are also experimental methods that give this class more mapping behavior. You can use them or you can use the standardized getAttribute*() family of methods on the Element objects.



Comment Objects

Comment represents a comment in the XML document. It is a subclass of Node, but cannot have child nodes.

Comment.data

The content of the comment as a string. The attribute contains all characters between the leading , but does not include them.



Text and CDATASection Objects

The Text interface represents text in the XML document. If the parser and DOM implementation support the DOM’s XML extension, portions of the text enclosed in CDATA marked sections are stored in CDATASection objects. These two interfaces are identical, but provide different values for the nodeType attribute.

These interfaces extend the Node interface. They cannot have child nodes.



The Python Library Reference, Release 3.13.2



Text.data

The content of the text node as a string.



® Note

The use of a CDATASection node does not indicate that the node represents a complete CDATA marked section,

only that the content of the node was part of a CDATA section. A single CDATA section may be represented by

more than one node in the document tree. There is no way to determine whether two adjacent CDATASection

nodes represent different CDATA marked sections.



ProcessingInstruction Objects

Represents a processing instruction in the XML document; this inherits from the Node interface and cannot have child nodes.

ProcessingInstruction.target

The content of the processing instruction up to the first whitespace character. This is a read-only attribute.

ProcessingInstruction.data

The content of the processing instruction following the first whitespace character.



Exceptions

The DOM Level 2 recommendation defines a single exception, DOMException, and a number of constants that

allow applications to determine what sort of error occurred. DOMException instances carry a code attribute that provides the appropriate value for the specific exception.

The Python DOM interface provides the constants, but also expands the set of exceptions so that a specific exception exists for each of the exception codes defined by the DOM. The implementations must raise the appropriate specific

exception, each of which carries the appropriate value for the code attribute.

exception xml.dom.DOMException

Base exception class used for all specific DOM exceptions. This exception class cannot be directly instantiated.

exception xml.dom.DomstringSizeErr

Raised when a specified range of text does not fit into a string. This is not known to be used in the Python

DOM implementations, but may be received from DOM implementations not written in Python.

exception xml.dom.HierarchyRequestErr

Raised when an attempt is made to insert a node where the node type is not allowed.

exception xml.dom.IndexSizeErr

Raised when an index or size parameter to a method is negative or exceeds the allowed values.

exception xml.dom.InuseAttributeErr

Raised when an attempt is made to insert an Attr node that is already present elsewhere in the document.

exception xml.dom.InvalidAccessErr

Raised if a parameter or an operation is not supported on the underlying object.

exception xml.dom.InvalidCharacterErr

This exception is raised when a string parameter contains a character that is not permitted in the context it’s

being used in by the XML 1.0 recommendation. For example, attempting to create an Element node with a

space in the element type name will cause this error to be raised.

exception xml.dom.InvalidModificationErr

Raised when an attempt is made to modify the type of a node.

exception xml.dom.InvalidStateErr

Raised when an attempt is made to use an object that is not defined or is no longer usable.

The Python Library Reference, Release 3.13.2



exception xml.dom.NamespaceErr

If an attempt is made to change any object in a way that is not permitted with regard to the Namespaces in

XML recommendation, this exception is raised.

exception xml.dom.NotFoundErr

Exception when a node does not exist in the referenced context. For example, NamedNodeMap.

removeNamedItem() will raise this if the node passed in does not exist in the map.

exception xml.dom.NotSupportedErr

Raised when the implementation does not support the requested type of object or operation.

exception xml.dom.NoDataAllowedErr

This is raised if data is specified for a node which does not support data.

exception xml.dom.NoModificationAllowedErr

Raised on attempts to modify an object where modifications are not allowed (such as for read-only nodes).

exception xml.dom.SyntaxErr

Raised when an invalid or illegal string is specified.

exception xml.dom.WrongDocumentErr

Raised when a node is inserted in a different document than it currently belongs to, and the implementation

does not support migrating the node from one document to the other.

The exception codes defined in the DOM recommendation map to the exceptions described above according to this table:



Constant Exception

DOMSTRING_SIZE_ERR DomstringSizeErr

HIERARCHY_REQUEST_ERR HierarchyRequestErr

INDEX_SIZE_ERR IndexSizeErr

INUSE_ATTRIBUTE_ERR InuseAttributeErr

INVALID_ACCESS_ERR InvalidAccessErr

INVALID_CHARACTER_ERR InvalidCharacterErr

INVALID_MODIFICATION_ERR InvalidModificationErr

INVALID_STATE_ERR InvalidStateErr

NAMESPACE_ERR NamespaceErr

NOT_FOUND_ERR NotFoundErr

NOT_SUPPORTED_ERR NotSupportedErr

NO_DATA_ALLOWED_ERR NoDataAllowedErr

NO_MODIFICATION_ALLOWED_ERR NoModificationAllowedErr

SYNTAX_ERR SyntaxErr

WRONG_DOCUMENT_ERR WrongDocumentErr



21.6.3 Conformance

This section describes the conformance requirements and relationships between the Python DOM API, the W3C DOM recommendations, and the OMG IDL mapping for Python.



Type Mapping

The IDL types used in the DOM specification are mapped to Python types according to the following table.



The Python Library Reference, Release 3.13.2



IDL Type Python Type

boolean bool or int

int int

long int int

unsigned int int

DOMString str or bytes

null None



Accessor Methods

The mapping from OMG IDL to Python defines accessor functions for IDL attribute declarations in much the way the Java mapping does. Mapping the IDL declarations

readonly attribute string someValue;

attribute string anotherValue;



yields three accessor functions: a “get” method for someValue (_get_someValue()), and “get” and “set” methods for anotherValue (_get_anotherValue() and _set_anotherValue()). The mapping, in particular, does not require that the IDL attributes are accessible as normal Python attributes: object.someValue is not required

to work, and may raise an AttributeError.

The Python DOM API, however, does require that normal attribute access work. This means that the typical surro-gates generated by Python IDL compilers are not likely to work, and wrapper objects may be needed on the client if the DOM objects are accessed via CORBA. While this does require some additional consideration for CORBA DOM clients, the implementers with experience using DOM over CORBA from Python do not consider this a problem. Attributes that are declared readonly may not restrict write access in all DOM implementations.

In the Python DOM API, accessor functions are not required. If provided, they should take the form defined by the Python IDL mapping, but these methods are considered unnecessary since the attributes are accessible directly from Python. “Set” accessors should never be provided for readonly attributes.

The IDL definitions do not fully embody the requirements of the W3C DOM API, such as the notion of certain objects, such as the return value of getElementsByTagName(), being “live”. The Python DOM API does not require implementations to enforce such requirements.



21.7 xml.dom.minidom — Minimal DOM implementation

Source code: Lib/xml/dom/minidom.py



xml.dom.minidom is a minimal implementation of the Document Object Model interface, with an API similar to that in other languages. It is intended to be simpler than the full DOM and also significantly smaller. Users who are

not already proficient with the DOM should consider using the xml.etree.ElementTree module for their XML processing instead.



Á Warning

The xml.dom.minidom module is not secure against maliciously constructed data. If you need to parse untrusted

or unauthenticated data see XML vulnerabilities.



DOM applications typically start by parsing some XML into a DOM. With xml.dom.minidom, this is done through the parse functions:

from xml.dom.minidom import parse, parseString

dom1 = parse('c:\\temp\\mydata.xml') # parse an XML file by name

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)



datasource = open('c:\\temp\\mydata.xml')

dom2 = parse(datasource) # parse an open file

dom3 = parseString('Some data some more data')



The parse() function can take either a filename or an open file object.

xml.dom.minidom.parse( filename_or_file, parser=None, bufsize=None)

Return a Document from the given input. filename_or_file may be either a file name, or a file-like object.

parser, if given, must be a SAX2 parser object. This function will change the document handler of the parser

and activate namespace support; other parser configuration (like setting an entity resolver) must have been

done in advance.

If you have XML in a string, you can use the parseString() function instead:

xml.dom.minidom.parseString(string, parser=None)

Return a Document that represents the string. This method creates an io.StringIO object for the string and

passes that on to parse().

Both functions return a Document object representing the content of the document.

What the parse() and parseString() functions do is connect an XML parser with a “DOM builder” that can accept parse events from any SAX parser and convert them into a DOM tree. The name of the functions are perhaps misleading, but are easy to grasp when learning the interfaces. The parsing of the document will be completed before these functions return; it’s simply that these functions do not provide a parser implementation themselves.

You can also create a Document by calling a method on a “DOM Implementation” object. You can get this object

either by calling the getDOMImplementation() function in the xml.dom package or the xml.dom.minidom module. Once you have a Document, you can add child nodes to it to populate the DOM:

from xml.dom.minidom import getDOMImplementation

impl = getDOMImplementation()

newdoc = impl.createDocument(None, "some_tag", None)

top_element = newdoc.documentElement

text = newdoc.createTextNode('Some textual content.') top_element.appendChild(text)



Once you have a DOM document object, you can access the parts of your XML document through its properties and methods. These properties are defined in the DOM specification. The main property of the document object is the documentElement property. It gives you the main element in the XML document: the one that holds all others. Here is an example program:

dom3 = parseString("Some data")

assert dom3.documentElement.tagName == "myxml"



When you are finished with a DOM tree, you may optionally call the unlink() method to encourage early cleanup

of the now-unneeded objects. unlink() is an xml.dom.minidom-specific extension to the DOM API that renders the node and its descendants essentially useless. Otherwise, Python’s garbage collector will eventually take care of the objects in the tree.



µ See also

Document Object Model (DOM) Level 1 Specification

The W3C recommendation for the DOM supported by xml.dom.minidom.



The Python Library Reference, Release 3.13.2



21.7.1 DOM Objects

The definition of the DOM API for Python is given as part of the xml.dom module documentation. This section

lists the differences between the API and xml.dom.minidom.

Node.unlink()

Break internal references within the DOM so that it will be garbage collected on versions of Python without

cyclic GC. Even when cyclic GC is available, using this can make large amounts of memory available sooner,

so calling this on DOM objects as soon as they are no longer needed is good practice. This only needs to be

called on the Document object, but may be called on child nodes to discard children of that node.

You can avoid calling this method explicitly by using the with statement. The following code will automatically

unlink dom when the with block is exited:

with xml.dom.minidom.parse(datasource) as dom:

... # Work with dom.



Node.writexml(writer, indent=”, addindent=”, newl=”, encoding=None, standalone=None)

Write XML to the writer object. The writer receives texts but not bytes as input, it should have a write()

method which matches that of the file object interface. The indent parameter is the indentation of the current

node. The addindent parameter is the incremental indentation to use for subnodes of the current one. The

newl parameter specifies the string to use to terminate newlines.

For the Document node, an additional keyword argument encoding can be used to specify the encoding field

of the XML header.

Similarly, explicitly stating the standalone argument causes the standalone document declarations to be added

to the prologue of the XML document. If the value is set to True, standalone="yes" is added, otherwise

it is set to "no". Not stating the argument will omit the declaration from the document.

Changed in version 3.8: The writexml() method now preserves the attribute order specified by the user.

Changed in version 3.9: The standalone parameter was added.

Node.toxml(encoding=None, standalone=None)

Return a string or byte string containing the XML represented by the DOM node.

With an explicit 1 encoding argument, the result is a byte string in the specified encoding. With no encoding

argument, the result is a Unicode string, and the XML declaration in the resulting string does not specify an

encoding. Encoding this string in an encoding other than UTF-8 is likely incorrect, since UTF-8 is the default

encoding of XML.

The standalone argument behaves exactly as in writexml().

Changed in version 3.8: The toxml() method now preserves the attribute order specified by the user.

Changed in version 3.9: The standalone parameter was added.

Node.toprettyxml(indent=’\t’, newl=’\n’, encoding=None, standalone=None)

Return a pretty-printed version of the document. indent specifies the indentation string and defaults to a tabu-

lator; newl specifies the string emitted at the end of each line and defaults to \n.

The encoding argument behaves like the corresponding argument of toxml().

The standalone argument behaves exactly as in writexml().

Changed in version 3.8: The toprettyxml() method now preserves the attribute order specified by the user.

Changed in version 3.9: The standalone parameter was added.

1 The encoding name included in the XML output should conform to the appropriate standards. For example, “UTF-8” is valid, but

“UTF8” is not valid in an XML document’s declaration, even though Python accepts it as an encoding name. See https://www.w3.org/TR/

2006/REC-xml11-20060816/#NT-EncodingDecl and https://www.iana.org/assignments/character-sets/character-sets.xhtml.



The Python Library Reference, Release 3.13.2



21.7.2 DOM Example

This example program is a fairly realistic example of a simple program. In this particular case, we do not take much advantage of the flexibility of the DOM.

import xml.dom.minidom

document = """\





This is a demo

Of a program for processing slides





It is important

To have more than

one slide





"""

dom = xml.dom.minidom.parseString(document)

def getText(nodelist):

rc = []

for node in nodelist:

if node.nodeType == node.TEXT_NODE:

rc.append(node.data)

return ''.join(rc)

def handleSlideshow(slideshow):

print("")

handleSlideshowTitle(slideshow.getElementsByTagName("title")[0])

slides = slideshow.getElementsByTagName("slide")

handleToc(slides)

handleSlides(slides)

print("")

def handleSlides(slides):

for slide in slides:

handleSlide(slide)

def handleSlide(slide):

handleSlideTitle(slide.getElementsByTagName("title")[0])

handlePoints(slide.getElementsByTagName("point"))

def handleSlideshowTitle(title):

print(f"")

def handleSlideTitle(title):

print(f"





{getText(title.childNodes)}


")

def handlePoints(points):

print("

")

for point in points:

handlePoint(point)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

print("



")

def handlePoint(point):

print(f"

{getText(point.childNodes)}

")

def handleToc(slides):

for slide in slides:

title = slide.getElementsByTagName("title")[0]

print(f"

{getText(title.childNodes)}

")

handleSlideshow(dom)



21.7.3 minidom and the DOM standard

The xml.dom.minidom module is essentially a DOM 1.0-compatible DOM with some DOM 2 features (primarily namespace features).

Usage of the DOM interface in Python is straight-forward. The following mapping rules apply:

• Interfaces are accessed through instance objects. Applications should not instantiate the classes themselves;

they should use the creator functions available on the Document object. Derived interfaces support all opera-

tions (and attributes) from the base interfaces, plus any new operations.

• Operations are used as methods. Since the DOM uses only in parameters, the arguments are passed in normal

order (from left to right). There are no optional arguments. void operations return None.

• IDL attributes map to instance attributes. For compatibility with the OMG IDL language mapping for Python,

an attribute foo can also be accessed through accessor methods _get_foo() and _set_foo(). readonly

attributes must not be changed; this is not enforced at runtime.

• The types short int, unsigned int, unsigned long long, and boolean all map to Python integer

objects.

• The type DOMString maps to Python strings. xml.dom.minidom supports either bytes or strings, but will

normally produce strings. Values of type DOMString may also be None where allowed to have the IDL null

value by the DOM specification from the W3C.

• const declarations map to variables in their respective scope (e.g. xml.dom.minidom.Node.

PROCESSING_INSTRUCTION_NODE); they must not be changed.

• DOMException is currently not supported in xml.dom.minidom. Instead, xml.dom.minidom uses stan-

dard Python exceptions such as TypeError and AttributeError.

• NodeList objects are implemented using Python’s built-in list type. These objects provide the interface de-

fined in the DOM specification, but with earlier versions of Python they do not support the official API. They

are, however, much more “Pythonic” than the interface defined in the W3C recommendations.

The following interfaces have no implementation in xml.dom.minidom:

• DOMTimeStamp

• EntityReference

Most of these reflect information in the XML document that is not of general utility to most DOM users.



21.8 xml.dom.pulldom — Support for building partial DOM trees

Source code: Lib/xml/dom/pulldom.py



The xml.dom.pulldom module provides a “pull parser” which can also be asked to produce DOM-accessible frag-ments of the document where necessary. The basic concept involves pulling “events” from a stream of incoming The Python Library Reference, Release 3.13.2



XML and processing them. In contrast to SAX which also employs an event-driven processing model together with callbacks, the user of a pull parser is responsible for explicitly pulling events from the stream, looping over those events until either processing is finished or an error condition occurs.



Á Warning

The xml.dom.pulldom module is not secure against maliciously constructed data. If you need to parse untrusted

or unauthenticated data see XML vulnerabilities.



Changed in version 3.7.1: The SAX parser no longer processes general external entities by default to increase security by default. To enable processing of external entities, pass a custom parser instance in:

from xml.dom.pulldom import parse

from xml.sax import make_parser

from xml.sax.handler import feature_external_ges

parser = make_parser()

parser.setFeature(feature_external_ges, True)

parse(filename, parser=parser)



Example:

from xml.dom import pulldom

doc = pulldom.parse('sales_items.xml')

for event, node in doc:

if event == pulldom.START_ELEMENT and node.tagName == 'item':

if int(node.getAttribute('price')) > 50:

doc.expandNode(node)

print(node.toxml())



event is a constant and can be one of:

• START_ELEMENT

• END_ELEMENT

• COMMENT

• START_DOCUMENT

• END_DOCUMENT

• CHARACTERS

• PROCESSING_INSTRUCTION

• IGNORABLE_WHITESPACE

node is an object of type xml.dom.minidom.Document, xml.dom.minidom.Element or xml.dom.minidom. Text.

Since the document is treated as a “flat” stream of events, the document “tree” is implicitly traversed and the desired elements are found regardless of their depth in the tree. In other words, one does not need to consider hierarchical issues such as recursive searching of the document nodes, although if the context of elements were important, one would either need to maintain some context-related state (i.e. remembering where one is in the document at any given

point) or to make use of the DOMEventStream.expandNode() method and switch to DOM-related processing.

class xml.dom.pulldom.PullDom(documentFactory=None)

Subclass of xml.sax.handler.ContentHandler.

class xml.dom.pulldom.SAX2DOM(documentFactory=None)

Subclass of xml.sax.handler.ContentHandler.

The Python Library Reference, Release 3.13.2



xml.dom.pulldom.parse( stream_or_string, parser=None, bufsize=None)

Return a DOMEventStream from the given input. stream_or_string may be either a file name, or a file-like

object. parser, if given, must be an XMLReader object. This function will change the document handler of the

parser and activate namespace support; other parser configuration (like setting an entity resolver) must have

been done in advance.

If you have XML in a string, you can use the parseString() function instead:

xml.dom.pulldom.parseString(string, parser=None)

Return a DOMEventStream that represents the (Unicode) string.

xml.dom.pulldom.default_bufsize

Default value for the bufsize parameter to parse().

The value of this variable can be changed before calling parse() and the new value will take effect.



21.8.1 DOMEventStream Objects

class xml.dom.pulldom.DOMEventStream(stream, parser, bufsize)

Changed in version 3.11: Support for __getitem__() method has been removed.

getEvent()

Return a tuple containing event and the current node as xml.dom.minidom.Document if event equals START_DOCUMENT, xml.dom.minidom.Element if event equals START_ELEMENT or END_ELEMENT or xml.dom.minidom.Text if event equals CHARACTERS. The current node does not contain informa-

tion about its children, unless expandNode() is called.

expandNode(node)

Expands all children of node into node. Example:

from xml.dom import pulldom

xml = '

Some text

and more





, →html>'

doc = pulldom.parseString(xml)

for event, node in doc:

if event == pulldom.START_ELEMENT and node.tagName == 'p':

# Following statement only prints '<p/>'

print(node.toxml())

doc.expandNode(node)

# Following statement prints node with all its children '<p>Some␣

, →text <div>and more</div></p>'

print(node.toxml())



reset()



21.9 xml.sax — Support for SAX2 parsers

Source code: Lib/xml/sax/__init__.py



The xml.sax package provides a number of modules which implement the Simple API for XML (SAX) interface for Python. The package itself provides the SAX exceptions and the convenience functions which will be most used by users of the SAX API.



Á Warning

The xml.sax module is not secure against maliciously constructed data. If you need to parse untrusted or

unauthenticated data see XML vulnerabilities.

The Python Library Reference, Release 3.13.2



Changed in version 3.7.1: The SAX parser no longer processes general external entities by default to increase security. Before, the parser created network connections to fetch remote files or loaded local files from the file system for DTD

and entities. The feature can be enabled again with method setFeature() on the parser object and argument

feature_external_ges.

The convenience functions are:

xml.sax.make_parser(parser_list=[])

Create and return a SAX XMLReader object. The first parser found will be used. If parser_list is provided, it

must be an iterable of strings which name modules that have a function named create_parser(). Modules

listed in parser_list will be used before modules in the default list of parsers.

Changed in version 3.8: The parser_list argument can be any iterable, not just a list.

xml.sax.parse(filename_or_stream, handler, error_handler=handler.ErrorHandler())

Create a SAX parser and use it to parse a document. The document, passed in as filename_or_stream, can

be a filename or a file object. The handler parameter needs to be a SAX ContentHandler instance. If

error_handler is given, it must be a SAX ErrorHandler instance; if omitted, SAXParseException will be

raised on all errors. There is no return value; all work must be done by the handler passed in.

xml.sax.parseString(string, handler, error_handler=handler.ErrorHandler())

Similar to parse(), but parses from a buffer string received as a parameter. string must be a str instance or

a bytes-like object.

Changed in version 3.5: Added support of str instances.

A typical SAX application uses three kinds of objects: readers, handlers and input sources. “Reader” in this context is another term for parser, i.e. some piece of code that reads the bytes or characters from the input source, and produces a sequence of events. The events then get distributed to the handler objects, i.e. the reader invokes a method on the handler. A SAX application must therefore obtain a reader object, create or open the input sources, create the handlers, and connect these objects all together. As the final step of preparation, the reader is called to parse the input. During parsing, methods on the handler objects are called based on structural and syntactic events from the input data.

For these objects, only the interfaces are relevant; they are normally not instantiated by the application itself. Since Python does not have an explicit notion of interface, they are formally introduced as classes, but applications may

use implementations which do not inherit from the provided classes. The InputSource, Locator, Attributes,

AttributesNS, and XMLReader interfaces are defined in the module xml.sax.xmlreader. The handler inter-

faces are defined in xml.sax.handler. For convenience, InputSource (which is often instantiated directly) and

the handler classes are also available from xml.sax. These interfaces are described below.

In addition to these classes, xml.sax provides the following exception classes.

exception xml.sax.SAXException(msg, exception=None)

Encapsulate an XML error or warning. This class can contain basic error or warning information from either

the XML parser or the application: it can be subclassed to provide additional functionality or to add localization.

Note that although the handlers defined in the ErrorHandler interface receive instances of this exception, it

is not required to actually raise the exception — it is also useful as a container for information.

When instantiated, msg should be a human-readable description of the error. The optional exception parameter,

if given, should be None or an exception that was caught by the parsing code and is being passed along as

information.

This is the base class for the other SAX exception classes.

exception xml.sax.SAXParseException( msg, exception, locator)

Subclass of SAXException raised on parse errors. Instances of this class are passed to the methods of the

SAX ErrorHandler interface to provide information about the parse error. This class supports the SAX

Locator interface as well as the SAXException interface.

exception xml.sax.SAXNotRecognizedException(msg, exception=None)

Subclass of SAXException raised when a SAX XMLReader is confronted with an unrecognized feature or

property. SAX applications and extensions may use this class for similar purposes.

The Python Library Reference, Release 3.13.2



exception xml.sax.SAXNotSupportedException(msg, exception=None)

Subclass of SAXException raised when a SAX XMLReader is asked to enable a feature that is not supported,

or to set a property to a value that the implementation does not support. SAX applications and extensions may

use this class for similar purposes.



µ See also

SAX: The Simple API for XML

This site is the focal point for the definition of the SAX API. It provides a Java implementation and online documentation. Links to implementations and historical information are also available.

Module xml.sax.handler

Definitions of the interfaces for application-provided objects.

Module xml.sax.saxutils

Convenience functions for use in SAX applications.

Module xml.sax.xmlreader

Definitions of the interfaces for parser-provided objects.



21.9.1 SAXException Objects

The SAXException exception class supports the following methods:

SAXException.getMessage()

Return a human-readable message describing the error condition.

SAXException.getException()

Return an encapsulated exception object, or None.



21.10 xml.sax.handler — Base classes for SAX handlers

Source code: Lib/xml/sax/handler.py



The SAX API defines five kinds of handlers: content handlers, DTD handlers, error handlers, entity resolvers and lexical handlers. Applications normally only need to implement those interfaces whose events they are interested in; they can implement the interfaces in a single object or in multiple objects. Handler implementations should inherit

from the base classes provided in the module xml.sax.handler, so that all methods get default implementations.

class xml.sax.handler.ContentHandler

This is the main callback interface in SAX, and the one most important to applications. The order of events

in this interface mirrors the order of the information in the document.

class xml.sax.handler.DTDHandler

Handle DTD events.

This interface specifies only those DTD events required for basic parsing (unparsed entities and attributes).

class xml.sax.handler.EntityResolver

Basic interface for resolving entities. If you create an object implementing this interface, then register the

object with your Parser, the parser will call the method in your object to resolve all external entities.

class xml.sax.handler.ErrorHandler

Interface used by the parser to present error and warning messages to the application. The methods of this

object control whether errors are immediately converted to exceptions or are handled in some other way.



The Python Library Reference, Release 3.13.2



class xml.sax.handler.LexicalHandler

Interface used by the parser to represent low frequency events which may not be of interest to many applications.

In addition to these classes, xml.sax.handler provides symbolic constants for the feature and property names.

xml.sax.handler.feature_namespaces

value: "http://xml.org/sax/features/namespaces"

true: Perform Namespace processing.

false: Optionally do not perform Namespace processing (implies namespace-prefixes; default).

access: (parsing) read-only; (not parsing) read/write

xml.sax.handler.feature_namespace_prefixes

value: "http://xml.org/sax/features/namespace-prefixes"

true: Report the original prefixed names and attributes used for Namespace declarations.

false: Do not report attributes used for Namespace declarations, and optionally do not report original prefixed

names (default).

access: (parsing) read-only; (not parsing) read/write

xml.sax.handler.feature_string_interning

value: "http://xml.org/sax/features/string-interning"

true: All element names, prefixes, attribute names, Namespace URIs, and local names are interned using the

built-in intern function.

false: Names are not necessarily interned, although they may be (default).

access: (parsing) read-only; (not parsing) read/write

xml.sax.handler.feature_validation

value: "http://xml.org/sax/features/validation"

true: Report all validation errors (implies external-general-entities and external-parameter-entities).

false: Do not report validation errors.

access: (parsing) read-only; (not parsing) read/write

xml.sax.handler.feature_external_ges

value: "http://xml.org/sax/features/external-general-entities"

true: Include all external general (text) entities.

false: Do not include external general entities.

access: (parsing) read-only; (not parsing) read/write

xml.sax.handler.feature_external_pes

value: "http://xml.org/sax/features/external-parameter-entities"

true: Include all external parameter entities, including the external DTD subset.

false: Do not include any external parameter entities, even the external DTD subset.

access: (parsing) read-only; (not parsing) read/write

xml.sax.handler.all_features

List of all features.

xml.sax.handler.property_lexical_handler

value: "http://xml.org/sax/properties/lexical-handler"

data type: xml.sax.handler.LexicalHandler (not supported in Python 2)

description: An optional extension handler for lexical events like comments.

access: read/write



The Python Library Reference, Release 3.13.2



xml.sax.handler.property_declaration_handler

value: "http://xml.org/sax/properties/declaration-handler"

data type: xml.sax.sax2lib.DeclHandler (not supported in Python 2)

description: An optional extension handler for DTD-related events other than notations and unparsed entities.

access: read/write

xml.sax.handler.property_dom_node

value: "http://xml.org/sax/properties/dom-node"

data type: org.w3c.dom.Node (not supported in Python 2)

description: When parsing, the current DOM node being visited if this is a DOM iterator; when not parsing,

the root DOM node for iteration.

access: (parsing) read-only; (not parsing) read/write

xml.sax.handler.property_xml_string

value: "http://xml.org/sax/properties/xml-string"

data type: Bytes

description: The literal string of characters that was the source for the current event.

access: read-only

xml.sax.handler.all_properties

List of all known property names.



21.10.1 ContentHandler Objects

Users are expected to subclass ContentHandler to support their application. The following methods are called by the parser on the appropriate events in the input document:

ContentHandler.setDocumentLocator(locator)

Called by the parser to give the application a locator for locating the origin of document events.

SAX parsers are strongly encouraged (though not absolutely required) to supply a locator: if it does so, it must

supply the locator to the application by invoking this method before invoking any of the other methods in the

DocumentHandler interface.

The locator allows the application to determine the end position of any document-related event, even if the

parser is not reporting an error. Typically, the application will use this information for reporting its own errors

(such as character content that does not match an application’s business rules). The information returned by

the locator is probably not sufficient for use with a search engine.

Note that the locator will return correct information only during the invocation of the events in this interface.

The application should not attempt to use it at any other time.

ContentHandler.startDocument()

Receive notification of the beginning of a document.

The SAX parser will invoke this method only once, before any other methods in this interface or in DTDHandler

(except for setDocumentLocator()).

ContentHandler.endDocument()

Receive notification of the end of a document.

The SAX parser will invoke this method only once, and it will be the last method invoked during the parse.

The parser shall not invoke this method until it has either abandoned parsing (because of an unrecoverable

error) or reached the end of input.

ContentHandler.startPrefixMapping(prefix, uri)

Begin the scope of a prefix-URI Namespace mapping.



The Python Library Reference, Release 3.13.2



The information from this event is not necessary for normal Namespace processing: the SAX XML reader

will automatically replace prefixes for element and attribute names when the feature_namespaces feature

is enabled (the default).

There are cases, however, when applications need to use prefixes in character data or in attribute values, where

they cannot safely be expanded automatically; the startPrefixMapping() and endPrefixMapping()

events supply the information to the application to expand prefixes in those contexts itself, if necessary.

Note that startPrefixMapping() and endPrefixMapping() events are not guaranteed to be prop-

erly nested relative to each-other: all startPrefixMapping() events will occur before the correspond-

ing startElement() event, and all endPrefixMapping() events will occur after the corresponding

endElement() event, but their order is not guaranteed.

ContentHandler.endPrefixMapping(prefix)

End the scope of a prefix-URI mapping.

See startPrefixMapping() for details. This event will always occur after the corresponding

endElement() event, but the order of endPrefixMapping() events is not otherwise guaranteed.

ContentHandler.startElement(name, attrs)

Signals the start of an element in non-namespace mode.

The name parameter contains the raw XML 1.0 name of the element type as a string and the attrs parameter

holds an object of the Attributes interface (see The Attributes Interface) containing the attributes of the

element. The object passed as attrs may be re-used by the parser; holding on to a reference to it is not a reliable

way to keep a copy of the attributes. To keep a copy of the attributes, use the copy() method of the attrs

object.

ContentHandler.endElement(name)

Signals the end of an element in non-namespace mode.

The name parameter contains the name of the element type, just as with the startElement() event.

ContentHandler.startElementNS(name, qname, attrs)

Signals the start of an element in namespace mode.

The name parameter contains the name of the element type as a (uri, localname) tuple, the qname param-

eter contains the raw XML 1.0 name used in the source document, and the attrs parameter holds an instance

of the AttributesNS interface (see The AttributesNS Interface) containing the attributes of the element. If

no namespace is associated with the element, the uri component of name will be None. The object passed as

attrs may be re-used by the parser; holding on to a reference to it is not a reliable way to keep a copy of the

attributes. To keep a copy of the attributes, use the copy() method of the attrs object.

Parsers may set the qname parameter to None, unless the feature_namespace_prefixes feature is acti-

vated.

ContentHandler.endElementNS(name, qname)

Signals the end of an element in namespace mode.

The name parameter contains the name of the element type, just as with the startElementNS() method,

likewise the qname parameter.

ContentHandler.characters(content)

Receive notification of character data.

The Parser will call this method to report each chunk of character data. SAX parsers may return all contiguous

character data in a single chunk, or they may split it into several chunks; however, all of the characters in any

single event must come from the same external entity so that the Locator provides useful information.

content may be a string or bytes instance; the expat reader module always produces strings.



The Python Library Reference, Release 3.13.2



® Note

The earlier SAX 1 interface provided by the Python XML Special Interest Group used a more Java-like interface for this method. Since most parsers used from Python did not take advantage of the older inter-face, the simpler signature was chosen to replace it. To convert old code to the new interface, use content instead of slicing content with the old offset and length parameters.



ContentHandler.ignorableWhitespace(whitespace)

Receive notification of ignorable whitespace in element content.

Validating Parsers must use this method to report each chunk of ignorable whitespace (see the W3C XML 1.0

recommendation, section 2.10): non-validating parsers may also use this method if they are capable of parsing

and using content models.

SAX parsers may return all contiguous whitespace in a single chunk, or they may split it into several chunks;

however, all of the characters in any single event must come from the same external entity, so that the Locator

provides useful information.

ContentHandler.processingInstruction(target, data)

Receive notification of a processing instruction.

The Parser will invoke this method once for each processing instruction found: note that processing instructions

may occur before or after the main document element.

A SAX parser should never report an XML declaration (XML 1.0, section 2.8) or a text declaration (XML

1.0, section 4.3.1) using this method.

ContentHandler.skippedEntity(name)

Receive notification of a skipped entity.

The Parser will invoke this method once for each entity skipped. Non-validating processors may skip entities if

they have not seen the declarations (because, for example, the entity was declared in an external DTD subset).

All processors may skip external entities, depending on the values of the feature_external_ges and the

feature_external_pes properties.



21.10.2 DTDHandler Objects

DTDHandler instances provide the following methods:

DTDHandler.notationDecl(name, publicId, systemId)

Handle a notation declaration event.

DTDHandler.unparsedEntityDecl(name, publicId, systemId, ndata)

Handle an unparsed entity declaration event.



21.10.3 EntityResolver Objects

EntityResolver.resolveEntity(publicId, systemId)

Resolve the system identifier of an entity and return either the system identifier to read from as a string, or an

InputSource to read from. The default implementation returns systemId.



21.10.4 ErrorHandler Objects

Objects with this interface are used to receive error and warning information from the XMLReader. If you create an

object that implements this interface, then register the object with your XMLReader, the parser will call the methods in your object to report all warnings and errors. There are three levels of errors available: warnings, (possibly)

recoverable errors, and unrecoverable errors. All methods take a SAXParseException as the only parameter. Errors and warnings may be converted to an exception by raising the passed-in exception object.

The Python Library Reference, Release 3.13.2



ErrorHandler.error(exception)

Called when the parser encounters a recoverable error. If this method does not raise an exception, parsing may

continue, but further document information should not be expected by the application. Allowing the parser to

continue may allow additional errors to be discovered in the input document.

ErrorHandler.fatalError(exception)

Called when the parser encounters an error it cannot recover from; parsing is expected to terminate when this

method returns.

ErrorHandler.warning(exception)

Called when the parser presents minor warning information to the application. Parsing is expected to continue

when this method returns, and document information will continue to be passed to the application. Raising an

exception in this method will cause parsing to end.



21.10.5 LexicalHandler Objects

Optional SAX2 handler for lexical events.

This handler is used to obtain lexical information about an XML document. Lexical information includes informa-tion describing the document encoding used and XML comments embedded in the document, as well as section boundaries for the DTD and for any CDATA sections. The lexical handlers are used in the same manner as content handlers.

Set the LexicalHandler of an XMLReader by using the setProperty method with the property identifier 'http:// xml.org/sax/properties/lexical-handler'.

LexicalHandler.comment(content)

Reports a comment anywhere in the document (including the DTD and outside the document element).

LexicalHandler.startDTD(name, public_id, system_id)

Reports the start of the DTD declarations if the document has an associated DTD.

LexicalHandler.endDTD()

Reports the end of DTD declaration.

LexicalHandler.startCDATA()

Reports the start of a CDATA marked section.

The contents of the CDATA marked section will be reported through the characters handler.

LexicalHandler.endCDATA()

Reports the end of a CDATA marked section.



21.11 xml.sax.saxutils — SAX Utilities

Source code: Lib/xml/sax/saxutils.py



The module xml.sax.saxutils contains a number of classes and functions that are commonly useful when creating SAX applications, either in direct use, or as base classes.

xml.sax.saxutils.escape(data, entities={})

Escape '&', '<', and '>' in a string of data.

You can escape other strings of data by passing a dictionary as the optional entities parameter. The keys and

values must all be strings; each key will be replaced with its corresponding value. The characters '&', '<'

and '>' are always escaped, even if entities is provided.



The Python Library Reference, Release 3.13.2



® Note

This function should only be used to escape characters that can’t be used directly in XML. Do not use this function as a general string translation function.



xml.sax.saxutils.unescape(data, entities={})

Unescape '&', '<', and '>' in a string of data.

You can unescape other strings of data by passing a dictionary as the optional entities parameter. The keys

and values must all be strings; each key will be replaced with its corresponding value. '&', '<', and

'>' are always unescaped, even if entities is provided.

xml.sax.saxutils.quoteattr(data, entities={})

Similar to escape(), but also prepares data to be used as an attribute value. The return value is a quoted

version of data with any additional required replacements. quoteattr() will select a quote character based

on the content of data, attempting to avoid encoding any quote characters in the string. If both single- and

double-quote characters are already in data, the double-quote characters will be encoded and data will be

wrapped in double-quotes. The resulting string can be used directly as an attribute value:

>>> print("%s>" % quoteattr("ab ' cd \" ef"))





This function is useful when generating attribute values for HTML or any SGML using the reference concrete

syntax.

class xml.sax.saxutils.XMLGenerator( out=None, encoding=’iso-8859-1’, short_empty_elements=False)

This class implements the ContentHandler interface by writing SAX events back into an XML document.

In other words, using an XMLGenerator as the content handler will reproduce the original document being

parsed. out should be a file-like object which will default to sys.stdout. encoding is the encoding of the out-

put stream which defaults to 'iso-8859-1'. short_empty_elements controls the formatting of elements that

contain no content: if False (the default) they are emitted as a pair of start/end tags, if set to True they are

emitted as a single self-closed tag.

Changed in version 3.2: Added the short_empty_elements parameter.

class xml.sax.saxutils.XMLFilterBase(base)

This class is designed to sit between an XMLReader and the client application’s event handlers. By default, it

does nothing but pass requests up to the reader and events on to the handlers unmodified, but subclasses can

override specific methods to modify the event stream or the configuration requests as they pass through.

xml.sax.saxutils.prepare_input_source(source, base=”)

This function takes an input source and an optional base URL and returns a fully resolved InputSource object

ready for reading. The input source can be given as a string, a file-like object, or an InputSource object;

parsers will use this function to implement the polymorphic source argument to their parse() method.



21.12 xml.sax.xmlreader — Interface for XML parsers

Source code: Lib/xml/sax/xmlreader.py



SAX parsers implement the XMLReader interface. They are implemented in a Python module, which must provide a

function create_parser(). This function is invoked by xml.sax.make_parser() with no arguments to create a new parser object.

class xml.sax.xmlreader.XMLReader

Base class which can be inherited by SAX parsers.

The Python Library Reference, Release 3.13.2



class xml.sax.xmlreader.IncrementalParser

In some cases, it is desirable not to parse an input source at once, but to feed chunks of the document as

they get available. Note that the reader will normally not read the entire file, but read it in chunks as well;

still parse() won’t return until the entire document is processed. So these interfaces should be used if the

blocking behaviour of parse() is not desirable.

When the parser is instantiated it is ready to begin accepting data from the feed method immediately. After

parsing has been finished with a call to close the reset method must be called to make the parser ready to accept

new data, either from feed or using the parse method.

Note that these methods must not be called during parsing, that is, after parse has been called and before it

returns.

By default, the class also implements the parse method of the XMLReader interface using the feed, close and

reset methods of the IncrementalParser interface as a convenience to SAX 2.0 driver writers.

class xml.sax.xmlreader.Locator

Interface for associating a SAX event with a document location. A locator object will return valid results only

during calls to DocumentHandler methods; at any other time, the results are unpredictable. If information is

not available, methods may return None.

class xml.sax.xmlreader.InputSource( system_id=None)

Encapsulation of the information needed by the XMLReader to read entities.

This class may include information about the public identifier, system identifier, byte stream (possibly with

character encoding information) and/or the character stream of an entity.

Applications will create objects of this class for use in the XMLReader.parse() method and for returning

from EntityResolver.resolveEntity.

An InputSource belongs to the application, the XMLReader is not allowed to modify InputSource objects

passed to it from the application, although it may make copies and modify those.

class xml.sax.xmlreader.AttributesImpl(attrs)

This is an implementation of the Attributes interface (see section The Attributes Interface). This is a

dictionary-like object which represents the element attributes in a startElement() call. In addition to

the most useful dictionary operations, it supports a number of other methods as described by the interface.

Objects of this class should be instantiated by readers; attrs must be a dictionary-like object containing a

mapping from attribute names to attribute values.

class xml.sax.xmlreader.AttributesNSImpl(attrs, qnames)

Namespace-aware variant of AttributesImpl, which will be passed to startElementNS(). It is derived

from AttributesImpl, but understands attribute names as two-tuples of namespaceURI and localname. In

addition, it provides a number of methods expecting qualified names as they appear in the original document.

This class implements the AttributesNS interface (see section The AttributesNS Interface).



21.12.1 XMLReader Objects

The XMLReader interface supports the following methods:

XMLReader.parse(source)

Process an input source, producing SAX events. The source object can be a system identifier (a string iden-

tifying the input source – typically a file name or a URL), a pathlib.Path or path-like object, or an

InputSource object. When parse() returns, the input is completely processed, and the parser object

can be discarded or reset.

Changed in version 3.5: Added support of character streams.

Changed in version 3.8: Added support of path-like objects.

XMLReader.getContentHandler()

Return the current ContentHandler.

The Python Library Reference, Release 3.13.2



XMLReader.setContentHandler(handler)

Set the current ContentHandler. If no ContentHandler is set, content events will be discarded.

XMLReader.getDTDHandler()

Return the current DTDHandler.

XMLReader.setDTDHandler(handler)

Set the current DTDHandler. If no DTDHandler is set, DTD events will be discarded.

XMLReader.getEntityResolver()

Return the current EntityResolver.

XMLReader.setEntityResolver(handler)

Set the current EntityResolver. If no EntityResolver is set, attempts to resolve an external entity will

result in opening the system identifier for the entity, and fail if it is not available.

XMLReader.getErrorHandler()

Return the current ErrorHandler.

XMLReader.setErrorHandler(handler)

Set the current error handler. If no ErrorHandler is set, errors will be raised as exceptions, and warnings

will be printed.

XMLReader.setLocale(locale)

Allow an application to set the locale for errors and warnings.

SAX parsers are not required to provide localization for errors and warnings; if they cannot support the re-

quested locale, however, they must raise a SAX exception. Applications may request a locale change in the

middle of a parse.

XMLReader.getFeature(featurename)

Return the current setting for feature featurename. If the feature is not recognized,

SAXNotRecognizedException is raised. The well-known featurenames are listed in the module

xml.sax.handler .

XMLReader.setFeature(featurename, value)

Set the featurename to value. If the feature is not recognized, SAXNotRecognizedException is raised. If

the feature or its setting is not supported by the parser, SAXNotSupportedException is raised.

XMLReader.getProperty( propertyname)

Return the current setting for property propertyname. If the property is not recognized, a

SAXNotRecognizedException is raised. The well-known propertynames are listed in the module xml.

sax.handler.

XMLReader.setProperty( propertyname, value)

Set the propertyname to value. If the property is not recognized, SAXNotRecognizedException is raised.

If the property or its setting is not supported by the parser, SAXNotSupportedException is raised.



21.12.2 IncrementalParser Objects

Instances of IncrementalParser offer the following additional methods:

IncrementalParser.feed(data)

Process a chunk of data.

IncrementalParser.close()

Assume the end of the document. That will check well-formedness conditions that can be checked only at the

end, invoke handlers, and may clean up resources allocated during parsing.

IncrementalParser.reset()

This method is called after close has been called to reset the parser so that it is ready to parse new documents.

The results of calling parse or feed after close without calling reset are undefined.

The Python Library Reference, Release 3.13.2



21.12.3 Locator Objects

Instances of Locator provide these methods:

Locator.getColumnNumber()

Return the column number where the current event begins.

Locator.getLineNumber()

Return the line number where the current event begins.

Locator.getPublicId()

Return the public identifier for the current event.

Locator.getSystemId()

Return the system identifier for the current event.



21.12.4 InputSource Objects

InputSource.setPublicId(id)

Sets the public identifier of this InputSource.

InputSource.getPublicId()

Returns the public identifier of this InputSource.

InputSource.setSystemId(id)

Sets the system identifier of this InputSource.

InputSource.getSystemId()

Returns the system identifier of this InputSource.

InputSource.setEncoding(encoding)

Sets the character encoding of this InputSource.

The encoding must be a string acceptable for an XML encoding declaration (see section 4.3.3 of the XML

recommendation).

The encoding attribute of the InputSource is ignored if the InputSource also contains a character stream.

InputSource.getEncoding()

Get the character encoding of this InputSource.

InputSource.setByteStream(bytefile)

Set the byte stream (a binary file) for this input source.

The SAX parser will ignore this if there is also a character stream specified, but it will use a byte stream in

preference to opening a URI connection itself.

If the application knows the character encoding of the byte stream, it should set it with the setEncoding method.

InputSource.getByteStream()

Get the byte stream for this input source.

The getEncoding method will return the character encoding for this byte stream, or None if unknown.

InputSource.setCharacterStream(charfile)

Set the character stream (a text file) for this input source.

If there is a character stream specified, the SAX parser will ignore any byte stream and will not attempt to

open a URI connection to the system identifier.

InputSource.getCharacterStream()

Get the character stream for this input source.



The Python Library Reference, Release 3.13.2



21.12.5 The Attributes Interface

Attributes objects implement a portion of the mapping protocol, including the methods copy(), get(), __contains__(), items(), keys(), and values(). The following methods are also provided:

Attributes.getLength()

Return the number of attributes.

Attributes.getNames()

Return the names of the attributes.

Attributes.getType(name)

Returns the type of the attribute name, which is normally 'CDATA'.

Attributes.getValue(name)

Return the value of attribute name.



21.12.6 The AttributesNS Interface

This interface is a subtype of the Attributes interface (see section The Attributes Interface). All methods supported by that interface are also available on AttributesNS objects.

The following methods are also available:

AttributesNS.getValueByQName(name)

Return the value for a qualified name.

AttributesNS.getNameByQName(name)

Return the (namespace, localname) pair for a qualified name.

AttributesNS.getQNameByName(name)

Return the qualified name for a (namespace, localname) pair.

AttributesNS.getQNames()

Return the qualified names of all attributes.



21.13 xml.parsers.expat — Fast XML parsing using Expat



Á Warning

The pyexpat module is not secure against maliciously constructed data. If you need to parse untrusted or

unauthenticated data see XML vulnerabilities.



The xml.parsers.expat module is a Python interface to the Expat non-validating XML parser. The module pro-vides a single extension type, xmlparser, that represents the current state of an XML parser. After an xmlparser object has been created, various attributes of the object can be set to handler functions. When an XML document is then fed to the parser, the handler functions are called for the character data and markup in the XML document.

This module uses the pyexpat module to provide access to the Expat parser. Direct use of the pyexpat module is deprecated.

This module provides one exception and one type object:

exception xml.parsers.expat.ExpatError

The exception raised when Expat reports an error. See section ExpatError Exceptions for more information on

interpreting Expat errors.



The Python Library Reference, Release 3.13.2



exception xml.parsers.expat.error

Alias for ExpatError.

xml.parsers.expat.XMLParserType

The type of the return values from the ParserCreate() function.

The xml.parsers.expat module contains two functions:

xml.parsers.expat.ErrorString(errno)

Returns an explanatory string for a given error number errno.

xml.parsers.expat.ParserCreate(encoding=None, namespace_separator=None)

Creates and returns a new xmlparser object. encoding, if specified, must be a string naming the encoding

used by the XML data. Expat doesn’t support as many encodings as Python does, and its repertoire of encodings

can’t be extended; it supports UTF-8, UTF-16, ISO-8859-1 (Latin1), and ASCII. If 1 encoding is given it will

override the implicit or explicit encoding of the document.

Expat can optionally do XML namespace processing for you, enabled by providing a value for names-

pace_separator. The value must be a one-character string; a ValueError will be raised if the string has

an illegal length (None is considered the same as omission). When namespace processing is enabled, element

type names and attribute names that belong to a namespace will be expanded. The element name passed to

the element handlers StartElementHandler and EndElementHandler will be the concatenation of the

namespace URI, the namespace separator character, and the local part of the name. If the namespace sep-

arator is a zero byte (chr(0)) then the namespace URI and the local part will be concatenated without any

separator.

For example, if namespace_separator is set to a space character (' ') and the following document is parsed:

<?xml version="1.0"?>

<root xmlns = "http://default-namespace.org/"

xmlns:py = "http://www.python.org/ns/">

<py:elem1 />

<elem2 xmlns="" />

</root>



StartElementHandler will receive the following strings for each element:

http://default-namespace.org/ root

http://www.python.org/ns/ elem1

elem2



Due to limitations in the Expat library used by pyexpat, the xmlparser instance returned can only be used

to parse a single XML document. Call ParserCreate for each document to provide unique parser instances.



µ See also

The Expat XML Parser

Home page of the Expat project.



21.13.1 XMLParser Objects

xmlparser objects have the following methods:

xmlparser.Parse(data[, isfinal ])

Parses the contents of the string data, calling the appropriate handler functions to process the parsed data.

isfinal must be true on the final call to this method; it allows the parsing of a single file in fragments, not the

submission of multiple files. data can be the empty string at any time.

1 The encoding string included in XML output should conform to the appropriate standards. For example, “UTF-8” is valid, but “UTF8”

is not. See https://www.w3.org/TR/2006/REC-xml11-20060816/#NT-EncodingDecl and https://www.iana.org/assignments/character-sets/

character-sets.xhtml.

The Python Library Reference, Release 3.13.2



xmlparser.ParseFile(file)

Parse XML data reading from the object file. file only needs to provide the read(nbytes) method, returning

the empty string when there’s no more data.

xmlparser.SetBase(base)

Sets the base to be used for resolving relative URIs in system identifiers in declarations. Resolving rel-

ative identifiers is left to the application: this value will be passed through as the base argument to the

ExternalEntityRefHandler(), NotationDeclHandler(), and UnparsedEntityDeclHandler()

functions.

xmlparser.GetBase()

Returns a string containing the base set by a previous call to SetBase(), or None if SetBase() hasn’t been

called.

xmlparser.GetInputContext()

Returns the input data that generated the current event as a string. The data is in the encoding of the entity

which contains the text. When called while an event handler is not active, the return value is None.

xmlparser.ExternalEntityParserCreate(context[, encoding ])

Create a “child” parser which can be used to parse an external parsed entity referred to by content parsed by the

parent parser. The context parameter should be the string passed to the ExternalEntityRefHandler()

handler function, described below. The child parser is created with the ordered_attributes and

specified_attributes set to the values of this parser.

xmlparser.SetParamEntityParsing(flag)

Control parsing of parameter entities (including the external DTD subset). Possible flag values

are XML_PARAM_ENTITY_PARSING_NEVER, XML_PARAM_ENTITY_PARSING_UNLESS_STANDALONE and

XML_PARAM_ENTITY_PARSING_ALWAYS . Return true if setting the flag was successful.

xmlparser.UseForeignDTD( flag [ ])

Calling this with a true value for flag (the default) will cause Expat to call the ExternalEntityRefHandler

with None for all arguments to allow an alternate DTD to be loaded. If the document does not

contain a document type declaration, the ExternalEntityRefHandler will still be called, but the

StartDoctypeDeclHandler and EndDoctypeDeclHandler will not be called.

Passing a false value for flag will cancel a previous call that passed a true value, but otherwise has no effect.

This method can only be called before the Parse() or ParseFile() methods are called; calling it after

either of those have been called causes ExpatError to be raised with the code attribute set to errors.

codes[errors.XML_ERROR_CANT_CHANGE_FEATURE_ONCE_PARSING].

xmlparser.SetReparseDeferralEnabled( enabled)



Á Warning

Calling SetReparseDeferralEnabled(False) has security implications, as detailed below; please make sure to understand these consequences prior to using the SetReparseDeferralEnabled method.



Expat 2.6.0 introduced a security mechanism called “reparse deferral” where instead of causing denial of

service through quadratic runtime from reparsing large tokens, reparsing of unfinished tokens is now delayed

by default until a sufficient amount of input is reached. Due to this delay, registered handlers may — depending

of the sizing of input chunks pushed to Expat — no longer be called right after pushing new input to the parser.

Where immediate feedback and taking over responsibility of protecting against denial of service from large

tokens are both wanted, calling SetReparseDeferralEnabled(False) disables reparse deferral for the

current Expat parser instance, temporarily or altogether. Calling SetReparseDeferralEnabled(True)

allows re-enabling reparse deferral.

Note that SetReparseDeferralEnabled() has been backported to some prior releases of CPython as a

security fix. Check for availability of SetReparseDeferralEnabled() using hasattr() if used in code

running across a variety of Python versions.

The Python Library Reference, Release 3.13.2



Added in version 3.13.

xmlparser.GetReparseDeferralEnabled()

Returns whether reparse deferral is currently enabled for the given Expat parser instance.

Added in version 3.13.

xmlparser objects have the following attributes:

xmlparser.buffer_size

The size of the buffer used when buffer_text is true. A new buffer size can be set by assigning a new integer

value to this attribute. When the size is changed, the buffer will be flushed.

xmlparser.buffer_text

Setting this to true causes the xmlparser object to buffer textual content returned by Expat to avoid multiple

calls to the CharacterDataHandler() callback whenever possible. This can improve performance sub-

stantially since Expat normally breaks character data into chunks at every line ending. This attribute is false

by default, and may be changed at any time. Note that when it is false, data that does not contain newlines may

be chunked too.

xmlparser.buffer_used

If buffer_text is enabled, the number of bytes stored in the buffer. These bytes represent UTF-8 encoded

text. This attribute has no meaningful interpretation when buffer_text is false.

xmlparser.ordered_attributes

Setting this attribute to a non-zero integer causes the attributes to be reported as a list rather than a dictionary.

The attributes are presented in the order found in the document text. For each attribute, two list entries are

presented: the attribute name and the attribute value. (Older versions of this module also used this format.)

By default, this attribute is false; it may be changed at any time.

xmlparser.specified_attributes

If set to a non-zero integer, the parser will report only those attributes which were specified in the document

instance and not those which were derived from attribute declarations. Applications which set this need to be

especially careful to use what additional information is available from the declarations as needed to comply

with the standards for the behavior of XML processors. By default, this attribute is false; it may be changed at

any time.

The following attributes contain values relating to the most recent error encountered by an xmlparser object,

and will only have correct values once a call to Parse() or ParseFile() has raised an xml.parsers.expat.

ExpatError exception.

xmlparser.ErrorByteIndex

Byte index at which an error occurred.

xmlparser.ErrorCode

Numeric code specifying the problem. This value can be passed to the ErrorString() function, or compared

to one of the constants defined in the errors object.

xmlparser.ErrorColumnNumber

Column number at which an error occurred.

xmlparser.ErrorLineNumber

Line number at which an error occurred.

The following attributes contain values relating to the current parse location in an xmlparser object. During a callback reporting a parse event they indicate the location of the first of the sequence of characters that generated the event. When called outside of a callback, the position indicated will be just past the last parse event (regardless of whether there was an associated callback).

xmlparser.CurrentByteIndex

Current byte index in the parser input.

The Python Library Reference, Release 3.13.2



xmlparser.CurrentColumnNumber

Current column number in the parser input.

xmlparser.CurrentLineNumber

Current line number in the parser input.

Here is the list of handlers that can be set. To set a handler on an xmlparser object o, use o.handlername = func. handlername must be taken from the following list, and func must be a callable object accepting the correct number of arguments. The arguments are all strings, unless otherwise stated.

xmlparser.XmlDeclHandler(version, encoding, standalone)

Called when the XML declaration is parsed. The XML declaration is the (optional) declaration of the appli-

cable version of the XML recommendation, the encoding of the document text, and an optional “standalone”

declaration. version and encoding will be strings, and standalone will be 1 if the document is declared stan-

dalone, 0 if it is declared not to be standalone, or-1 if the standalone clause was omitted. This is only available

with Expat version 1.95.0 or newer.

xmlparser.StartDoctypeDeclHandler(doctypeName, systemId, publicId, has_internal_subset)

Called when Expat begins parsing the document type declaration (). The doctypeName is

provided exactly as presented. The systemId and publicId parameters give the system and public identifiers if

specified, or None if omitted. has_internal_subset will be true if the document contains and internal document

declaration subset. This requires Expat version 1.2 or newer.

xmlparser.EndDoctypeDeclHandler()

Called when Expat is done parsing the document type declaration. This requires Expat version 1.2 or newer.

xmlparser.ElementDeclHandler(name, model)

Called once for each element type declaration. name is the name of the element type, and model is a repre-

sentation of the content model.

xmlparser.AttlistDeclHandler(elname, attname, type, default, required)

Called for each declared attribute for an element type. If an attribute list declaration declares three attributes,

this handler is called three times, once for each attribute. elname is the name of the element to which the

declaration applies and attname is the name of the attribute declared. The attribute type is a string passed as

type; the possible values are 'CDATA', 'ID', 'IDREF', … default gives the default value for the attribute used

when the attribute is not specified by the document instance, or None if there is no default value (#IMPLIED

values). If the attribute is required to be given in the document instance, required will be true. This requires

Expat version 1.95.0 or newer.

xmlparser.StartElementHandler(name, attributes)

Called for the start of every element. name is a string containing the element name, and attributes is the element

attributes. If ordered_attributes is true, this is a list (see ordered_attributes for a full description).

Otherwise it’s a dictionary mapping names to values.

xmlparser.EndElementHandler(name)

Called for the end of every element.

xmlparser.ProcessingInstructionHandler(target, data)

Called for every processing instruction.

xmlparser.CharacterDataHandler(data)

Called for character data. This will be called for normal character data, CDATA marked content, and ignorable

whitespace. Applications which must distinguish these cases can use the StartCdataSectionHandler,

EndCdataSectionHandler, and ElementDeclHandler callbacks to collect the required information.

Note that the character data may be chunked even if it is short and so you may receive more than one call

to CharacterDataHandler(). Set the buffer_text instance attribute to True to avoid that.

xmlparser.UnparsedEntityDeclHandler( entityName, base, systemId, publicId, notationName)

Called for unparsed (NDATA) entity declarations. This is only present for version 1.2 of the Expat library; for

more recent versions, use EntityDeclHandler instead. (The underlying function in the Expat library has

been declared obsolete.)

The Python Library Reference, Release 3.13.2



xmlparser.EntityDeclHandler(entityName, is_parameter_entity, value, base, systemId, publicId,

notationName)

Called for all entity declarations. For parameter and internal entities, value will be a string giving the declared

contents of the entity; this will be None for external entities. The notationName parameter will be None for

parsed entities, and the name of the notation for unparsed entities. is_parameter_entity will be true if the entity

is a parameter entity or false for general entities (most applications only need to be concerned with general

entities). This is only available starting with version 1.95.0 of the Expat library.

xmlparser.NotationDeclHandler(notationName, base, systemId, publicId)

Called for notation declarations. notationName, base, and systemId, and publicId are strings if given. If the

public identifier is omitted, publicId will be None.

xmlparser.StartNamespaceDeclHandler( prefix, uri)

Called when an element contains a namespace declaration. Namespace declarations are processed before the

StartElementHandler is called for the element on which declarations are placed.

xmlparser.EndNamespaceDeclHandler(prefix)

Called when the closing tag is reached for an element that contained a namespace declaration. This is

called once for each namespace declaration on the element in the reverse of the order for which the

StartNamespaceDeclHandler was called to indicate the start of each namespace declaration’s scope. Calls

to this handler are made after the corresponding EndElementHandler for the end of the element.

xmlparser.CommentHandler(data)

Called for comments. data is the text of the comment, excluding the leading ''.

xmlparser.StartCdataSectionHandler()

Called at the start of a CDATA section. This and EndCdataSectionHandler are needed to be able to

identify the syntactical start and end for CDATA sections.

xmlparser.EndCdataSectionHandler()

Called at the end of a CDATA section.

xmlparser.DefaultHandler(data)

Called for any characters in the XML document for which no applicable handler has been specified. This means

characters that are part of a construct which could be reported, but for which no handler has been supplied.

xmlparser.DefaultHandlerExpand(data)

This is the same as the DefaultHandler(), but doesn’t inhibit expansion of internal entities. The entity

reference will not be passed to the default handler.

xmlparser.NotStandaloneHandler()

Called if the XML document hasn’t been declared as being a standalone document. This happens when there is

an external subset or a reference to a parameter entity, but the XML declaration does not set standalone to yes

in an XML declaration. If this handler returns 0, then the parser will raise an XML_ERROR_NOT_STANDALONE

error. If this handler is not set, no exception is raised by the parser for this condition.

xmlparser.ExternalEntityRefHandler(context, base, systemId, publicId)

Called for references to external entities. base is the current base, as set by a previous call to SetBase(). The

public and system identifiers, systemId and publicId, are strings if given; if the public identifier is not given,

publicId will be None. The context value is opaque and should only be used as described below.

For external entities to be parsed, this handler must be implemented. It is responsible for creating the sub-

parser using ExternalEntityParserCreate(context), initializing it with the appropriate callbacks,

and parsing the entity. This handler should return an integer; if it returns 0, the parser will raise an

XML_ERROR_EXTERNAL_ENTITY_HANDLING error, otherwise parsing will continue.

If this handler is not provided, external entities are reported by the DefaultHandler callback, if provided.



The Python Library Reference, Release 3.13.2



21.13.2 ExpatError Exceptions

ExpatError exceptions have a number of interesting attributes:

ExpatError.code

Expat’s internal error number for the specific error. The errors.messages dictionary maps these error

numbers to Expat’s error messages. For example:

from xml.parsers.expat import ParserCreate, ExpatError, errors

p = ParserCreate()

try:

p.Parse(some_xml_document)

except ExpatError as err:

print("Error:", errors.messages[err.code])



The errors module also provides error message constants and a dictionary codes mapping these messages

back to the error codes, see below.

ExpatError.lineno

Line number on which the error was detected. The first line is numbered 1.

ExpatError.offset

Character offset into the line where the error occurred. The first column is numbered 0.



21.13.3 Example

The following program defines three handlers that just print out their arguments.

import xml.parsers.expat

# 3 handler functions

def start_element(name, attrs):

print('Start element:', name, attrs)

def end_element(name):

print('End element:', name)

def char_data(data):

print('Character data:', repr(data))

p = xml.parsers.expat.ParserCreate()

p.StartElementHandler = start_element

p.EndElementHandler = end_element

p.CharacterDataHandler = char_data

p.Parse("""

Text goes here More text

""", 1)



The output from this program is:

Start element: parent {'id': 'top'}

Start element: child1 {'name': 'paul'}

Character data: 'Text goes here'

End element: child1

Character data: '\n'

Start element: child2 {'name': 'fred'}

Character data: 'More text'

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

End element: child2

Character data: '\n'

End element: parent



21.13.4 Content Model Descriptions

Content models are described using nested tuples. Each tuple contains four values: the type, the quantifier, the name, and a tuple of children. Children are simply additional content model descriptions.

The values of the first two fields are constants defined in the xml.parsers.expat.model module. These constants can be collected in two groups: the model type group and the quantifier group.

The constants in the model type group are:

xml.parsers.expat.model.XML_CTYPE_ANY

The element named by the model name was declared to have a content model of ANY.

xml.parsers.expat.model.XML_CTYPE_CHOICE

The named element allows a choice from a number of options; this is used for content models such as (A |

B | C) .

xml.parsers.expat.model.XML_CTYPE_EMPTY

Elements which are declared to be EMPTY have this model type.

xml.parsers.expat.model.XML_CTYPE_MIXED

xml.parsers.expat.model.XML_CTYPE_NAME

xml.parsers.expat.model.XML_CTYPE_SEQ

Models which represent a series of models which follow one after the other are indicated with this model type.

This is used for models such as (A, B, C).

The constants in the quantifier group are:

xml.parsers.expat.model.XML_CQUANT_NONE

No modifier is given, so it can appear exactly once, as for A.

xml.parsers.expat.model.XML_CQUANT_OPT

The model is optional: it can appear once or not at all, as for A?.

xml.parsers.expat.model.XML_CQUANT_PLUS

The model must occur one or more times (like A+).

xml.parsers.expat.model.XML_CQUANT_REP

The model must occur zero or more times, as for A*.



21.13.5 Expat error constants

The following constants are provided in the xml.parsers.expat.errors module. These constants are useful in interpreting some of the attributes of the ExpatError exception objects raised when an error has occurred. Since for backwards compatibility reasons, the constants’ value is the error message and not the numeric error code, you do

this by comparing its code attribute with errors.codes[errors.XML_ERROR_CONSTANT_NAME].

The errors module has the following attributes:

xml.parsers.expat.errors.codes

A dictionary mapping string descriptions to their error codes.

Added in version 3.2.



The Python Library Reference, Release 3.13.2



xml.parsers.expat.errors.messages

A dictionary mapping numeric error codes to their string descriptions.

Added in version 3.2.

xml.parsers.expat.errors.XML_ERROR_ASYNC_ENTITY

xml.parsers.expat.errors.XML_ERROR_ATTRIBUTE_EXTERNAL_ENTITY_REF

An entity reference in an attribute value referred to an external entity instead of an internal entity.

xml.parsers.expat.errors.XML_ERROR_BAD_CHAR_REF

A character reference referred to a character which is illegal in XML (for example, character 0, or ‘�’).

xml.parsers.expat.errors.XML_ERROR_BINARY_ENTITY_REF

An entity reference referred to an entity which was declared with a notation, so cannot be parsed.

xml.parsers.expat.errors.XML_ERROR_DUPLICATE_ATTRIBUTE

An attribute was used more than once in a start tag.

xml.parsers.expat.errors.XML_ERROR_INCORRECT_ENCODING

xml.parsers.expat.errors.XML_ERROR_INVALID_TOKEN

Raised when an input byte could not properly be assigned to a character; for example, a NUL byte (value 0)

in a UTF-8 input stream.

xml.parsers.expat.errors.XML_ERROR_JUNK_AFTER_DOC_ELEMENT

Something other than whitespace occurred after the document element.

xml.parsers.expat.errors.XML_ERROR_MISPLACED_XML_PI

An XML declaration was found somewhere other than the start of the input data.

xml.parsers.expat.errors.XML_ERROR_NO_ELEMENTS

The document contains no elements (XML requires all documents to contain exactly one top-level element)..

xml.parsers.expat.errors.XML_ERROR_NO_MEMORY

Expat was not able to allocate memory internally.

xml.parsers.expat.errors.XML_ERROR_PARAM_ENTITY_REF

A parameter entity reference was found where it was not allowed.

xml.parsers.expat.errors.XML_ERROR_PARTIAL_CHAR

An incomplete character was found in the input.

xml.parsers.expat.errors.XML_ERROR_RECURSIVE_ENTITY_REF

An entity reference contained another reference to the same entity; possibly via a different name, and possibly

indirectly.

xml.parsers.expat.errors.XML_ERROR_SYNTAX

Some unspecified syntax error was encountered.

xml.parsers.expat.errors.XML_ERROR_TAG_MISMATCH

An end tag did not match the innermost open start tag.

xml.parsers.expat.errors.XML_ERROR_UNCLOSED_TOKEN

Some token (such as a start tag) was not closed before the end of the stream or the next token was encountered.

xml.parsers.expat.errors.XML_ERROR_UNDEFINED_ENTITY

A reference was made to an entity which was not defined.

xml.parsers.expat.errors.XML_ERROR_UNKNOWN_ENCODING

The document encoding is not supported by Expat.



The Python Library Reference, Release 3.13.2



xml.parsers.expat.errors.XML_ERROR_UNCLOSED_CDATA_SECTION

A CDATA marked section was not closed.

xml.parsers.expat.errors.XML_ERROR_EXTERNAL_ENTITY_HANDLING

xml.parsers.expat.errors.XML_ERROR_NOT_STANDALONE

The parser determined that the document was not “standalone” though it declared itself to be in the XML

declaration, and the NotStandaloneHandler was set and returned 0.

xml.parsers.expat.errors.XML_ERROR_UNEXPECTED_STATE

xml.parsers.expat.errors.XML_ERROR_ENTITY_DECLARED_IN_PE

xml.parsers.expat.errors.XML_ERROR_FEATURE_REQUIRES_XML_DTD

An operation was requested that requires DTD support to be compiled in, but Expat was configured without

DTD support. This should never be reported by a standard build of the xml.parsers.expat module.

xml.parsers.expat.errors.XML_ERROR_CANT_CHANGE_FEATURE_ONCE_PARSING

A behavioral change was requested after parsing started that can only be changed before parsing has started.

This is (currently) only raised by UseForeignDTD().

xml.parsers.expat.errors.XML_ERROR_UNBOUND_PREFIX

An undeclared prefix was found when namespace processing was enabled.

xml.parsers.expat.errors.XML_ERROR_UNDECLARING_PREFIX

The document attempted to remove the namespace declaration associated with a prefix.

xml.parsers.expat.errors.XML_ERROR_INCOMPLETE_PE

A parameter entity contained incomplete markup.

xml.parsers.expat.errors.XML_ERROR_XML_DECL

The document contained no document element at all.

xml.parsers.expat.errors.XML_ERROR_TEXT_DECL

There was an error parsing a text declaration in an external entity.

xml.parsers.expat.errors.XML_ERROR_PUBLICID

Characters were found in the public id that are not allowed.

xml.parsers.expat.errors.XML_ERROR_SUSPENDED

The requested operation was made on a suspended parser, but isn’t allowed. This includes attempts to provide

additional input or to stop the parser.

xml.parsers.expat.errors.XML_ERROR_NOT_SUSPENDED

An attempt to resume the parser was made when the parser had not been suspended.

xml.parsers.expat.errors.XML_ERROR_ABORTED

This should not be reported to Python applications.

xml.parsers.expat.errors.XML_ERROR_FINISHED

The requested operation was made on a parser which was finished parsing input, but isn’t allowed. This includes

attempts to provide additional input or to stop the parser.

xml.parsers.expat.errors.XML_ERROR_SUSPEND_PE

xml.parsers.expat.errors.XML_ERROR_RESERVED_PREFIX_XML

An attempt was made to undeclare reserved namespace prefix xml or to bind it to another namespace URI.

xml.parsers.expat.errors.XML_ERROR_RESERVED_PREFIX_XMLNS

An attempt was made to declare or undeclare reserved namespace prefix xmlns.



The Python Library Reference, Release 3.13.2



xml.parsers.expat.errors.XML_ERROR_RESERVED_NAMESPACE_URI

An attempt was made to bind the URI of one the reserved namespace prefixes xml and xmlns to another

namespace prefix.

xml.parsers.expat.errors.XML_ERROR_INVALID_ARGUMENT

This should not be reported to Python applications.

xml.parsers.expat.errors.XML_ERROR_NO_BUFFER

This should not be reported to Python applications.

xml.parsers.expat.errors.XML_ERROR_AMPLIFICATION_LIMIT_BREACH

The limit on input amplification factor (from DTD and entities) has been breached.



The Python Library Reference, Release 3.13.2





CHAPTER




TWENTYTWO



INTERNET PROTOCOLS AND SUPPORT



The modules described in this chapter implement internet protocols and support for related technology. They are

all implemented in Python. Most of these modules require the presence of the system-dependent module socket, which is currently supported on most popular platforms. Here is an overview:



22.1 webbrowser — Convenient web-browser controller

Source code: Lib/webbrowser.py



The webbrowser module provides a high-level interface to allow displaying web-based documents to users. Under

most circumstances, simply calling the open() function from this module will do the right thing.

Under Unix, graphical browsers are preferred under X11, but text-mode browsers will be used if graphical browsers are not available or an X11 display isn’t available. If text-mode browsers are used, the calling process will block until the user exits the browser.

If the environment variable BROWSER exists, it is interpreted as the os.pathsep-separated list of browsers to try ahead of the platform defaults. When the value of a list part contains the string %s, then it is interpreted as a literal browser command line to be used with the argument URL substituted for %s; if the part does not contain %s, it is

simply interpreted as the name of the browser to launch.1

For non-Unix platforms, or when a remote browser is available on Unix, the controlling process will not wait for the user to finish with the browser, but allow the remote browser to maintain its own windows on the display. If remote browsers are not available on Unix, the controlling process will launch a new browser and wait.

On iOS, the BROWSER environment variable, as well as any arguments controlling autoraise, browser preference, and new tab/window creation will be ignored. Web pages will always be opened in the user’s preferred browser, in a new

tab, with the browser being brought to the foreground. The use of the webbrowser module on iOS requires the

ctypes module. If ctypes isn’t available, calls to open() will fail.

The script webbrowser can be used as a command-line interface for the module. It accepts a URL as the argument. It accepts the following optional parameters:

•-n/--new-window opens the URL in a new browser window, if possible.

•-t/--new-tab opens the URL in a new browser page (“tab”).

The options are, naturally, mutually exclusive. Usage example:

python-m webbrowser-t "https://www.python.org"



Availability: not WASI, not Android.

The following exception is defined:

1 Executables named here without a full path will be searched in the directories given in the PATH environment variable.



The Python Library Reference, Release 3.13.2



exception webbrowser.Error

Exception raised when a browser control error occurs.

The following functions are defined:

webbrowser.open(url, new=0, autoraise=True)

Display url using the default browser. If new is 0, the url is opened in the same browser window if possible.

If new is 1, a new browser window is opened if possible. If new is 2, a new browser page (“tab”) is opened if

possible. If autoraise is True, the window is raised if possible (note that under many window managers this

will occur regardless of the setting of this variable).

Returns True if a browser was successfully launched, False otherwise.

Note that on some platforms, trying to open a filename using this function, may work and start the operating

system’s associated program. However, this is neither supported nor portable.

Raises an auditing event webbrowser.open with argument url.

webbrowser.open_new(url)

Open url in a new window of the default browser, if possible, otherwise, open url in the only browser window.

Returns True if a browser was successfully launched, False otherwise.

webbrowser.open_new_tab(url)

Open url in a new page (“tab”) of the default browser, if possible, otherwise equivalent to open_new().

Returns True if a browser was successfully launched, False otherwise.

webbrowser.get(using=None)

Return a controller object for the browser type using. If using is None, return a controller for a default browser

appropriate to the caller’s environment.

webbrowser.register(name, constructor, instance=None, *, preferred=False)

Register the browser type name. Once a browser type is registered, the get() function can return a controller

for that browser type. If instance is not provided, or is None, constructor will be called without parameters to

create an instance when needed. If instance is provided, constructor will never be called, and may be None.

Setting preferred to True makes this browser a preferred result for a get() call with no argument. Otherwise,

this entry point is only useful if you plan to either set the BROWSER variable or call get() with a nonempty

argument matching the name of a handler you declare.

Changed in version 3.7: preferred keyword-only parameter was added.

A number of browser types are predefined. This table gives the type names that may be passed to the get() function and the corresponding instantiations for the controller classes, all defined in this module.



The Python Library Reference, Release 3.13.2



Type Name Class Name Notes

'mozilla' Mozilla('mozilla')

'firefox' Mozilla('mozilla')

'epiphany' Epiphany('epiphany')

'kfmclient' Konqueror() (1)

'konqueror' Konqueror() (1)

'kfm' Konqueror() (1)

'opera' Opera()

'links' GenericBrowser('links')

'elinks' Elinks('elinks')

'lynx' GenericBrowser('lynx')

'w3m' GenericBrowser('w3m')

'windows-default' WindowsDefault (2)

'macosx' MacOSXOSAScript('default') (3)

'safari' MacOSXOSAScript('safari') (3)

'google-chrome' Chrome('google-chrome')

'chrome' Chrome('chrome')

'chromium' Chromium('chromium')

'chromium-browser' Chromium('chromium-browser')

'iosbrowser' IOSBrowser (4)



Notes:

(1) “Konqueror” is the file manager for the KDE desktop environment for Unix, and only makes sense to use if KDE

is running. Some way of reliably detecting KDE would be nice; the KDEDIR variable is not sufficient. Note also

that the name “kfm” is used even when using the konqueror command with KDE 2 — the implementation

selects the best strategy for running Konqueror.

(2) Only on Windows platforms.

(3) Only on macOS.

(4) Only on iOS.

Added in version 3.2: A new MacOSXOSAScript class has been added and is used on Mac instead of the previous MacOSX class. This adds support for opening browsers not currently set as the OS default.

Added in version 3.3: Support for Chrome/Chromium has been added.

Changed in version 3.12: Support for several obsolete browsers has been removed. Removed browsers include Grail, Mosaic, Netscape, Galeon, Skipstone, Iceape, and Firefox versions 35 and below.

Changed in version 3.13: Support for iOS has been added.

Here are some simple examples:

url = 'https://docs.python.org/'

# Open URL in a new tab, if a browser window is already open. webbrowser.open_new_tab(url)

# Open URL in new window, raising the window if possible. webbrowser.open_new(url)



22.1.1 Browser Controller Objects

Browser controllers provide these methods which parallel three of the module-level convenience functions:

controller.name

System-dependent name for the browser.

The Python Library Reference, Release 3.13.2



controller.open(url, new=0, autoraise=True)

Display url using the browser handled by this controller. If new is 1, a new browser window is opened if

possible. If new is 2, a new browser page (“tab”) is opened if possible.

controller.open_new(url)

Open url in a new window of the browser handled by this controller, if possible, otherwise, open url in the

only browser window. Alias open_new().

controller.open_new_tab(url)

Open url in a new page (“tab”) of the browser handled by this controller, if possible, otherwise equivalent to

open_new().



22.2 wsgiref — WSGI Utilities and Reference Implementation

Source code: Lib/wsgiref



The Web Server Gateway Interface (WSGI) is a standard interface between web server software and web applications written in Python. Having a standard interface makes it easy to use an application that supports WSGI with a number of different web servers.

Only authors of web servers and programming frameworks need to know every detail and corner case of the WSGI design. You don’t need to understand every detail of WSGI just to install a WSGI application or to write a web application using an existing framework.

wsgiref is a reference implementation of the WSGI specification that can be used to add WSGI support to a web server or framework. It provides utilities for manipulating WSGI environment variables and response headers, base classes for implementing WSGI servers, a demo HTTP server that serves WSGI applications, types for static type checking, and a validation tool that checks WSGI servers and applications for conformance to the WSGI specification

(PEP 3333).

See wsgi.readthedocs.io for more information about WSGI, and links to tutorials and other resources.



22.2.1 wsgiref.util – WSGI environment utilities

This module provides a variety of utility functions for working with WSGI environments. A WSGI environment is

a dictionary containing HTTP request variables as described in PEP 3333. All of the functions taking an environ

parameter expect a WSGI-compliant dictionary to be supplied; please see PEP 3333 for a detailed specification and

WSGIEnvironment for a type alias that can be used in type annotations.

wsgiref.util.guess_scheme(environ)

Return a guess for whether wsgi.url_scheme should be “http” or “https”, by checking for a HTTPS envi-

ronment variable in the environ dictionary. The return value is a string.

This function is useful when creating a gateway that wraps CGI or a CGI-like protocol such as FastCGI. Typ-

ically, servers providing such protocols will include a HTTPS variable with a value of “1”, “yes”, or “on” when

a request is received via SSL. So, this function returns “https” if such a value is found, and “http” otherwise.

wsgiref.util.request_uri(environ, include_query=True)

Return the full request URI, optionally including the query string, using the algorithm found in the “URL

Reconstruction” section of PEP 3333. If include_query is false, the query string is not included in the resulting

URI.

wsgiref.util.application_uri(environ)

Similar to request_uri(), except that the PATH_INFO and QUERY_STRING variables are ignored. The

result is the base URI of the application object addressed by the request.



The Python Library Reference, Release 3.13.2



wsgiref.util.shift_path_info(environ)

Shift a single name from PATH_INFO to SCRIPT_NAME and return the name. The environ dictionary is mod-

ified in-place; use a copy if you need to keep the original PATH_INFO or SCRIPT_NAME intact.

If there are no remaining path segments in PATH_INFO, None is returned.

Typically, this routine is used to process each portion of a request URI path, for example to treat the path as

a series of dictionary keys. This routine modifies the passed-in environment to make it suitable for invoking

another WSGI application that is located at the target URI. For example, if there is a WSGI application at /foo,

and the request URI path is /foo/bar/baz, and the WSGI application at /foo calls shift_path_info(),

it will receive the string “bar”, and the environment will be updated to be suitable for passing to a WSGI

application at /foo/bar. That is, SCRIPT_NAME will change from /foo to /foo/bar, and PATH_INFO will

change from /bar/baz to /baz.

When PATH_INFO is just a “/”, this routine returns an empty string and appends a trailing slash to

SCRIPT_NAME, even though empty path segments are normally ignored, and SCRIPT_NAME doesn’t normally

end in a slash. This is intentional behavior, to ensure that an application can tell the difference between URIs

ending in /x from ones ending in /x/ when using this routine to do object traversal.

wsgiref.util.setup_testing_defaults( environ)

Update environ with trivial defaults for testing purposes.

This routine adds various parameters required for WSGI, including HTTP_HOST, SERVER_NAME,

SERVER_PORT, REQUEST_METHOD, SCRIPT_NAME, PATH_INFO, and all of the PEP 3333-defined wsgi.

* variables. It only supplies default values, and does not replace any existing settings for these variables.

This routine is intended to make it easier for unit tests of WSGI servers and applications to set up dummy

environments. It should NOT be used by actual WSGI servers or applications, since the data is fake!

Example usage:

from wsgiref.util import setup_testing_defaults

from wsgiref.simple_server import make_server

# A relatively simple WSGI application. It's going to print out the

# environment dictionary after being updated by setup_testing_defaults

def simple_app(environ, start_response):

setup_testing_defaults(environ)

status = '200 OK'

headers = [('Content-type', 'text/plain; charset=utf-8')]

start_response(status, headers)

ret = [("%s: %s\n" % (key, value)).encode("utf-8")

for key, value in environ.items()]

return ret

with make_server('', 8000, simple_app) as httpd:

print("Serving on port 8000...")

httpd.serve_forever()



In addition to the environment functions above, the wsgiref.util module also provides these miscellaneous util-ities:

wsgiref.util.is_hop_by_hop(header_name)

Return True if ‘header_name’ is an HTTP/1.1 “Hop-by-Hop” header, as defined by RFC 2616.

class wsgiref.util.FileWrapper(filelike, blksize=8192)

A concrete implementation of the wsgiref.types.FileWrapper protocol used to convert a file-like object

to an iterator. The resulting objects are iterables. As the object is iterated over, the optional blksize parameter The Python Library Reference, Release 3.13.2



will be repeatedly passed to the filelike object’s read() method to obtain bytestrings to yield. When read()

returns an empty bytestring, iteration is ended and is not resumable.

If filelike has a close() method, the returned object will also have a close() method, and it will invoke the

filelike object’s close() method when called.

Example usage:

from io import StringIO

from wsgiref.util import FileWrapper

# We're using a StringIO-buffer for as the file-like object

filelike = StringIO("This is an example file-like object"*10)

wrapper = FileWrapper(filelike, blksize=5)

for chunk in wrapper:

print(chunk)



Changed in version 3.11: Support for __getitem__() method has been removed.



22.2.2 wsgiref.headers – WSGI response header tools

This module provides a single class, Headers, for convenient manipulation of WSGI response headers using a mapping-like interface.

class wsgiref.headers.Headers( headers [ ])

Create a mapping-like object wrapping headers, which must be a list of header name/value tuples as described

in PEP 3333. The default value of headers is an empty list.

Headers objects support typical mapping operations including __getitem__(), get(), __setitem__(),

setdefault(), __delitem__() and __contains__(). For each of these methods, the key is the header

name (treated case-insensitively), and the value is the first value associated with that header name. Setting a

header deletes any existing values for that header, then adds a new value at the end of the wrapped header list.

Headers’ existing order is generally maintained, with new headers added to the end of the wrapped list.

Unlike a dictionary, Headers objects do not raise an error when you try to get or delete a key that isn’t in the

wrapped header list. Getting a nonexistent header just returns None, and deleting a nonexistent header does

nothing.

Headers objects also support keys(), values(), and items() methods. The lists returned by keys()

and items() can include the same key more than once if there is a multi-valued header. The len() of a

Headers object is the same as the length of its items(), which is the same as the length of the wrapped

header list. In fact, the items() method just returns a copy of the wrapped header list.

Calling bytes() on a Headers object returns a formatted bytestring suitable for transmission as HTTP re-

sponse headers. Each header is placed on a line with its value, separated by a colon and a space. Each line is

terminated by a carriage return and line feed, and the bytestring is terminated with a blank line.

In addition to their mapping interface and formatting features, Headers objects also have the following meth-

ods for querying and adding multi-valued headers, and for adding headers with MIME parameters:

get_all(name)

Return a list of all the values for the named header.

The returned list will be sorted in the order they appeared in the original header list or were added to this instance, and may contain duplicates. Any fields deleted and re-inserted are always appended to the header list. If no fields exist with the given name, returns an empty list.

add_header(name, value, **_params)

Add a (possibly multi-valued) header, with optional MIME parameters specified via keyword arguments.

name is the header field to add. Keyword arguments can be used to set MIME parameters for the header field. Each parameter must be a string or None. Underscores in parameter names are converted to dashes, since dashes are illegal in Python identifiers, but many MIME parameter names include dashes. If the

The Python Library Reference, Release 3.13.2



parameter value is a string, it is added to the header value parameters in the form name="value". If it is None , only the parameter name is added. (This is used for MIME parameters without a value.) Example usage:

h.add_header('content-disposition', 'attachment', filename='bud.gif')



The above will add a header that looks like this:

Content-Disposition: attachment; filename="bud.gif"



Changed in version 3.5: headers parameter is optional.



22.2.3 wsgiref.simple_server – a simple WSGI HTTP server

This module implements a simple HTTP server (based on http.server) that serves WSGI applications. Each server instance serves a single WSGI application on a given host and port. If you want to serve multiple applications on a single host and port, you should create a WSGI application that parses PATH_INFO to select which application

to invoke for each request. (E.g., using the shift_path_info() function from wsgiref.util.)

wsgiref.simple_server.make_server(host, port, app, server_class=WSGIServer,

handler_class=WSGIRequestHandler)

Create a new WSGI server listening on host and port, accepting connections for app. The return value is an

instance of the supplied server_class, and will process requests using the specified handler_class. app must be

a WSGI application object, as defined by PEP 3333.

Example usage:

from wsgiref.simple_server import make_server, demo_app

with make_server('', 8000, demo_app) as httpd:

print("Serving HTTP on port 8000...")

# Respond to requests until process is killed

httpd.serve_forever()

# Alternative: serve one request, then exit

httpd.handle_request()



wsgiref.simple_server.demo_app(environ, start_response)

This function is a small but complete WSGI application that returns a text page containing the message “Hello

world!” and a list of the key/value pairs provided in the environ parameter. It’s useful for verifying that a WSGI

server (such as wsgiref.simple_server) is able to run a simple WSGI application correctly.

class wsgiref.simple_server.WSGIServer(server_address, RequestHandlerClass)

Create a WSGIServer instance. server_address should be a (host,port) tuple, and RequestHandlerClass

should be the subclass of http.server.BaseHTTPRequestHandler that will be used to process requests.

You do not normally need to call this constructor, as the make_server() function can handle all the details

for you.

WSGIServer is a subclass of http.server.HTTPServer, so all of its methods (such as serve_forever()

and handle_request()) are available. WSGIServer also provides these WSGI-specific methods:

set_app(application)

Sets the callable application as the WSGI application that will receive requests.

get_app()

Returns the currently set application callable.

Normally, however, you do not need to use these additional methods, as set_app() is normally called by

make_server(), and the get_app() exists mainly for the benefit of request handler instances.

The Python Library Reference, Release 3.13.2



class wsgiref.simple_server.WSGIRequestHandler(request, client_address, server)

Create an HTTP handler for the given request (i.e. a socket), client_address (a (host,port) tuple), and

server (WSGIServer instance).

You do not need to create instances of this class directly; they are automatically created as needed by

WSGIServer objects. You can, however, subclass this class and supply it as a handler_class to the

make_server() function. Some possibly relevant methods for overriding in subclasses:

get_environ()

Return a WSGIEnvironment dictionary for a request. The default implementation copies the contents

of the WSGIServer object’s base_environ dictionary attribute and then adds various headers derived from the HTTP request. Each call to this method should return a new dictionary containing all of the

relevant CGI environment variables as specified in PEP 3333.

get_stderr()

Return the object that should be used as the wsgi.errors stream. The default implementation just returns sys.stderr.

handle()

Process the HTTP request. The default implementation creates a handler instance using a wsgiref.

handlers class to implement the actual WSGI application interface.



22.2.4 wsgiref.validate — WSGI conformance checker

When creating new WSGI application objects, frameworks, servers, or middleware, it can be useful to validate the

new code’s conformance using wsgiref.validate. This module provides a function that creates WSGI application objects that validate communications between a WSGI server or gateway and a WSGI application object, to check both sides for protocol conformance.

Note that this utility does not guarantee complete PEP 3333 compliance; an absence of errors from this module does not necessarily mean that errors do not exist. However, if this module does produce an error, then it is virtually certain that either the server or application is not 100% compliant.

This module is based on the paste.lint module from Ian Bicking’s “Python Paste” library.

wsgiref.validate.validator(application)

Wrap application and return a new WSGI application object. The returned application will forward all requests

to the original application, and will check that both the application and the server invoking it are conforming

to the WSGI specification and to RFC 2616.

Any detected nonconformance results in an AssertionError being raised; note, however, that how these

errors are handled is server-dependent. For example, wsgiref.simple_server and other servers based on

wsgiref.handlers (that don’t override the error handling methods to do something else) will simply output

a message that an error has occurred, and dump the traceback to sys.stderr or some other error stream.

This wrapper may also generate output using the warnings module to indicate behaviors that are questionable

but which may not actually be prohibited by PEP 3333. Unless they are suppressed using Python command-

line options or the warnings API, any such warnings will be written to sys.stderr (not wsgi.errors,

unless they happen to be the same object).

Example usage:

from wsgiref.validate import validator

from wsgiref.simple_server import make_server

# Our callable object which is intentionally not compliant to the

# standard, so the validator is going to break

def simple_app(environ, start_response):

status = '200 OK' # HTTP Status

headers = [('Content-type', 'text/plain')] # HTTP Headers start_response(status, headers)

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)



# This is going to break because we need to return a list, and # the validator is going to inform us

return b"Hello World"

# This is the application wrapped in a validator

validator_app = validator(simple_app)

with make_server('', 8000, validator_app) as httpd:

print("Listening on port 8000....")

httpd.serve_forever()



22.2.5 wsgiref.handlers – server/gateway base classes

This module provides base handler classes for implementing WSGI servers and gateways. These base classes handle most of the work of communicating with a WSGI application, as long as they are given a CGI-like environment, along with input, output, and error streams.

class wsgiref.handlers.CGIHandler

CGI-based invocation via sys.stdin, sys.stdout, sys.stderr and os.environ. This is useful when

you have a WSGI application and want to run it as a CGI script. Simply invoke CGIHandler().run(app),

where app is the WSGI application object you wish to invoke.

This class is a subclass of BaseCGIHandler that sets wsgi.run_once to true, wsgi.multithread to

false, and wsgi.multiprocess to true, and always uses sys and os to obtain the necessary CGI streams

and environment.

class wsgiref.handlers.IISCGIHandler

A specialized alternative to CGIHandler, for use when deploying on Microsoft’s IIS web server, without

having set the config allowPathInfo option (IIS>=7) or metabase allowPathInfoForScriptMappings (IIS<7).

By default, IIS gives a PATH_INFO that duplicates the SCRIPT_NAME at the front, causing problems for WSGI

applications that wish to implement routing. This handler strips any such duplicated path.

IIS can be configured to pass the correct PATH_INFO, but this causes another bug where PATH_TRANSLATED

is wrong. Luckily this variable is rarely used and is not guaranteed by WSGI. On IIS<7, though, the setting

can only be made on a vhost level, affecting all other script mappings, many of which break when exposed to

the PATH_TRANSLATED bug. For this reason IIS<7 is almost never deployed with the fix (Even IIS7 rarely

uses it because there is still no UI for it.).

There is no way for CGI code to tell whether the option was set, so a separate handler class is provided. It

is used in the same way as CGIHandler, i.e., by calling IISCGIHandler().run(app), where app is the

WSGI application object you wish to invoke.

Added in version 3.2.

class wsgiref.handlers.BaseCGIHandler(stdin, stdout, stderr, environ, multithread=True,

multiprocess=False)

Similar to CGIHandler, but instead of using the sys and os modules, the CGI environment and I/O streams

are specified explicitly. The multithread and multiprocess values are used to set the wsgi.multithread and

wsgi.multiprocess flags for any applications run by the handler instance.

This class is a subclass of SimpleHandler intended for use with software other than HTTP “origin servers”.

If you are writing a gateway protocol implementation (such as CGI, FastCGI, SCGI, etc.) that uses a Status:

header to send an HTTP status, you probably want to subclass this instead of SimpleHandler.

class wsgiref.handlers.SimpleHandler(stdin, stdout, stderr, environ, multithread=True,

multiprocess=False)

Similar to BaseCGIHandler, but designed for use with HTTP origin servers. If you are writing an HTTP

server implementation, you will probably want to subclass this instead of BaseCGIHandler.

The Python Library Reference, Release 3.13.2



This class is a subclass of BaseHandler. It overrides the __init__(), get_stdin(), get_stderr(),

add_cgi_vars(), _write(), and _flush() methods to support explicitly setting the environment and

streams via the constructor. The supplied environment and streams are stored in the stdin, stdout, stderr,

and environ attributes.

The write() method of stdout should write each chunk in full, like io.BufferedIOBase.

class wsgiref.handlers.BaseHandler

This is an abstract base class for running WSGI applications. Each instance will handle a single HTTP request,

although in principle you could create a subclass that was reusable for multiple requests.

BaseHandler instances have only one method intended for external use:

run(app)

Run the specified WSGI application, app.

All of the other BaseHandler methods are invoked by this method in the process of running the application,

and thus exist primarily to allow customizing the process.

The following methods MUST be overridden in a subclass:

_write(data)

Buffer the bytes data for transmission to the client. It’s okay if this method actually transmits the data;

BaseHandler just separates write and flush operations for greater efficiency when the underlying system actually has such a distinction.

_flush()

Force buffered data to be transmitted to the client. It’s okay if this method is a no-op (i.e., if _write() actually sends the data).

get_stdin()

Return an object compatible with InputStream suitable for use as the wsgi.input of the request currently being processed.

get_stderr()

Return an object compatible with ErrorStream suitable for use as the wsgi.errors of the request currently being processed.

add_cgi_vars()

Insert CGI variables for the current request into the environ attribute.

Here are some other methods and attributes you may wish to override. This list is only a summary, however,

and does not include every method that can be overridden. You should consult the docstrings and source code

for additional information before attempting to create a customized BaseHandler subclass.

Attributes and methods for customizing the WSGI environment:

wsgi_multithread

The value to be used for the wsgi.multithread environment variable. It defaults to true in

BaseHandler, but may have a different default (or be set by the constructor) in the other subclasses.

wsgi_multiprocess

The value to be used for the wsgi.multiprocess environment variable. It defaults to true in

BaseHandler, but may have a different default (or be set by the constructor) in the other subclasses.

wsgi_run_once

The value to be used for the wsgi.run_once environment variable. It defaults to false in BaseHandler,

but CGIHandler sets it to true by default.

os_environ

The default environment variables to be included in every request’s WSGI environment. By default, this

is a copy of os.environ at the time that wsgiref.handlers was imported, but subclasses can either create their own at the class or instance level. Note that the dictionary should be considered read-only, since the default value is shared between multiple classes and instances.

The Python Library Reference, Release 3.13.2



server_software

If the origin_server attribute is set, this attribute’s value is used to set the default SERVER_SOFTWARE WSGI environment variable, and also to set a default Server: header in HTTP responses. It is ignored

for handlers (such as BaseCGIHandler and CGIHandler) that are not HTTP origin servers.

Changed in version 3.3: The term “Python” is replaced with implementation specific term like “CPython”, “Jython” etc.

get_scheme()

Return the URL scheme being used for the current request. The default implementation uses the

guess_scheme() function from wsgiref.util to guess whether the scheme should be “http” or “https”, based on the current request’s environ variables.

setup_environ()

Set the environ attribute to a fully populated WSGI environment. The default implementation uses all

of the above methods and attributes, plus the get_stdin(), get_stderr(), and add_cgi_vars()

methods and the wsgi_file_wrapper attribute. It also inserts a SERVER_SOFTWARE key if not present,

as long as the origin_server attribute is a true value and the server_software attribute is set.

Methods and attributes for customizing exception handling:

log_exception(exc_info)

Log the exc_info tuple in the server log. exc_info is a (type, value, traceback) tuple. The de-fault implementation simply writes the traceback to the request’s wsgi.errors stream and flushes it. Subclasses can override this method to change the format or retarget the output, mail the traceback to an administrator, or whatever other action may be deemed suitable.

traceback_limit

The maximum number of frames to include in tracebacks output by the default log_exception() method. If None, all frames are included.

error_output(environ, start_response)

This method is a WSGI application to generate an error page for the user. It is only invoked if an error occurs before headers are sent to the client.

This method can access the current error using sys.exception(), and should pass that information to

start_response when calling it (as described in the “Error Handling” section of PEP 3333).

The default implementation just uses the error_status, error_headers, and error_body at-tributes to generate an output page. Subclasses can override this to produce more dynamic error output.

Note, however, that it’s not recommended from a security perspective to spit out diagnostics to any old user; ideally, you should have to do something special to enable diagnostic output, which is why the default implementation doesn’t include any.

error_status

The HTTP status used for error responses. This should be a status string as defined in PEP 3333; it defaults to a 500 code and message.

error_headers

The HTTP headers used for error responses. This should be a list of WSGI response headers ((name,

value) tuples), as described in PEP 3333. The default list just sets the content type to text/plain.

error_body

The error response body. This should be an HTTP response body bytestring. It defaults to the plain text, “A server error occurred. Please contact the administrator.”

Methods and attributes for PEP 3333’s “Optional Platform-Specific File Handling” feature:

wsgi_file_wrapper

A wsgi.file_wrapper factory, compatible with wsgiref.types.FileWrapper, or None. The

default value of this attribute is the wsgiref.util.FileWrapper class.

The Python Library Reference, Release 3.13.2



sendfile()

Override to implement platform-specific file transmission. This method is called only if the application’s

return value is an instance of the class specified by the wsgi_file_wrapper attribute. It should return a true value if it was able to successfully transmit the file, so that the default transmission code will not be executed. The default implementation of this method just returns a false value.

Miscellaneous methods and attributes:

origin_server

This attribute should be set to a true value if the handler’s _write() and _flush() are being used to communicate directly to the client, rather than via a CGI-like gateway protocol that wants the HTTP status in a special Status: header.

This attribute’s default value is true in BaseHandler, but false in BaseCGIHandler and CGIHandler.

http_version

If origin_server is true, this string attribute is used to set the HTTP version of the response set to the client. It defaults to "1.0".

wsgiref.handlers.read_environ()

Transcode CGI variables from os.environ to PEP 3333 “bytes in unicode” strings, returning a new dictio-

nary. This function is used by CGIHandler and IISCGIHandler in place of directly using os.environ,

which is not necessarily WSGI-compliant on all platforms and web servers using Python 3 – specifically, ones

where the OS’s actual environment is Unicode (i.e. Windows), or ones where the environment is bytes, but

the system encoding used by Python to decode it is anything other than ISO-8859-1 (e.g. Unix systems using

UTF-8).

If you are implementing a CGI-based handler of your own, you probably want to use this routine instead of

just copying values out of os.environ directly.

Added in version 3.2.



22.2.6 wsgiref.types – WSGI types for static type checking

This module provides various types for static type checking as described in PEP 3333.

Added in version 3.11.

class wsgiref.types.StartResponse

A typing.Protocol describing start_response() callables (PEP 3333).

wsgiref.types.WSGIEnvironment

A type alias describing a WSGI environment dictionary.

wsgiref.types.WSGIApplication

A type alias describing a WSGI application callable.

class wsgiref.types.InputStream

A typing.Protocol describing a WSGI Input Stream.

class wsgiref.types.ErrorStream

A typing.Protocol describing a WSGI Error Stream.

class wsgiref.types.FileWrapper

A typing.Protocol describing a file wrapper. See wsgiref.util.FileWrapper for a concrete imple-

mentation of this protocol.



22.2.7 Examples

This is a working “Hello World” WSGI application:



The Python Library Reference, Release 3.13.2



"""

Every WSGI application must have an application object - a callable object that accepts two arguments. For that purpose, we're going to use a function (note that you're not limited to a function, you can use a class for example). The first argument passed to the function is a dictionary containing CGI-style environment variables and the second variable is the callable object.

"""

from wsgiref.simple_server import make_server



def hello_world_app(environ, start_response):

status = "200 OK" # HTTP Status

headers = [("Content-type", "text/plain; charset=utf-8")] # HTTP Headers

start_response(status, headers)

# The returned object is going to be printed

return [b"Hello World"]

with make_server("", 8000, hello_world_app) as httpd:

print("Serving on port 8000...")

# Serve until process is killed

httpd.serve_forever()



Example of a WSGI application serving the current directory, accept optional directory and port number (default: 8000) on the command line:

"""

Small wsgiref based web server. Takes a path to serve from and an optional port number (defaults to 8000), then tries to serve files. MIME types are guessed from the file names, 404 errors are raised if the file is not found.

"""

import mimetypes

import os

import sys

from wsgiref import simple_server, util



def app(environ, respond):

# Get the file name and MIME type

fn = os.path.join(path, environ["PATH_INFO"][1:])

if "." not in fn.split(os.path.sep)[-1]:

fn = os.path.join(fn, "index.html")

mime_type = mimetypes.guess_file_type(fn)[0]

# Return 200 OK if file exists, otherwise 404 Not Found

if os.path.exists(fn):

respond("200 OK", [("Content-Type", mime_type)])

return util.FileWrapper(open(fn, "rb"))

else:

respond("404 Not Found", [("Content-Type", "text/plain")]) return [b"not found"]



if __name__ == "__main__":

(continues on next page)

The Python Library Reference, Release 3.13.2



(continued from previous page)

# Get the path and port from command-line arguments

path = sys.argv[1] if len(sys.argv) > 1 else os.getcwd()

port = int(sys.argv[2]) if len(sys.argv) > 2 else 8000

# Make and start the server until control-c

httpd = simple_server.make_server("", port, app)

print(f"Serving {path} on port {port}, control-C to stop")

try:

httpd.serve_forever()

except KeyboardInterrupt:

print("Shutting down.")

httpd.server_close()



22.3 urllib — URL handling modules

Source code: Lib/urllib/



urllib is a package that collects several modules for working with URLs:

• urllib.request for opening and reading URLs

• urllib.error containing the exceptions raised by urllib.request

• urllib.parse for parsing URLs

• urllib.robotparser for parsing robots.txt files



22.4 urllib.request — Extensible library for opening URLs

Source code: Lib/urllib/request.py



The urllib.request module defines functions and classes which help in opening URLs (mostly HTTP) in a complex world — basic and digest authentication, redirections, cookies and more.



µ See also

The Requests package is recommended for a higher-level HTTP client interface.



Á Warning

On macOS it is unsafe to use this module in programs using os.fork() because the getproxies() imple-

mentation for macOS uses a higher-level system API. Set the environment variable no_proxy to * to avoid this

problem (e.g. os.environ["no_proxy"] = "*").



Availability: not WASI.

This module does not work or is not available on WebAssembly. See WebAssembly platforms for more information.

The urllib.request module defines the following functions:



The Python Library Reference, Release 3.13.2



urllib.request.urlopen(url, data=None, [timeout, ]*, context=None)

Open url, which can be either a string containing a valid, properly encoded URL, or a Request object.

data must be an object specifying additional data to be sent to the server, or None if no such data is needed.

See Request for details.

urllib.request module uses HTTP/1.1 and includes Connection:close header in its HTTP requests.

The optional timeout parameter specifies a timeout in seconds for blocking operations like the connection

attempt (if not specified, the global default timeout setting will be used). This actually only works for HTTP,

HTTPS and FTP connections.

If context is specified, it must be a ssl.SSLContext instance describing the various SSL options. See

HTTPSConnection for more details.

This function always returns an object which can work as a context manager and has the properties url, headers,

and status. See urllib.response.addinfourl for more detail on these properties.

For HTTP and HTTPS URLs, this function returns a http.client.HTTPResponse object slightly modified.

In addition to the three new methods above, the msg attribute contains the same information as the reason

attribute — the reason phrase returned by server — instead of the response headers as it is specified in the

documentation for HTTPResponse.

For FTP, file, and data URLs and requests explicitly handled by legacy URLopener and FancyURLopener

classes, this function returns a urllib.response.addinfourl object.

Raises URLError on protocol errors.

Note that None may be returned if no handler handles the request (though the default installed global

OpenerDirector uses UnknownHandler to ensure this never happens).

In addition, if proxy settings are detected (for example, when a *_proxy environment variable like

http_proxy is set), ProxyHandler is default installed and makes sure the requests are handled through

the proxy.

The legacy urllib.urlopen function from Python 2.6 and earlier has been discontinued; urllib.

request.urlopen() corresponds to the old urllib2.urlopen. Proxy handling, which was done by pass-

ing a dictionary parameter to urllib.urlopen, can be obtained by using ProxyHandler objects.



The default opener raises an auditing event urllib.Request with arguments fullurl, data, headers,

method taken from the request object.

Changed in version 3.2: cafile and capath were added.

HTTPS virtual hosts are now supported if possible (that is, if ssl.HAS_SNI is true).

data can be an iterable object.

Changed in version 3.3: cadefault was added.

Changed in version 3.4.3: context was added.

Changed in version 3.10: HTTPS connection now send an ALPN extension with protocol indicator http/1.1

when no context is given. Custom context should set ALPN protocols with set_alpn_protocols().

Changed in version 3.13: Remove cafile, capath and cadefault parameters: use the context parameter instead.

urllib.request.install_opener(opener)

Install an OpenerDirector instance as the default global opener. Installing an opener is only necessary if you

want urlopen to use that opener; otherwise, simply call OpenerDirector.open() instead of urlopen().

The code does not check for a real OpenerDirector, and any class with the appropriate interface will work.

urllib.request.build_opener( handler [, ... ])

Return an OpenerDirector instance, which chains the handlers in the order given. handlers can be either

instances of BaseHandler, or subclasses of BaseHandler (in which case it must be possible to call the

constructor without any parameters). Instances of the following classes will be in front of the handlers, unless The Python Library Reference, Release 3.13.2



the handlers contain them, instances of them or subclasses of them: ProxyHandler (if proxy settings are

detected), UnknownHandler, HTTPHandler, HTTPDefaultErrorHandler, HTTPRedirectHandler,

FTPHandler, FileHandler, HTTPErrorProcessor.

If the Python installation has SSL support (i.e., if the ssl module can be imported), HTTPSHandler will also

be added.

A BaseHandler subclass may also change its handler_order attribute to modify its position in the handlers

list.

urllib.request.pathname2url(path)

Convert the given local path to a file: URL. This function uses quote() function to encode the path. For

historical reasons, the return value omits the file: scheme prefix. This example shows the function being

used on Windows:

>>> from urllib.request import pathname2url

>>> path = 'C:\\Program Files'

>>> 'file:' + pathname2url(path)

'file:///C:/Program%20Files'



urllib.request.url2pathname(url)

Convert the given file: URL to a local path. This function uses unquote() to decode the URL. For

historical reasons, the given value must omit the file: scheme prefix. This example shows the function being

used on Windows:

>>> from urllib.request import url2pathname

>>> url = 'file:///C:/Program%20Files'

>>> url2pathname(url.removeprefix('file:'))

'C:\\Program Files'



urllib.request.getproxies()

This helper function returns a dictionary of scheme to proxy server URL mappings. It scans the environment for

variables named _proxy, in a case insensitive approach, for all operating systems first, and when

it cannot find it, looks for proxy information from System Configuration for macOS and Windows Systems

Registry for Windows. If both lowercase and uppercase environment variables exist (and disagree), lowercase

is preferred.



® Note

If the environment variable REQUEST_METHOD is set, which usually indicates your script is running in a CGI environment, the environment variable HTTP_PROXY (uppercase _PROXY) will be ignored. This is because that variable can be injected by a client using the “Proxy:” HTTP header. If you need to use an HTTP proxy in a CGI environment, either use ProxyHandler explicitly, or make sure the variable name is in lowercase (or at least the _proxy suffix).



The following classes are provided:

class urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False,

method=None)

This class is an abstraction of a URL request.

url should be a string containing a valid, properly encoded URL.

data must be an object specifying additional data to send to the server, or None if no such data is needed.

Currently HTTP requests are the only ones that use data. The supported object types include bytes, file-like

objects, and iterables of bytes-like objects. If no Content-Length nor Transfer-Encoding header field

has been provided, HTTPHandler will set these headers according to the type of data. Content-Length will

be used to send bytes objects, while Transfer-Encoding: chunked as specified in RFC 7230, Section

3.3.1 will be used to send files and other iterables.

The Python Library Reference, Release 3.13.2



For an HTTP POST request method, data should be a buffer in the standard application/

x-www-form-urlencoded format. The urllib.parse.urlencode() function takes a mapping or se-

quence of 2-tuples and returns an ASCII string in this format. It should be encoded to bytes before being used

as the data parameter.

headers should be a dictionary, and will be treated as if add_header() was called with each key and value

as arguments. This is often used to “spoof” the User-Agent header value, which is used by a browser to

identify itself – some HTTP servers only allow requests coming from common browsers as opposed to scripts.

For example, Mozilla Firefox may identify itself as "Mozilla/5.0 (X11; U; Linux i686) Gecko/

20071127 Firefox/2.0.0.11", while urllib’s default user agent string is "Python-urllib/2.6" (on

Python 2.6). All header keys are sent in camel case.

An appropriate Content-Type header should be included if the data argument is present. If this header has

not been provided and data is not None, Content-Type: application/x-www-form-urlencoded will

be added as a default.

The next two arguments are only of interest for correct handling of third-party HTTP cookies:

origin_req_host should be the request-host of the origin transaction, as defined by RFC 2965. It defaults to

http.cookiejar.request_host(self) . This is the host name or IP address of the original request that

was initiated by the user. For example, if the request is for an image in an HTML document, this should be

the request-host of the request for the page containing the image.

unverifiable should indicate whether the request is unverifiable, as defined by RFC 2965. It defaults to False.

An unverifiable request is one whose URL the user did not have the option to approve. For example, if the

request is for an image in an HTML document, and the user had no option to approve the automatic fetching

of the image, this should be true.

method should be a string that indicates the HTTP request method that will be used (e.g. 'HEAD'). If provided,

its value is stored in the method attribute and is used by get_method(). The default is 'GET' if data is None

or 'POST' otherwise. Subclasses may indicate a different default method by setting the method attribute in

the class itself.



® Note

The request will not work as expected if the data object is unable to deliver its content more than once (e.g. a file or an iterable that can produce the content only once) and the request is retried for HTTP redirects or authentication. The data is sent to the HTTP server right away after the headers. There is no support for a 100-continue expectation in the library.



Changed in version 3.3: Request.method argument is added to the Request class.

Changed in version 3.4: Default Request.method may be indicated at the class level.

Changed in version 3.6: Do not raise an error if the Content-Length has not been provided and data is

neither None nor a bytes object. Fall back to use chunked transfer encoding instead.

class urllib.request.OpenerDirector

The OpenerDirector class opens URLs via BaseHandlers chained together. It manages the chaining of

handlers, and recovery from errors.

class urllib.request.BaseHandler

This is the base class for all registered handlers — and handles only the simple mechanics of registration.

class urllib.request.HTTPDefaultErrorHandler

A class which defines a default handler for HTTP error responses; all responses are turned into HTTPError

exceptions.

class urllib.request.HTTPRedirectHandler

A class to handle redirections.



The Python Library Reference, Release 3.13.2



class urllib.request.HTTPCookieProcessor(cookiejar=None)

A class to handle HTTP Cookies.

class urllib.request.ProxyHandler(proxies=None)

Cause requests to go through a proxy. If proxies is given, it must be a dictionary mapping protocol

names to URLs of proxies. The default is to read the list of proxies from the environment variables

_proxy. If no proxy environment variables are set, then in a Windows environment proxy set-

tings are obtained from the registry’s Internet Settings section, and in a macOS environment proxy information

is retrieved from the System Configuration Framework.

To disable autodetected proxy pass an empty dictionary.

The no_proxy environment variable can be used to specify hosts which shouldn’t be reached via proxy; if

set, it should be a comma-separated list of hostname suffixes, optionally with :port appended, for example

cern.ch,ncsa.uiuc.edu,some.host:8080.



® Note

HTTP_PROXY will be ignored if a variable REQUEST_METHOD is set; see the documentation on

getproxies() .



class urllib.request.HTTPPasswordMgr

Keep a database of (realm, uri) -> (user, password) mappings.

class urllib.request.HTTPPasswordMgrWithDefaultRealm

Keep a database of (realm, uri) -> (user, password) mappings. A realm of None is considered a

catch-all realm, which is searched if no other realm fits.

class urllib.request.HTTPPasswordMgrWithPriorAuth

A variant of HTTPPasswordMgrWithDefaultRealm that also has a database of uri ->

is_authenticated mappings. Can be used by a BasicAuth handler to determine when to send au-

thentication credentials immediately instead of waiting for a 401 response first.

Added in version 3.5.

class urllib.request.AbstractBasicAuthHandler(password_mgr=None)

This is a mixin class that helps with HTTP authentication, both to the remote host and to a proxy. pass-

word_mgr, if given, should be something that is compatible with HTTPPasswordMgr; refer to section HTTP-

PasswordMgr Objects for information on the interface that must be supported. If passwd_mgr also provides

is_authenticated and update_authenticated methods (see HTTPPasswordMgrWithPriorAuth Ob-

jects), then the handler will use the is_authenticated result for a given URI to determine whether or not to

send authentication credentials with the request. If is_authenticated returns True for the URI, credentials

are sent. If is_authenticated is False, credentials are not sent, and then if a 401 response is received the

request is re-sent with the authentication credentials. If authentication succeeds, update_authenticated

is called to set is_authenticated True for the URI, so that subsequent requests to the URI or any of its

super-URIs will automatically include the authentication credentials.

Added in version 3.5: Added is_authenticated support.

class urllib.request.HTTPBasicAuthHandler(password_mgr=None)

Handle authentication with the remote host. password_mgr, if given, should be something that is compatible

with HTTPPasswordMgr; refer to section HTTPPasswordMgr Objects for information on the interface that

must be supported. HTTPBasicAuthHandler will raise a ValueError when presented with a wrong Authen-

tication scheme.

class urllib.request.ProxyBasicAuthHandler(password_mgr=None)

Handle authentication with the proxy. password_mgr, if given, should be something that is compatible with

HTTPPasswordMgr ; refer to section HTTPPasswordMgr Objects for information on the interface that must be

supported.

The Python Library Reference, Release 3.13.2



class urllib.request.AbstractDigestAuthHandler(password_mgr=None)

This is a mixin class that helps with HTTP authentication, both to the remote host and to a proxy. pass-

word_mgr, if given, should be something that is compatible with HTTPPasswordMgr; refer to section HTTP-

PasswordMgr Objects for information on the interface that must be supported.

class urllib.request.HTTPDigestAuthHandler(password_mgr=None)

Handle authentication with the remote host. password_mgr, if given, should be something that is compatible

with HTTPPasswordMgr; refer to section HTTPPasswordMgr Objects for information on the interface that

must be supported. When both Digest Authentication Handler and Basic Authentication Handler are both

added, Digest Authentication is always tried first. If the Digest Authentication returns a 40x response again,

it is sent to Basic Authentication handler to Handle. This Handler method will raise a ValueError when

presented with an authentication scheme other than Digest or Basic.

Changed in version 3.3: Raise ValueError on unsupported Authentication Scheme.

class urllib.request.ProxyDigestAuthHandler(password_mgr=None)

Handle authentication with the proxy. password_mgr, if given, should be something that is compatible with

HTTPPasswordMgr ; refer to section HTTPPasswordMgr Objects for information on the interface that must be

supported.

class urllib.request.HTTPHandler

A class to handle opening of HTTP URLs.

class urllib.request.HTTPSHandler(debuglevel=0, context=None, check_hostname=None)

A class to handle opening of HTTPS URLs. context and check_hostname have the same meaning as in http.

client.HTTPSConnection.

Changed in version 3.2: context and check_hostname were added.

class urllib.request.FileHandler

Open local files.

class urllib.request.DataHandler

Open data URLs.

Added in version 3.4.

class urllib.request.FTPHandler

Open FTP URLs.

class urllib.request.CacheFTPHandler

Open FTP URLs, keeping a cache of open FTP connections to minimize delays.

class urllib.request.UnknownHandler

A catch-all class to handle unknown URLs.

class urllib.request.HTTPErrorProcessor

Process HTTP error responses.



22.4.1 Request Objects

The following methods describe Request’s public interface, and so all may be overridden in subclasses. It also defines several public attributes that can be used by clients to inspect the parsed request.

Request.full_url

The original URL passed to the constructor.

Changed in version 3.4.

Request.full_url is a property with setter, getter and a deleter. Getting full_url returns the original request

URL with the fragment, if it was present.



The Python Library Reference, Release 3.13.2



Request.type

The URI scheme.

Request.host

The URI authority, typically a host, but may also contain a port separated by a colon.

Request.origin_req_host

The original host for the request, without port.

Request.selector

The URI path. If the Request uses a proxy, then selector will be the full URL that is passed to the proxy.

Request.data

The entity body for the request, or None if not specified.

Changed in version 3.4: Changing value of Request.data now deletes “Content-Length” header if it was

previously set or calculated.

Request.unverifiable

boolean, indicates whether the request is unverifiable as defined by RFC 2965.

Request.method

The HTTP request method to use. By default its value is None, which means that get_method() will do its

normal computation of the method to be used. Its value can be set (thus overriding the default computation in

get_method()) either by providing a default value by setting it at the class level in a Request subclass, or

by passing a value in to the Request constructor via the method argument.

Added in version 3.3.

Changed in version 3.4: A default value can now be set in subclasses; previously it could only be set via the

constructor argument.

Request.get_method()

Return a string indicating the HTTP request method. If Request.method is not None, return its value,

otherwise return 'GET' if Request.data is None, or 'POST' if it’s not. This is only meaningful for HTTP

requests.

Changed in version 3.3: get_method now looks at the value of Request.method.

Request.add_header(key, val)

Add another header to the request. Headers are currently ignored by all handlers except HTTP handlers, where

they are added to the list of headers sent to the server. Note that there cannot be more than one header with

the same name, and later calls will overwrite previous calls in case the key collides. Currently, this is no loss of

HTTP functionality, since all headers which have meaning when used more than once have a (header-specific)

way of gaining the same functionality using only one header. Note that headers added using this method are

also added to redirected requests.

Request.add_unredirected_header(key, header)

Add a header that will not be added to a redirected request.

Request.has_header(header)

Return whether the instance has the named header (checks both regular and unredirected).

Request.remove_header( header)

Remove named header from the request instance (both from regular and unredirected headers).

Added in version 3.4.

Request.get_full_url()

Return the URL given in the constructor.

Changed in version 3.4.

Returns Request.full_url

The Python Library Reference, Release 3.13.2



Request.set_proxy(host, type)

Prepare the request by connecting to a proxy server. The host and type will replace those of the instance, and

the instance’s selector will be the original URL given in the constructor.

Request.get_header(header_name, default=None)

Return the value of the given header. If the header is not present, return the default value.

Request.header_items()

Return a list of tuples (header_name, header_value) of the Request headers.

Changed in version 3.4: The request methods add_data, has_data, get_data, get_type, get_host, get_selector, get_origin_req_host and is_unverifiable that were deprecated since 3.3 have been removed.



22.4.2 OpenerDirector Objects

OpenerDirector instances have the following methods:

OpenerDirector.add_handler(handler)

handler should be an instance of BaseHandler. The following methods are searched, and added to the

possible chains (note that HTTP errors are a special case). Note that, in the following, protocol should be

replaced with the actual protocol to handle, for example http_response() would be the HTTP protocol

response handler. Also type should be replaced with the actual HTTP code, for example http_error_404()

would handle HTTP 404 errors.

• _open() — signal that the handler knows how to open protocol URLs.

See BaseHandler.<protocol>_open() for more information.

• http_error_() — signal that the handler knows how to handle HTTP errors with HTTP error

code type.

See BaseHandler.http_error_<nnn>() for more information.

• _error() — signal that the handler knows how to handle errors from (non-http) protocol.

• _request() — signal that the handler knows how to pre-process protocol requests.

See BaseHandler.<protocol>_request() for more information.

• _response() — signal that the handler knows how to post-process protocol responses.

See BaseHandler.<protocol>_response() for more information.

OpenerDirector.open(url, data=None[, timeout ])

Open the given url (which can be a request object or a string), optionally passing the given data. Arguments,

return values and exceptions raised are the same as those of urlopen() (which simply calls the open()

method on the currently installed global OpenerDirector). The optional timeout parameter specifies a time-

out in seconds for blocking operations like the connection attempt (if not specified, the global default timeout

setting will be used). The timeout feature actually works only for HTTP, HTTPS and FTP connections.

OpenerDirector.error(proto, *args)

Handle an error of the given protocol. This will call the registered error handlers for the given protocol with

the given arguments (which are protocol specific). The HTTP protocol is a special case which uses the HTTP

response code to determine the specific error handler; refer to the http_error_() methods of the

handler classes.

Return values and exceptions raised are the same as those of urlopen().

OpenerDirector objects open URLs in three stages:

The order in which these methods are called within each stage is determined by sorting the handler instances.

1. Every handler with a method named like _request() has that method called to pre-process the

request.



The Python Library Reference, Release 3.13.2



2. Handlers with a method named like _open() are called to handle the request. This stage ends

when a handler either returns a non-None value (ie. a response), or raises an exception (usually URLError).

Exceptions are allowed to propagate.

In fact, the above algorithm is first tried for methods named default_open(). If all such methods return

None , the algorithm is repeated for methods named like _open(). If all such methods return

None , the algorithm is repeated for methods named unknown_open().

Note that the implementation of these methods may involve calls of the parent OpenerDirector instance’s

open() and error() methods.

3. Every handler with a method named like _response() has that method called to post-process

the response.



22.4.3 BaseHandler Objects

BaseHandler objects provide a couple of methods that are directly useful, and others that are meant to be used by derived classes. These are intended for direct use:

BaseHandler.add_parent(director)

Add a director as parent.

BaseHandler.close()

Remove any parents.

The following attribute and methods should only be used by classes derived from BaseHandler.



® Note

The convention has been adopted that subclasses defining _request() or

_response() methods are named *Processor; all others are named *Handler.



BaseHandler.parent

A valid OpenerDirector, which can be used to open using a different protocol, or handle errors.

BaseHandler.default_open(req)

This method is not defined in BaseHandler, but subclasses should define it if they want to catch all URLs.

This method, if implemented, will be called by the parent OpenerDirector. It should return a file-like

object as described in the return value of the open() method of OpenerDirector, or None. It should raise

URLError, unless a truly exceptional thing happens (for example, MemoryError should not be mapped to

URLError).

This method will be called before any protocol-specific open method.

BaseHandler.<protocol>_open(req)

This method is not defined in BaseHandler, but subclasses should define it if they want to handle URLs with

the given protocol.

This method, if defined, will be called by the parent OpenerDirector. Return values should be the same as

for default_open().

BaseHandler.unknown_open(req)

This method is not defined in BaseHandler, but subclasses should define it if they want to catch all URLs

with no specific registered handler to open it.

This method, if implemented, will be called by the parent OpenerDirector. Return values should be the

same as for default_open().

BaseHandler.http_error_default(req, fp, code, msg, hdrs)

This method is not defined in BaseHandler, but subclasses should override it if they intend to provide a catch-

all for otherwise unhandled HTTP errors. It will be called automatically by the OpenerDirector getting the

error, and should not normally be called in other circumstances.

The Python Library Reference, Release 3.13.2



req will be a Request object, fp will be a file-like object with the HTTP error body, code will be the three-digit

code of the error, msg will be the user-visible explanation of the code and hdrs will be a mapping object with

the headers of the error.

Return values and exceptions raised should be the same as those of urlopen().

BaseHandler.http_error_<nnn>(req, fp, code, msg, hdrs)

nnn should be a three-digit HTTP error code. This method is also not defined in BaseHandler, but will be

called, if it exists, on an instance of a subclass, when an HTTP error with code nnn occurs.

Subclasses should override this method to handle specific HTTP errors.

Arguments, return values and exceptions raised should be the same as for http_error_default().

BaseHandler.<protocol>_request(req)

This method is not defined in BaseHandler, but subclasses should define it if they want to pre-process requests

of the given protocol.

This method, if defined, will be called by the parent OpenerDirector. req will be a Request object. The

return value should be a Request object.

BaseHandler.<protocol>_response(req, response)

This method is not defined in BaseHandler, but subclasses should define it if they want to post-process

responses of the given protocol.

This method, if defined, will be called by the parent OpenerDirector. req will be a Request object.

response will be an object implementing the same interface as the return value of urlopen(). The return

value should implement the same interface as the return value of urlopen().



22.4.4 HTTPRedirectHandler Objects



® Note

Some HTTP redirections require action from this module’s client code. If this is the case, HTTPError is raised.

See RFC 2616 for details of the precise meanings of the various redirection codes.

An HTTPError exception raised as a security consideration if the HTTPRedirectHandler is presented with a

redirected URL which is not an HTTP, HTTPS or FTP URL.



HTTPRedirectHandler.redirect_request(req, fp, code, msg, hdrs, newurl)

Return a Request or None in response to a redirect. This is called by the default implementations of the

http_error_30*() methods when a redirection is received from the server. If a redirection should take

place, return a new Request to allow http_error_30*() to perform the redirect to newurl. Otherwise,

raise HTTPError if no other handler should try to handle this URL, or return None if you can’t but another

handler might.



® Note

The default implementation of this method does not strictly follow RFC 2616, which says that 301 and 302 responses to POST requests must not be automatically redirected without confirmation by the user. In reality, browsers do allow automatic redirection of these responses, changing the POST to a GET, and the default implementation reproduces this behavior.



HTTPRedirectHandler.http_error_301(req, fp, code, msg, hdrs)

Redirect to the Location: or URI: URL. This method is called by the parent OpenerDirector when

getting an HTTP ‘moved permanently’ response.

HTTPRedirectHandler.http_error_302(req, fp, code, msg, hdrs)

The same as http_error_301(), but called for the ‘found’ response.

The Python Library Reference, Release 3.13.2



HTTPRedirectHandler.http_error_303(req, fp, code, msg, hdrs)

The same as http_error_301(), but called for the ‘see other’ response.

HTTPRedirectHandler.http_error_307(req, fp, code, msg, hdrs)

The same as http_error_301(), but called for the ‘temporary redirect’ response. It does not allow changing

the request method from POST to GET.

HTTPRedirectHandler.http_error_308(req, fp, code, msg, hdrs)

The same as http_error_301(), but called for the ‘permanent redirect’ response. It does not allow changing

the request method from POST to GET.

Added in version 3.11.



22.4.5 HTTPCookieProcessor Objects

HTTPCookieProcessor instances have one attribute:

HTTPCookieProcessor.cookiejar

The http.cookiejar.CookieJar in which cookies are stored.



22.4.6 ProxyHandler Objects

ProxyHandler.<protocol>_open(request)

The ProxyHandler will have a method _open() for every protocol which has a proxy in the

proxies dictionary given in the constructor. The method will modify requests to go through the proxy, by calling

request.set_proxy() , and call the next handler in the chain to actually execute the protocol.



22.4.7 HTTPPasswordMgr Objects

These methods are available on HTTPPasswordMgr and HTTPPasswordMgrWithDefaultRealm objects.

HTTPPasswordMgr.add_password(realm, uri, user, passwd)

uri can be either a single URI, or a sequence of URIs. realm, user and passwd must be strings. This causes

(user, passwd) to be used as authentication tokens when authentication for realm and a super-URI of any

of the given URIs is given.

HTTPPasswordMgr.find_user_password(realm, authuri)

Get user/password for given realm and URI, if any. This method will return (None, None) if there is no

matching user/password.

For HTTPPasswordMgrWithDefaultRealm objects, the realm None will be searched if the given realm has

no matching user/password.



22.4.8 HTTPPasswordMgrWithPriorAuth Objects

This password manager extends HTTPPasswordMgrWithDefaultRealm to support tracking URIs for which au-thentication credentials should always be sent.

HTTPPasswordMgrWithPriorAuth.add_password(realm, uri, user, passwd, is_authenticated=False)

realm, uri, user, passwd are as for HTTPPasswordMgr.add_password(). is_authenticated sets the initial

value of the is_authenticated flag for the given URI or list of URIs. If is_authenticated is specified as

True , realm is ignored.

HTTPPasswordMgrWithPriorAuth.find_user_password(realm, authuri)

Same as for HTTPPasswordMgrWithDefaultRealm objects

HTTPPasswordMgrWithPriorAuth.update_authenticated(self, uri, is_authenticated=False)

Update the is_authenticated flag for the given uri or list of URIs.

HTTPPasswordMgrWithPriorAuth.is_authenticated(self, authuri)

Returns the current state of the is_authenticated flag for the given URI.

The Python Library Reference, Release 3.13.2



22.4.9 AbstractBasicAuthHandler Objects

AbstractBasicAuthHandler.http_error_auth_reqed(authreq, host, req, headers)

Handle an authentication request by getting a user/password pair, and re-trying the request. authreq should

be the name of the header where the information about the realm is included in the request, host specifies the

URL and path to authenticate for, req should be the (failed) Request object, and headers should be the error

headers.

host is either an authority (e.g. "python.org") or a URL containing an authority component (e.g. "http:/

/python.org/"). In either case, the authority must not contain a userinfo component (so, "python.org"

and "python.org:80" are fine, "joe:password@python.org" is not).



22.4.10 HTTPBasicAuthHandler Objects

HTTPBasicAuthHandler.http_error_401( req, fp, code, msg, hdrs)

Retry the request with authentication information, if available.



22.4.11 ProxyBasicAuthHandler Objects

ProxyBasicAuthHandler.http_error_407(req, fp, code, msg, hdrs)

Retry the request with authentication information, if available.



22.4.12 AbstractDigestAuthHandler Objects

AbstractDigestAuthHandler.http_error_auth_reqed(authreq, host, req, headers)

authreq should be the name of the header where the information about the realm is included in the request,

host should be the host to authenticate to, req should be the (failed) Request object, and headers should be

the error headers.



22.4.13 HTTPDigestAuthHandler Objects

HTTPDigestAuthHandler.http_error_401(req, fp, code, msg, hdrs)

Retry the request with authentication information, if available.



22.4.14 ProxyDigestAuthHandler Objects

ProxyDigestAuthHandler.http_error_407(req, fp, code, msg, hdrs)

Retry the request with authentication information, if available.



22.4.15 HTTPHandler Objects

HTTPHandler.http_open( req)

Send an HTTP request, which can be either GET or POST, depending on req.has_data().



22.4.16 HTTPSHandler Objects

HTTPSHandler.https_open(req)

Send an HTTPS request, which can be either GET or POST, depending on req.has_data().



22.4.17 FileHandler Objects

FileHandler.file_open( req)

Open the file locally, if there is no host name, or the host name is 'localhost'.

Changed in version 3.2: This method is applicable only for local hostnames. When a remote hostname is given,

a URLError is raised.

The Python Library Reference, Release 3.13.2



22.4.18 DataHandler Objects

DataHandler.data_open( req)

Read a data URL. This kind of URL contains the content encoded in the URL itself. The data URL syntax is

specified in RFC 2397. This implementation ignores white spaces in base64 encoded data URLs so the URL

may be wrapped in whatever source file it comes from. But even though some browsers don’t mind about a

missing padding at the end of a base64 encoded data URL, this implementation will raise a ValueError in

that case.



22.4.19 FTPHandler Objects

FTPHandler.ftp_open(req)

Open the FTP file indicated by req. The login is always done with empty username and password.



22.4.20 CacheFTPHandler Objects

CacheFTPHandler objects are FTPHandler objects with the following additional methods:

CacheFTPHandler.setTimeout(t)

Set timeout of connections to t seconds.

CacheFTPHandler.setMaxConns(m)

Set maximum number of cached connections to m.



22.4.21 UnknownHandler Objects

UnknownHandler.unknown_open()

Raise a URLError exception.



22.4.22 HTTPErrorProcessor Objects

HTTPErrorProcessor.http_response(request, response)

Process HTTP error responses.

For 200 error codes, the response object is returned immediately.

For non-200 error codes, this simply passes the job on to the http_error_() handler methods, via

OpenerDirector.error(). Eventually, HTTPDefaultErrorHandler will raise an HTTPError if no

other handler handles the error.

HTTPErrorProcessor.https_response(request, response)

Process HTTPS error responses.

The behavior is same as http_response().



22.4.23 Examples

In addition to the examples below, more examples are given in urllib-howto.

This example gets the python.org main page and displays the first 300 bytes of it.

>>> import urllib.request

>>> with urllib.request.urlopen('http://www.python.org/') as f: ... print(f.read(300))

...

b'

"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">\n\n\n xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">\n\n\n \n





